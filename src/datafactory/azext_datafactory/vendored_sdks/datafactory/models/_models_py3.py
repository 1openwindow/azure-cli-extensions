# coding=utf-8
# --------------------------------------------------------------------------
# Code generated by Microsoft (R) AutoRest Code Generator (autorest: 3.0.6237, generator: {generator})
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------

import datetime
from typing import Dict, List, Optional, Union

from azure.core.exceptions import HttpResponseError
import msrest.serialization


class AccessPolicyResponse(msrest.serialization.Model):
    """Get Data Plane read only token response definition.

    :param policy: Get Data Plane read only token request definition.
    :type policy: ~data_factory_management_client.models.UserAccessPolicy
    :param access_token: Data Plane read only access token.
    :type access_token: str
    :param data_plane_url: Data Plane service base URL.
    :type data_plane_url: str
    """

    _attribute_map = {
        'policy': {'key': 'policy', 'type': 'UserAccessPolicy'},
        'access_token': {'key': 'accessToken', 'type': 'str'},
        'data_plane_url': {'key': 'dataPlaneUrl', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        policy: Optional["UserAccessPolicy"] = None,
        access_token: Optional[str] = None,
        data_plane_url: Optional[str] = None,
        **kwargs
    ):
        super(AccessPolicyResponse, self).__init__(**kwargs)
        self.policy = policy
        self.access_token = access_token
        self.data_plane_url = data_plane_url


class Activity(msrest.serialization.Model):
    """A pipeline activity.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: ControlActivity, ExecutionActivity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
    }

    _subtype_map = {
        'type': {'Container': 'ControlActivity', 'Execution': 'ExecutionActivity'}
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        **kwargs
    ):
        super(Activity, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.name = name
        self.type = 'Activity'
        self.description = description
        self.depends_on = depends_on
        self.user_properties = user_properties


class ActivityDependency(msrest.serialization.Model):
    """Activity dependency information.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param activity: Required. Activity name.
    :type activity: str
    :param dependency_conditions: Required. Match-Condition for the dependency.
    :type dependency_conditions: list[str or
     ~data_factory_management_client.models.DependencyCondition]
    """

    _validation = {
        'activity': {'required': True},
        'dependency_conditions': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'activity': {'key': 'activity', 'type': 'str'},
        'dependency_conditions': {'key': 'dependencyConditions', 'type': '[str]'},
    }

    def __init__(
        self,
        *,
        activity: str,
        dependency_conditions: List[Union[str, "DependencyCondition"]],
        additional_properties: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(ActivityDependency, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.activity = activity
        self.dependency_conditions = dependency_conditions


class ActivityPolicy(msrest.serialization.Model):
    """Execution policy for an activity.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param timeout: Specifies the timeout for the activity to run. The default timeout is 7 days.
     Type: string (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type timeout: ~data_factory_management_client.models.ActivityPolicyTimeout
    :param retry: Maximum ordinary retry attempts. Default is 0. Type: integer (or Expression with
     resultType integer), minimum: 0.
    :type retry: ~data_factory_management_client.models.ActivityPolicyRetry
    :param retry_interval_in_seconds: Interval between each retry attempt (in seconds). The default
     is 30 sec.
    :type retry_interval_in_seconds: int
    :param secure_input: When set to true, Input from activity is considered as secure and will not
     be logged to monitoring.
    :type secure_input: bool
    :param secure_output: When set to true, Output from activity is considered as secure and will
     not be logged to monitoring.
    :type secure_output: bool
    """

    _validation = {
        'retry_interval_in_seconds': {'maximum': 86400, 'minimum': 30},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'timeout': {'key': 'timeout', 'type': 'ActivityPolicyTimeout'},
        'retry': {'key': 'retry', 'type': 'ActivityPolicyRetry'},
        'retry_interval_in_seconds': {'key': 'retryIntervalInSeconds', 'type': 'int'},
        'secure_input': {'key': 'secureInput', 'type': 'bool'},
        'secure_output': {'key': 'secureOutput', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        timeout: Optional["ActivityPolicyTimeout"] = None,
        retry: Optional["ActivityPolicyRetry"] = None,
        retry_interval_in_seconds: Optional[int] = None,
        secure_input: Optional[bool] = None,
        secure_output: Optional[bool] = None,
        **kwargs
    ):
        super(ActivityPolicy, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.timeout = timeout
        self.retry = retry
        self.retry_interval_in_seconds = retry_interval_in_seconds
        self.secure_input = secure_input
        self.secure_output = secure_output


class ActivityPolicyRetry(msrest.serialization.Model):
    """Maximum ordinary retry attempts. Default is 0. Type: integer (or Expression with resultType integer), minimum: 0.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ActivityPolicyRetry, self).__init__(**kwargs)


class ActivityPolicyTimeout(msrest.serialization.Model):
    """Specifies the timeout for the activity to run. The default timeout is 7 days. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ActivityPolicyTimeout, self).__init__(**kwargs)


class ActivityRun(msrest.serialization.Model):
    """Information about an activity run in a pipeline.

    Variables are only populated by the server, and will be ignored when sending a request.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :ivar pipeline_name: The name of the pipeline.
    :vartype pipeline_name: str
    :ivar pipeline_run_id: The id of the pipeline run.
    :vartype pipeline_run_id: str
    :ivar activity_name: The name of the activity.
    :vartype activity_name: str
    :ivar activity_type: The type of the activity.
    :vartype activity_type: str
    :ivar activity_run_id: The id of the activity run.
    :vartype activity_run_id: str
    :ivar linked_service_name: The name of the compute linked service.
    :vartype linked_service_name: str
    :ivar status: The status of the activity run.
    :vartype status: str
    :ivar activity_run_start: The start time of the activity run in 'ISO 8601' format.
    :vartype activity_run_start: ~datetime.datetime
    :ivar activity_run_end: The end time of the activity run in 'ISO 8601' format.
    :vartype activity_run_end: ~datetime.datetime
    :ivar duration_in_ms: The duration of the activity run.
    :vartype duration_in_ms: int
    :ivar input: The input for the activity.
    :vartype input: ~data_factory_management_client.models.ActivityRunInput
    :ivar output: The output for the activity.
    :vartype output: ~data_factory_management_client.models.ActivityRunOutput
    :ivar error: The error if any from the activity run.
    :vartype error: ~data_factory_management_client.models.ActivityRunError
    """

    _validation = {
        'pipeline_name': {'readonly': True},
        'pipeline_run_id': {'readonly': True},
        'activity_name': {'readonly': True},
        'activity_type': {'readonly': True},
        'activity_run_id': {'readonly': True},
        'linked_service_name': {'readonly': True},
        'status': {'readonly': True},
        'activity_run_start': {'readonly': True},
        'activity_run_end': {'readonly': True},
        'duration_in_ms': {'readonly': True},
        'input': {'readonly': True},
        'output': {'readonly': True},
        'error': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'pipeline_name': {'key': 'pipelineName', 'type': 'str'},
        'pipeline_run_id': {'key': 'pipelineRunId', 'type': 'str'},
        'activity_name': {'key': 'activityName', 'type': 'str'},
        'activity_type': {'key': 'activityType', 'type': 'str'},
        'activity_run_id': {'key': 'activityRunId', 'type': 'str'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'activity_run_start': {'key': 'activityRunStart', 'type': 'iso-8601'},
        'activity_run_end': {'key': 'activityRunEnd', 'type': 'iso-8601'},
        'duration_in_ms': {'key': 'durationInMs', 'type': 'int'},
        'input': {'key': 'input', 'type': 'ActivityRunInput'},
        'output': {'key': 'output', 'type': 'ActivityRunOutput'},
        'error': {'key': 'error', 'type': 'ActivityRunError'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(ActivityRun, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.pipeline_name = None
        self.pipeline_run_id = None
        self.activity_name = None
        self.activity_type = None
        self.activity_run_id = None
        self.linked_service_name = None
        self.status = None
        self.activity_run_start = None
        self.activity_run_end = None
        self.duration_in_ms = None
        self.input = None
        self.output = None
        self.error = None


class ActivityRunError(msrest.serialization.Model):
    """The error if any from the activity run.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ActivityRunError, self).__init__(**kwargs)


class ActivityRunInput(msrest.serialization.Model):
    """The input for the activity.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ActivityRunInput, self).__init__(**kwargs)


class ActivityRunOutput(msrest.serialization.Model):
    """The output for the activity.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ActivityRunOutput, self).__init__(**kwargs)


class ActivityRunsQueryResponse(msrest.serialization.Model):
    """A list activity runs.

    All required parameters must be populated in order to send to Azure.

    :param value: Required. List of activity runs.
    :type value: list[~data_factory_management_client.models.ActivityRun]
    :param continuation_token: The continuation token for getting the next page of results, if any
     remaining results exist, null otherwise.
    :type continuation_token: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[ActivityRun]'},
        'continuation_token': {'key': 'continuationToken', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["ActivityRun"],
        continuation_token: Optional[str] = None,
        **kwargs
    ):
        super(ActivityRunsQueryResponse, self).__init__(**kwargs)
        self.value = value
        self.continuation_token = continuation_token


class AddDataFlowToDebugSessionResponse(msrest.serialization.Model):
    """Response body structure for starting data flow debug session.

    :param job_version: The ID of data flow debug job version.
    :type job_version: str
    """

    _attribute_map = {
        'job_version': {'key': 'jobVersion', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        job_version: Optional[str] = None,
        **kwargs
    ):
        super(AddDataFlowToDebugSessionResponse, self).__init__(**kwargs)
        self.job_version = job_version


class AdditionalColumns(msrest.serialization.Model):
    """Specify the column name and value of additional columns.

    :param name: Additional column name. Type: string (or Expression with resultType string).
    :type name: ~data_factory_management_client.models.AdditionalColumnsName
    :param value: Additional column value. Type: string (or Expression with resultType string).
    :type value: ~data_factory_management_client.models.AdditionalColumnsValue
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'AdditionalColumnsName'},
        'value': {'key': 'value', 'type': 'AdditionalColumnsValue'},
    }

    def __init__(
        self,
        *,
        name: Optional["AdditionalColumnsName"] = None,
        value: Optional["AdditionalColumnsValue"] = None,
        **kwargs
    ):
        super(AdditionalColumns, self).__init__(**kwargs)
        self.name = name
        self.value = value


class AdditionalColumnsName(msrest.serialization.Model):
    """Additional column name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AdditionalColumnsName, self).__init__(**kwargs)


class AdditionalColumnsValue(msrest.serialization.Model):
    """Additional column value. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AdditionalColumnsValue, self).__init__(**kwargs)


class LinkedService(msrest.serialization.Model):
    """The Azure Data Factory nested object which contains the information and credential which can be used to connect with related store or compute resource.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AmazonMWSLinkedService, AmazonRedshiftLinkedService, AmazonS3LinkedService, AzureBatchLinkedService, AzureBlobFSLinkedService, AzureBlobStorageLinkedService, AzureDataExplorerLinkedService, AzureDataLakeAnalyticsLinkedService, AzureDataLakeStoreLinkedService, AzureDatabricksLinkedService, AzureFileStorageLinkedService, AzureFunctionLinkedService, AzureKeyVaultLinkedService, AzureMLLinkedService, AzureMLServiceLinkedService, AzureMariaDBLinkedService, AzureMySqlLinkedService, AzurePostgreSqlLinkedService, AzureSearchLinkedService, AzureSqlDWLinkedService, AzureSqlDatabaseLinkedService, AzureSqlMILinkedService, AzureStorageLinkedService, AzureTableStorageLinkedService, CassandraLinkedService, CommonDataServiceForAppsLinkedService, ConcurLinkedService, CosmosDbLinkedService, CosmosDbMongoDbApiLinkedService, CouchbaseLinkedService, CustomDataSourceLinkedService, Db2LinkedService, DrillLinkedService, DynamicsLinkedService, DynamicsAXLinkedService, DynamicsCrmLinkedService, EloquaLinkedService, FileServerLinkedService, FtpServerLinkedService, GoogleAdWordsLinkedService, GoogleBigQueryLinkedService, GoogleCloudStorageLinkedService, GreenplumLinkedService, HBaseLinkedService, HDInsightLinkedService, HDInsightOnDemandLinkedService, HdfsLinkedService, HiveLinkedService, HttpLinkedService, HubspotLinkedService, ImpalaLinkedService, InformixLinkedService, JiraLinkedService, MagentoLinkedService, MariaDBLinkedService, MarketoLinkedService, MicrosoftAccessLinkedService, MongoDbLinkedService, MongoDbV2LinkedService, MySqlLinkedService, NetezzaLinkedService, ODataLinkedService, OdbcLinkedService, Office365LinkedService, OracleLinkedService, OracleServiceCloudLinkedService, PaypalLinkedService, PhoenixLinkedService, PostgreSqlLinkedService, PrestoLinkedService, QuickBooksLinkedService, ResponsysLinkedService, RestServiceLinkedService, SalesforceLinkedService, SalesforceMarketingCloudLinkedService, SalesforceServiceCloudLinkedService, SapBWLinkedService, SapCloudForCustomerLinkedService, SapEccLinkedService, SapHanaLinkedService, SapOpenHubLinkedService, SapTableLinkedService, ServiceNowLinkedService, SftpServerLinkedService, ShopifyLinkedService, SparkLinkedService, SqlServerLinkedService, SquareLinkedService, SybaseLinkedService, TeradataLinkedService, VerticaLinkedService, WebLinkedService, XeroLinkedService, ZohoLinkedService.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
    }

    _subtype_map = {
        'type': {'AmazonMWS': 'AmazonMWSLinkedService', 'AmazonRedshift': 'AmazonRedshiftLinkedService', 'AmazonS3': 'AmazonS3LinkedService', 'AzureBatch': 'AzureBatchLinkedService', 'AzureBlobFS': 'AzureBlobFSLinkedService', 'AzureBlobStorage': 'AzureBlobStorageLinkedService', 'AzureDataExplorer': 'AzureDataExplorerLinkedService', 'AzureDataLakeAnalytics': 'AzureDataLakeAnalyticsLinkedService', 'AzureDataLakeStore': 'AzureDataLakeStoreLinkedService', 'AzureDatabricks': 'AzureDatabricksLinkedService', 'AzureFileStorage': 'AzureFileStorageLinkedService', 'AzureFunction': 'AzureFunctionLinkedService', 'AzureKeyVault': 'AzureKeyVaultLinkedService', 'AzureML': 'AzureMLLinkedService', 'AzureMLService': 'AzureMLServiceLinkedService', 'AzureMariaDB': 'AzureMariaDBLinkedService', 'AzureMySql': 'AzureMySqlLinkedService', 'AzurePostgreSql': 'AzurePostgreSqlLinkedService', 'AzureSearch': 'AzureSearchLinkedService', 'AzureSqlDW': 'AzureSqlDWLinkedService', 'AzureSqlDatabase': 'AzureSqlDatabaseLinkedService', 'AzureSqlMI': 'AzureSqlMILinkedService', 'AzureStorage': 'AzureStorageLinkedService', 'AzureTableStorage': 'AzureTableStorageLinkedService', 'Cassandra': 'CassandraLinkedService', 'CommonDataServiceForApps': 'CommonDataServiceForAppsLinkedService', 'Concur': 'ConcurLinkedService', 'CosmosDb': 'CosmosDbLinkedService', 'CosmosDbMongoDbApi': 'CosmosDbMongoDbApiLinkedService', 'Couchbase': 'CouchbaseLinkedService', 'CustomDataSource': 'CustomDataSourceLinkedService', 'Db2': 'Db2LinkedService', 'Drill': 'DrillLinkedService', 'Dynamics': 'DynamicsLinkedService', 'DynamicsAX': 'DynamicsAXLinkedService', 'DynamicsCrm': 'DynamicsCrmLinkedService', 'Eloqua': 'EloquaLinkedService', 'FileServer': 'FileServerLinkedService', 'FtpServer': 'FtpServerLinkedService', 'GoogleAdWords': 'GoogleAdWordsLinkedService', 'GoogleBigQuery': 'GoogleBigQueryLinkedService', 'GoogleCloudStorage': 'GoogleCloudStorageLinkedService', 'Greenplum': 'GreenplumLinkedService', 'HBase': 'HBaseLinkedService', 'HDInsight': 'HDInsightLinkedService', 'HDInsightOnDemand': 'HDInsightOnDemandLinkedService', 'Hdfs': 'HdfsLinkedService', 'Hive': 'HiveLinkedService', 'HttpServer': 'HttpLinkedService', 'Hubspot': 'HubspotLinkedService', 'Impala': 'ImpalaLinkedService', 'Informix': 'InformixLinkedService', 'Jira': 'JiraLinkedService', 'Magento': 'MagentoLinkedService', 'MariaDB': 'MariaDBLinkedService', 'Marketo': 'MarketoLinkedService', 'MicrosoftAccess': 'MicrosoftAccessLinkedService', 'MongoDb': 'MongoDbLinkedService', 'MongoDbV2': 'MongoDbV2LinkedService', 'MySql': 'MySqlLinkedService', 'Netezza': 'NetezzaLinkedService', 'OData': 'ODataLinkedService', 'Odbc': 'OdbcLinkedService', 'Office365': 'Office365LinkedService', 'Oracle': 'OracleLinkedService', 'OracleServiceCloud': 'OracleServiceCloudLinkedService', 'Paypal': 'PaypalLinkedService', 'Phoenix': 'PhoenixLinkedService', 'PostgreSql': 'PostgreSqlLinkedService', 'Presto': 'PrestoLinkedService', 'QuickBooks': 'QuickBooksLinkedService', 'Responsys': 'ResponsysLinkedService', 'RestService': 'RestServiceLinkedService', 'Salesforce': 'SalesforceLinkedService', 'SalesforceMarketingCloud': 'SalesforceMarketingCloudLinkedService', 'SalesforceServiceCloud': 'SalesforceServiceCloudLinkedService', 'SapBW': 'SapBWLinkedService', 'SapCloudForCustomer': 'SapCloudForCustomerLinkedService', 'SapEcc': 'SapEccLinkedService', 'SapHana': 'SapHanaLinkedService', 'SapOpenHub': 'SapOpenHubLinkedService', 'SapTable': 'SapTableLinkedService', 'ServiceNow': 'ServiceNowLinkedService', 'Sftp': 'SftpServerLinkedService', 'Shopify': 'ShopifyLinkedService', 'Spark': 'SparkLinkedService', 'SqlServer': 'SqlServerLinkedService', 'Square': 'SquareLinkedService', 'Sybase': 'SybaseLinkedService', 'Teradata': 'TeradataLinkedService', 'Vertica': 'VerticaLinkedService', 'Web': 'WebLinkedService', 'Xero': 'XeroLinkedService', 'Zoho': 'ZohoLinkedService'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        **kwargs
    ):
        super(LinkedService, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'LinkedService'
        self.connect_via = connect_via
        self.description = description
        self.parameters = parameters
        self.annotations = annotations


class AmazonMWSLinkedService(LinkedService):
    """Amazon Marketplace Web Service linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param endpoint: Required. The endpoint of the Amazon MWS server, (i.e.
     mws.amazonservices.com).
    :type endpoint:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesEndpoint
    :param marketplace_id: Required. The Amazon Marketplace ID you want to retrieve data from. To
     retrieve data from multiple Marketplace IDs, separate them with a comma (,). (i.e.
     A2EUQ1WTGCTBG2).
    :type marketplace_id:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesMarketplaceID
    :param seller_id: Required. The Amazon seller ID.
    :type seller_id:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesSellerID
    :param mws_auth_token: The base definition of a secret type.
    :type mws_auth_token: ~data_factory_management_client.models.SecretBase
    :param access_key_id: Required. The access key id used to access data.
    :type access_key_id:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesAccessKeyId
    :param secret_key: The base definition of a secret type.
    :type secret_key: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'endpoint': {'required': True},
        'marketplace_id': {'required': True},
        'seller_id': {'required': True},
        'access_key_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'AmazonMWSLinkedServiceTypePropertiesEndpoint'},
        'marketplace_id': {'key': 'typeProperties.marketplaceID', 'type': 'AmazonMWSLinkedServiceTypePropertiesMarketplaceID'},
        'seller_id': {'key': 'typeProperties.sellerID', 'type': 'AmazonMWSLinkedServiceTypePropertiesSellerID'},
        'mws_auth_token': {'key': 'typeProperties.mwsAuthToken', 'type': 'SecretBase'},
        'access_key_id': {'key': 'typeProperties.accessKeyId', 'type': 'AmazonMWSLinkedServiceTypePropertiesAccessKeyId'},
        'secret_key': {'key': 'typeProperties.secretKey', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'AmazonMWSLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'AmazonMWSLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'AmazonMWSLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AmazonMWSLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        endpoint: "AmazonMWSLinkedServiceTypePropertiesEndpoint",
        marketplace_id: "AmazonMWSLinkedServiceTypePropertiesMarketplaceID",
        seller_id: "AmazonMWSLinkedServiceTypePropertiesSellerID",
        access_key_id: "AmazonMWSLinkedServiceTypePropertiesAccessKeyId",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        mws_auth_token: Optional["SecretBase"] = None,
        secret_key: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["AmazonMWSLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["AmazonMWSLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["AmazonMWSLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["AmazonMWSLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AmazonMWSLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AmazonMWS'
        self.endpoint = endpoint
        self.marketplace_id = marketplace_id
        self.seller_id = seller_id
        self.mws_auth_token = mws_auth_token
        self.access_key_id = access_key_id
        self.secret_key = secret_key
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class AmazonMWSLinkedServiceTypeProperties(msrest.serialization.Model):
    """Amazon Marketplace Web Service linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param endpoint: Required. The endpoint of the Amazon MWS server, (i.e.
     mws.amazonservices.com).
    :type endpoint:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesEndpoint
    :param marketplace_id: Required. The Amazon Marketplace ID you want to retrieve data from. To
     retrieve data from multiple Marketplace IDs, separate them with a comma (,). (i.e.
     A2EUQ1WTGCTBG2).
    :type marketplace_id:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesMarketplaceID
    :param seller_id: Required. The Amazon seller ID.
    :type seller_id:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesSellerID
    :param mws_auth_token: The base definition of a secret type.
    :type mws_auth_token: ~data_factory_management_client.models.SecretBase
    :param access_key_id: Required. The access key id used to access data.
    :type access_key_id:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesAccessKeyId
    :param secret_key: The base definition of a secret type.
    :type secret_key: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AmazonMWSLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'endpoint': {'required': True},
        'marketplace_id': {'required': True},
        'seller_id': {'required': True},
        'access_key_id': {'required': True},
    }

    _attribute_map = {
        'endpoint': {'key': 'endpoint', 'type': 'AmazonMWSLinkedServiceTypePropertiesEndpoint'},
        'marketplace_id': {'key': 'marketplaceID', 'type': 'AmazonMWSLinkedServiceTypePropertiesMarketplaceID'},
        'seller_id': {'key': 'sellerID', 'type': 'AmazonMWSLinkedServiceTypePropertiesSellerID'},
        'mws_auth_token': {'key': 'mwsAuthToken', 'type': 'SecretBase'},
        'access_key_id': {'key': 'accessKeyId', 'type': 'AmazonMWSLinkedServiceTypePropertiesAccessKeyId'},
        'secret_key': {'key': 'secretKey', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'AmazonMWSLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'AmazonMWSLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'AmazonMWSLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AmazonMWSLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        endpoint: "AmazonMWSLinkedServiceTypePropertiesEndpoint",
        marketplace_id: "AmazonMWSLinkedServiceTypePropertiesMarketplaceID",
        seller_id: "AmazonMWSLinkedServiceTypePropertiesSellerID",
        access_key_id: "AmazonMWSLinkedServiceTypePropertiesAccessKeyId",
        mws_auth_token: Optional["SecretBase"] = None,
        secret_key: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["AmazonMWSLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["AmazonMWSLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["AmazonMWSLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["AmazonMWSLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AmazonMWSLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.endpoint = endpoint
        self.marketplace_id = marketplace_id
        self.seller_id = seller_id
        self.mws_auth_token = mws_auth_token
        self.access_key_id = access_key_id
        self.secret_key = secret_key
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class AmazonMWSLinkedServiceTypePropertiesAccessKeyId(msrest.serialization.Model):
    """The access key id used to access data.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonMWSLinkedServiceTypePropertiesAccessKeyId, self).__init__(**kwargs)


class AmazonMWSLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonMWSLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AmazonMWSLinkedServiceTypePropertiesEndpoint(msrest.serialization.Model):
    """The endpoint of the Amazon MWS server, (i.e. mws.amazonservices.com).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonMWSLinkedServiceTypePropertiesEndpoint, self).__init__(**kwargs)


class AmazonMWSLinkedServiceTypePropertiesMarketplaceID(msrest.serialization.Model):
    """The Amazon Marketplace ID you want to retrieve data from. To retrieve data from multiple Marketplace IDs, separate them with a comma (,). (i.e. A2EUQ1WTGCTBG2).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonMWSLinkedServiceTypePropertiesMarketplaceID, self).__init__(**kwargs)


class AmazonMWSLinkedServiceTypePropertiesSellerID(msrest.serialization.Model):
    """The Amazon seller ID.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonMWSLinkedServiceTypePropertiesSellerID, self).__init__(**kwargs)


class AmazonMWSLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonMWSLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class AmazonMWSLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonMWSLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class AmazonMWSLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonMWSLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class Dataset(msrest.serialization.Model):
    """The Azure Data Factory nested object which identifies data within different data stores, such as tables, files, folders, and documents.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AmazonMWSObjectDataset, AmazonRedshiftTableDataset, AmazonS3Dataset, AvroDataset, AzureBlobDataset, AzureBlobFSDataset, AzureDataExplorerTableDataset, AzureDataLakeStoreDataset, AzureMariaDBTableDataset, AzureMySqlTableDataset, AzurePostgreSqlTableDataset, AzureSearchIndexDataset, AzureSqlDWTableDataset, AzureSqlMITableDataset, AzureSqlTableDataset, AzureTableDataset, BinaryDataset, CassandraTableDataset, CommonDataServiceForAppsEntityDataset, ConcurObjectDataset, CosmosDbMongoDbApiCollectionDataset, CosmosDbSqlApiCollectionDataset, CouchbaseTableDataset, CustomDataset, Db2TableDataset, DelimitedTextDataset, DocumentDbCollectionDataset, DrillTableDataset, DynamicsAXResourceDataset, DynamicsCrmEntityDataset, DynamicsEntityDataset, EloquaObjectDataset, FileShareDataset, GoogleAdWordsObjectDataset, GoogleBigQueryObjectDataset, GreenplumTableDataset, HBaseObjectDataset, HiveObjectDataset, HttpDataset, HubspotObjectDataset, ImpalaObjectDataset, InformixTableDataset, JiraObjectDataset, JsonDataset, MagentoObjectDataset, MariaDBTableDataset, MarketoObjectDataset, MicrosoftAccessTableDataset, MongoDbCollectionDataset, MongoDbV2CollectionDataset, MySqlTableDataset, NetezzaTableDataset, ODataResourceDataset, OdbcTableDataset, Office365Dataset, OracleServiceCloudObjectDataset, OracleTableDataset, OrcDataset, ParquetDataset, PaypalObjectDataset, PhoenixObjectDataset, PostgreSqlTableDataset, PrestoObjectDataset, QuickBooksObjectDataset, RelationalTableDataset, ResponsysObjectDataset, RestResourceDataset, SalesforceMarketingCloudObjectDataset, SalesforceObjectDataset, SalesforceServiceCloudObjectDataset, SapBwCubeDataset, SapCloudForCustomerResourceDataset, SapEccResourceDataset, SapHanaTableDataset, SapOpenHubTableDataset, SapTableResourceDataset, ServiceNowObjectDataset, ShopifyObjectDataset, SparkObjectDataset, SqlServerTableDataset, SquareObjectDataset, SybaseTableDataset, TeradataTableDataset, VerticaTableDataset, WebTableDataset, XeroObjectDataset, ZohoObjectDataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
    }

    _subtype_map = {
        'type': {'AmazonMWSObject': 'AmazonMWSObjectDataset', 'AmazonRedshiftTable': 'AmazonRedshiftTableDataset', 'AmazonS3Object': 'AmazonS3Dataset', 'Avro': 'AvroDataset', 'AzureBlob': 'AzureBlobDataset', 'AzureBlobFSFile': 'AzureBlobFSDataset', 'AzureDataExplorerTable': 'AzureDataExplorerTableDataset', 'AzureDataLakeStoreFile': 'AzureDataLakeStoreDataset', 'AzureMariaDBTable': 'AzureMariaDBTableDataset', 'AzureMySqlTable': 'AzureMySqlTableDataset', 'AzurePostgreSqlTable': 'AzurePostgreSqlTableDataset', 'AzureSearchIndex': 'AzureSearchIndexDataset', 'AzureSqlDWTable': 'AzureSqlDWTableDataset', 'AzureSqlMITable': 'AzureSqlMITableDataset', 'AzureSqlTable': 'AzureSqlTableDataset', 'AzureTable': 'AzureTableDataset', 'Binary': 'BinaryDataset', 'CassandraTable': 'CassandraTableDataset', 'CommonDataServiceForAppsEntity': 'CommonDataServiceForAppsEntityDataset', 'ConcurObject': 'ConcurObjectDataset', 'CosmosDbMongoDbApiCollection': 'CosmosDbMongoDbApiCollectionDataset', 'CosmosDbSqlApiCollection': 'CosmosDbSqlApiCollectionDataset', 'CouchbaseTable': 'CouchbaseTableDataset', 'CustomDataset': 'CustomDataset', 'Db2Table': 'Db2TableDataset', 'DelimitedText': 'DelimitedTextDataset', 'DocumentDbCollection': 'DocumentDbCollectionDataset', 'DrillTable': 'DrillTableDataset', 'DynamicsAXResource': 'DynamicsAXResourceDataset', 'DynamicsCrmEntity': 'DynamicsCrmEntityDataset', 'DynamicsEntity': 'DynamicsEntityDataset', 'EloquaObject': 'EloquaObjectDataset', 'FileShare': 'FileShareDataset', 'GoogleAdWordsObject': 'GoogleAdWordsObjectDataset', 'GoogleBigQueryObject': 'GoogleBigQueryObjectDataset', 'GreenplumTable': 'GreenplumTableDataset', 'HBaseObject': 'HBaseObjectDataset', 'HiveObject': 'HiveObjectDataset', 'HttpFile': 'HttpDataset', 'HubspotObject': 'HubspotObjectDataset', 'ImpalaObject': 'ImpalaObjectDataset', 'InformixTable': 'InformixTableDataset', 'JiraObject': 'JiraObjectDataset', 'Json': 'JsonDataset', 'MagentoObject': 'MagentoObjectDataset', 'MariaDBTable': 'MariaDBTableDataset', 'MarketoObject': 'MarketoObjectDataset', 'MicrosoftAccessTable': 'MicrosoftAccessTableDataset', 'MongoDbCollection': 'MongoDbCollectionDataset', 'MongoDbV2Collection': 'MongoDbV2CollectionDataset', 'MySqlTable': 'MySqlTableDataset', 'NetezzaTable': 'NetezzaTableDataset', 'ODataResource': 'ODataResourceDataset', 'OdbcTable': 'OdbcTableDataset', 'Office365Table': 'Office365Dataset', 'OracleServiceCloudObject': 'OracleServiceCloudObjectDataset', 'OracleTable': 'OracleTableDataset', 'Orc': 'OrcDataset', 'Parquet': 'ParquetDataset', 'PaypalObject': 'PaypalObjectDataset', 'PhoenixObject': 'PhoenixObjectDataset', 'PostgreSqlTable': 'PostgreSqlTableDataset', 'PrestoObject': 'PrestoObjectDataset', 'QuickBooksObject': 'QuickBooksObjectDataset', 'RelationalTable': 'RelationalTableDataset', 'ResponsysObject': 'ResponsysObjectDataset', 'RestResource': 'RestResourceDataset', 'SalesforceMarketingCloudObject': 'SalesforceMarketingCloudObjectDataset', 'SalesforceObject': 'SalesforceObjectDataset', 'SalesforceServiceCloudObject': 'SalesforceServiceCloudObjectDataset', 'SapBwCube': 'SapBwCubeDataset', 'SapCloudForCustomerResource': 'SapCloudForCustomerResourceDataset', 'SapEccResource': 'SapEccResourceDataset', 'SapHanaTable': 'SapHanaTableDataset', 'SapOpenHubTable': 'SapOpenHubTableDataset', 'SapTableResource': 'SapTableResourceDataset', 'ServiceNowObject': 'ServiceNowObjectDataset', 'ShopifyObject': 'ShopifyObjectDataset', 'SparkObject': 'SparkObjectDataset', 'SqlServerTable': 'SqlServerTableDataset', 'SquareObject': 'SquareObjectDataset', 'SybaseTable': 'SybaseTableDataset', 'TeradataTable': 'TeradataTableDataset', 'VerticaTable': 'VerticaTableDataset', 'WebTable': 'WebTableDataset', 'XeroObject': 'XeroObjectDataset', 'ZohoObject': 'ZohoObjectDataset'}
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        super(Dataset, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'Dataset'
        self.description = description
        self.structure = structure
        self.schema = schema
        self.linked_service_name = linked_service_name
        self.parameters = parameters
        self.annotations = annotations
        self.folder = folder


class AmazonMWSObjectDataset(Dataset):
    """Amazon Marketplace Web Service dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(AmazonMWSObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AmazonMWSObject'
        self.table_name = table_name


class CopySource(msrest.serialization.Model):
    """A copy activity source.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AvroSource, AzureBlobFSSource, AzureDataExplorerSource, AzureDataLakeStoreSource, BinarySource, BlobSource, CommonDataServiceForAppsSource, CosmosDbMongoDbApiSource, CosmosDbSqlApiSource, DelimitedTextSource, DocumentDbCollectionSource, DynamicsCrmSource, DynamicsSource, FileSystemSource, HdfsSource, HttpSource, JsonSource, MicrosoftAccessSource, MongoDbSource, MongoDbV2Source, ODataSource, Office365Source, OracleSource, OrcSource, ParquetSource, RelationalSource, RestSource, SalesforceServiceCloudSource, TabularSource, WebSource.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
    }

    _subtype_map = {
        'type': {'AvroSource': 'AvroSource', 'AzureBlobFSSource': 'AzureBlobFSSource', 'AzureDataExplorerSource': 'AzureDataExplorerSource', 'AzureDataLakeStoreSource': 'AzureDataLakeStoreSource', 'BinarySource': 'BinarySource', 'BlobSource': 'BlobSource', 'CommonDataServiceForAppsSource': 'CommonDataServiceForAppsSource', 'CosmosDbMongoDbApiSource': 'CosmosDbMongoDbApiSource', 'CosmosDbSqlApiSource': 'CosmosDbSqlApiSource', 'DelimitedTextSource': 'DelimitedTextSource', 'DocumentDbCollectionSource': 'DocumentDbCollectionSource', 'DynamicsCrmSource': 'DynamicsCrmSource', 'DynamicsSource': 'DynamicsSource', 'FileSystemSource': 'FileSystemSource', 'HdfsSource': 'HdfsSource', 'HttpSource': 'HttpSource', 'JsonSource': 'JsonSource', 'MicrosoftAccessSource': 'MicrosoftAccessSource', 'MongoDbSource': 'MongoDbSource', 'MongoDbV2Source': 'MongoDbV2Source', 'ODataSource': 'ODataSource', 'Office365Source': 'Office365Source', 'OracleSource': 'OracleSource', 'OrcSource': 'OrcSource', 'ParquetSource': 'ParquetSource', 'RelationalSource': 'RelationalSource', 'RestSource': 'RestSource', 'SalesforceServiceCloudSource': 'SalesforceServiceCloudSource', 'TabularSource': 'TabularSource', 'WebSource': 'WebSource'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        **kwargs
    ):
        super(CopySource, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'CopySource'
        self.source_retry_count = source_retry_count
        self.source_retry_wait = source_retry_wait
        self.max_concurrent_connections = max_concurrent_connections


class TabularSource(CopySource):
    """Copy activity sources of tabular type.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AmazonMWSSource, AmazonRedshiftSource, AzureMariaDBSource, AzureMySqlSource, AzurePostgreSqlSource, AzureSqlSource, AzureTableSource, CassandraSource, ConcurSource, CouchbaseSource, Db2Source, DrillSource, DynamicsAXSource, EloquaSource, GoogleAdWordsSource, GoogleBigQuerySource, GreenplumSource, HBaseSource, HiveSource, HubspotSource, ImpalaSource, InformixSource, JiraSource, MagentoSource, MariaDBSource, MarketoSource, MySqlSource, NetezzaSource, OdbcSource, OracleServiceCloudSource, PaypalSource, PhoenixSource, PostgreSqlSource, PrestoSource, QuickBooksSource, ResponsysSource, SalesforceMarketingCloudSource, SalesforceSource, SapBwSource, SapCloudForCustomerSource, SapEccSource, SapHanaSource, SapOpenHubSource, SapTableSource, ServiceNowSource, ShopifySource, SparkSource, SqlDWSource, SqlMISource, SqlServerSource, SqlSource, SquareSource, SybaseSource, TeradataSource, VerticaSource, XeroSource, ZohoSource.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    _subtype_map = {
        'type': {'AmazonMWSSource': 'AmazonMWSSource', 'AmazonRedshiftSource': 'AmazonRedshiftSource', 'AzureMariaDBSource': 'AzureMariaDBSource', 'AzureMySqlSource': 'AzureMySqlSource', 'AzurePostgreSqlSource': 'AzurePostgreSqlSource', 'AzureSqlSource': 'AzureSqlSource', 'AzureTableSource': 'AzureTableSource', 'CassandraSource': 'CassandraSource', 'ConcurSource': 'ConcurSource', 'CouchbaseSource': 'CouchbaseSource', 'Db2Source': 'Db2Source', 'DrillSource': 'DrillSource', 'DynamicsAXSource': 'DynamicsAXSource', 'EloquaSource': 'EloquaSource', 'GoogleAdWordsSource': 'GoogleAdWordsSource', 'GoogleBigQuerySource': 'GoogleBigQuerySource', 'GreenplumSource': 'GreenplumSource', 'HBaseSource': 'HBaseSource', 'HiveSource': 'HiveSource', 'HubspotSource': 'HubspotSource', 'ImpalaSource': 'ImpalaSource', 'InformixSource': 'InformixSource', 'JiraSource': 'JiraSource', 'MagentoSource': 'MagentoSource', 'MariaDBSource': 'MariaDBSource', 'MarketoSource': 'MarketoSource', 'MySqlSource': 'MySqlSource', 'NetezzaSource': 'NetezzaSource', 'OdbcSource': 'OdbcSource', 'OracleServiceCloudSource': 'OracleServiceCloudSource', 'PaypalSource': 'PaypalSource', 'PhoenixSource': 'PhoenixSource', 'PostgreSqlSource': 'PostgreSqlSource', 'PrestoSource': 'PrestoSource', 'QuickBooksSource': 'QuickBooksSource', 'ResponsysSource': 'ResponsysSource', 'SalesforceMarketingCloudSource': 'SalesforceMarketingCloudSource', 'SalesforceSource': 'SalesforceSource', 'SapBwSource': 'SapBwSource', 'SapCloudForCustomerSource': 'SapCloudForCustomerSource', 'SapEccSource': 'SapEccSource', 'SapHanaSource': 'SapHanaSource', 'SapOpenHubSource': 'SapOpenHubSource', 'SapTableSource': 'SapTableSource', 'ServiceNowSource': 'ServiceNowSource', 'ShopifySource': 'ShopifySource', 'SparkSource': 'SparkSource', 'SqlDWSource': 'SqlDWSource', 'SqlMISource': 'SqlMISource', 'SqlServerSource': 'SqlServerSource', 'SqlSource': 'SqlSource', 'SquareSource': 'SquareSource', 'SybaseSource': 'SybaseSource', 'TeradataSource': 'TeradataSource', 'VerticaSource': 'VerticaSource', 'XeroSource': 'XeroSource', 'ZohoSource': 'ZohoSource'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(TabularSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'TabularSource'
        self.query_timeout = query_timeout
        self.additional_columns = additional_columns


class AmazonMWSSource(TabularSource):
    """A copy activity Amazon Marketplace Web Service source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.AmazonMWSSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'AmazonMWSSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["AmazonMWSSourceQuery"] = None,
        **kwargs
    ):
        super(AmazonMWSSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'AmazonMWSSource'
        self.query = query


class AmazonMWSSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonMWSSourceQuery, self).__init__(**kwargs)


class AmazonRedshiftLinkedService(LinkedService):
    """Linked service for Amazon Redshift.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param server: Required. The name of the Amazon Redshift server. Type: string (or Expression
     with resultType string).
    :type server:
     ~data_factory_management_client.models.AmazonRedshiftLinkedServiceTypePropertiesServer
    :param username: The username of the Amazon Redshift source. Type: string (or Expression with
     resultType string).
    :type username:
     ~data_factory_management_client.models.AmazonRedshiftLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param database: Required. The database name of the Amazon Redshift source. Type: string (or
     Expression with resultType string).
    :type database:
     ~data_factory_management_client.models.AmazonRedshiftLinkedServiceTypePropertiesDatabase
    :param port: The TCP port number that the Amazon Redshift server uses to listen for client
     connections. The default value is 5439. Type: integer (or Expression with resultType integer).
    :type port:
     ~data_factory_management_client.models.AmazonRedshiftLinkedServiceTypePropertiesPort
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AmazonRedshiftLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'server': {'required': True},
        'database': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'server': {'key': 'typeProperties.server', 'type': 'AmazonRedshiftLinkedServiceTypePropertiesServer'},
        'username': {'key': 'typeProperties.username', 'type': 'AmazonRedshiftLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'database': {'key': 'typeProperties.database', 'type': 'AmazonRedshiftLinkedServiceTypePropertiesDatabase'},
        'port': {'key': 'typeProperties.port', 'type': 'AmazonRedshiftLinkedServiceTypePropertiesPort'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AmazonRedshiftLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        server: "AmazonRedshiftLinkedServiceTypePropertiesServer",
        database: "AmazonRedshiftLinkedServiceTypePropertiesDatabase",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        username: Optional["AmazonRedshiftLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        port: Optional["AmazonRedshiftLinkedServiceTypePropertiesPort"] = None,
        encrypted_credential: Optional["AmazonRedshiftLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AmazonRedshiftLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AmazonRedshift'
        self.server = server
        self.username = username
        self.password = password
        self.database = database
        self.port = port
        self.encrypted_credential = encrypted_credential


class AmazonRedshiftLinkedServiceTypeProperties(msrest.serialization.Model):
    """Amazon Redshift linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param server: Required. The name of the Amazon Redshift server. Type: string (or Expression
     with resultType string).
    :type server:
     ~data_factory_management_client.models.AmazonRedshiftLinkedServiceTypePropertiesServer
    :param username: The username of the Amazon Redshift source. Type: string (or Expression with
     resultType string).
    :type username:
     ~data_factory_management_client.models.AmazonRedshiftLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param database: Required. The database name of the Amazon Redshift source. Type: string (or
     Expression with resultType string).
    :type database:
     ~data_factory_management_client.models.AmazonRedshiftLinkedServiceTypePropertiesDatabase
    :param port: The TCP port number that the Amazon Redshift server uses to listen for client
     connections. The default value is 5439. Type: integer (or Expression with resultType integer).
    :type port:
     ~data_factory_management_client.models.AmazonRedshiftLinkedServiceTypePropertiesPort
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AmazonRedshiftLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'server': {'required': True},
        'database': {'required': True},
    }

    _attribute_map = {
        'server': {'key': 'server', 'type': 'AmazonRedshiftLinkedServiceTypePropertiesServer'},
        'username': {'key': 'username', 'type': 'AmazonRedshiftLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'database': {'key': 'database', 'type': 'AmazonRedshiftLinkedServiceTypePropertiesDatabase'},
        'port': {'key': 'port', 'type': 'AmazonRedshiftLinkedServiceTypePropertiesPort'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AmazonRedshiftLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        server: "AmazonRedshiftLinkedServiceTypePropertiesServer",
        database: "AmazonRedshiftLinkedServiceTypePropertiesDatabase",
        username: Optional["AmazonRedshiftLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        port: Optional["AmazonRedshiftLinkedServiceTypePropertiesPort"] = None,
        encrypted_credential: Optional["AmazonRedshiftLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AmazonRedshiftLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.server = server
        self.username = username
        self.password = password
        self.database = database
        self.port = port
        self.encrypted_credential = encrypted_credential


class AmazonRedshiftLinkedServiceTypePropertiesDatabase(msrest.serialization.Model):
    """The database name of the Amazon Redshift source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonRedshiftLinkedServiceTypePropertiesDatabase, self).__init__(**kwargs)


class AmazonRedshiftLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonRedshiftLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AmazonRedshiftLinkedServiceTypePropertiesPort(msrest.serialization.Model):
    """The TCP port number that the Amazon Redshift server uses to listen for client connections. The default value is 5439. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonRedshiftLinkedServiceTypePropertiesPort, self).__init__(**kwargs)


class AmazonRedshiftLinkedServiceTypePropertiesServer(msrest.serialization.Model):
    """The name of the Amazon Redshift server. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonRedshiftLinkedServiceTypePropertiesServer, self).__init__(**kwargs)


class AmazonRedshiftLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """The username of the Amazon Redshift source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonRedshiftLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class AmazonRedshiftSource(TabularSource):
    """A copy activity source for Amazon Redshift Source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: Database query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.AmazonRedshiftSourceQuery
    :param redshift_unload_settings: The Amazon S3 settings needed for the interim Amazon S3 when
     copying from Amazon Redshift with unload. With this, data from Amazon Redshift source will be
     unloaded into S3 first and then copied into the targeted sink from the interim S3.
    :type redshift_unload_settings: ~data_factory_management_client.models.RedshiftUnloadSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'AmazonRedshiftSourceQuery'},
        'redshift_unload_settings': {'key': 'redshiftUnloadSettings', 'type': 'RedshiftUnloadSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["AmazonRedshiftSourceQuery"] = None,
        redshift_unload_settings: Optional["RedshiftUnloadSettings"] = None,
        **kwargs
    ):
        super(AmazonRedshiftSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'AmazonRedshiftSource'
        self.query = query
        self.redshift_unload_settings = redshift_unload_settings


class AmazonRedshiftSourceQuery(msrest.serialization.Model):
    """Database query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonRedshiftSourceQuery, self).__init__(**kwargs)


class AmazonRedshiftTableDataset(Dataset):
    """The Amazon Redshift table dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.AmazonRedshiftTableDatasetTypePropertiesTableName
    :param table: The Amazon Redshift table name. Type: string (or Expression with resultType
     string).
    :type table:
     ~data_factory_management_client.models.AmazonRedshiftTableDatasetTypePropertiesTable
    :param schema_type_properties_schema: The Amazon Redshift schema name. Type: string (or
     Expression with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.AmazonRedshiftTableDatasetTypePropertiesSchema
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'AmazonRedshiftTableDatasetTypePropertiesTableName'},
        'table': {'key': 'typeProperties.table', 'type': 'AmazonRedshiftTableDatasetTypePropertiesTable'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'AmazonRedshiftTableDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["AmazonRedshiftTableDatasetTypePropertiesTableName"] = None,
        table: Optional["AmazonRedshiftTableDatasetTypePropertiesTable"] = None,
        schema_type_properties_schema: Optional["AmazonRedshiftTableDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(AmazonRedshiftTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AmazonRedshiftTable'
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class AmazonRedshiftTableDatasetTypeProperties(msrest.serialization.Model):
    """Amazon Redshift table dataset properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.AmazonRedshiftTableDatasetTypePropertiesTableName
    :param table: The Amazon Redshift table name. Type: string (or Expression with resultType
     string).
    :type table:
     ~data_factory_management_client.models.AmazonRedshiftTableDatasetTypePropertiesTable
    :param schema: The Amazon Redshift schema name. Type: string (or Expression with resultType
     string).
    :type schema:
     ~data_factory_management_client.models.AmazonRedshiftTableDatasetTypePropertiesSchema
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'AmazonRedshiftTableDatasetTypePropertiesTableName'},
        'table': {'key': 'table', 'type': 'AmazonRedshiftTableDatasetTypePropertiesTable'},
        'schema': {'key': 'schema', 'type': 'AmazonRedshiftTableDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["AmazonRedshiftTableDatasetTypePropertiesTableName"] = None,
        table: Optional["AmazonRedshiftTableDatasetTypePropertiesTable"] = None,
        schema: Optional["AmazonRedshiftTableDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(AmazonRedshiftTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.table = table
        self.schema = schema


class AmazonRedshiftTableDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The Amazon Redshift schema name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonRedshiftTableDatasetTypePropertiesSchema, self).__init__(**kwargs)


class AmazonRedshiftTableDatasetTypePropertiesTable(msrest.serialization.Model):
    """The Amazon Redshift table name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonRedshiftTableDatasetTypePropertiesTable, self).__init__(**kwargs)


class AmazonRedshiftTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonRedshiftTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class AmazonS3Dataset(Dataset):
    """A single Amazon Simple Storage Service (S3) object or a set of S3 objects.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param bucket_name: Required. The name of the Amazon S3 bucket. Type: string (or Expression
     with resultType string).
    :type bucket_name:
     ~data_factory_management_client.models.AmazonS3DatasetTypePropertiesBucketName
    :param key: The key of the Amazon S3 object. Type: string (or Expression with resultType
     string).
    :type key: ~data_factory_management_client.models.AmazonS3DatasetTypePropertiesKey
    :param prefix: The prefix filter for the S3 object name. Type: string (or Expression with
     resultType string).
    :type prefix: ~data_factory_management_client.models.AmazonS3DatasetTypePropertiesPrefix
    :param version: The version for the S3 object. Type: string (or Expression with resultType
     string).
    :type version: ~data_factory_management_client.models.AmazonS3DatasetTypePropertiesVersion
    :param modified_datetime_start: The start of S3 object's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_start:
     ~data_factory_management_client.models.AmazonS3DatasetTypePropertiesModifiedDatetimeStart
    :param modified_datetime_end: The end of S3 object's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_end:
     ~data_factory_management_client.models.AmazonS3DatasetTypePropertiesModifiedDatetimeEnd
    :param format: The format definition of a storage.
    :type format: ~data_factory_management_client.models.DatasetStorageFormat
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'bucket_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'bucket_name': {'key': 'typeProperties.bucketName', 'type': 'AmazonS3DatasetTypePropertiesBucketName'},
        'key': {'key': 'typeProperties.key', 'type': 'AmazonS3DatasetTypePropertiesKey'},
        'prefix': {'key': 'typeProperties.prefix', 'type': 'AmazonS3DatasetTypePropertiesPrefix'},
        'version': {'key': 'typeProperties.version', 'type': 'AmazonS3DatasetTypePropertiesVersion'},
        'modified_datetime_start': {'key': 'typeProperties.modifiedDatetimeStart', 'type': 'AmazonS3DatasetTypePropertiesModifiedDatetimeStart'},
        'modified_datetime_end': {'key': 'typeProperties.modifiedDatetimeEnd', 'type': 'AmazonS3DatasetTypePropertiesModifiedDatetimeEnd'},
        'format': {'key': 'typeProperties.format', 'type': 'DatasetStorageFormat'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        bucket_name: "AmazonS3DatasetTypePropertiesBucketName",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        key: Optional["AmazonS3DatasetTypePropertiesKey"] = None,
        prefix: Optional["AmazonS3DatasetTypePropertiesPrefix"] = None,
        version: Optional["AmazonS3DatasetTypePropertiesVersion"] = None,
        modified_datetime_start: Optional["AmazonS3DatasetTypePropertiesModifiedDatetimeStart"] = None,
        modified_datetime_end: Optional["AmazonS3DatasetTypePropertiesModifiedDatetimeEnd"] = None,
        format: Optional["DatasetStorageFormat"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(AmazonS3Dataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AmazonS3Object'
        self.bucket_name = bucket_name
        self.key = key
        self.prefix = prefix
        self.version = version
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end
        self.format = format
        self.compression = compression


class AmazonS3DatasetTypeProperties(msrest.serialization.Model):
    """Amazon S3 dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param bucket_name: Required. The name of the Amazon S3 bucket. Type: string (or Expression
     with resultType string).
    :type bucket_name:
     ~data_factory_management_client.models.AmazonS3DatasetTypePropertiesBucketName
    :param key: The key of the Amazon S3 object. Type: string (or Expression with resultType
     string).
    :type key: ~data_factory_management_client.models.AmazonS3DatasetTypePropertiesKey
    :param prefix: The prefix filter for the S3 object name. Type: string (or Expression with
     resultType string).
    :type prefix: ~data_factory_management_client.models.AmazonS3DatasetTypePropertiesPrefix
    :param version: The version for the S3 object. Type: string (or Expression with resultType
     string).
    :type version: ~data_factory_management_client.models.AmazonS3DatasetTypePropertiesVersion
    :param modified_datetime_start: The start of S3 object's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_start:
     ~data_factory_management_client.models.AmazonS3DatasetTypePropertiesModifiedDatetimeStart
    :param modified_datetime_end: The end of S3 object's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_end:
     ~data_factory_management_client.models.AmazonS3DatasetTypePropertiesModifiedDatetimeEnd
    :param format: The format definition of a storage.
    :type format: ~data_factory_management_client.models.DatasetStorageFormat
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _validation = {
        'bucket_name': {'required': True},
    }

    _attribute_map = {
        'bucket_name': {'key': 'bucketName', 'type': 'AmazonS3DatasetTypePropertiesBucketName'},
        'key': {'key': 'key', 'type': 'AmazonS3DatasetTypePropertiesKey'},
        'prefix': {'key': 'prefix', 'type': 'AmazonS3DatasetTypePropertiesPrefix'},
        'version': {'key': 'version', 'type': 'AmazonS3DatasetTypePropertiesVersion'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'AmazonS3DatasetTypePropertiesModifiedDatetimeStart'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'AmazonS3DatasetTypePropertiesModifiedDatetimeEnd'},
        'format': {'key': 'format', 'type': 'DatasetStorageFormat'},
        'compression': {'key': 'compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        bucket_name: "AmazonS3DatasetTypePropertiesBucketName",
        key: Optional["AmazonS3DatasetTypePropertiesKey"] = None,
        prefix: Optional["AmazonS3DatasetTypePropertiesPrefix"] = None,
        version: Optional["AmazonS3DatasetTypePropertiesVersion"] = None,
        modified_datetime_start: Optional["AmazonS3DatasetTypePropertiesModifiedDatetimeStart"] = None,
        modified_datetime_end: Optional["AmazonS3DatasetTypePropertiesModifiedDatetimeEnd"] = None,
        format: Optional["DatasetStorageFormat"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(AmazonS3DatasetTypeProperties, self).__init__(**kwargs)
        self.bucket_name = bucket_name
        self.key = key
        self.prefix = prefix
        self.version = version
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end
        self.format = format
        self.compression = compression


class AmazonS3DatasetTypePropertiesBucketName(msrest.serialization.Model):
    """The name of the Amazon S3 bucket. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3DatasetTypePropertiesBucketName, self).__init__(**kwargs)


class AmazonS3DatasetTypePropertiesKey(msrest.serialization.Model):
    """The key of the Amazon S3 object. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3DatasetTypePropertiesKey, self).__init__(**kwargs)


class AmazonS3DatasetTypePropertiesModifiedDatetimeEnd(msrest.serialization.Model):
    """The end of S3 object's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3DatasetTypePropertiesModifiedDatetimeEnd, self).__init__(**kwargs)


class AmazonS3DatasetTypePropertiesModifiedDatetimeStart(msrest.serialization.Model):
    """The start of S3 object's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3DatasetTypePropertiesModifiedDatetimeStart, self).__init__(**kwargs)


class AmazonS3DatasetTypePropertiesPrefix(msrest.serialization.Model):
    """The prefix filter for the S3 object name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3DatasetTypePropertiesPrefix, self).__init__(**kwargs)


class AmazonS3DatasetTypePropertiesVersion(msrest.serialization.Model):
    """The version for the S3 object. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3DatasetTypePropertiesVersion, self).__init__(**kwargs)


class AmazonS3LinkedService(LinkedService):
    """Linked service for Amazon S3.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param access_key_id: The access key identifier of the Amazon S3 Identity and Access Management
     (IAM) user. Type: string (or Expression with resultType string).
    :type access_key_id:
     ~data_factory_management_client.models.AmazonS3LinkedServiceTypePropertiesAccessKeyId
    :param secret_access_key: The base definition of a secret type.
    :type secret_access_key: ~data_factory_management_client.models.SecretBase
    :param service_url: This value specifies the endpoint to access with the S3 Connector. This is
     an optional property; change it only if you want to try a different service endpoint or want to
     switch between https and http. Type: string (or Expression with resultType string).
    :type service_url:
     ~data_factory_management_client.models.AmazonS3LinkedServiceTypePropertiesServiceUrl
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AmazonS3LinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'access_key_id': {'key': 'typeProperties.accessKeyId', 'type': 'AmazonS3LinkedServiceTypePropertiesAccessKeyId'},
        'secret_access_key': {'key': 'typeProperties.secretAccessKey', 'type': 'SecretBase'},
        'service_url': {'key': 'typeProperties.serviceUrl', 'type': 'AmazonS3LinkedServiceTypePropertiesServiceUrl'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AmazonS3LinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        access_key_id: Optional["AmazonS3LinkedServiceTypePropertiesAccessKeyId"] = None,
        secret_access_key: Optional["SecretBase"] = None,
        service_url: Optional["AmazonS3LinkedServiceTypePropertiesServiceUrl"] = None,
        encrypted_credential: Optional["AmazonS3LinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AmazonS3LinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AmazonS3'
        self.access_key_id = access_key_id
        self.secret_access_key = secret_access_key
        self.service_url = service_url
        self.encrypted_credential = encrypted_credential


class AmazonS3LinkedServiceTypeProperties(msrest.serialization.Model):
    """Amazon S3 linked service properties.

    :param access_key_id: The access key identifier of the Amazon S3 Identity and Access Management
     (IAM) user. Type: string (or Expression with resultType string).
    :type access_key_id:
     ~data_factory_management_client.models.AmazonS3LinkedServiceTypePropertiesAccessKeyId
    :param secret_access_key: The base definition of a secret type.
    :type secret_access_key: ~data_factory_management_client.models.SecretBase
    :param service_url: This value specifies the endpoint to access with the S3 Connector. This is
     an optional property; change it only if you want to try a different service endpoint or want to
     switch between https and http. Type: string (or Expression with resultType string).
    :type service_url:
     ~data_factory_management_client.models.AmazonS3LinkedServiceTypePropertiesServiceUrl
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AmazonS3LinkedServiceTypePropertiesEncryptedCredential
    """

    _attribute_map = {
        'access_key_id': {'key': 'accessKeyId', 'type': 'AmazonS3LinkedServiceTypePropertiesAccessKeyId'},
        'secret_access_key': {'key': 'secretAccessKey', 'type': 'SecretBase'},
        'service_url': {'key': 'serviceUrl', 'type': 'AmazonS3LinkedServiceTypePropertiesServiceUrl'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AmazonS3LinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        access_key_id: Optional["AmazonS3LinkedServiceTypePropertiesAccessKeyId"] = None,
        secret_access_key: Optional["SecretBase"] = None,
        service_url: Optional["AmazonS3LinkedServiceTypePropertiesServiceUrl"] = None,
        encrypted_credential: Optional["AmazonS3LinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AmazonS3LinkedServiceTypeProperties, self).__init__(**kwargs)
        self.access_key_id = access_key_id
        self.secret_access_key = secret_access_key
        self.service_url = service_url
        self.encrypted_credential = encrypted_credential


class AmazonS3LinkedServiceTypePropertiesAccessKeyId(msrest.serialization.Model):
    """The access key identifier of the Amazon S3 Identity and Access Management (IAM) user. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3LinkedServiceTypePropertiesAccessKeyId, self).__init__(**kwargs)


class AmazonS3LinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3LinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AmazonS3LinkedServiceTypePropertiesServiceUrl(msrest.serialization.Model):
    """This value specifies the endpoint to access with the S3 Connector. This is an optional property; change it only if you want to try a different service endpoint or want to switch between https and http. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3LinkedServiceTypePropertiesServiceUrl, self).__init__(**kwargs)


class DatasetLocation(msrest.serialization.Model):
    """Dataset location.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AmazonS3Location, AzureBlobFSLocation, AzureBlobStorageLocation, AzureDataLakeStoreLocation, AzureFileStorageLocation, FileServerLocation, FtpServerLocation, GoogleCloudStorageLocation, HdfsLocation, HttpServerLocation, SftpLocation.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage location.Constant filled by server.
    :type type: str
    :param folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :type folder_path: ~data_factory_management_client.models.DatasetLocationFolderPath
    :param file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :type file_name: ~data_factory_management_client.models.DatasetLocationFileName
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'DatasetLocationFolderPath'},
        'file_name': {'key': 'fileName', 'type': 'DatasetLocationFileName'},
    }

    _subtype_map = {
        'type': {'AmazonS3Location': 'AmazonS3Location', 'AzureBlobFSLocation': 'AzureBlobFSLocation', 'AzureBlobStorageLocation': 'AzureBlobStorageLocation', 'AzureDataLakeStoreLocation': 'AzureDataLakeStoreLocation', 'AzureFileStorageLocation': 'AzureFileStorageLocation', 'FileServerLocation': 'FileServerLocation', 'FtpServerLocation': 'FtpServerLocation', 'GoogleCloudStorageLocation': 'GoogleCloudStorageLocation', 'HdfsLocation': 'HdfsLocation', 'HttpServerLocation': 'HttpServerLocation', 'SftpLocation': 'SftpLocation'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        folder_path: Optional["DatasetLocationFolderPath"] = None,
        file_name: Optional["DatasetLocationFileName"] = None,
        **kwargs
    ):
        super(DatasetLocation, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'DatasetLocation'
        self.folder_path = folder_path
        self.file_name = file_name


class AmazonS3Location(DatasetLocation):
    """The location of amazon S3 dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage location.Constant filled by server.
    :type type: str
    :param folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :type folder_path: ~data_factory_management_client.models.DatasetLocationFolderPath
    :param file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :type file_name: ~data_factory_management_client.models.DatasetLocationFileName
    :param bucket_name: Specify the bucketName of amazon S3. Type: string (or Expression with
     resultType string).
    :type bucket_name: ~data_factory_management_client.models.AmazonS3LocationBucketName
    :param version: Specify the version of amazon S3. Type: string (or Expression with resultType
     string).
    :type version: ~data_factory_management_client.models.AmazonS3LocationVersion
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'DatasetLocationFolderPath'},
        'file_name': {'key': 'fileName', 'type': 'DatasetLocationFileName'},
        'bucket_name': {'key': 'bucketName', 'type': 'AmazonS3LocationBucketName'},
        'version': {'key': 'version', 'type': 'AmazonS3LocationVersion'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        folder_path: Optional["DatasetLocationFolderPath"] = None,
        file_name: Optional["DatasetLocationFileName"] = None,
        bucket_name: Optional["AmazonS3LocationBucketName"] = None,
        version: Optional["AmazonS3LocationVersion"] = None,
        **kwargs
    ):
        super(AmazonS3Location, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'AmazonS3Location'
        self.bucket_name = bucket_name
        self.version = version


class AmazonS3LocationBucketName(msrest.serialization.Model):
    """Specify the bucketName of amazon S3. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3LocationBucketName, self).__init__(**kwargs)


class AmazonS3LocationVersion(msrest.serialization.Model):
    """Specify the version of amazon S3. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3LocationVersion, self).__init__(**kwargs)


class StoreReadSettings(msrest.serialization.Model):
    """Connector read setting.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AmazonS3ReadSettings, AzureBlobFSReadSettings, AzureBlobStorageReadSettings, AzureDataLakeStoreReadSettings, AzureFileStorageReadSettings, FileServerReadSettings, FtpReadSettings, GoogleCloudStorageReadSettings, HdfsReadSettings, HttpReadSettings, SftpReadSettings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The read setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreReadSettingsMaxConcurrentConnections
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreReadSettingsMaxConcurrentConnections'},
    }

    _subtype_map = {
        'type': {'AmazonS3ReadSettings': 'AmazonS3ReadSettings', 'AzureBlobFSReadSettings': 'AzureBlobFSReadSettings', 'AzureBlobStorageReadSettings': 'AzureBlobStorageReadSettings', 'AzureDataLakeStoreReadSettings': 'AzureDataLakeStoreReadSettings', 'AzureFileStorageReadSettings': 'AzureFileStorageReadSettings', 'FileServerReadSettings': 'FileServerReadSettings', 'FtpReadSettings': 'FtpReadSettings', 'GoogleCloudStorageReadSettings': 'GoogleCloudStorageReadSettings', 'HdfsReadSettings': 'HdfsReadSettings', 'HttpReadSettings': 'HttpReadSettings', 'SftpReadSettings': 'SftpReadSettings'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreReadSettingsMaxConcurrentConnections"] = None,
        **kwargs
    ):
        super(StoreReadSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'StoreReadSettings'
        self.max_concurrent_connections = max_concurrent_connections


class AmazonS3ReadSettings(StoreReadSettings):
    """Azure data lake store read settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The read setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreReadSettingsMaxConcurrentConnections
    :param recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.AmazonS3ReadSettingsRecursive
    :param wildcard_folder_path: AmazonS3 wildcardFolderPath. Type: string (or Expression with
     resultType string).
    :type wildcard_folder_path:
     ~data_factory_management_client.models.AmazonS3ReadSettingsWildcardFolderPath
    :param wildcard_file_name: AmazonS3 wildcardFileName. Type: string (or Expression with
     resultType string).
    :type wildcard_file_name:
     ~data_factory_management_client.models.AmazonS3ReadSettingsWildcardFileName
    :param prefix: The prefix filter for the S3 object name. Type: string (or Expression with
     resultType string).
    :type prefix: ~data_factory_management_client.models.AmazonS3ReadSettingsPrefix
    :param file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :type file_list_path: ~data_factory_management_client.models.AmazonS3ReadSettingsFileListPath
    :param enable_partition_discovery: Indicates whether to enable partition discovery.
    :type enable_partition_discovery: bool
    :param modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_start:
     ~data_factory_management_client.models.AmazonS3ReadSettingsModifiedDatetimeStart
    :param modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :type modified_datetime_end:
     ~data_factory_management_client.models.AmazonS3ReadSettingsModifiedDatetimeEnd
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreReadSettingsMaxConcurrentConnections'},
        'recursive': {'key': 'recursive', 'type': 'AmazonS3ReadSettingsRecursive'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'AmazonS3ReadSettingsWildcardFolderPath'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'AmazonS3ReadSettingsWildcardFileName'},
        'prefix': {'key': 'prefix', 'type': 'AmazonS3ReadSettingsPrefix'},
        'file_list_path': {'key': 'fileListPath', 'type': 'AmazonS3ReadSettingsFileListPath'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'AmazonS3ReadSettingsModifiedDatetimeStart'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'AmazonS3ReadSettingsModifiedDatetimeEnd'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreReadSettingsMaxConcurrentConnections"] = None,
        recursive: Optional["AmazonS3ReadSettingsRecursive"] = None,
        wildcard_folder_path: Optional["AmazonS3ReadSettingsWildcardFolderPath"] = None,
        wildcard_file_name: Optional["AmazonS3ReadSettingsWildcardFileName"] = None,
        prefix: Optional["AmazonS3ReadSettingsPrefix"] = None,
        file_list_path: Optional["AmazonS3ReadSettingsFileListPath"] = None,
        enable_partition_discovery: Optional[bool] = None,
        modified_datetime_start: Optional["AmazonS3ReadSettingsModifiedDatetimeStart"] = None,
        modified_datetime_end: Optional["AmazonS3ReadSettingsModifiedDatetimeEnd"] = None,
        **kwargs
    ):
        super(AmazonS3ReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AmazonS3ReadSettings'
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.prefix = prefix
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class AmazonS3ReadSettingsFileListPath(msrest.serialization.Model):
    """Point to a text file that lists each file (relative path to the path configured in the dataset) that you want to copy. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3ReadSettingsFileListPath, self).__init__(**kwargs)


class AmazonS3ReadSettingsModifiedDatetimeEnd(msrest.serialization.Model):
    """The end of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3ReadSettingsModifiedDatetimeEnd, self).__init__(**kwargs)


class AmazonS3ReadSettingsModifiedDatetimeStart(msrest.serialization.Model):
    """The start of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3ReadSettingsModifiedDatetimeStart, self).__init__(**kwargs)


class AmazonS3ReadSettingsPrefix(msrest.serialization.Model):
    """The prefix filter for the S3 object name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3ReadSettingsPrefix, self).__init__(**kwargs)


class AmazonS3ReadSettingsRecursive(msrest.serialization.Model):
    """If true, files under the folder path will be read recursively. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3ReadSettingsRecursive, self).__init__(**kwargs)


class AmazonS3ReadSettingsWildcardFileName(msrest.serialization.Model):
    """AmazonS3 wildcardFileName. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3ReadSettingsWildcardFileName, self).__init__(**kwargs)


class AmazonS3ReadSettingsWildcardFolderPath(msrest.serialization.Model):
    """AmazonS3 wildcardFolderPath. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AmazonS3ReadSettingsWildcardFolderPath, self).__init__(**kwargs)


class ControlActivity(Activity):
    """Base class for all control activities like IfCondition, ForEach , Until.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AppendVariableActivity, ExecutePipelineActivity, FilterActivity, ForEachActivity, IfConditionActivity, SetVariableActivity, SwitchActivity, UntilActivity, ValidationActivity, WaitActivity, WebHookActivity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
    }

    _subtype_map = {
        'type': {'AppendVariable': 'AppendVariableActivity', 'ExecutePipeline': 'ExecutePipelineActivity', 'Filter': 'FilterActivity', 'ForEach': 'ForEachActivity', 'IfCondition': 'IfConditionActivity', 'SetVariable': 'SetVariableActivity', 'Switch': 'SwitchActivity', 'Until': 'UntilActivity', 'Validation': 'ValidationActivity', 'Wait': 'WaitActivity', 'WebHook': 'WebHookActivity'}
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        **kwargs
    ):
        super(ControlActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'Container'


class AppendVariableActivity(ControlActivity):
    """Append value for a Variable of type Array.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param variable_name: Name of the variable whose value needs to be appended to.
    :type variable_name: str
    :param value: Value to be appended. Could be a static value or Expression.
    :type value: ~data_factory_management_client.models.AppendVariableActivityTypePropertiesValue
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'variable_name': {'key': 'typeProperties.variableName', 'type': 'str'},
        'value': {'key': 'typeProperties.value', 'type': 'AppendVariableActivityTypePropertiesValue'},
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        variable_name: Optional[str] = None,
        value: Optional["AppendVariableActivityTypePropertiesValue"] = None,
        **kwargs
    ):
        super(AppendVariableActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'AppendVariable'
        self.variable_name = variable_name
        self.value = value


class AppendVariableActivityTypeProperties(msrest.serialization.Model):
    """AppendVariable activity properties.

    :param variable_name: Name of the variable whose value needs to be appended to.
    :type variable_name: str
    :param value: Value to be appended. Could be a static value or Expression.
    :type value: ~data_factory_management_client.models.AppendVariableActivityTypePropertiesValue
    """

    _attribute_map = {
        'variable_name': {'key': 'variableName', 'type': 'str'},
        'value': {'key': 'value', 'type': 'AppendVariableActivityTypePropertiesValue'},
    }

    def __init__(
        self,
        *,
        variable_name: Optional[str] = None,
        value: Optional["AppendVariableActivityTypePropertiesValue"] = None,
        **kwargs
    ):
        super(AppendVariableActivityTypeProperties, self).__init__(**kwargs)
        self.variable_name = variable_name
        self.value = value


class AppendVariableActivityTypePropertiesValue(msrest.serialization.Model):
    """Value to be appended. Could be a static value or Expression.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AppendVariableActivityTypePropertiesValue, self).__init__(**kwargs)


class AvroDataset(Dataset):
    """Avro dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param location: Dataset location.
    :type location: ~data_factory_management_client.models.DatasetLocation
    :param avro_compression_codec:  Possible values include: 'none', 'deflate', 'snappy', 'xz',
     'bzip2'.
    :type avro_compression_codec: str or
     ~data_factory_management_client.models.AvroCompressionCodec
    :param avro_compression_level:
    :type avro_compression_level: int
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'avro_compression_level': {'maximum': 9, 'minimum': 1},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'location': {'key': 'typeProperties.location', 'type': 'DatasetLocation'},
        'avro_compression_codec': {'key': 'typeProperties.avroCompressionCodec', 'type': 'str'},
        'avro_compression_level': {'key': 'typeProperties.avroCompressionLevel', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        location: Optional["DatasetLocation"] = None,
        avro_compression_codec: Optional[Union[str, "AvroCompressionCodec"]] = None,
        avro_compression_level: Optional[int] = None,
        **kwargs
    ):
        super(AvroDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Avro'
        self.location = location
        self.avro_compression_codec = avro_compression_codec
        self.avro_compression_level = avro_compression_level


class AvroDatasetTypeProperties(msrest.serialization.Model):
    """Avro dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param location: Required. Dataset location.
    :type location: ~data_factory_management_client.models.DatasetLocation
    :param avro_compression_codec:  Possible values include: 'none', 'deflate', 'snappy', 'xz',
     'bzip2'.
    :type avro_compression_codec: str or
     ~data_factory_management_client.models.AvroCompressionCodec
    :param avro_compression_level:
    :type avro_compression_level: int
    """

    _validation = {
        'location': {'required': True},
        'avro_compression_level': {'maximum': 9, 'minimum': 1},
    }

    _attribute_map = {
        'location': {'key': 'location', 'type': 'DatasetLocation'},
        'avro_compression_codec': {'key': 'avroCompressionCodec', 'type': 'str'},
        'avro_compression_level': {'key': 'avroCompressionLevel', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        location: "DatasetLocation",
        avro_compression_codec: Optional[Union[str, "AvroCompressionCodec"]] = None,
        avro_compression_level: Optional[int] = None,
        **kwargs
    ):
        super(AvroDatasetTypeProperties, self).__init__(**kwargs)
        self.location = location
        self.avro_compression_codec = avro_compression_codec
        self.avro_compression_level = avro_compression_level


class DatasetStorageFormat(msrest.serialization.Model):
    """The format definition of a storage.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AvroFormat, JsonFormat, OrcFormat, ParquetFormat, TextFormat.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage format.Constant filled by server.
    :type type: str
    :param serializer: Serializer. Type: string (or Expression with resultType string).
    :type serializer: ~data_factory_management_client.models.DatasetStorageFormatSerializer
    :param deserializer: Deserializer. Type: string (or Expression with resultType string).
    :type deserializer: ~data_factory_management_client.models.DatasetStorageFormatDeserializer
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'serializer': {'key': 'serializer', 'type': 'DatasetStorageFormatSerializer'},
        'deserializer': {'key': 'deserializer', 'type': 'DatasetStorageFormatDeserializer'},
    }

    _subtype_map = {
        'type': {'AvroFormat': 'AvroFormat', 'JsonFormat': 'JsonFormat', 'OrcFormat': 'OrcFormat', 'ParquetFormat': 'ParquetFormat', 'TextFormat': 'TextFormat'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        serializer: Optional["DatasetStorageFormatSerializer"] = None,
        deserializer: Optional["DatasetStorageFormatDeserializer"] = None,
        **kwargs
    ):
        super(DatasetStorageFormat, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'DatasetStorageFormat'
        self.serializer = serializer
        self.deserializer = deserializer


class AvroFormat(DatasetStorageFormat):
    """The data stored in Avro format.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage format.Constant filled by server.
    :type type: str
    :param serializer: Serializer. Type: string (or Expression with resultType string).
    :type serializer: ~data_factory_management_client.models.DatasetStorageFormatSerializer
    :param deserializer: Deserializer. Type: string (or Expression with resultType string).
    :type deserializer: ~data_factory_management_client.models.DatasetStorageFormatDeserializer
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'serializer': {'key': 'serializer', 'type': 'DatasetStorageFormatSerializer'},
        'deserializer': {'key': 'deserializer', 'type': 'DatasetStorageFormatDeserializer'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        serializer: Optional["DatasetStorageFormatSerializer"] = None,
        deserializer: Optional["DatasetStorageFormatDeserializer"] = None,
        **kwargs
    ):
        super(AvroFormat, self).__init__(additional_properties=additional_properties, serializer=serializer, deserializer=deserializer, **kwargs)
        self.type = 'AvroFormat'


class CopySink(msrest.serialization.Model):
    """A copy activity sink.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AvroSink, AzureBlobFSSink, AzureDataExplorerSink, AzureDataLakeStoreSink, AzureMySqlSink, AzurePostgreSqlSink, AzureQueueSink, AzureSearchIndexSink, AzureSqlSink, AzureTableSink, BinarySink, BlobSink, CommonDataServiceForAppsSink, CosmosDbMongoDbApiSink, CosmosDbSqlApiSink, DelimitedTextSink, DocumentDbCollectionSink, DynamicsCrmSink, DynamicsSink, FileSystemSink, InformixSink, JsonSink, MicrosoftAccessSink, OdbcSink, OracleSink, OrcSink, ParquetSink, SalesforceServiceCloudSink, SalesforceSink, SapCloudForCustomerSink, SqlDWSink, SqlMISink, SqlServerSink, SqlSink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
    }

    _subtype_map = {
        'type': {'AvroSink': 'AvroSink', 'AzureBlobFSSink': 'AzureBlobFSSink', 'AzureDataExplorerSink': 'AzureDataExplorerSink', 'AzureDataLakeStoreSink': 'AzureDataLakeStoreSink', 'AzureMySqlSink': 'AzureMySqlSink', 'AzurePostgreSqlSink': 'AzurePostgreSqlSink', 'AzureQueueSink': 'AzureQueueSink', 'AzureSearchIndexSink': 'AzureSearchIndexSink', 'AzureSqlSink': 'AzureSqlSink', 'AzureTableSink': 'AzureTableSink', 'BinarySink': 'BinarySink', 'BlobSink': 'BlobSink', 'CommonDataServiceForAppsSink': 'CommonDataServiceForAppsSink', 'CosmosDbMongoDbApiSink': 'CosmosDbMongoDbApiSink', 'CosmosDbSqlApiSink': 'CosmosDbSqlApiSink', 'DelimitedTextSink': 'DelimitedTextSink', 'DocumentDbCollectionSink': 'DocumentDbCollectionSink', 'DynamicsCrmSink': 'DynamicsCrmSink', 'DynamicsSink': 'DynamicsSink', 'FileSystemSink': 'FileSystemSink', 'InformixSink': 'InformixSink', 'JsonSink': 'JsonSink', 'MicrosoftAccessSink': 'MicrosoftAccessSink', 'OdbcSink': 'OdbcSink', 'OracleSink': 'OracleSink', 'OrcSink': 'OrcSink', 'ParquetSink': 'ParquetSink', 'SalesforceServiceCloudSink': 'SalesforceServiceCloudSink', 'SalesforceSink': 'SalesforceSink', 'SapCloudForCustomerSink': 'SapCloudForCustomerSink', 'SqlDWSink': 'SqlDWSink', 'SqlMISink': 'SqlMISink', 'SqlServerSink': 'SqlServerSink', 'SqlSink': 'SqlSink'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        **kwargs
    ):
        super(CopySink, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'CopySink'
        self.write_batch_size = write_batch_size
        self.write_batch_timeout = write_batch_timeout
        self.sink_retry_count = sink_retry_count
        self.sink_retry_wait = sink_retry_wait
        self.max_concurrent_connections = max_concurrent_connections


class AvroSink(CopySink):
    """A copy activity Avro sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param store_settings: Connector write settings.
    :type store_settings: ~data_factory_management_client.models.StoreWriteSettings
    :param format_settings: Avro write settings.
    :type format_settings: ~data_factory_management_client.models.AvroWriteSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreWriteSettings'},
        'format_settings': {'key': 'formatSettings', 'type': 'AvroWriteSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        store_settings: Optional["StoreWriteSettings"] = None,
        format_settings: Optional["AvroWriteSettings"] = None,
        **kwargs
    ):
        super(AvroSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AvroSink'
        self.store_settings = store_settings
        self.format_settings = format_settings


class AvroSource(CopySource):
    """A copy activity Avro source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param store_settings: Connector read setting.
    :type store_settings: ~data_factory_management_client.models.StoreReadSettings
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreReadSettings'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(AvroSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AvroSource'
        self.store_settings = store_settings
        self.additional_columns = additional_columns


class FormatWriteSettings(msrest.serialization.Model):
    """Format write settings.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AvroWriteSettings, DelimitedTextWriteSettings, JsonWriteSettings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The write setting type.Constant filled by server.
    :type type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'AvroWriteSettings': 'AvroWriteSettings', 'DelimitedTextWriteSettings': 'DelimitedTextWriteSettings', 'JsonWriteSettings': 'JsonWriteSettings'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(FormatWriteSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'FormatWriteSettings'


class AvroWriteSettings(FormatWriteSettings):
    """Avro write settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The write setting type.Constant filled by server.
    :type type: str
    :param record_name: Top level record name in write result, which is required in AVRO spec.
    :type record_name: str
    :param record_namespace: Record namespace in the write result.
    :type record_namespace: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'record_name': {'key': 'recordName', 'type': 'str'},
        'record_namespace': {'key': 'recordNamespace', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        record_name: Optional[str] = None,
        record_namespace: Optional[str] = None,
        **kwargs
    ):
        super(AvroWriteSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'AvroWriteSettings'
        self.record_name = record_name
        self.record_namespace = record_namespace


class AzureBatchLinkedService(LinkedService):
    """Azure Batch linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param account_name: Required. The Azure Batch account name. Type: string (or Expression with
     resultType string).
    :type account_name:
     ~data_factory_management_client.models.AzureBatchLinkedServiceTypePropertiesAccountName
    :param access_key: The base definition of a secret type.
    :type access_key: ~data_factory_management_client.models.SecretBase
    :param batch_uri: Required. The Azure Batch URI. Type: string (or Expression with resultType
     string).
    :type batch_uri:
     ~data_factory_management_client.models.AzureBatchLinkedServiceTypePropertiesBatchUri
    :param pool_name: Required. The Azure Batch pool name. Type: string (or Expression with
     resultType string).
    :type pool_name:
     ~data_factory_management_client.models.AzureBatchLinkedServiceTypePropertiesPoolName
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureBatchLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'account_name': {'required': True},
        'batch_uri': {'required': True},
        'pool_name': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'account_name': {'key': 'typeProperties.accountName', 'type': 'AzureBatchLinkedServiceTypePropertiesAccountName'},
        'access_key': {'key': 'typeProperties.accessKey', 'type': 'SecretBase'},
        'batch_uri': {'key': 'typeProperties.batchUri', 'type': 'AzureBatchLinkedServiceTypePropertiesBatchUri'},
        'pool_name': {'key': 'typeProperties.poolName', 'type': 'AzureBatchLinkedServiceTypePropertiesPoolName'},
        'linked_service_name': {'key': 'typeProperties.linkedServiceName', 'type': 'LinkedServiceReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzureBatchLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        account_name: "AzureBatchLinkedServiceTypePropertiesAccountName",
        batch_uri: "AzureBatchLinkedServiceTypePropertiesBatchUri",
        pool_name: "AzureBatchLinkedServiceTypePropertiesPoolName",
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        access_key: Optional["SecretBase"] = None,
        encrypted_credential: Optional["AzureBatchLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureBatchLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureBatch'
        self.account_name = account_name
        self.access_key = access_key
        self.batch_uri = batch_uri
        self.pool_name = pool_name
        self.linked_service_name = linked_service_name
        self.encrypted_credential = encrypted_credential


class AzureBatchLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure Batch linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param account_name: Required. The Azure Batch account name. Type: string (or Expression with
     resultType string).
    :type account_name:
     ~data_factory_management_client.models.AzureBatchLinkedServiceTypePropertiesAccountName
    :param access_key: The base definition of a secret type.
    :type access_key: ~data_factory_management_client.models.SecretBase
    :param batch_uri: Required. The Azure Batch URI. Type: string (or Expression with resultType
     string).
    :type batch_uri:
     ~data_factory_management_client.models.AzureBatchLinkedServiceTypePropertiesBatchUri
    :param pool_name: Required. The Azure Batch pool name. Type: string (or Expression with
     resultType string).
    :type pool_name:
     ~data_factory_management_client.models.AzureBatchLinkedServiceTypePropertiesPoolName
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureBatchLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'account_name': {'required': True},
        'batch_uri': {'required': True},
        'pool_name': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'account_name': {'key': 'accountName', 'type': 'AzureBatchLinkedServiceTypePropertiesAccountName'},
        'access_key': {'key': 'accessKey', 'type': 'SecretBase'},
        'batch_uri': {'key': 'batchUri', 'type': 'AzureBatchLinkedServiceTypePropertiesBatchUri'},
        'pool_name': {'key': 'poolName', 'type': 'AzureBatchLinkedServiceTypePropertiesPoolName'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzureBatchLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        account_name: "AzureBatchLinkedServiceTypePropertiesAccountName",
        batch_uri: "AzureBatchLinkedServiceTypePropertiesBatchUri",
        pool_name: "AzureBatchLinkedServiceTypePropertiesPoolName",
        linked_service_name: "LinkedServiceReference",
        access_key: Optional["SecretBase"] = None,
        encrypted_credential: Optional["AzureBatchLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureBatchLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.account_name = account_name
        self.access_key = access_key
        self.batch_uri = batch_uri
        self.pool_name = pool_name
        self.linked_service_name = linked_service_name
        self.encrypted_credential = encrypted_credential


class AzureBatchLinkedServiceTypePropertiesAccountName(msrest.serialization.Model):
    """The Azure Batch account name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBatchLinkedServiceTypePropertiesAccountName, self).__init__(**kwargs)


class AzureBatchLinkedServiceTypePropertiesBatchUri(msrest.serialization.Model):
    """The Azure Batch URI. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBatchLinkedServiceTypePropertiesBatchUri, self).__init__(**kwargs)


class AzureBatchLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBatchLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzureBatchLinkedServiceTypePropertiesPoolName(msrest.serialization.Model):
    """The Azure Batch pool name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBatchLinkedServiceTypePropertiesPoolName, self).__init__(**kwargs)


class AzureBlobDataset(Dataset):
    """The Azure Blob storage.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param folder_path: The path of the Azure Blob storage. Type: string (or Expression with
     resultType string).
    :type folder_path:
     ~data_factory_management_client.models.AzureBlobDatasetTypePropertiesFolderPath
    :param table_root_location: The root of blob path. Type: string (or Expression with resultType
     string).
    :type table_root_location:
     ~data_factory_management_client.models.AzureBlobDatasetTypePropertiesTableRootLocation
    :param file_name: The name of the Azure Blob. Type: string (or Expression with resultType
     string).
    :type file_name: ~data_factory_management_client.models.AzureBlobDatasetTypePropertiesFileName
    :param modified_datetime_start: The start of Azure Blob's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_start:
     ~data_factory_management_client.models.AzureBlobDatasetTypePropertiesModifiedDatetimeStart
    :param modified_datetime_end: The end of Azure Blob's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_end:
     ~data_factory_management_client.models.AzureBlobDatasetTypePropertiesModifiedDatetimeEnd
    :param format: The format definition of a storage.
    :type format: ~data_factory_management_client.models.DatasetStorageFormat
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'folder_path': {'key': 'typeProperties.folderPath', 'type': 'AzureBlobDatasetTypePropertiesFolderPath'},
        'table_root_location': {'key': 'typeProperties.tableRootLocation', 'type': 'AzureBlobDatasetTypePropertiesTableRootLocation'},
        'file_name': {'key': 'typeProperties.fileName', 'type': 'AzureBlobDatasetTypePropertiesFileName'},
        'modified_datetime_start': {'key': 'typeProperties.modifiedDatetimeStart', 'type': 'AzureBlobDatasetTypePropertiesModifiedDatetimeStart'},
        'modified_datetime_end': {'key': 'typeProperties.modifiedDatetimeEnd', 'type': 'AzureBlobDatasetTypePropertiesModifiedDatetimeEnd'},
        'format': {'key': 'typeProperties.format', 'type': 'DatasetStorageFormat'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        folder_path: Optional["AzureBlobDatasetTypePropertiesFolderPath"] = None,
        table_root_location: Optional["AzureBlobDatasetTypePropertiesTableRootLocation"] = None,
        file_name: Optional["AzureBlobDatasetTypePropertiesFileName"] = None,
        modified_datetime_start: Optional["AzureBlobDatasetTypePropertiesModifiedDatetimeStart"] = None,
        modified_datetime_end: Optional["AzureBlobDatasetTypePropertiesModifiedDatetimeEnd"] = None,
        format: Optional["DatasetStorageFormat"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(AzureBlobDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureBlob'
        self.folder_path = folder_path
        self.table_root_location = table_root_location
        self.file_name = file_name
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end
        self.format = format
        self.compression = compression


class AzureBlobDatasetTypeProperties(msrest.serialization.Model):
    """Azure Blob dataset properties.

    :param folder_path: The path of the Azure Blob storage. Type: string (or Expression with
     resultType string).
    :type folder_path:
     ~data_factory_management_client.models.AzureBlobDatasetTypePropertiesFolderPath
    :param table_root_location: The root of blob path. Type: string (or Expression with resultType
     string).
    :type table_root_location:
     ~data_factory_management_client.models.AzureBlobDatasetTypePropertiesTableRootLocation
    :param file_name: The name of the Azure Blob. Type: string (or Expression with resultType
     string).
    :type file_name: ~data_factory_management_client.models.AzureBlobDatasetTypePropertiesFileName
    :param modified_datetime_start: The start of Azure Blob's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_start:
     ~data_factory_management_client.models.AzureBlobDatasetTypePropertiesModifiedDatetimeStart
    :param modified_datetime_end: The end of Azure Blob's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_end:
     ~data_factory_management_client.models.AzureBlobDatasetTypePropertiesModifiedDatetimeEnd
    :param format: The format definition of a storage.
    :type format: ~data_factory_management_client.models.DatasetStorageFormat
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _attribute_map = {
        'folder_path': {'key': 'folderPath', 'type': 'AzureBlobDatasetTypePropertiesFolderPath'},
        'table_root_location': {'key': 'tableRootLocation', 'type': 'AzureBlobDatasetTypePropertiesTableRootLocation'},
        'file_name': {'key': 'fileName', 'type': 'AzureBlobDatasetTypePropertiesFileName'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'AzureBlobDatasetTypePropertiesModifiedDatetimeStart'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'AzureBlobDatasetTypePropertiesModifiedDatetimeEnd'},
        'format': {'key': 'format', 'type': 'DatasetStorageFormat'},
        'compression': {'key': 'compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        folder_path: Optional["AzureBlobDatasetTypePropertiesFolderPath"] = None,
        table_root_location: Optional["AzureBlobDatasetTypePropertiesTableRootLocation"] = None,
        file_name: Optional["AzureBlobDatasetTypePropertiesFileName"] = None,
        modified_datetime_start: Optional["AzureBlobDatasetTypePropertiesModifiedDatetimeStart"] = None,
        modified_datetime_end: Optional["AzureBlobDatasetTypePropertiesModifiedDatetimeEnd"] = None,
        format: Optional["DatasetStorageFormat"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(AzureBlobDatasetTypeProperties, self).__init__(**kwargs)
        self.folder_path = folder_path
        self.table_root_location = table_root_location
        self.file_name = file_name
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end
        self.format = format
        self.compression = compression


class AzureBlobDatasetTypePropertiesFileName(msrest.serialization.Model):
    """The name of the Azure Blob. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobDatasetTypePropertiesFileName, self).__init__(**kwargs)


class AzureBlobDatasetTypePropertiesFolderPath(msrest.serialization.Model):
    """The path of the Azure Blob storage. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobDatasetTypePropertiesFolderPath, self).__init__(**kwargs)


class AzureBlobDatasetTypePropertiesModifiedDatetimeEnd(msrest.serialization.Model):
    """The end of Azure Blob's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobDatasetTypePropertiesModifiedDatetimeEnd, self).__init__(**kwargs)


class AzureBlobDatasetTypePropertiesModifiedDatetimeStart(msrest.serialization.Model):
    """The start of Azure Blob's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobDatasetTypePropertiesModifiedDatetimeStart, self).__init__(**kwargs)


class AzureBlobDatasetTypePropertiesTableRootLocation(msrest.serialization.Model):
    """The root of blob path. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobDatasetTypePropertiesTableRootLocation, self).__init__(**kwargs)


class AzureBlobFSDataset(Dataset):
    """The Azure Data Lake Storage Gen2 storage.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param folder_path: The path of the Azure Data Lake Storage Gen2 storage. Type: string (or
     Expression with resultType string).
    :type folder_path:
     ~data_factory_management_client.models.AzureBlobFSDatasetTypePropertiesFolderPath
    :param file_name: The name of the Azure Data Lake Storage Gen2. Type: string (or Expression
     with resultType string).
    :type file_name:
     ~data_factory_management_client.models.AzureBlobFSDatasetTypePropertiesFileName
    :param format: The format definition of a storage.
    :type format: ~data_factory_management_client.models.DatasetStorageFormat
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'folder_path': {'key': 'typeProperties.folderPath', 'type': 'AzureBlobFSDatasetTypePropertiesFolderPath'},
        'file_name': {'key': 'typeProperties.fileName', 'type': 'AzureBlobFSDatasetTypePropertiesFileName'},
        'format': {'key': 'typeProperties.format', 'type': 'DatasetStorageFormat'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        folder_path: Optional["AzureBlobFSDatasetTypePropertiesFolderPath"] = None,
        file_name: Optional["AzureBlobFSDatasetTypePropertiesFileName"] = None,
        format: Optional["DatasetStorageFormat"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(AzureBlobFSDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureBlobFSFile'
        self.folder_path = folder_path
        self.file_name = file_name
        self.format = format
        self.compression = compression


class AzureBlobFSDatasetTypeProperties(msrest.serialization.Model):
    """Azure Data Lake Storage Gen2 dataset properties.

    :param folder_path: The path of the Azure Data Lake Storage Gen2 storage. Type: string (or
     Expression with resultType string).
    :type folder_path:
     ~data_factory_management_client.models.AzureBlobFSDatasetTypePropertiesFolderPath
    :param file_name: The name of the Azure Data Lake Storage Gen2. Type: string (or Expression
     with resultType string).
    :type file_name:
     ~data_factory_management_client.models.AzureBlobFSDatasetTypePropertiesFileName
    :param format: The format definition of a storage.
    :type format: ~data_factory_management_client.models.DatasetStorageFormat
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _attribute_map = {
        'folder_path': {'key': 'folderPath', 'type': 'AzureBlobFSDatasetTypePropertiesFolderPath'},
        'file_name': {'key': 'fileName', 'type': 'AzureBlobFSDatasetTypePropertiesFileName'},
        'format': {'key': 'format', 'type': 'DatasetStorageFormat'},
        'compression': {'key': 'compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        folder_path: Optional["AzureBlobFSDatasetTypePropertiesFolderPath"] = None,
        file_name: Optional["AzureBlobFSDatasetTypePropertiesFileName"] = None,
        format: Optional["DatasetStorageFormat"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(AzureBlobFSDatasetTypeProperties, self).__init__(**kwargs)
        self.folder_path = folder_path
        self.file_name = file_name
        self.format = format
        self.compression = compression


class AzureBlobFSDatasetTypePropertiesFileName(msrest.serialization.Model):
    """The name of the Azure Data Lake Storage Gen2. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSDatasetTypePropertiesFileName, self).__init__(**kwargs)


class AzureBlobFSDatasetTypePropertiesFolderPath(msrest.serialization.Model):
    """The path of the Azure Data Lake Storage Gen2 storage. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSDatasetTypePropertiesFolderPath, self).__init__(**kwargs)


class AzureBlobFSLinkedService(LinkedService):
    """Azure Data Lake Storage Gen2 linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param url: Required. Endpoint for the Azure Data Lake Storage Gen2 service. Type: string (or
     Expression with resultType string).
    :type url: ~data_factory_management_client.models.AzureBlobFSLinkedServiceTypePropertiesUrl
    :param account_key: Account key for the Azure Data Lake Storage Gen2 service. Type: string (or
     Expression with resultType string).
    :type account_key:
     ~data_factory_management_client.models.AzureBlobFSLinkedServiceTypePropertiesAccountKey
    :param service_principal_id: The ID of the application used to authenticate against the Azure
     Data Lake Storage Gen2 account. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureBlobFSLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureBlobFSLinkedServiceTypePropertiesTenant
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureBlobFSLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'url': {'key': 'typeProperties.url', 'type': 'AzureBlobFSLinkedServiceTypePropertiesUrl'},
        'account_key': {'key': 'typeProperties.accountKey', 'type': 'AzureBlobFSLinkedServiceTypePropertiesAccountKey'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'AzureBlobFSLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'AzureBlobFSLinkedServiceTypePropertiesTenant'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzureBlobFSLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        url: "AzureBlobFSLinkedServiceTypePropertiesUrl",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        account_key: Optional["AzureBlobFSLinkedServiceTypePropertiesAccountKey"] = None,
        service_principal_id: Optional["AzureBlobFSLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureBlobFSLinkedServiceTypePropertiesTenant"] = None,
        encrypted_credential: Optional["AzureBlobFSLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureBlobFSLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureBlobFS'
        self.url = url
        self.account_key = account_key
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential


class AzureBlobFSLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure Data Lake Storage Gen2 linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param url: Required. Endpoint for the Azure Data Lake Storage Gen2 service. Type: string (or
     Expression with resultType string).
    :type url: ~data_factory_management_client.models.AzureBlobFSLinkedServiceTypePropertiesUrl
    :param account_key: Account key for the Azure Data Lake Storage Gen2 service. Type: string (or
     Expression with resultType string).
    :type account_key:
     ~data_factory_management_client.models.AzureBlobFSLinkedServiceTypePropertiesAccountKey
    :param service_principal_id: The ID of the application used to authenticate against the Azure
     Data Lake Storage Gen2 account. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureBlobFSLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureBlobFSLinkedServiceTypePropertiesTenant
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureBlobFSLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'url': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'AzureBlobFSLinkedServiceTypePropertiesUrl'},
        'account_key': {'key': 'accountKey', 'type': 'AzureBlobFSLinkedServiceTypePropertiesAccountKey'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'AzureBlobFSLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'tenant', 'type': 'AzureBlobFSLinkedServiceTypePropertiesTenant'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzureBlobFSLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        url: "AzureBlobFSLinkedServiceTypePropertiesUrl",
        account_key: Optional["AzureBlobFSLinkedServiceTypePropertiesAccountKey"] = None,
        service_principal_id: Optional["AzureBlobFSLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureBlobFSLinkedServiceTypePropertiesTenant"] = None,
        encrypted_credential: Optional["AzureBlobFSLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureBlobFSLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.url = url
        self.account_key = account_key
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential


class AzureBlobFSLinkedServiceTypePropertiesAccountKey(msrest.serialization.Model):
    """Account key for the Azure Data Lake Storage Gen2 service. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSLinkedServiceTypePropertiesAccountKey, self).__init__(**kwargs)


class AzureBlobFSLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzureBlobFSLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """The ID of the application used to authenticate against the Azure Data Lake Storage Gen2 account. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class AzureBlobFSLinkedServiceTypePropertiesTenant(msrest.serialization.Model):
    """The name or ID of the tenant to which the service principal belongs. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSLinkedServiceTypePropertiesTenant, self).__init__(**kwargs)


class AzureBlobFSLinkedServiceTypePropertiesUrl(msrest.serialization.Model):
    """Endpoint for the Azure Data Lake Storage Gen2 service. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSLinkedServiceTypePropertiesUrl, self).__init__(**kwargs)


class AzureBlobFSLocation(DatasetLocation):
    """The location of azure blobFS dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage location.Constant filled by server.
    :type type: str
    :param folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :type folder_path: ~data_factory_management_client.models.DatasetLocationFolderPath
    :param file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :type file_name: ~data_factory_management_client.models.DatasetLocationFileName
    :param file_system: Specify the fileSystem of azure blobFS. Type: string (or Expression with
     resultType string).
    :type file_system: ~data_factory_management_client.models.AzureBlobFSLocationFileSystem
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'DatasetLocationFolderPath'},
        'file_name': {'key': 'fileName', 'type': 'DatasetLocationFileName'},
        'file_system': {'key': 'fileSystem', 'type': 'AzureBlobFSLocationFileSystem'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        folder_path: Optional["DatasetLocationFolderPath"] = None,
        file_name: Optional["DatasetLocationFileName"] = None,
        file_system: Optional["AzureBlobFSLocationFileSystem"] = None,
        **kwargs
    ):
        super(AzureBlobFSLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'AzureBlobFSLocation'
        self.file_system = file_system


class AzureBlobFSLocationFileSystem(msrest.serialization.Model):
    """Specify the fileSystem of azure blobFS. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSLocationFileSystem, self).__init__(**kwargs)


class AzureBlobFSReadSettings(StoreReadSettings):
    """Azure blobFS read settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The read setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreReadSettingsMaxConcurrentConnections
    :param recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.AzureBlobFSReadSettingsRecursive
    :param wildcard_folder_path: Azure blobFS wildcardFolderPath. Type: string (or Expression with
     resultType string).
    :type wildcard_folder_path:
     ~data_factory_management_client.models.AzureBlobFSReadSettingsWildcardFolderPath
    :param wildcard_file_name: Azure blobFS wildcardFileName. Type: string (or Expression with
     resultType string).
    :type wildcard_file_name:
     ~data_factory_management_client.models.AzureBlobFSReadSettingsWildcardFileName
    :param file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :type file_list_path:
     ~data_factory_management_client.models.AzureBlobFSReadSettingsFileListPath
    :param enable_partition_discovery: Indicates whether to enable partition discovery.
    :type enable_partition_discovery: bool
    :param modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_start:
     ~data_factory_management_client.models.AzureBlobFSReadSettingsModifiedDatetimeStart
    :param modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :type modified_datetime_end:
     ~data_factory_management_client.models.AzureBlobFSReadSettingsModifiedDatetimeEnd
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreReadSettingsMaxConcurrentConnections'},
        'recursive': {'key': 'recursive', 'type': 'AzureBlobFSReadSettingsRecursive'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'AzureBlobFSReadSettingsWildcardFolderPath'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'AzureBlobFSReadSettingsWildcardFileName'},
        'file_list_path': {'key': 'fileListPath', 'type': 'AzureBlobFSReadSettingsFileListPath'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'AzureBlobFSReadSettingsModifiedDatetimeStart'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'AzureBlobFSReadSettingsModifiedDatetimeEnd'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreReadSettingsMaxConcurrentConnections"] = None,
        recursive: Optional["AzureBlobFSReadSettingsRecursive"] = None,
        wildcard_folder_path: Optional["AzureBlobFSReadSettingsWildcardFolderPath"] = None,
        wildcard_file_name: Optional["AzureBlobFSReadSettingsWildcardFileName"] = None,
        file_list_path: Optional["AzureBlobFSReadSettingsFileListPath"] = None,
        enable_partition_discovery: Optional[bool] = None,
        modified_datetime_start: Optional["AzureBlobFSReadSettingsModifiedDatetimeStart"] = None,
        modified_datetime_end: Optional["AzureBlobFSReadSettingsModifiedDatetimeEnd"] = None,
        **kwargs
    ):
        super(AzureBlobFSReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzureBlobFSReadSettings'
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class AzureBlobFSReadSettingsFileListPath(msrest.serialization.Model):
    """Point to a text file that lists each file (relative path to the path configured in the dataset) that you want to copy. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSReadSettingsFileListPath, self).__init__(**kwargs)


class AzureBlobFSReadSettingsModifiedDatetimeEnd(msrest.serialization.Model):
    """The end of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSReadSettingsModifiedDatetimeEnd, self).__init__(**kwargs)


class AzureBlobFSReadSettingsModifiedDatetimeStart(msrest.serialization.Model):
    """The start of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSReadSettingsModifiedDatetimeStart, self).__init__(**kwargs)


class AzureBlobFSReadSettingsRecursive(msrest.serialization.Model):
    """If true, files under the folder path will be read recursively. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSReadSettingsRecursive, self).__init__(**kwargs)


class AzureBlobFSReadSettingsWildcardFileName(msrest.serialization.Model):
    """Azure blobFS wildcardFileName. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSReadSettingsWildcardFileName, self).__init__(**kwargs)


class AzureBlobFSReadSettingsWildcardFolderPath(msrest.serialization.Model):
    """Azure blobFS wildcardFolderPath. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSReadSettingsWildcardFolderPath, self).__init__(**kwargs)


class AzureBlobFSSink(CopySink):
    """A copy activity Azure Data Lake Storage Gen2 sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param copy_behavior: The type of copy behavior for copy sink.
    :type copy_behavior: ~data_factory_management_client.models.AzureBlobFSSinkCopyBehavior
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'AzureBlobFSSinkCopyBehavior'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        copy_behavior: Optional["AzureBlobFSSinkCopyBehavior"] = None,
        **kwargs
    ):
        super(AzureBlobFSSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzureBlobFSSink'
        self.copy_behavior = copy_behavior


class AzureBlobFSSinkCopyBehavior(msrest.serialization.Model):
    """The type of copy behavior for copy sink.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSSinkCopyBehavior, self).__init__(**kwargs)


class AzureBlobFSSource(CopySource):
    """A copy activity Azure BlobFS source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param treat_empty_as_null: Treat empty as null. Type: boolean (or Expression with resultType
     boolean).
    :type treat_empty_as_null:
     ~data_factory_management_client.models.AzureBlobFSSourceTreatEmptyAsNull
    :param skip_header_line_count: Number of header lines to skip from each blob. Type: integer (or
     Expression with resultType integer).
    :type skip_header_line_count:
     ~data_factory_management_client.models.AzureBlobFSSourceSkipHeaderLineCount
    :param recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.AzureBlobFSSourceRecursive
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'treat_empty_as_null': {'key': 'treatEmptyAsNull', 'type': 'AzureBlobFSSourceTreatEmptyAsNull'},
        'skip_header_line_count': {'key': 'skipHeaderLineCount', 'type': 'AzureBlobFSSourceSkipHeaderLineCount'},
        'recursive': {'key': 'recursive', 'type': 'AzureBlobFSSourceRecursive'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        treat_empty_as_null: Optional["AzureBlobFSSourceTreatEmptyAsNull"] = None,
        skip_header_line_count: Optional["AzureBlobFSSourceSkipHeaderLineCount"] = None,
        recursive: Optional["AzureBlobFSSourceRecursive"] = None,
        **kwargs
    ):
        super(AzureBlobFSSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzureBlobFSSource'
        self.treat_empty_as_null = treat_empty_as_null
        self.skip_header_line_count = skip_header_line_count
        self.recursive = recursive


class AzureBlobFSSourceRecursive(msrest.serialization.Model):
    """If true, files under the folder path will be read recursively. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSSourceRecursive, self).__init__(**kwargs)


class AzureBlobFSSourceSkipHeaderLineCount(msrest.serialization.Model):
    """Number of header lines to skip from each blob. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSSourceSkipHeaderLineCount, self).__init__(**kwargs)


class AzureBlobFSSourceTreatEmptyAsNull(msrest.serialization.Model):
    """Treat empty as null. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSSourceTreatEmptyAsNull, self).__init__(**kwargs)


class StoreWriteSettings(msrest.serialization.Model):
    """Connector write settings.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AzureBlobFSWriteSettings, AzureBlobStorageWriteSettings, AzureDataLakeStoreWriteSettings, FileServerWriteSettings, SftpWriteSettings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The write setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreWriteSettingsMaxConcurrentConnections
    :param copy_behavior: The type of copy behavior for copy sink.
    :type copy_behavior: ~data_factory_management_client.models.StoreWriteSettingsCopyBehavior
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreWriteSettingsMaxConcurrentConnections'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'StoreWriteSettingsCopyBehavior'},
    }

    _subtype_map = {
        'type': {'AzureBlobFSWriteSettings': 'AzureBlobFSWriteSettings', 'AzureBlobStorageWriteSettings': 'AzureBlobStorageWriteSettings', 'AzureDataLakeStoreWriteSettings': 'AzureDataLakeStoreWriteSettings', 'FileServerWriteSettings': 'FileServerWriteSettings', 'SftpWriteSettings': 'SftpWriteSettings'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreWriteSettingsMaxConcurrentConnections"] = None,
        copy_behavior: Optional["StoreWriteSettingsCopyBehavior"] = None,
        **kwargs
    ):
        super(StoreWriteSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'StoreWriteSettings'
        self.max_concurrent_connections = max_concurrent_connections
        self.copy_behavior = copy_behavior


class AzureBlobFSWriteSettings(StoreWriteSettings):
    """Azure blobFS write settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The write setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreWriteSettingsMaxConcurrentConnections
    :param copy_behavior: The type of copy behavior for copy sink.
    :type copy_behavior: ~data_factory_management_client.models.StoreWriteSettingsCopyBehavior
    :param block_size_in_mb: Indicates the block size(MB) when writing data to blob. Type: integer
     (or Expression with resultType integer).
    :type block_size_in_mb:
     ~data_factory_management_client.models.AzureBlobFSWriteSettingsBlockSizeInMB
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreWriteSettingsMaxConcurrentConnections'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'StoreWriteSettingsCopyBehavior'},
        'block_size_in_mb': {'key': 'blockSizeInMB', 'type': 'AzureBlobFSWriteSettingsBlockSizeInMB'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreWriteSettingsMaxConcurrentConnections"] = None,
        copy_behavior: Optional["StoreWriteSettingsCopyBehavior"] = None,
        block_size_in_mb: Optional["AzureBlobFSWriteSettingsBlockSizeInMB"] = None,
        **kwargs
    ):
        super(AzureBlobFSWriteSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, copy_behavior=copy_behavior, **kwargs)
        self.type = 'AzureBlobFSWriteSettings'
        self.block_size_in_mb = block_size_in_mb


class AzureBlobFSWriteSettingsBlockSizeInMB(msrest.serialization.Model):
    """Indicates the block size(MB) when writing data to blob. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobFSWriteSettingsBlockSizeInMB, self).__init__(**kwargs)


class AzureBlobStorageLinkedService(LinkedService):
    """The azure blob storage linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: The connection string. It is mutually exclusive with sasUri,
     serviceEndpoint property. Type: string, SecureString or AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzureBlobStorageLinkedServiceTypePropertiesConnectionString
    :param account_key: Azure Key Vault secret reference.
    :type account_key: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param sas_uri: SAS URI of the Azure Blob Storage resource. It is mutually exclusive with
     connectionString, serviceEndpoint property. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type sas_uri:
     ~data_factory_management_client.models.AzureBlobStorageLinkedServiceTypePropertiesSasUri
    :param sas_token: Azure Key Vault secret reference.
    :type sas_token: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param service_endpoint: Blob service endpoint of the Azure Blob Storage resource. It is
     mutually exclusive with connectionString, sasUri property.
    :type service_endpoint: str
    :param service_principal_id: The ID of the service principal used to authenticate against Azure
     SQL Data Warehouse. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureBlobStorageLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureBlobStorageLinkedServiceTypePropertiesTenant
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'AzureBlobStorageLinkedServiceTypePropertiesConnectionString'},
        'account_key': {'key': 'typeProperties.accountKey', 'type': 'AzureKeyVaultSecretReference'},
        'sas_uri': {'key': 'typeProperties.sasUri', 'type': 'AzureBlobStorageLinkedServiceTypePropertiesSasUri'},
        'sas_token': {'key': 'typeProperties.sasToken', 'type': 'AzureKeyVaultSecretReference'},
        'service_endpoint': {'key': 'typeProperties.serviceEndpoint', 'type': 'str'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'AzureBlobStorageLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'AzureBlobStorageLinkedServiceTypePropertiesTenant'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        connection_string: Optional["AzureBlobStorageLinkedServiceTypePropertiesConnectionString"] = None,
        account_key: Optional["AzureKeyVaultSecretReference"] = None,
        sas_uri: Optional["AzureBlobStorageLinkedServiceTypePropertiesSasUri"] = None,
        sas_token: Optional["AzureKeyVaultSecretReference"] = None,
        service_endpoint: Optional[str] = None,
        service_principal_id: Optional["AzureBlobStorageLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureBlobStorageLinkedServiceTypePropertiesTenant"] = None,
        encrypted_credential: Optional[str] = None,
        **kwargs
    ):
        super(AzureBlobStorageLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureBlobStorage'
        self.connection_string = connection_string
        self.account_key = account_key
        self.sas_uri = sas_uri
        self.sas_token = sas_token
        self.service_endpoint = service_endpoint
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential


class AzureBlobStorageLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure Blob Storage linked service properties.

    :param connection_string: The connection string. It is mutually exclusive with sasUri,
     serviceEndpoint property. Type: string, SecureString or AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzureBlobStorageLinkedServiceTypePropertiesConnectionString
    :param account_key: Azure Key Vault secret reference.
    :type account_key: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param sas_uri: SAS URI of the Azure Blob Storage resource. It is mutually exclusive with
     connectionString, serviceEndpoint property. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type sas_uri:
     ~data_factory_management_client.models.AzureBlobStorageLinkedServiceTypePropertiesSasUri
    :param sas_token: Azure Key Vault secret reference.
    :type sas_token: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param service_endpoint: Blob service endpoint of the Azure Blob Storage resource. It is
     mutually exclusive with connectionString, sasUri property.
    :type service_endpoint: str
    :param service_principal_id: The ID of the service principal used to authenticate against Azure
     SQL Data Warehouse. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureBlobStorageLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureBlobStorageLinkedServiceTypePropertiesTenant
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential: str
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'AzureBlobStorageLinkedServiceTypePropertiesConnectionString'},
        'account_key': {'key': 'accountKey', 'type': 'AzureKeyVaultSecretReference'},
        'sas_uri': {'key': 'sasUri', 'type': 'AzureBlobStorageLinkedServiceTypePropertiesSasUri'},
        'sas_token': {'key': 'sasToken', 'type': 'AzureKeyVaultSecretReference'},
        'service_endpoint': {'key': 'serviceEndpoint', 'type': 'str'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'AzureBlobStorageLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'tenant', 'type': 'AzureBlobStorageLinkedServiceTypePropertiesTenant'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional["AzureBlobStorageLinkedServiceTypePropertiesConnectionString"] = None,
        account_key: Optional["AzureKeyVaultSecretReference"] = None,
        sas_uri: Optional["AzureBlobStorageLinkedServiceTypePropertiesSasUri"] = None,
        sas_token: Optional["AzureKeyVaultSecretReference"] = None,
        service_endpoint: Optional[str] = None,
        service_principal_id: Optional["AzureBlobStorageLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureBlobStorageLinkedServiceTypePropertiesTenant"] = None,
        encrypted_credential: Optional[str] = None,
        **kwargs
    ):
        super(AzureBlobStorageLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.account_key = account_key
        self.sas_uri = sas_uri
        self.sas_token = sas_token
        self.service_endpoint = service_endpoint
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential


class AzureBlobStorageLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The connection string. It is mutually exclusive with sasUri, serviceEndpoint property. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobStorageLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class AzureBlobStorageLinkedServiceTypePropertiesSasUri(msrest.serialization.Model):
    """SAS URI of the Azure Blob Storage resource. It is mutually exclusive with connectionString, serviceEndpoint property. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobStorageLinkedServiceTypePropertiesSasUri, self).__init__(**kwargs)


class AzureBlobStorageLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """The ID of the service principal used to authenticate against Azure SQL Data Warehouse. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobStorageLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class AzureBlobStorageLinkedServiceTypePropertiesTenant(msrest.serialization.Model):
    """The name or ID of the tenant to which the service principal belongs. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobStorageLinkedServiceTypePropertiesTenant, self).__init__(**kwargs)


class AzureBlobStorageLocation(DatasetLocation):
    """The location of azure blob dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage location.Constant filled by server.
    :type type: str
    :param folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :type folder_path: ~data_factory_management_client.models.DatasetLocationFolderPath
    :param file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :type file_name: ~data_factory_management_client.models.DatasetLocationFileName
    :param container: Specify the container of azure blob. Type: string (or Expression with
     resultType string).
    :type container: ~data_factory_management_client.models.AzureBlobStorageLocationContainer
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'DatasetLocationFolderPath'},
        'file_name': {'key': 'fileName', 'type': 'DatasetLocationFileName'},
        'container': {'key': 'container', 'type': 'AzureBlobStorageLocationContainer'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        folder_path: Optional["DatasetLocationFolderPath"] = None,
        file_name: Optional["DatasetLocationFileName"] = None,
        container: Optional["AzureBlobStorageLocationContainer"] = None,
        **kwargs
    ):
        super(AzureBlobStorageLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'AzureBlobStorageLocation'
        self.container = container


class AzureBlobStorageLocationContainer(msrest.serialization.Model):
    """Specify the container of azure blob. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobStorageLocationContainer, self).__init__(**kwargs)


class AzureBlobStorageReadSettings(StoreReadSettings):
    """Azure blob read settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The read setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreReadSettingsMaxConcurrentConnections
    :param recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.AzureBlobStorageReadSettingsRecursive
    :param wildcard_folder_path: Azure blob wildcardFolderPath. Type: string (or Expression with
     resultType string).
    :type wildcard_folder_path:
     ~data_factory_management_client.models.AzureBlobStorageReadSettingsWildcardFolderPath
    :param wildcard_file_name: Azure blob wildcardFileName. Type: string (or Expression with
     resultType string).
    :type wildcard_file_name:
     ~data_factory_management_client.models.AzureBlobStorageReadSettingsWildcardFileName
    :param prefix: The prefix filter for the Azure Blob name. Type: string (or Expression with
     resultType string).
    :type prefix: ~data_factory_management_client.models.AzureBlobStorageReadSettingsPrefix
    :param file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :type file_list_path:
     ~data_factory_management_client.models.AzureBlobStorageReadSettingsFileListPath
    :param enable_partition_discovery: Indicates whether to enable partition discovery.
    :type enable_partition_discovery: bool
    :param modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_start:
     ~data_factory_management_client.models.AzureBlobStorageReadSettingsModifiedDatetimeStart
    :param modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :type modified_datetime_end:
     ~data_factory_management_client.models.AzureBlobStorageReadSettingsModifiedDatetimeEnd
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreReadSettingsMaxConcurrentConnections'},
        'recursive': {'key': 'recursive', 'type': 'AzureBlobStorageReadSettingsRecursive'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'AzureBlobStorageReadSettingsWildcardFolderPath'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'AzureBlobStorageReadSettingsWildcardFileName'},
        'prefix': {'key': 'prefix', 'type': 'AzureBlobStorageReadSettingsPrefix'},
        'file_list_path': {'key': 'fileListPath', 'type': 'AzureBlobStorageReadSettingsFileListPath'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'AzureBlobStorageReadSettingsModifiedDatetimeStart'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'AzureBlobStorageReadSettingsModifiedDatetimeEnd'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreReadSettingsMaxConcurrentConnections"] = None,
        recursive: Optional["AzureBlobStorageReadSettingsRecursive"] = None,
        wildcard_folder_path: Optional["AzureBlobStorageReadSettingsWildcardFolderPath"] = None,
        wildcard_file_name: Optional["AzureBlobStorageReadSettingsWildcardFileName"] = None,
        prefix: Optional["AzureBlobStorageReadSettingsPrefix"] = None,
        file_list_path: Optional["AzureBlobStorageReadSettingsFileListPath"] = None,
        enable_partition_discovery: Optional[bool] = None,
        modified_datetime_start: Optional["AzureBlobStorageReadSettingsModifiedDatetimeStart"] = None,
        modified_datetime_end: Optional["AzureBlobStorageReadSettingsModifiedDatetimeEnd"] = None,
        **kwargs
    ):
        super(AzureBlobStorageReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzureBlobStorageReadSettings'
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.prefix = prefix
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class AzureBlobStorageReadSettingsFileListPath(msrest.serialization.Model):
    """Point to a text file that lists each file (relative path to the path configured in the dataset) that you want to copy. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobStorageReadSettingsFileListPath, self).__init__(**kwargs)


class AzureBlobStorageReadSettingsModifiedDatetimeEnd(msrest.serialization.Model):
    """The end of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobStorageReadSettingsModifiedDatetimeEnd, self).__init__(**kwargs)


class AzureBlobStorageReadSettingsModifiedDatetimeStart(msrest.serialization.Model):
    """The start of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobStorageReadSettingsModifiedDatetimeStart, self).__init__(**kwargs)


class AzureBlobStorageReadSettingsPrefix(msrest.serialization.Model):
    """The prefix filter for the Azure Blob name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobStorageReadSettingsPrefix, self).__init__(**kwargs)


class AzureBlobStorageReadSettingsRecursive(msrest.serialization.Model):
    """If true, files under the folder path will be read recursively. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobStorageReadSettingsRecursive, self).__init__(**kwargs)


class AzureBlobStorageReadSettingsWildcardFileName(msrest.serialization.Model):
    """Azure blob wildcardFileName. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobStorageReadSettingsWildcardFileName, self).__init__(**kwargs)


class AzureBlobStorageReadSettingsWildcardFolderPath(msrest.serialization.Model):
    """Azure blob wildcardFolderPath. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobStorageReadSettingsWildcardFolderPath, self).__init__(**kwargs)


class AzureBlobStorageWriteSettings(StoreWriteSettings):
    """Azure blob write settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The write setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreWriteSettingsMaxConcurrentConnections
    :param copy_behavior: The type of copy behavior for copy sink.
    :type copy_behavior: ~data_factory_management_client.models.StoreWriteSettingsCopyBehavior
    :param block_size_in_mb: Indicates the block size(MB) when writing data to blob. Type: integer
     (or Expression with resultType integer).
    :type block_size_in_mb:
     ~data_factory_management_client.models.AzureBlobStorageWriteSettingsBlockSizeInMB
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreWriteSettingsMaxConcurrentConnections'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'StoreWriteSettingsCopyBehavior'},
        'block_size_in_mb': {'key': 'blockSizeInMB', 'type': 'AzureBlobStorageWriteSettingsBlockSizeInMB'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreWriteSettingsMaxConcurrentConnections"] = None,
        copy_behavior: Optional["StoreWriteSettingsCopyBehavior"] = None,
        block_size_in_mb: Optional["AzureBlobStorageWriteSettingsBlockSizeInMB"] = None,
        **kwargs
    ):
        super(AzureBlobStorageWriteSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, copy_behavior=copy_behavior, **kwargs)
        self.type = 'AzureBlobStorageWriteSettings'
        self.block_size_in_mb = block_size_in_mb


class AzureBlobStorageWriteSettingsBlockSizeInMB(msrest.serialization.Model):
    """Indicates the block size(MB) when writing data to blob. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureBlobStorageWriteSettingsBlockSizeInMB, self).__init__(**kwargs)


class AzureDatabricksLinkedService(LinkedService):
    """Azure Databricks linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param domain: Required. :code:`<REGION>`.azuredatabricks.net, domain name of your Databricks
     deployment. Type: string (or Expression with resultType string).
    :type domain:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesDomain
    :param access_token: Required. The base definition of a secret type.
    :type access_token: ~data_factory_management_client.models.SecretBase
    :param existing_cluster_id: The id of an existing interactive cluster that will be used for all
     runs of this activity. Type: string (or Expression with resultType string).
    :type existing_cluster_id:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesExistingClusterId
    :param instance_pool_id: The id of an existing instance pool that will be used for all runs of
     this activity. Type: string (or Expression with resultType string).
    :type instance_pool_id:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesInstancePoolId
    :param new_cluster_version: If not using an existing interactive cluster, this specifies the
     Spark version of a new job cluster or instance pool nodes created for each run of this
     activity. Required if instancePoolId is specified. Type: string (or Expression with resultType
     string).
    :type new_cluster_version:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesNewClusterVersion
    :param new_cluster_num_of_worker: If not using an existing interactive cluster, this specifies
     the number of worker nodes to use for the new job cluster or instance pool. For new job
     clusters, this a string-formatted Int32, like '1' means numOfWorker is 1 or '1:10' means auto-
     scale from 1 (min) to 10 (max). For instance pools, this is a string-formatted Int32, and can
     only specify a fixed number of worker nodes, such as '2'. Required if newClusterVersion is
     specified. Type: string (or Expression with resultType string).
    :type new_cluster_num_of_worker:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesNewClusterNumOfWorker
    :param new_cluster_node_type: The node type of the new job cluster. This property is required
     if newClusterVersion is specified and instancePoolId is not specified. If instancePoolId is
     specified, this property is ignored. Type: string (or Expression with resultType string).
    :type new_cluster_node_type:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesNewClusterNodeType
    :param new_cluster_spark_conf: A set of optional, user-specified Spark configuration key-value
     pairs.
    :type new_cluster_spark_conf: dict[str, object]
    :param new_cluster_spark_env_vars: A set of optional, user-specified Spark environment
     variables key-value pairs.
    :type new_cluster_spark_env_vars: dict[str, object]
    :param new_cluster_custom_tags: Additional tags for cluster resources. This property is ignored
     in instance pool configurations.
    :type new_cluster_custom_tags: dict[str, object]
    :param new_cluster_driver_node_type: The driver node type for the new job cluster. This
     property is ignored in instance pool configurations. Type: string (or Expression with
     resultType string).
    :type new_cluster_driver_node_type:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesNewClusterDriverNodeType
    :param new_cluster_init_scripts: User-defined initialization scripts for the new cluster. Type:
     array of strings (or Expression with resultType array of strings).
    :type new_cluster_init_scripts:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesNewClusterInitScripts
    :param new_cluster_enable_elastic_disk: Enable the elastic disk on the new cluster. This
     property is now ignored, and takes the default elastic disk behavior in Databricks (elastic
     disks are always enabled). Type: boolean (or Expression with resultType boolean).
    :type new_cluster_enable_elastic_disk:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesNewClusterEnableElasticDisk
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'domain': {'required': True},
        'access_token': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'domain': {'key': 'typeProperties.domain', 'type': 'AzureDatabricksLinkedServiceTypePropertiesDomain'},
        'access_token': {'key': 'typeProperties.accessToken', 'type': 'SecretBase'},
        'existing_cluster_id': {'key': 'typeProperties.existingClusterId', 'type': 'AzureDatabricksLinkedServiceTypePropertiesExistingClusterId'},
        'instance_pool_id': {'key': 'typeProperties.instancePoolId', 'type': 'AzureDatabricksLinkedServiceTypePropertiesInstancePoolId'},
        'new_cluster_version': {'key': 'typeProperties.newClusterVersion', 'type': 'AzureDatabricksLinkedServiceTypePropertiesNewClusterVersion'},
        'new_cluster_num_of_worker': {'key': 'typeProperties.newClusterNumOfWorker', 'type': 'AzureDatabricksLinkedServiceTypePropertiesNewClusterNumOfWorker'},
        'new_cluster_node_type': {'key': 'typeProperties.newClusterNodeType', 'type': 'AzureDatabricksLinkedServiceTypePropertiesNewClusterNodeType'},
        'new_cluster_spark_conf': {'key': 'typeProperties.newClusterSparkConf', 'type': '{object}'},
        'new_cluster_spark_env_vars': {'key': 'typeProperties.newClusterSparkEnvVars', 'type': '{object}'},
        'new_cluster_custom_tags': {'key': 'typeProperties.newClusterCustomTags', 'type': '{object}'},
        'new_cluster_driver_node_type': {'key': 'typeProperties.newClusterDriverNodeType', 'type': 'AzureDatabricksLinkedServiceTypePropertiesNewClusterDriverNodeType'},
        'new_cluster_init_scripts': {'key': 'typeProperties.newClusterInitScripts', 'type': 'AzureDatabricksLinkedServiceTypePropertiesNewClusterInitScripts'},
        'new_cluster_enable_elastic_disk': {'key': 'typeProperties.newClusterEnableElasticDisk', 'type': 'AzureDatabricksLinkedServiceTypePropertiesNewClusterEnableElasticDisk'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzureDatabricksLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        domain: "AzureDatabricksLinkedServiceTypePropertiesDomain",
        access_token: "SecretBase",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        existing_cluster_id: Optional["AzureDatabricksLinkedServiceTypePropertiesExistingClusterId"] = None,
        instance_pool_id: Optional["AzureDatabricksLinkedServiceTypePropertiesInstancePoolId"] = None,
        new_cluster_version: Optional["AzureDatabricksLinkedServiceTypePropertiesNewClusterVersion"] = None,
        new_cluster_num_of_worker: Optional["AzureDatabricksLinkedServiceTypePropertiesNewClusterNumOfWorker"] = None,
        new_cluster_node_type: Optional["AzureDatabricksLinkedServiceTypePropertiesNewClusterNodeType"] = None,
        new_cluster_spark_conf: Optional[Dict[str, object]] = None,
        new_cluster_spark_env_vars: Optional[Dict[str, object]] = None,
        new_cluster_custom_tags: Optional[Dict[str, object]] = None,
        new_cluster_driver_node_type: Optional["AzureDatabricksLinkedServiceTypePropertiesNewClusterDriverNodeType"] = None,
        new_cluster_init_scripts: Optional["AzureDatabricksLinkedServiceTypePropertiesNewClusterInitScripts"] = None,
        new_cluster_enable_elastic_disk: Optional["AzureDatabricksLinkedServiceTypePropertiesNewClusterEnableElasticDisk"] = None,
        encrypted_credential: Optional["AzureDatabricksLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureDatabricksLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureDatabricks'
        self.domain = domain
        self.access_token = access_token
        self.existing_cluster_id = existing_cluster_id
        self.instance_pool_id = instance_pool_id
        self.new_cluster_version = new_cluster_version
        self.new_cluster_num_of_worker = new_cluster_num_of_worker
        self.new_cluster_node_type = new_cluster_node_type
        self.new_cluster_spark_conf = new_cluster_spark_conf
        self.new_cluster_spark_env_vars = new_cluster_spark_env_vars
        self.new_cluster_custom_tags = new_cluster_custom_tags
        self.new_cluster_driver_node_type = new_cluster_driver_node_type
        self.new_cluster_init_scripts = new_cluster_init_scripts
        self.new_cluster_enable_elastic_disk = new_cluster_enable_elastic_disk
        self.encrypted_credential = encrypted_credential


class AzureDatabricksLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure Databricks linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param domain: Required. :code:`<REGION>`.azuredatabricks.net, domain name of your Databricks
     deployment. Type: string (or Expression with resultType string).
    :type domain:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesDomain
    :param access_token: Required. The base definition of a secret type.
    :type access_token: ~data_factory_management_client.models.SecretBase
    :param existing_cluster_id: The id of an existing interactive cluster that will be used for all
     runs of this activity. Type: string (or Expression with resultType string).
    :type existing_cluster_id:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesExistingClusterId
    :param instance_pool_id: The id of an existing instance pool that will be used for all runs of
     this activity. Type: string (or Expression with resultType string).
    :type instance_pool_id:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesInstancePoolId
    :param new_cluster_version: If not using an existing interactive cluster, this specifies the
     Spark version of a new job cluster or instance pool nodes created for each run of this
     activity. Required if instancePoolId is specified. Type: string (or Expression with resultType
     string).
    :type new_cluster_version:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesNewClusterVersion
    :param new_cluster_num_of_worker: If not using an existing interactive cluster, this specifies
     the number of worker nodes to use for the new job cluster or instance pool. For new job
     clusters, this a string-formatted Int32, like '1' means numOfWorker is 1 or '1:10' means auto-
     scale from 1 (min) to 10 (max). For instance pools, this is a string-formatted Int32, and can
     only specify a fixed number of worker nodes, such as '2'. Required if newClusterVersion is
     specified. Type: string (or Expression with resultType string).
    :type new_cluster_num_of_worker:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesNewClusterNumOfWorker
    :param new_cluster_node_type: The node type of the new job cluster. This property is required
     if newClusterVersion is specified and instancePoolId is not specified. If instancePoolId is
     specified, this property is ignored. Type: string (or Expression with resultType string).
    :type new_cluster_node_type:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesNewClusterNodeType
    :param new_cluster_spark_conf: A set of optional, user-specified Spark configuration key-value
     pairs.
    :type new_cluster_spark_conf: dict[str, object]
    :param new_cluster_spark_env_vars: A set of optional, user-specified Spark environment
     variables key-value pairs.
    :type new_cluster_spark_env_vars: dict[str, object]
    :param new_cluster_custom_tags: Additional tags for cluster resources. This property is ignored
     in instance pool configurations.
    :type new_cluster_custom_tags: dict[str, object]
    :param new_cluster_driver_node_type: The driver node type for the new job cluster. This
     property is ignored in instance pool configurations. Type: string (or Expression with
     resultType string).
    :type new_cluster_driver_node_type:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesNewClusterDriverNodeType
    :param new_cluster_init_scripts: User-defined initialization scripts for the new cluster. Type:
     array of strings (or Expression with resultType array of strings).
    :type new_cluster_init_scripts:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesNewClusterInitScripts
    :param new_cluster_enable_elastic_disk: Enable the elastic disk on the new cluster. This
     property is now ignored, and takes the default elastic disk behavior in Databricks (elastic
     disks are always enabled). Type: boolean (or Expression with resultType boolean).
    :type new_cluster_enable_elastic_disk:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesNewClusterEnableElasticDisk
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureDatabricksLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'domain': {'required': True},
        'access_token': {'required': True},
    }

    _attribute_map = {
        'domain': {'key': 'domain', 'type': 'AzureDatabricksLinkedServiceTypePropertiesDomain'},
        'access_token': {'key': 'accessToken', 'type': 'SecretBase'},
        'existing_cluster_id': {'key': 'existingClusterId', 'type': 'AzureDatabricksLinkedServiceTypePropertiesExistingClusterId'},
        'instance_pool_id': {'key': 'instancePoolId', 'type': 'AzureDatabricksLinkedServiceTypePropertiesInstancePoolId'},
        'new_cluster_version': {'key': 'newClusterVersion', 'type': 'AzureDatabricksLinkedServiceTypePropertiesNewClusterVersion'},
        'new_cluster_num_of_worker': {'key': 'newClusterNumOfWorker', 'type': 'AzureDatabricksLinkedServiceTypePropertiesNewClusterNumOfWorker'},
        'new_cluster_node_type': {'key': 'newClusterNodeType', 'type': 'AzureDatabricksLinkedServiceTypePropertiesNewClusterNodeType'},
        'new_cluster_spark_conf': {'key': 'newClusterSparkConf', 'type': '{object}'},
        'new_cluster_spark_env_vars': {'key': 'newClusterSparkEnvVars', 'type': '{object}'},
        'new_cluster_custom_tags': {'key': 'newClusterCustomTags', 'type': '{object}'},
        'new_cluster_driver_node_type': {'key': 'newClusterDriverNodeType', 'type': 'AzureDatabricksLinkedServiceTypePropertiesNewClusterDriverNodeType'},
        'new_cluster_init_scripts': {'key': 'newClusterInitScripts', 'type': 'AzureDatabricksLinkedServiceTypePropertiesNewClusterInitScripts'},
        'new_cluster_enable_elastic_disk': {'key': 'newClusterEnableElasticDisk', 'type': 'AzureDatabricksLinkedServiceTypePropertiesNewClusterEnableElasticDisk'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzureDatabricksLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        domain: "AzureDatabricksLinkedServiceTypePropertiesDomain",
        access_token: "SecretBase",
        existing_cluster_id: Optional["AzureDatabricksLinkedServiceTypePropertiesExistingClusterId"] = None,
        instance_pool_id: Optional["AzureDatabricksLinkedServiceTypePropertiesInstancePoolId"] = None,
        new_cluster_version: Optional["AzureDatabricksLinkedServiceTypePropertiesNewClusterVersion"] = None,
        new_cluster_num_of_worker: Optional["AzureDatabricksLinkedServiceTypePropertiesNewClusterNumOfWorker"] = None,
        new_cluster_node_type: Optional["AzureDatabricksLinkedServiceTypePropertiesNewClusterNodeType"] = None,
        new_cluster_spark_conf: Optional[Dict[str, object]] = None,
        new_cluster_spark_env_vars: Optional[Dict[str, object]] = None,
        new_cluster_custom_tags: Optional[Dict[str, object]] = None,
        new_cluster_driver_node_type: Optional["AzureDatabricksLinkedServiceTypePropertiesNewClusterDriverNodeType"] = None,
        new_cluster_init_scripts: Optional["AzureDatabricksLinkedServiceTypePropertiesNewClusterInitScripts"] = None,
        new_cluster_enable_elastic_disk: Optional["AzureDatabricksLinkedServiceTypePropertiesNewClusterEnableElasticDisk"] = None,
        encrypted_credential: Optional["AzureDatabricksLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureDatabricksLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.domain = domain
        self.access_token = access_token
        self.existing_cluster_id = existing_cluster_id
        self.instance_pool_id = instance_pool_id
        self.new_cluster_version = new_cluster_version
        self.new_cluster_num_of_worker = new_cluster_num_of_worker
        self.new_cluster_node_type = new_cluster_node_type
        self.new_cluster_spark_conf = new_cluster_spark_conf
        self.new_cluster_spark_env_vars = new_cluster_spark_env_vars
        self.new_cluster_custom_tags = new_cluster_custom_tags
        self.new_cluster_driver_node_type = new_cluster_driver_node_type
        self.new_cluster_init_scripts = new_cluster_init_scripts
        self.new_cluster_enable_elastic_disk = new_cluster_enable_elastic_disk
        self.encrypted_credential = encrypted_credential


class AzureDatabricksLinkedServiceTypePropertiesDomain(msrest.serialization.Model):
    """:code:`<REGION>`.azuredatabricks.net, domain name of your Databricks deployment. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDatabricksLinkedServiceTypePropertiesDomain, self).__init__(**kwargs)


class AzureDatabricksLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDatabricksLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzureDatabricksLinkedServiceTypePropertiesExistingClusterId(msrest.serialization.Model):
    """The id of an existing interactive cluster that will be used for all runs of this activity. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDatabricksLinkedServiceTypePropertiesExistingClusterId, self).__init__(**kwargs)


class AzureDatabricksLinkedServiceTypePropertiesInstancePoolId(msrest.serialization.Model):
    """The id of an existing instance pool that will be used for all runs of this activity. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDatabricksLinkedServiceTypePropertiesInstancePoolId, self).__init__(**kwargs)


class AzureDatabricksLinkedServiceTypePropertiesNewClusterDriverNodeType(msrest.serialization.Model):
    """The driver node type for the new job cluster. This property is ignored in instance pool configurations. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDatabricksLinkedServiceTypePropertiesNewClusterDriverNodeType, self).__init__(**kwargs)


class AzureDatabricksLinkedServiceTypePropertiesNewClusterEnableElasticDisk(msrest.serialization.Model):
    """Enable the elastic disk on the new cluster. This property is now ignored, and takes the default elastic disk behavior in Databricks (elastic disks are always enabled). Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDatabricksLinkedServiceTypePropertiesNewClusterEnableElasticDisk, self).__init__(**kwargs)


class AzureDatabricksLinkedServiceTypePropertiesNewClusterInitScripts(msrest.serialization.Model):
    """User-defined initialization scripts for the new cluster. Type: array of strings (or Expression with resultType array of strings).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDatabricksLinkedServiceTypePropertiesNewClusterInitScripts, self).__init__(**kwargs)


class AzureDatabricksLinkedServiceTypePropertiesNewClusterNodeType(msrest.serialization.Model):
    """The node type of the new job cluster. This property is required if newClusterVersion is specified and instancePoolId is not specified. If instancePoolId is specified, this property is ignored. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDatabricksLinkedServiceTypePropertiesNewClusterNodeType, self).__init__(**kwargs)


class AzureDatabricksLinkedServiceTypePropertiesNewClusterNumOfWorker(msrest.serialization.Model):
    """If not using an existing interactive cluster, this specifies the number of worker nodes to use for the new job cluster or instance pool. For new job clusters, this a string-formatted Int32, like '1' means numOfWorker is 1 or '1:10' means auto-scale from 1 (min) to 10 (max). For instance pools, this is a string-formatted Int32, and can only specify a fixed number of worker nodes, such as '2'. Required if newClusterVersion is specified. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDatabricksLinkedServiceTypePropertiesNewClusterNumOfWorker, self).__init__(**kwargs)


class AzureDatabricksLinkedServiceTypePropertiesNewClusterVersion(msrest.serialization.Model):
    """If not using an existing interactive cluster, this specifies the Spark version of a new job cluster or instance pool nodes created for each run of this activity. Required if instancePoolId is specified. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDatabricksLinkedServiceTypePropertiesNewClusterVersion, self).__init__(**kwargs)


class ExecutionActivity(Activity):
    """Base class for all execution activities.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AzureDataExplorerCommandActivity, AzureFunctionActivity, AzureMLBatchExecutionActivity, AzureMLExecutePipelineActivity, AzureMLUpdateResourceActivity, CopyActivity, CustomActivity, DataLakeAnalyticsUSQLActivity, DatabricksNotebookActivity, DatabricksSparkJarActivity, DatabricksSparkPythonActivity, DeleteActivity, ExecuteDataFlowActivity, ExecuteSSISPackageActivity, GetMetadataActivity, HDInsightHiveActivity, HDInsightMapReduceActivity, HDInsightPigActivity, HDInsightSparkActivity, HDInsightStreamingActivity, LookupActivity, SqlServerStoredProcedureActivity, WebActivity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
    }

    _subtype_map = {
        'type': {'AzureDataExplorerCommand': 'AzureDataExplorerCommandActivity', 'AzureFunctionActivity': 'AzureFunctionActivity', 'AzureMLBatchExecution': 'AzureMLBatchExecutionActivity', 'AzureMLExecutePipeline': 'AzureMLExecutePipelineActivity', 'AzureMLUpdateResource': 'AzureMLUpdateResourceActivity', 'Copy': 'CopyActivity', 'Custom': 'CustomActivity', 'DataLakeAnalyticsU-SQL': 'DataLakeAnalyticsUSQLActivity', 'DatabricksNotebook': 'DatabricksNotebookActivity', 'DatabricksSparkJar': 'DatabricksSparkJarActivity', 'DatabricksSparkPython': 'DatabricksSparkPythonActivity', 'Delete': 'DeleteActivity', 'ExecuteDataFlow': 'ExecuteDataFlowActivity', 'ExecuteSSISPackage': 'ExecuteSSISPackageActivity', 'GetMetadata': 'GetMetadataActivity', 'HDInsightHive': 'HDInsightHiveActivity', 'HDInsightMapReduce': 'HDInsightMapReduceActivity', 'HDInsightPig': 'HDInsightPigActivity', 'HDInsightSpark': 'HDInsightSparkActivity', 'HDInsightStreaming': 'HDInsightStreamingActivity', 'Lookup': 'LookupActivity', 'SqlServerStoredProcedure': 'SqlServerStoredProcedureActivity', 'WebActivity': 'WebActivity'}
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        **kwargs
    ):
        super(ExecutionActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'Execution'
        self.linked_service_name = linked_service_name
        self.policy = policy


class AzureDataExplorerCommandActivity(ExecutionActivity):
    """Azure Data Explorer command activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param command: Required. A control command, according to the Azure Data Explorer command
     syntax. Type: string (or Expression with resultType string).
    :type command:
     ~data_factory_management_client.models.AzureDataExplorerCommandActivityTypePropertiesCommand
    :param command_timeout: Control command timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9]))..).
    :type command_timeout:
     ~data_factory_management_client.models.AzureDataExplorerCommandActivityTypePropertiesCommandTimeout
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'command': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'command': {'key': 'typeProperties.command', 'type': 'AzureDataExplorerCommandActivityTypePropertiesCommand'},
        'command_timeout': {'key': 'typeProperties.commandTimeout', 'type': 'AzureDataExplorerCommandActivityTypePropertiesCommandTimeout'},
    }

    def __init__(
        self,
        *,
        name: str,
        command: "AzureDataExplorerCommandActivityTypePropertiesCommand",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        command_timeout: Optional["AzureDataExplorerCommandActivityTypePropertiesCommandTimeout"] = None,
        **kwargs
    ):
        super(AzureDataExplorerCommandActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'AzureDataExplorerCommand'
        self.command = command
        self.command_timeout = command_timeout


class AzureDataExplorerCommandActivityTypeProperties(msrest.serialization.Model):
    """Azure Data Explorer command activity properties.

    All required parameters must be populated in order to send to Azure.

    :param command: Required. A control command, according to the Azure Data Explorer command
     syntax. Type: string (or Expression with resultType string).
    :type command:
     ~data_factory_management_client.models.AzureDataExplorerCommandActivityTypePropertiesCommand
    :param command_timeout: Control command timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9]))..).
    :type command_timeout:
     ~data_factory_management_client.models.AzureDataExplorerCommandActivityTypePropertiesCommandTimeout
    """

    _validation = {
        'command': {'required': True},
    }

    _attribute_map = {
        'command': {'key': 'command', 'type': 'AzureDataExplorerCommandActivityTypePropertiesCommand'},
        'command_timeout': {'key': 'commandTimeout', 'type': 'AzureDataExplorerCommandActivityTypePropertiesCommandTimeout'},
    }

    def __init__(
        self,
        *,
        command: "AzureDataExplorerCommandActivityTypePropertiesCommand",
        command_timeout: Optional["AzureDataExplorerCommandActivityTypePropertiesCommandTimeout"] = None,
        **kwargs
    ):
        super(AzureDataExplorerCommandActivityTypeProperties, self).__init__(**kwargs)
        self.command = command
        self.command_timeout = command_timeout


class AzureDataExplorerCommandActivityTypePropertiesCommand(msrest.serialization.Model):
    """A control command, according to the Azure Data Explorer command syntax. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataExplorerCommandActivityTypePropertiesCommand, self).__init__(**kwargs)


class AzureDataExplorerCommandActivityTypePropertiesCommandTimeout(msrest.serialization.Model):
    """Control command timeout. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9]))..).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataExplorerCommandActivityTypePropertiesCommandTimeout, self).__init__(**kwargs)


class AzureDataExplorerDatasetTypeProperties(msrest.serialization.Model):
    """Azure Data Explorer (Kusto) dataset properties.

    :param table: The table name of the Azure Data Explorer database. Type: string (or Expression
     with resultType string).
    :type table: ~data_factory_management_client.models.AzureDataExplorerDatasetTypePropertiesTable
    """

    _attribute_map = {
        'table': {'key': 'table', 'type': 'AzureDataExplorerDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        table: Optional["AzureDataExplorerDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(AzureDataExplorerDatasetTypeProperties, self).__init__(**kwargs)
        self.table = table


class AzureDataExplorerDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the Azure Data Explorer database. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataExplorerDatasetTypePropertiesTable, self).__init__(**kwargs)


class AzureDataExplorerLinkedService(LinkedService):
    """Azure Data Explorer (Kusto) linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param endpoint: Required. The endpoint of Azure Data Explorer (the engine's endpoint). URL
     will be in the format https://:code:`<clusterName>`.:code:`<regionName>`.kusto.windows.net.
     Type: string (or Expression with resultType string).
    :type endpoint:
     ~data_factory_management_client.models.AzureDataExplorerLinkedServiceTypePropertiesEndpoint
    :param service_principal_id: Required. The ID of the service principal used to authenticate
     against Azure Data Explorer. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureDataExplorerLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: Required. The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param database: Required. Database name for connection. Type: string (or Expression with
     resultType string).
    :type database:
     ~data_factory_management_client.models.AzureDataExplorerLinkedServiceTypePropertiesDatabase
    :param tenant: Required. The name or ID of the tenant to which the service principal belongs.
     Type: string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureDataExplorerLinkedServiceTypePropertiesTenant
    """

    _validation = {
        'type': {'required': True},
        'endpoint': {'required': True},
        'service_principal_id': {'required': True},
        'service_principal_key': {'required': True},
        'database': {'required': True},
        'tenant': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'AzureDataExplorerLinkedServiceTypePropertiesEndpoint'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'AzureDataExplorerLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'database': {'key': 'typeProperties.database', 'type': 'AzureDataExplorerLinkedServiceTypePropertiesDatabase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'AzureDataExplorerLinkedServiceTypePropertiesTenant'},
    }

    def __init__(
        self,
        *,
        endpoint: "AzureDataExplorerLinkedServiceTypePropertiesEndpoint",
        service_principal_id: "AzureDataExplorerLinkedServiceTypePropertiesServicePrincipalId",
        service_principal_key: "SecretBase",
        database: "AzureDataExplorerLinkedServiceTypePropertiesDatabase",
        tenant: "AzureDataExplorerLinkedServiceTypePropertiesTenant",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        **kwargs
    ):
        super(AzureDataExplorerLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureDataExplorer'
        self.endpoint = endpoint
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.database = database
        self.tenant = tenant


class AzureDataExplorerLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure Data Explorer (Kusto) linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param endpoint: Required. The endpoint of Azure Data Explorer (the engine's endpoint). URL
     will be in the format https://:code:`<clusterName>`.:code:`<regionName>`.kusto.windows.net.
     Type: string (or Expression with resultType string).
    :type endpoint:
     ~data_factory_management_client.models.AzureDataExplorerLinkedServiceTypePropertiesEndpoint
    :param service_principal_id: Required. The ID of the service principal used to authenticate
     against Azure Data Explorer. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureDataExplorerLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: Required. The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param database: Required. Database name for connection. Type: string (or Expression with
     resultType string).
    :type database:
     ~data_factory_management_client.models.AzureDataExplorerLinkedServiceTypePropertiesDatabase
    :param tenant: Required. The name or ID of the tenant to which the service principal belongs.
     Type: string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureDataExplorerLinkedServiceTypePropertiesTenant
    """

    _validation = {
        'endpoint': {'required': True},
        'service_principal_id': {'required': True},
        'service_principal_key': {'required': True},
        'database': {'required': True},
        'tenant': {'required': True},
    }

    _attribute_map = {
        'endpoint': {'key': 'endpoint', 'type': 'AzureDataExplorerLinkedServiceTypePropertiesEndpoint'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'AzureDataExplorerLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'database': {'key': 'database', 'type': 'AzureDataExplorerLinkedServiceTypePropertiesDatabase'},
        'tenant': {'key': 'tenant', 'type': 'AzureDataExplorerLinkedServiceTypePropertiesTenant'},
    }

    def __init__(
        self,
        *,
        endpoint: "AzureDataExplorerLinkedServiceTypePropertiesEndpoint",
        service_principal_id: "AzureDataExplorerLinkedServiceTypePropertiesServicePrincipalId",
        service_principal_key: "SecretBase",
        database: "AzureDataExplorerLinkedServiceTypePropertiesDatabase",
        tenant: "AzureDataExplorerLinkedServiceTypePropertiesTenant",
        **kwargs
    ):
        super(AzureDataExplorerLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.endpoint = endpoint
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.database = database
        self.tenant = tenant


class AzureDataExplorerLinkedServiceTypePropertiesDatabase(msrest.serialization.Model):
    """Database name for connection. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataExplorerLinkedServiceTypePropertiesDatabase, self).__init__(**kwargs)


class AzureDataExplorerLinkedServiceTypePropertiesEndpoint(msrest.serialization.Model):
    """The endpoint of Azure Data Explorer (the engine's endpoint). URL will be in the format https://:code:`<clusterName>`.:code:`<regionName>`.kusto.windows.net. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataExplorerLinkedServiceTypePropertiesEndpoint, self).__init__(**kwargs)


class AzureDataExplorerLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """The ID of the service principal used to authenticate against Azure Data Explorer. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataExplorerLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class AzureDataExplorerLinkedServiceTypePropertiesTenant(msrest.serialization.Model):
    """The name or ID of the tenant to which the service principal belongs. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataExplorerLinkedServiceTypePropertiesTenant, self).__init__(**kwargs)


class AzureDataExplorerSink(CopySink):
    """A copy activity Azure Data Explorer sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param ingestion_mapping_name: A name of a pre-created csv mapping that was defined on the
     target Kusto table. Type: string.
    :type ingestion_mapping_name:
     ~data_factory_management_client.models.AzureDataExplorerSinkIngestionMappingName
    :param ingestion_mapping_as_json: An explicit column mapping description provided in a json
     format. Type: string.
    :type ingestion_mapping_as_json:
     ~data_factory_management_client.models.AzureDataExplorerSinkIngestionMappingAsJson
    :param flush_immediately: If set to true, any aggregation will be skipped. Default is false.
     Type: boolean.
    :type flush_immediately:
     ~data_factory_management_client.models.AzureDataExplorerSinkFlushImmediately
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'ingestion_mapping_name': {'key': 'ingestionMappingName', 'type': 'AzureDataExplorerSinkIngestionMappingName'},
        'ingestion_mapping_as_json': {'key': 'ingestionMappingAsJson', 'type': 'AzureDataExplorerSinkIngestionMappingAsJson'},
        'flush_immediately': {'key': 'flushImmediately', 'type': 'AzureDataExplorerSinkFlushImmediately'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        ingestion_mapping_name: Optional["AzureDataExplorerSinkIngestionMappingName"] = None,
        ingestion_mapping_as_json: Optional["AzureDataExplorerSinkIngestionMappingAsJson"] = None,
        flush_immediately: Optional["AzureDataExplorerSinkFlushImmediately"] = None,
        **kwargs
    ):
        super(AzureDataExplorerSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzureDataExplorerSink'
        self.ingestion_mapping_name = ingestion_mapping_name
        self.ingestion_mapping_as_json = ingestion_mapping_as_json
        self.flush_immediately = flush_immediately


class AzureDataExplorerSinkFlushImmediately(msrest.serialization.Model):
    """If set to true, any aggregation will be skipped. Default is false. Type: boolean.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataExplorerSinkFlushImmediately, self).__init__(**kwargs)


class AzureDataExplorerSinkIngestionMappingAsJson(msrest.serialization.Model):
    """An explicit column mapping description provided in a json format. Type: string.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataExplorerSinkIngestionMappingAsJson, self).__init__(**kwargs)


class AzureDataExplorerSinkIngestionMappingName(msrest.serialization.Model):
    """A name of a pre-created csv mapping that was defined on the target Kusto table. Type: string.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataExplorerSinkIngestionMappingName, self).__init__(**kwargs)


class AzureDataExplorerSource(CopySource):
    """A copy activity Azure Data Explorer (Kusto) source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query: Required. Database query. Should be a Kusto Query Language (KQL) query. Type:
     string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.AzureDataExplorerSourceQuery
    :param no_truncation: The name of the Boolean option that controls whether truncation is
     applied to result-sets that go beyond a certain row-count limit.
    :type no_truncation: ~data_factory_management_client.models.AzureDataExplorerSourceNoTruncation
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9]))..
    :type query_timeout: ~data_factory_management_client.models.AzureDataExplorerSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
        'query': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query': {'key': 'query', 'type': 'AzureDataExplorerSourceQuery'},
        'no_truncation': {'key': 'noTruncation', 'type': 'AzureDataExplorerSourceNoTruncation'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'AzureDataExplorerSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        query: "AzureDataExplorerSourceQuery",
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        no_truncation: Optional["AzureDataExplorerSourceNoTruncation"] = None,
        query_timeout: Optional["AzureDataExplorerSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(AzureDataExplorerSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzureDataExplorerSource'
        self.query = query
        self.no_truncation = no_truncation
        self.query_timeout = query_timeout
        self.additional_columns = additional_columns


class AzureDataExplorerSourceNoTruncation(msrest.serialization.Model):
    """The name of the Boolean option that controls whether truncation is applied to result-sets that go beyond a certain row-count limit.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataExplorerSourceNoTruncation, self).__init__(**kwargs)


class AzureDataExplorerSourceQuery(msrest.serialization.Model):
    """Database query. Should be a Kusto Query Language (KQL) query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataExplorerSourceQuery, self).__init__(**kwargs)


class AzureDataExplorerSourceQueryTimeout(msrest.serialization.Model):
    """Query timeout. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9]))..

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataExplorerSourceQueryTimeout, self).__init__(**kwargs)


class AzureDataExplorerTableDataset(Dataset):
    """The Azure Data Explorer (Kusto) dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table: The table name of the Azure Data Explorer database. Type: string (or Expression
     with resultType string).
    :type table: ~data_factory_management_client.models.AzureDataExplorerDatasetTypePropertiesTable
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table': {'key': 'typeProperties.table', 'type': 'AzureDataExplorerDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table: Optional["AzureDataExplorerDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(AzureDataExplorerTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureDataExplorerTable'
        self.table = table


class AzureDataLakeAnalyticsLinkedService(LinkedService):
    """Azure Data Lake Analytics linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param account_name: Required. The Azure Data Lake Analytics account name. Type: string (or
     Expression with resultType string).
    :type account_name:
     ~data_factory_management_client.models.AzureDataLakeAnalyticsLinkedServiceTypePropertiesAccountName
    :param service_principal_id: The ID of the application used to authenticate against the Azure
     Data Lake Analytics account. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureDataLakeAnalyticsLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: Required. The name or ID of the tenant to which the service principal belongs.
     Type: string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureDataLakeAnalyticsLinkedServiceTypePropertiesTenant
    :param subscription_id: Data Lake Analytics account subscription ID (if different from Data
     Factory account). Type: string (or Expression with resultType string).
    :type subscription_id:
     ~data_factory_management_client.models.AzureDataLakeAnalyticsLinkedServiceTypePropertiesSubscriptionId
    :param resource_group_name: Data Lake Analytics account resource group name (if different from
     Data Factory account). Type: string (or Expression with resultType string).
    :type resource_group_name:
     ~data_factory_management_client.models.AzureDataLakeAnalyticsLinkedServiceTypePropertiesResourceGroupName
    :param data_lake_analytics_uri: Azure Data Lake Analytics URI Type: string (or Expression with
     resultType string).
    :type data_lake_analytics_uri:
     ~data_factory_management_client.models.AzureDataLakeAnalyticsLinkedServiceTypePropertiesDataLakeAnalyticsUri
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureDataLakeAnalyticsLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'account_name': {'required': True},
        'tenant': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'account_name': {'key': 'typeProperties.accountName', 'type': 'AzureDataLakeAnalyticsLinkedServiceTypePropertiesAccountName'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'AzureDataLakeAnalyticsLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'AzureDataLakeAnalyticsLinkedServiceTypePropertiesTenant'},
        'subscription_id': {'key': 'typeProperties.subscriptionId', 'type': 'AzureDataLakeAnalyticsLinkedServiceTypePropertiesSubscriptionId'},
        'resource_group_name': {'key': 'typeProperties.resourceGroupName', 'type': 'AzureDataLakeAnalyticsLinkedServiceTypePropertiesResourceGroupName'},
        'data_lake_analytics_uri': {'key': 'typeProperties.dataLakeAnalyticsUri', 'type': 'AzureDataLakeAnalyticsLinkedServiceTypePropertiesDataLakeAnalyticsUri'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzureDataLakeAnalyticsLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        account_name: "AzureDataLakeAnalyticsLinkedServiceTypePropertiesAccountName",
        tenant: "AzureDataLakeAnalyticsLinkedServiceTypePropertiesTenant",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        service_principal_id: Optional["AzureDataLakeAnalyticsLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        subscription_id: Optional["AzureDataLakeAnalyticsLinkedServiceTypePropertiesSubscriptionId"] = None,
        resource_group_name: Optional["AzureDataLakeAnalyticsLinkedServiceTypePropertiesResourceGroupName"] = None,
        data_lake_analytics_uri: Optional["AzureDataLakeAnalyticsLinkedServiceTypePropertiesDataLakeAnalyticsUri"] = None,
        encrypted_credential: Optional["AzureDataLakeAnalyticsLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureDataLakeAnalyticsLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureDataLakeAnalytics'
        self.account_name = account_name
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.subscription_id = subscription_id
        self.resource_group_name = resource_group_name
        self.data_lake_analytics_uri = data_lake_analytics_uri
        self.encrypted_credential = encrypted_credential


class AzureDataLakeAnalyticsLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure Data Lake Analytics linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param account_name: Required. The Azure Data Lake Analytics account name. Type: string (or
     Expression with resultType string).
    :type account_name:
     ~data_factory_management_client.models.AzureDataLakeAnalyticsLinkedServiceTypePropertiesAccountName
    :param service_principal_id: The ID of the application used to authenticate against the Azure
     Data Lake Analytics account. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureDataLakeAnalyticsLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: Required. The name or ID of the tenant to which the service principal belongs.
     Type: string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureDataLakeAnalyticsLinkedServiceTypePropertiesTenant
    :param subscription_id: Data Lake Analytics account subscription ID (if different from Data
     Factory account). Type: string (or Expression with resultType string).
    :type subscription_id:
     ~data_factory_management_client.models.AzureDataLakeAnalyticsLinkedServiceTypePropertiesSubscriptionId
    :param resource_group_name: Data Lake Analytics account resource group name (if different from
     Data Factory account). Type: string (or Expression with resultType string).
    :type resource_group_name:
     ~data_factory_management_client.models.AzureDataLakeAnalyticsLinkedServiceTypePropertiesResourceGroupName
    :param data_lake_analytics_uri: Azure Data Lake Analytics URI Type: string (or Expression with
     resultType string).
    :type data_lake_analytics_uri:
     ~data_factory_management_client.models.AzureDataLakeAnalyticsLinkedServiceTypePropertiesDataLakeAnalyticsUri
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureDataLakeAnalyticsLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'account_name': {'required': True},
        'tenant': {'required': True},
    }

    _attribute_map = {
        'account_name': {'key': 'accountName', 'type': 'AzureDataLakeAnalyticsLinkedServiceTypePropertiesAccountName'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'AzureDataLakeAnalyticsLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'tenant', 'type': 'AzureDataLakeAnalyticsLinkedServiceTypePropertiesTenant'},
        'subscription_id': {'key': 'subscriptionId', 'type': 'AzureDataLakeAnalyticsLinkedServiceTypePropertiesSubscriptionId'},
        'resource_group_name': {'key': 'resourceGroupName', 'type': 'AzureDataLakeAnalyticsLinkedServiceTypePropertiesResourceGroupName'},
        'data_lake_analytics_uri': {'key': 'dataLakeAnalyticsUri', 'type': 'AzureDataLakeAnalyticsLinkedServiceTypePropertiesDataLakeAnalyticsUri'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzureDataLakeAnalyticsLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        account_name: "AzureDataLakeAnalyticsLinkedServiceTypePropertiesAccountName",
        tenant: "AzureDataLakeAnalyticsLinkedServiceTypePropertiesTenant",
        service_principal_id: Optional["AzureDataLakeAnalyticsLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        subscription_id: Optional["AzureDataLakeAnalyticsLinkedServiceTypePropertiesSubscriptionId"] = None,
        resource_group_name: Optional["AzureDataLakeAnalyticsLinkedServiceTypePropertiesResourceGroupName"] = None,
        data_lake_analytics_uri: Optional["AzureDataLakeAnalyticsLinkedServiceTypePropertiesDataLakeAnalyticsUri"] = None,
        encrypted_credential: Optional["AzureDataLakeAnalyticsLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureDataLakeAnalyticsLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.account_name = account_name
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.subscription_id = subscription_id
        self.resource_group_name = resource_group_name
        self.data_lake_analytics_uri = data_lake_analytics_uri
        self.encrypted_credential = encrypted_credential


class AzureDataLakeAnalyticsLinkedServiceTypePropertiesAccountName(msrest.serialization.Model):
    """The Azure Data Lake Analytics account name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeAnalyticsLinkedServiceTypePropertiesAccountName, self).__init__(**kwargs)


class AzureDataLakeAnalyticsLinkedServiceTypePropertiesDataLakeAnalyticsUri(msrest.serialization.Model):
    """Azure Data Lake Analytics URI Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeAnalyticsLinkedServiceTypePropertiesDataLakeAnalyticsUri, self).__init__(**kwargs)


class AzureDataLakeAnalyticsLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeAnalyticsLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzureDataLakeAnalyticsLinkedServiceTypePropertiesResourceGroupName(msrest.serialization.Model):
    """Data Lake Analytics account resource group name (if different from Data Factory account). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeAnalyticsLinkedServiceTypePropertiesResourceGroupName, self).__init__(**kwargs)


class AzureDataLakeAnalyticsLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """The ID of the application used to authenticate against the Azure Data Lake Analytics account. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeAnalyticsLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class AzureDataLakeAnalyticsLinkedServiceTypePropertiesSubscriptionId(msrest.serialization.Model):
    """Data Lake Analytics account subscription ID (if different from Data Factory account). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeAnalyticsLinkedServiceTypePropertiesSubscriptionId, self).__init__(**kwargs)


class AzureDataLakeAnalyticsLinkedServiceTypePropertiesTenant(msrest.serialization.Model):
    """The name or ID of the tenant to which the service principal belongs. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeAnalyticsLinkedServiceTypePropertiesTenant, self).__init__(**kwargs)


class AzureDataLakeStoreDataset(Dataset):
    """Azure Data Lake Store dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param folder_path: Path to the folder in the Azure Data Lake Store. Type: string (or
     Expression with resultType string).
    :type folder_path:
     ~data_factory_management_client.models.AzureDataLakeStoreDatasetTypePropertiesFolderPath
    :param file_name: The name of the file in the Azure Data Lake Store. Type: string (or
     Expression with resultType string).
    :type file_name:
     ~data_factory_management_client.models.AzureDataLakeStoreDatasetTypePropertiesFileName
    :param format: The format definition of a storage.
    :type format: ~data_factory_management_client.models.DatasetStorageFormat
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'folder_path': {'key': 'typeProperties.folderPath', 'type': 'AzureDataLakeStoreDatasetTypePropertiesFolderPath'},
        'file_name': {'key': 'typeProperties.fileName', 'type': 'AzureDataLakeStoreDatasetTypePropertiesFileName'},
        'format': {'key': 'typeProperties.format', 'type': 'DatasetStorageFormat'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        folder_path: Optional["AzureDataLakeStoreDatasetTypePropertiesFolderPath"] = None,
        file_name: Optional["AzureDataLakeStoreDatasetTypePropertiesFileName"] = None,
        format: Optional["DatasetStorageFormat"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(AzureDataLakeStoreDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureDataLakeStoreFile'
        self.folder_path = folder_path
        self.file_name = file_name
        self.format = format
        self.compression = compression


class AzureDataLakeStoreDatasetTypeProperties(msrest.serialization.Model):
    """Azure Data Lake Store dataset properties.

    :param folder_path: Path to the folder in the Azure Data Lake Store. Type: string (or
     Expression with resultType string).
    :type folder_path:
     ~data_factory_management_client.models.AzureDataLakeStoreDatasetTypePropertiesFolderPath
    :param file_name: The name of the file in the Azure Data Lake Store. Type: string (or
     Expression with resultType string).
    :type file_name:
     ~data_factory_management_client.models.AzureDataLakeStoreDatasetTypePropertiesFileName
    :param format: The format definition of a storage.
    :type format: ~data_factory_management_client.models.DatasetStorageFormat
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _attribute_map = {
        'folder_path': {'key': 'folderPath', 'type': 'AzureDataLakeStoreDatasetTypePropertiesFolderPath'},
        'file_name': {'key': 'fileName', 'type': 'AzureDataLakeStoreDatasetTypePropertiesFileName'},
        'format': {'key': 'format', 'type': 'DatasetStorageFormat'},
        'compression': {'key': 'compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        folder_path: Optional["AzureDataLakeStoreDatasetTypePropertiesFolderPath"] = None,
        file_name: Optional["AzureDataLakeStoreDatasetTypePropertiesFileName"] = None,
        format: Optional["DatasetStorageFormat"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(AzureDataLakeStoreDatasetTypeProperties, self).__init__(**kwargs)
        self.folder_path = folder_path
        self.file_name = file_name
        self.format = format
        self.compression = compression


class AzureDataLakeStoreDatasetTypePropertiesFileName(msrest.serialization.Model):
    """The name of the file in the Azure Data Lake Store. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreDatasetTypePropertiesFileName, self).__init__(**kwargs)


class AzureDataLakeStoreDatasetTypePropertiesFolderPath(msrest.serialization.Model):
    """Path to the folder in the Azure Data Lake Store. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreDatasetTypePropertiesFolderPath, self).__init__(**kwargs)


class AzureDataLakeStoreLinkedService(LinkedService):
    """Azure Data Lake Store linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param data_lake_store_uri: Required. Data Lake Store service URI. Type: string (or Expression
     with resultType string).
    :type data_lake_store_uri:
     ~data_factory_management_client.models.AzureDataLakeStoreLinkedServiceTypePropertiesDataLakeStoreUri
    :param service_principal_id: The ID of the application used to authenticate against the Azure
     Data Lake Store account. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureDataLakeStoreLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureDataLakeStoreLinkedServiceTypePropertiesTenant
    :param account_name: Data Lake Store account name. Type: string (or Expression with resultType
     string).
    :type account_name:
     ~data_factory_management_client.models.AzureDataLakeStoreLinkedServiceTypePropertiesAccountName
    :param subscription_id: Data Lake Store account subscription ID (if different from Data Factory
     account). Type: string (or Expression with resultType string).
    :type subscription_id:
     ~data_factory_management_client.models.AzureDataLakeStoreLinkedServiceTypePropertiesSubscriptionId
    :param resource_group_name: Data Lake Store account resource group name (if different from Data
     Factory account). Type: string (or Expression with resultType string).
    :type resource_group_name:
     ~data_factory_management_client.models.AzureDataLakeStoreLinkedServiceTypePropertiesResourceGroupName
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureDataLakeStoreLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'data_lake_store_uri': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'data_lake_store_uri': {'key': 'typeProperties.dataLakeStoreUri', 'type': 'AzureDataLakeStoreLinkedServiceTypePropertiesDataLakeStoreUri'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'AzureDataLakeStoreLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'AzureDataLakeStoreLinkedServiceTypePropertiesTenant'},
        'account_name': {'key': 'typeProperties.accountName', 'type': 'AzureDataLakeStoreLinkedServiceTypePropertiesAccountName'},
        'subscription_id': {'key': 'typeProperties.subscriptionId', 'type': 'AzureDataLakeStoreLinkedServiceTypePropertiesSubscriptionId'},
        'resource_group_name': {'key': 'typeProperties.resourceGroupName', 'type': 'AzureDataLakeStoreLinkedServiceTypePropertiesResourceGroupName'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzureDataLakeStoreLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        data_lake_store_uri: "AzureDataLakeStoreLinkedServiceTypePropertiesDataLakeStoreUri",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        service_principal_id: Optional["AzureDataLakeStoreLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureDataLakeStoreLinkedServiceTypePropertiesTenant"] = None,
        account_name: Optional["AzureDataLakeStoreLinkedServiceTypePropertiesAccountName"] = None,
        subscription_id: Optional["AzureDataLakeStoreLinkedServiceTypePropertiesSubscriptionId"] = None,
        resource_group_name: Optional["AzureDataLakeStoreLinkedServiceTypePropertiesResourceGroupName"] = None,
        encrypted_credential: Optional["AzureDataLakeStoreLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureDataLakeStoreLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureDataLakeStore'
        self.data_lake_store_uri = data_lake_store_uri
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.account_name = account_name
        self.subscription_id = subscription_id
        self.resource_group_name = resource_group_name
        self.encrypted_credential = encrypted_credential


class AzureDataLakeStoreLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure Data Lake Store linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param data_lake_store_uri: Required. Data Lake Store service URI. Type: string (or Expression
     with resultType string).
    :type data_lake_store_uri:
     ~data_factory_management_client.models.AzureDataLakeStoreLinkedServiceTypePropertiesDataLakeStoreUri
    :param service_principal_id: The ID of the application used to authenticate against the Azure
     Data Lake Store account. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureDataLakeStoreLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureDataLakeStoreLinkedServiceTypePropertiesTenant
    :param account_name: Data Lake Store account name. Type: string (or Expression with resultType
     string).
    :type account_name:
     ~data_factory_management_client.models.AzureDataLakeStoreLinkedServiceTypePropertiesAccountName
    :param subscription_id: Data Lake Store account subscription ID (if different from Data Factory
     account). Type: string (or Expression with resultType string).
    :type subscription_id:
     ~data_factory_management_client.models.AzureDataLakeStoreLinkedServiceTypePropertiesSubscriptionId
    :param resource_group_name: Data Lake Store account resource group name (if different from Data
     Factory account). Type: string (or Expression with resultType string).
    :type resource_group_name:
     ~data_factory_management_client.models.AzureDataLakeStoreLinkedServiceTypePropertiesResourceGroupName
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureDataLakeStoreLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'data_lake_store_uri': {'required': True},
    }

    _attribute_map = {
        'data_lake_store_uri': {'key': 'dataLakeStoreUri', 'type': 'AzureDataLakeStoreLinkedServiceTypePropertiesDataLakeStoreUri'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'AzureDataLakeStoreLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'tenant', 'type': 'AzureDataLakeStoreLinkedServiceTypePropertiesTenant'},
        'account_name': {'key': 'accountName', 'type': 'AzureDataLakeStoreLinkedServiceTypePropertiesAccountName'},
        'subscription_id': {'key': 'subscriptionId', 'type': 'AzureDataLakeStoreLinkedServiceTypePropertiesSubscriptionId'},
        'resource_group_name': {'key': 'resourceGroupName', 'type': 'AzureDataLakeStoreLinkedServiceTypePropertiesResourceGroupName'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzureDataLakeStoreLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        data_lake_store_uri: "AzureDataLakeStoreLinkedServiceTypePropertiesDataLakeStoreUri",
        service_principal_id: Optional["AzureDataLakeStoreLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureDataLakeStoreLinkedServiceTypePropertiesTenant"] = None,
        account_name: Optional["AzureDataLakeStoreLinkedServiceTypePropertiesAccountName"] = None,
        subscription_id: Optional["AzureDataLakeStoreLinkedServiceTypePropertiesSubscriptionId"] = None,
        resource_group_name: Optional["AzureDataLakeStoreLinkedServiceTypePropertiesResourceGroupName"] = None,
        encrypted_credential: Optional["AzureDataLakeStoreLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureDataLakeStoreLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.data_lake_store_uri = data_lake_store_uri
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.account_name = account_name
        self.subscription_id = subscription_id
        self.resource_group_name = resource_group_name
        self.encrypted_credential = encrypted_credential


class AzureDataLakeStoreLinkedServiceTypePropertiesAccountName(msrest.serialization.Model):
    """Data Lake Store account name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreLinkedServiceTypePropertiesAccountName, self).__init__(**kwargs)


class AzureDataLakeStoreLinkedServiceTypePropertiesDataLakeStoreUri(msrest.serialization.Model):
    """Data Lake Store service URI. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreLinkedServiceTypePropertiesDataLakeStoreUri, self).__init__(**kwargs)


class AzureDataLakeStoreLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzureDataLakeStoreLinkedServiceTypePropertiesResourceGroupName(msrest.serialization.Model):
    """Data Lake Store account resource group name (if different from Data Factory account). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreLinkedServiceTypePropertiesResourceGroupName, self).__init__(**kwargs)


class AzureDataLakeStoreLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """The ID of the application used to authenticate against the Azure Data Lake Store account. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class AzureDataLakeStoreLinkedServiceTypePropertiesSubscriptionId(msrest.serialization.Model):
    """Data Lake Store account subscription ID (if different from Data Factory account). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreLinkedServiceTypePropertiesSubscriptionId, self).__init__(**kwargs)


class AzureDataLakeStoreLinkedServiceTypePropertiesTenant(msrest.serialization.Model):
    """The name or ID of the tenant to which the service principal belongs. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreLinkedServiceTypePropertiesTenant, self).__init__(**kwargs)


class AzureDataLakeStoreLocation(DatasetLocation):
    """The location of azure data lake store dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage location.Constant filled by server.
    :type type: str
    :param folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :type folder_path: ~data_factory_management_client.models.DatasetLocationFolderPath
    :param file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :type file_name: ~data_factory_management_client.models.DatasetLocationFileName
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'DatasetLocationFolderPath'},
        'file_name': {'key': 'fileName', 'type': 'DatasetLocationFileName'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        folder_path: Optional["DatasetLocationFolderPath"] = None,
        file_name: Optional["DatasetLocationFileName"] = None,
        **kwargs
    ):
        super(AzureDataLakeStoreLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'AzureDataLakeStoreLocation'


class AzureDataLakeStoreReadSettings(StoreReadSettings):
    """Azure data lake store read settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The read setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreReadSettingsMaxConcurrentConnections
    :param recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.AzureDataLakeStoreReadSettingsRecursive
    :param wildcard_folder_path: ADLS wildcardFolderPath. Type: string (or Expression with
     resultType string).
    :type wildcard_folder_path:
     ~data_factory_management_client.models.AzureDataLakeStoreReadSettingsWildcardFolderPath
    :param wildcard_file_name: ADLS wildcardFileName. Type: string (or Expression with resultType
     string).
    :type wildcard_file_name:
     ~data_factory_management_client.models.AzureDataLakeStoreReadSettingsWildcardFileName
    :param file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :type file_list_path:
     ~data_factory_management_client.models.AzureDataLakeStoreReadSettingsFileListPath
    :param enable_partition_discovery: Indicates whether to enable partition discovery.
    :type enable_partition_discovery: bool
    :param modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_start:
     ~data_factory_management_client.models.AzureDataLakeStoreReadSettingsModifiedDatetimeStart
    :param modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :type modified_datetime_end:
     ~data_factory_management_client.models.AzureDataLakeStoreReadSettingsModifiedDatetimeEnd
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreReadSettingsMaxConcurrentConnections'},
        'recursive': {'key': 'recursive', 'type': 'AzureDataLakeStoreReadSettingsRecursive'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'AzureDataLakeStoreReadSettingsWildcardFolderPath'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'AzureDataLakeStoreReadSettingsWildcardFileName'},
        'file_list_path': {'key': 'fileListPath', 'type': 'AzureDataLakeStoreReadSettingsFileListPath'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'AzureDataLakeStoreReadSettingsModifiedDatetimeStart'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'AzureDataLakeStoreReadSettingsModifiedDatetimeEnd'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreReadSettingsMaxConcurrentConnections"] = None,
        recursive: Optional["AzureDataLakeStoreReadSettingsRecursive"] = None,
        wildcard_folder_path: Optional["AzureDataLakeStoreReadSettingsWildcardFolderPath"] = None,
        wildcard_file_name: Optional["AzureDataLakeStoreReadSettingsWildcardFileName"] = None,
        file_list_path: Optional["AzureDataLakeStoreReadSettingsFileListPath"] = None,
        enable_partition_discovery: Optional[bool] = None,
        modified_datetime_start: Optional["AzureDataLakeStoreReadSettingsModifiedDatetimeStart"] = None,
        modified_datetime_end: Optional["AzureDataLakeStoreReadSettingsModifiedDatetimeEnd"] = None,
        **kwargs
    ):
        super(AzureDataLakeStoreReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzureDataLakeStoreReadSettings'
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class AzureDataLakeStoreReadSettingsFileListPath(msrest.serialization.Model):
    """Point to a text file that lists each file (relative path to the path configured in the dataset) that you want to copy. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreReadSettingsFileListPath, self).__init__(**kwargs)


class AzureDataLakeStoreReadSettingsModifiedDatetimeEnd(msrest.serialization.Model):
    """The end of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreReadSettingsModifiedDatetimeEnd, self).__init__(**kwargs)


class AzureDataLakeStoreReadSettingsModifiedDatetimeStart(msrest.serialization.Model):
    """The start of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreReadSettingsModifiedDatetimeStart, self).__init__(**kwargs)


class AzureDataLakeStoreReadSettingsRecursive(msrest.serialization.Model):
    """If true, files under the folder path will be read recursively. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreReadSettingsRecursive, self).__init__(**kwargs)


class AzureDataLakeStoreReadSettingsWildcardFileName(msrest.serialization.Model):
    """ADLS wildcardFileName. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreReadSettingsWildcardFileName, self).__init__(**kwargs)


class AzureDataLakeStoreReadSettingsWildcardFolderPath(msrest.serialization.Model):
    """ADLS wildcardFolderPath. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreReadSettingsWildcardFolderPath, self).__init__(**kwargs)


class AzureDataLakeStoreSink(CopySink):
    """A copy activity Azure Data Lake Store sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param copy_behavior: The type of copy behavior for copy sink.
    :type copy_behavior: ~data_factory_management_client.models.AzureDataLakeStoreSinkCopyBehavior
    :param enable_adls_single_file_parallel: Single File Parallel.
    :type enable_adls_single_file_parallel:
     ~data_factory_management_client.models.AzureDataLakeStoreSinkEnableAdlsSingleFileParallel
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'AzureDataLakeStoreSinkCopyBehavior'},
        'enable_adls_single_file_parallel': {'key': 'enableAdlsSingleFileParallel', 'type': 'AzureDataLakeStoreSinkEnableAdlsSingleFileParallel'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        copy_behavior: Optional["AzureDataLakeStoreSinkCopyBehavior"] = None,
        enable_adls_single_file_parallel: Optional["AzureDataLakeStoreSinkEnableAdlsSingleFileParallel"] = None,
        **kwargs
    ):
        super(AzureDataLakeStoreSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzureDataLakeStoreSink'
        self.copy_behavior = copy_behavior
        self.enable_adls_single_file_parallel = enable_adls_single_file_parallel


class AzureDataLakeStoreSinkCopyBehavior(msrest.serialization.Model):
    """The type of copy behavior for copy sink.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreSinkCopyBehavior, self).__init__(**kwargs)


class AzureDataLakeStoreSinkEnableAdlsSingleFileParallel(msrest.serialization.Model):
    """Single File Parallel.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreSinkEnableAdlsSingleFileParallel, self).__init__(**kwargs)


class AzureDataLakeStoreSource(CopySource):
    """A copy activity Azure Data Lake source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.AzureDataLakeStoreSourceRecursive
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'recursive': {'key': 'recursive', 'type': 'AzureDataLakeStoreSourceRecursive'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        recursive: Optional["AzureDataLakeStoreSourceRecursive"] = None,
        **kwargs
    ):
        super(AzureDataLakeStoreSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzureDataLakeStoreSource'
        self.recursive = recursive


class AzureDataLakeStoreSourceRecursive(msrest.serialization.Model):
    """If true, files under the folder path will be read recursively. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreSourceRecursive, self).__init__(**kwargs)


class AzureDataLakeStoreWriteSettings(StoreWriteSettings):
    """Azure data lake store write settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The write setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreWriteSettingsMaxConcurrentConnections
    :param copy_behavior: The type of copy behavior for copy sink.
    :type copy_behavior: ~data_factory_management_client.models.StoreWriteSettingsCopyBehavior
    :param expiry_date_time: Specifies the expiry time of the written files. The time is applied to
     the UTC time zone in the format of "2018-12-01T05:00:00Z". Default value is NULL. Type: integer
     (or Expression with resultType integer).
    :type expiry_date_time:
     ~data_factory_management_client.models.AzureDataLakeStoreWriteSettingsExpiryDateTime
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreWriteSettingsMaxConcurrentConnections'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'StoreWriteSettingsCopyBehavior'},
        'expiry_date_time': {'key': 'expiryDateTime', 'type': 'AzureDataLakeStoreWriteSettingsExpiryDateTime'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreWriteSettingsMaxConcurrentConnections"] = None,
        copy_behavior: Optional["StoreWriteSettingsCopyBehavior"] = None,
        expiry_date_time: Optional["AzureDataLakeStoreWriteSettingsExpiryDateTime"] = None,
        **kwargs
    ):
        super(AzureDataLakeStoreWriteSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, copy_behavior=copy_behavior, **kwargs)
        self.type = 'AzureDataLakeStoreWriteSettings'
        self.expiry_date_time = expiry_date_time


class AzureDataLakeStoreWriteSettingsExpiryDateTime(msrest.serialization.Model):
    """Specifies the expiry time of the written files. The time is applied to the UTC time zone in the format of "2018-12-01T05:00:00Z". Default value is NULL. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureDataLakeStoreWriteSettingsExpiryDateTime, self).__init__(**kwargs)


class AzureFileStorageLinkedService(LinkedService):
    """Azure File Storage linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. Host name of the server. Type: string (or Expression with resultType
     string).
    :type host:
     ~data_factory_management_client.models.AzureFileStorageLinkedServiceTypePropertiesHost
    :param user_id: User ID to logon the server. Type: string (or Expression with resultType
     string).
    :type user_id:
     ~data_factory_management_client.models.AzureFileStorageLinkedServiceTypePropertiesUserId
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureFileStorageLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'AzureFileStorageLinkedServiceTypePropertiesHost'},
        'user_id': {'key': 'typeProperties.userId', 'type': 'AzureFileStorageLinkedServiceTypePropertiesUserId'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzureFileStorageLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "AzureFileStorageLinkedServiceTypePropertiesHost",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        user_id: Optional["AzureFileStorageLinkedServiceTypePropertiesUserId"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["AzureFileStorageLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureFileStorageLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureFileStorage'
        self.host = host
        self.user_id = user_id
        self.password = password
        self.encrypted_credential = encrypted_credential


class AzureFileStorageLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure File Storage linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. Host name of the server. Type: string (or Expression with resultType
     string).
    :type host:
     ~data_factory_management_client.models.AzureFileStorageLinkedServiceTypePropertiesHost
    :param user_id: User ID to logon the server. Type: string (or Expression with resultType
     string).
    :type user_id:
     ~data_factory_management_client.models.AzureFileStorageLinkedServiceTypePropertiesUserId
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureFileStorageLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'AzureFileStorageLinkedServiceTypePropertiesHost'},
        'user_id': {'key': 'userId', 'type': 'AzureFileStorageLinkedServiceTypePropertiesUserId'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzureFileStorageLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "AzureFileStorageLinkedServiceTypePropertiesHost",
        user_id: Optional["AzureFileStorageLinkedServiceTypePropertiesUserId"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["AzureFileStorageLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureFileStorageLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.user_id = user_id
        self.password = password
        self.encrypted_credential = encrypted_credential


class AzureFileStorageLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureFileStorageLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzureFileStorageLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """Host name of the server. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureFileStorageLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class AzureFileStorageLinkedServiceTypePropertiesUserId(msrest.serialization.Model):
    """User ID to logon the server. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureFileStorageLinkedServiceTypePropertiesUserId, self).__init__(**kwargs)


class AzureFileStorageLocation(DatasetLocation):
    """The location of file server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage location.Constant filled by server.
    :type type: str
    :param folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :type folder_path: ~data_factory_management_client.models.DatasetLocationFolderPath
    :param file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :type file_name: ~data_factory_management_client.models.DatasetLocationFileName
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'DatasetLocationFolderPath'},
        'file_name': {'key': 'fileName', 'type': 'DatasetLocationFileName'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        folder_path: Optional["DatasetLocationFolderPath"] = None,
        file_name: Optional["DatasetLocationFileName"] = None,
        **kwargs
    ):
        super(AzureFileStorageLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'AzureFileStorageLocation'


class AzureFileStorageReadSettings(StoreReadSettings):
    """Azure File Storage read settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The read setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreReadSettingsMaxConcurrentConnections
    :param recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.AzureFileStorageReadSettingsRecursive
    :param wildcard_folder_path: Azure File Storage wildcardFolderPath. Type: string (or Expression
     with resultType string).
    :type wildcard_folder_path:
     ~data_factory_management_client.models.AzureFileStorageReadSettingsWildcardFolderPath
    :param wildcard_file_name: Azure File Storage wildcardFileName. Type: string (or Expression
     with resultType string).
    :type wildcard_file_name:
     ~data_factory_management_client.models.AzureFileStorageReadSettingsWildcardFileName
    :param file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :type file_list_path:
     ~data_factory_management_client.models.AzureFileStorageReadSettingsFileListPath
    :param enable_partition_discovery: Indicates whether to enable partition discovery.
    :type enable_partition_discovery: bool
    :param modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_start:
     ~data_factory_management_client.models.AzureFileStorageReadSettingsModifiedDatetimeStart
    :param modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :type modified_datetime_end:
     ~data_factory_management_client.models.AzureFileStorageReadSettingsModifiedDatetimeEnd
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreReadSettingsMaxConcurrentConnections'},
        'recursive': {'key': 'recursive', 'type': 'AzureFileStorageReadSettingsRecursive'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'AzureFileStorageReadSettingsWildcardFolderPath'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'AzureFileStorageReadSettingsWildcardFileName'},
        'file_list_path': {'key': 'fileListPath', 'type': 'AzureFileStorageReadSettingsFileListPath'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'AzureFileStorageReadSettingsModifiedDatetimeStart'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'AzureFileStorageReadSettingsModifiedDatetimeEnd'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreReadSettingsMaxConcurrentConnections"] = None,
        recursive: Optional["AzureFileStorageReadSettingsRecursive"] = None,
        wildcard_folder_path: Optional["AzureFileStorageReadSettingsWildcardFolderPath"] = None,
        wildcard_file_name: Optional["AzureFileStorageReadSettingsWildcardFileName"] = None,
        file_list_path: Optional["AzureFileStorageReadSettingsFileListPath"] = None,
        enable_partition_discovery: Optional[bool] = None,
        modified_datetime_start: Optional["AzureFileStorageReadSettingsModifiedDatetimeStart"] = None,
        modified_datetime_end: Optional["AzureFileStorageReadSettingsModifiedDatetimeEnd"] = None,
        **kwargs
    ):
        super(AzureFileStorageReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzureFileStorageReadSettings'
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class AzureFileStorageReadSettingsFileListPath(msrest.serialization.Model):
    """Point to a text file that lists each file (relative path to the path configured in the dataset) that you want to copy. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureFileStorageReadSettingsFileListPath, self).__init__(**kwargs)


class AzureFileStorageReadSettingsModifiedDatetimeEnd(msrest.serialization.Model):
    """The end of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureFileStorageReadSettingsModifiedDatetimeEnd, self).__init__(**kwargs)


class AzureFileStorageReadSettingsModifiedDatetimeStart(msrest.serialization.Model):
    """The start of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureFileStorageReadSettingsModifiedDatetimeStart, self).__init__(**kwargs)


class AzureFileStorageReadSettingsRecursive(msrest.serialization.Model):
    """If true, files under the folder path will be read recursively. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureFileStorageReadSettingsRecursive, self).__init__(**kwargs)


class AzureFileStorageReadSettingsWildcardFileName(msrest.serialization.Model):
    """Azure File Storage wildcardFileName. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureFileStorageReadSettingsWildcardFileName, self).__init__(**kwargs)


class AzureFileStorageReadSettingsWildcardFolderPath(msrest.serialization.Model):
    """Azure File Storage wildcardFolderPath. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureFileStorageReadSettingsWildcardFolderPath, self).__init__(**kwargs)


class AzureFunctionActivity(ExecutionActivity):
    """Azure Function activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param method: Required. The list of HTTP methods supported by a AzureFunctionActivity.
     Possible values include: 'GET', 'POST', 'PUT', 'DELETE', 'OPTIONS', 'HEAD', 'TRACE'.
    :type method: str or ~data_factory_management_client.models.AzureFunctionActivityMethod
    :param function_name: Required. Name of the Function that the Azure Function Activity will
     call. Type: string (or Expression with resultType string).
    :type function_name:
     ~data_factory_management_client.models.AzureFunctionActivityTypePropertiesFunctionName
    :param headers: Represents the headers that will be sent to the request. For example, to set
     the language and type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type":
     "application/json" }. Type: string (or Expression with resultType string).
    :type headers:
     ~data_factory_management_client.models.AzureFunctionActivityTypePropertiesHeaders
    :param body: Represents the payload that will be sent to the endpoint. Required for POST/PUT
     method, not allowed for GET method Type: string (or Expression with resultType string).
    :type body: ~data_factory_management_client.models.AzureFunctionActivityTypePropertiesBody
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'method': {'required': True},
        'function_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'method': {'key': 'typeProperties.method', 'type': 'str'},
        'function_name': {'key': 'typeProperties.functionName', 'type': 'AzureFunctionActivityTypePropertiesFunctionName'},
        'headers': {'key': 'typeProperties.headers', 'type': 'AzureFunctionActivityTypePropertiesHeaders'},
        'body': {'key': 'typeProperties.body', 'type': 'AzureFunctionActivityTypePropertiesBody'},
    }

    def __init__(
        self,
        *,
        name: str,
        method: Union[str, "AzureFunctionActivityMethod"],
        function_name: "AzureFunctionActivityTypePropertiesFunctionName",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        headers: Optional["AzureFunctionActivityTypePropertiesHeaders"] = None,
        body: Optional["AzureFunctionActivityTypePropertiesBody"] = None,
        **kwargs
    ):
        super(AzureFunctionActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'AzureFunctionActivity'
        self.method = method
        self.function_name = function_name
        self.headers = headers
        self.body = body


class AzureFunctionActivityTypeProperties(msrest.serialization.Model):
    """Azure Function activity type properties.

    All required parameters must be populated in order to send to Azure.

    :param method: Required. The list of HTTP methods supported by a AzureFunctionActivity.
     Possible values include: 'GET', 'POST', 'PUT', 'DELETE', 'OPTIONS', 'HEAD', 'TRACE'.
    :type method: str or ~data_factory_management_client.models.AzureFunctionActivityMethod
    :param function_name: Required. Name of the Function that the Azure Function Activity will
     call. Type: string (or Expression with resultType string).
    :type function_name:
     ~data_factory_management_client.models.AzureFunctionActivityTypePropertiesFunctionName
    :param headers: Represents the headers that will be sent to the request. For example, to set
     the language and type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type":
     "application/json" }. Type: string (or Expression with resultType string).
    :type headers:
     ~data_factory_management_client.models.AzureFunctionActivityTypePropertiesHeaders
    :param body: Represents the payload that will be sent to the endpoint. Required for POST/PUT
     method, not allowed for GET method Type: string (or Expression with resultType string).
    :type body: ~data_factory_management_client.models.AzureFunctionActivityTypePropertiesBody
    """

    _validation = {
        'method': {'required': True},
        'function_name': {'required': True},
    }

    _attribute_map = {
        'method': {'key': 'method', 'type': 'str'},
        'function_name': {'key': 'functionName', 'type': 'AzureFunctionActivityTypePropertiesFunctionName'},
        'headers': {'key': 'headers', 'type': 'AzureFunctionActivityTypePropertiesHeaders'},
        'body': {'key': 'body', 'type': 'AzureFunctionActivityTypePropertiesBody'},
    }

    def __init__(
        self,
        *,
        method: Union[str, "AzureFunctionActivityMethod"],
        function_name: "AzureFunctionActivityTypePropertiesFunctionName",
        headers: Optional["AzureFunctionActivityTypePropertiesHeaders"] = None,
        body: Optional["AzureFunctionActivityTypePropertiesBody"] = None,
        **kwargs
    ):
        super(AzureFunctionActivityTypeProperties, self).__init__(**kwargs)
        self.method = method
        self.function_name = function_name
        self.headers = headers
        self.body = body


class AzureFunctionActivityTypePropertiesBody(msrest.serialization.Model):
    """Represents the payload that will be sent to the endpoint. Required for POST/PUT method, not allowed for GET method Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureFunctionActivityTypePropertiesBody, self).__init__(**kwargs)


class AzureFunctionActivityTypePropertiesFunctionName(msrest.serialization.Model):
    """Name of the Function that the Azure Function Activity will call. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureFunctionActivityTypePropertiesFunctionName, self).__init__(**kwargs)


class AzureFunctionActivityTypePropertiesHeaders(msrest.serialization.Model):
    """Represents the headers that will be sent to the request. For example, to set the language and type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type": "application/json" }. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureFunctionActivityTypePropertiesHeaders, self).__init__(**kwargs)


class AzureFunctionLinkedService(LinkedService):
    """Azure Function linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param function_app_url: Required. The endpoint of the Azure Function App. URL will be in the
     format https://:code:`<accountName>`.azurewebsites.net.
    :type function_app_url:
     ~data_factory_management_client.models.AzureFunctionLinkedServiceTypePropertiesFunctionAppUrl
    :param function_key: The base definition of a secret type.
    :type function_key: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureFunctionLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'function_app_url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'function_app_url': {'key': 'typeProperties.functionAppUrl', 'type': 'AzureFunctionLinkedServiceTypePropertiesFunctionAppUrl'},
        'function_key': {'key': 'typeProperties.functionKey', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzureFunctionLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        function_app_url: "AzureFunctionLinkedServiceTypePropertiesFunctionAppUrl",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        function_key: Optional["SecretBase"] = None,
        encrypted_credential: Optional["AzureFunctionLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureFunctionLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureFunction'
        self.function_app_url = function_app_url
        self.function_key = function_key
        self.encrypted_credential = encrypted_credential


class AzureFunctionLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure Function linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param function_app_url: Required. The endpoint of the Azure Function App. URL will be in the
     format https://:code:`<accountName>`.azurewebsites.net.
    :type function_app_url:
     ~data_factory_management_client.models.AzureFunctionLinkedServiceTypePropertiesFunctionAppUrl
    :param function_key: The base definition of a secret type.
    :type function_key: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureFunctionLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'function_app_url': {'required': True},
    }

    _attribute_map = {
        'function_app_url': {'key': 'functionAppUrl', 'type': 'AzureFunctionLinkedServiceTypePropertiesFunctionAppUrl'},
        'function_key': {'key': 'functionKey', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzureFunctionLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        function_app_url: "AzureFunctionLinkedServiceTypePropertiesFunctionAppUrl",
        function_key: Optional["SecretBase"] = None,
        encrypted_credential: Optional["AzureFunctionLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureFunctionLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.function_app_url = function_app_url
        self.function_key = function_key
        self.encrypted_credential = encrypted_credential


class AzureFunctionLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureFunctionLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzureFunctionLinkedServiceTypePropertiesFunctionAppUrl(msrest.serialization.Model):
    """The endpoint of the Azure Function App. URL will be in the format https://:code:`<accountName>`.azurewebsites.net.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureFunctionLinkedServiceTypePropertiesFunctionAppUrl, self).__init__(**kwargs)


class AzureKeyVaultLinkedService(LinkedService):
    """Azure Key Vault linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param base_url: Required. The base URL of the Azure Key Vault. e.g.
     https://myakv.vault.azure.net Type: string (or Expression with resultType string).
    :type base_url:
     ~data_factory_management_client.models.AzureKeyVaultLinkedServiceTypePropertiesBaseUrl
    """

    _validation = {
        'type': {'required': True},
        'base_url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'base_url': {'key': 'typeProperties.baseUrl', 'type': 'AzureKeyVaultLinkedServiceTypePropertiesBaseUrl'},
    }

    def __init__(
        self,
        *,
        base_url: "AzureKeyVaultLinkedServiceTypePropertiesBaseUrl",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        **kwargs
    ):
        super(AzureKeyVaultLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureKeyVault'
        self.base_url = base_url


class AzureKeyVaultLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure Key Vault linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param base_url: Required. The base URL of the Azure Key Vault. e.g.
     https://myakv.vault.azure.net Type: string (or Expression with resultType string).
    :type base_url:
     ~data_factory_management_client.models.AzureKeyVaultLinkedServiceTypePropertiesBaseUrl
    """

    _validation = {
        'base_url': {'required': True},
    }

    _attribute_map = {
        'base_url': {'key': 'baseUrl', 'type': 'AzureKeyVaultLinkedServiceTypePropertiesBaseUrl'},
    }

    def __init__(
        self,
        *,
        base_url: "AzureKeyVaultLinkedServiceTypePropertiesBaseUrl",
        **kwargs
    ):
        super(AzureKeyVaultLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.base_url = base_url


class AzureKeyVaultLinkedServiceTypePropertiesBaseUrl(msrest.serialization.Model):
    """The base URL of the Azure Key Vault. e.g. https://myakv.vault.azure.net Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureKeyVaultLinkedServiceTypePropertiesBaseUrl, self).__init__(**kwargs)


class SecretBase(msrest.serialization.Model):
    """The base definition of a secret type.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AzureKeyVaultSecretReference, SecureString.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. Type of the secret.Constant filled by server.
    :type type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'AzureKeyVaultSecret': 'AzureKeyVaultSecretReference', 'SecureString': 'SecureString'}
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SecretBase, self).__init__(**kwargs)
        self.type = None


class AzureKeyVaultSecretReference(SecretBase):
    """Azure Key Vault secret reference.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. Type of the secret.Constant filled by server.
    :type type: str
    :param store: Required. Linked service reference type.
    :type store: ~data_factory_management_client.models.LinkedServiceReference
    :param secret_name: Required. The name of the secret in Azure Key Vault. Type: string (or
     Expression with resultType string).
    :type secret_name:
     ~data_factory_management_client.models.AzureKeyVaultSecretReferenceSecretName
    :param secret_version: The version of the secret in Azure Key Vault. The default value is the
     latest version of the secret. Type: string (or Expression with resultType string).
    :type secret_version:
     ~data_factory_management_client.models.AzureKeyVaultSecretReferenceSecretVersion
    """

    _validation = {
        'type': {'required': True},
        'store': {'required': True},
        'secret_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'store': {'key': 'store', 'type': 'LinkedServiceReference'},
        'secret_name': {'key': 'secretName', 'type': 'AzureKeyVaultSecretReferenceSecretName'},
        'secret_version': {'key': 'secretVersion', 'type': 'AzureKeyVaultSecretReferenceSecretVersion'},
    }

    def __init__(
        self,
        *,
        store: "LinkedServiceReference",
        secret_name: "AzureKeyVaultSecretReferenceSecretName",
        secret_version: Optional["AzureKeyVaultSecretReferenceSecretVersion"] = None,
        **kwargs
    ):
        super(AzureKeyVaultSecretReference, self).__init__(**kwargs)
        self.type = 'AzureKeyVaultSecret'
        self.store = store
        self.secret_name = secret_name
        self.secret_version = secret_version


class AzureKeyVaultSecretReferenceSecretName(msrest.serialization.Model):
    """The name of the secret in Azure Key Vault. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureKeyVaultSecretReferenceSecretName, self).__init__(**kwargs)


class AzureKeyVaultSecretReferenceSecretVersion(msrest.serialization.Model):
    """The version of the secret in Azure Key Vault. The default value is the latest version of the secret. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureKeyVaultSecretReferenceSecretVersion, self).__init__(**kwargs)


class AzureMariaDBLinkedService(LinkedService):
    """Azure Database for MariaDB linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzureMariaDBLinkedServiceTypePropertiesConnectionString
    :param pwd: Azure Key Vault secret reference.
    :type pwd: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureMariaDBLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'AzureMariaDBLinkedServiceTypePropertiesConnectionString'},
        'pwd': {'key': 'typeProperties.pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzureMariaDBLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        connection_string: Optional["AzureMariaDBLinkedServiceTypePropertiesConnectionString"] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["AzureMariaDBLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureMariaDBLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureMariaDB'
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class AzureMariaDBLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure Database for MariaDB linked service properties.

    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzureMariaDBLinkedServiceTypePropertiesConnectionString
    :param pwd: Azure Key Vault secret reference.
    :type pwd: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureMariaDBLinkedServiceTypePropertiesEncryptedCredential
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'AzureMariaDBLinkedServiceTypePropertiesConnectionString'},
        'pwd': {'key': 'pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzureMariaDBLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional["AzureMariaDBLinkedServiceTypePropertiesConnectionString"] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["AzureMariaDBLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureMariaDBLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class AzureMariaDBLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """An ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMariaDBLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class AzureMariaDBLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMariaDBLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzureMariaDBSource(TabularSource):
    """A copy activity Azure MariaDB source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.AzureMariaDBSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'AzureMariaDBSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["AzureMariaDBSourceQuery"] = None,
        **kwargs
    ):
        super(AzureMariaDBSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'AzureMariaDBSource'
        self.query = query


class AzureMariaDBSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMariaDBSourceQuery, self).__init__(**kwargs)


class AzureMariaDBTableDataset(Dataset):
    """Azure Database for MariaDB dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(AzureMariaDBTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureMariaDBTable'
        self.table_name = table_name


class AzureMLBatchExecutionActivity(ExecutionActivity):
    """Azure ML Batch Execution activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param global_parameters: Key,Value pairs to be passed to the Azure ML Batch Execution Service
     endpoint. Keys must match the names of web service parameters defined in the published Azure ML
     web service. Values will be passed in the GlobalParameters property of the Azure ML batch
     execution request.
    :type global_parameters: dict[str, object]
    :param web_service_outputs: Key,Value pairs, mapping the names of Azure ML endpoint's Web
     Service Outputs to AzureMLWebServiceFile objects specifying the output Blob locations. This
     information will be passed in the WebServiceOutputs property of the Azure ML batch execution
     request.
    :type web_service_outputs: dict[str,
     ~data_factory_management_client.models.AzureMLWebServiceFile]
    :param web_service_inputs: Key,Value pairs, mapping the names of Azure ML endpoint's Web
     Service Inputs to AzureMLWebServiceFile objects specifying the input Blob locations.. This
     information will be passed in the WebServiceInputs property of the Azure ML batch execution
     request.
    :type web_service_inputs: dict[str,
     ~data_factory_management_client.models.AzureMLWebServiceFile]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'global_parameters': {'key': 'typeProperties.globalParameters', 'type': '{object}'},
        'web_service_outputs': {'key': 'typeProperties.webServiceOutputs', 'type': '{AzureMLWebServiceFile}'},
        'web_service_inputs': {'key': 'typeProperties.webServiceInputs', 'type': '{AzureMLWebServiceFile}'},
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        global_parameters: Optional[Dict[str, object]] = None,
        web_service_outputs: Optional[Dict[str, "AzureMLWebServiceFile"]] = None,
        web_service_inputs: Optional[Dict[str, "AzureMLWebServiceFile"]] = None,
        **kwargs
    ):
        super(AzureMLBatchExecutionActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'AzureMLBatchExecution'
        self.global_parameters = global_parameters
        self.web_service_outputs = web_service_outputs
        self.web_service_inputs = web_service_inputs


class AzureMLBatchExecutionActivityTypeProperties(msrest.serialization.Model):
    """Azure ML Batch Execution activity properties.

    :param global_parameters: Key,Value pairs to be passed to the Azure ML Batch Execution Service
     endpoint. Keys must match the names of web service parameters defined in the published Azure ML
     web service. Values will be passed in the GlobalParameters property of the Azure ML batch
     execution request.
    :type global_parameters: dict[str, object]
    :param web_service_outputs: Key,Value pairs, mapping the names of Azure ML endpoint's Web
     Service Outputs to AzureMLWebServiceFile objects specifying the output Blob locations. This
     information will be passed in the WebServiceOutputs property of the Azure ML batch execution
     request.
    :type web_service_outputs: dict[str,
     ~data_factory_management_client.models.AzureMLWebServiceFile]
    :param web_service_inputs: Key,Value pairs, mapping the names of Azure ML endpoint's Web
     Service Inputs to AzureMLWebServiceFile objects specifying the input Blob locations.. This
     information will be passed in the WebServiceInputs property of the Azure ML batch execution
     request.
    :type web_service_inputs: dict[str,
     ~data_factory_management_client.models.AzureMLWebServiceFile]
    """

    _attribute_map = {
        'global_parameters': {'key': 'globalParameters', 'type': '{object}'},
        'web_service_outputs': {'key': 'webServiceOutputs', 'type': '{AzureMLWebServiceFile}'},
        'web_service_inputs': {'key': 'webServiceInputs', 'type': '{AzureMLWebServiceFile}'},
    }

    def __init__(
        self,
        *,
        global_parameters: Optional[Dict[str, object]] = None,
        web_service_outputs: Optional[Dict[str, "AzureMLWebServiceFile"]] = None,
        web_service_inputs: Optional[Dict[str, "AzureMLWebServiceFile"]] = None,
        **kwargs
    ):
        super(AzureMLBatchExecutionActivityTypeProperties, self).__init__(**kwargs)
        self.global_parameters = global_parameters
        self.web_service_outputs = web_service_outputs
        self.web_service_inputs = web_service_inputs


class AzureMLExecutePipelineActivity(ExecutionActivity):
    """Azure ML Execute Pipeline activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param ml_pipeline_id: Required. ID of the published Azure ML pipeline. Type: string (or
     Expression with resultType string).
    :type ml_pipeline_id:
     ~data_factory_management_client.models.AzureMLExecutePipelineActivityTypePropertiesMlPipelineId
    :param experiment_name: Run history experiment name of the pipeline run. This information will
     be passed in the ExperimentName property of the published pipeline execution request. Type:
     string (or Expression with resultType string).
    :type experiment_name:
     ~data_factory_management_client.models.AzureMLExecutePipelineActivityTypePropertiesExperimentName
    :param ml_pipeline_parameters: Key,Value pairs to be passed to the published Azure ML pipeline
     endpoint. Keys must match the names of pipeline parameters defined in the published pipeline.
     Values will be passed in the ParameterAssignments property of the published pipeline execution
     request. Type: object with key value pairs (or Expression with resultType object).
    :type ml_pipeline_parameters:
     ~data_factory_management_client.models.AzureMLExecutePipelineActivityTypePropertiesMlPipelineParameters
    :param ml_parent_run_id: The parent Azure ML Service pipeline run id. This information will be
     passed in the ParentRunId property of the published pipeline execution request. Type: string
     (or Expression with resultType string).
    :type ml_parent_run_id:
     ~data_factory_management_client.models.AzureMLExecutePipelineActivityTypePropertiesMlParentRunId
    :param continue_on_step_failure: Whether to continue execution of other steps in the
     PipelineRun if a step fails. This information will be passed in the continueOnStepFailure
     property of the published pipeline execution request. Type: boolean (or Expression with
     resultType boolean).
    :type continue_on_step_failure:
     ~data_factory_management_client.models.AzureMLExecutePipelineActivityTypePropertiesContinueOnStepFailure
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'ml_pipeline_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'ml_pipeline_id': {'key': 'typeProperties.mlPipelineId', 'type': 'AzureMLExecutePipelineActivityTypePropertiesMlPipelineId'},
        'experiment_name': {'key': 'typeProperties.experimentName', 'type': 'AzureMLExecutePipelineActivityTypePropertiesExperimentName'},
        'ml_pipeline_parameters': {'key': 'typeProperties.mlPipelineParameters', 'type': 'AzureMLExecutePipelineActivityTypePropertiesMlPipelineParameters'},
        'ml_parent_run_id': {'key': 'typeProperties.mlParentRunId', 'type': 'AzureMLExecutePipelineActivityTypePropertiesMlParentRunId'},
        'continue_on_step_failure': {'key': 'typeProperties.continueOnStepFailure', 'type': 'AzureMLExecutePipelineActivityTypePropertiesContinueOnStepFailure'},
    }

    def __init__(
        self,
        *,
        name: str,
        ml_pipeline_id: "AzureMLExecutePipelineActivityTypePropertiesMlPipelineId",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        experiment_name: Optional["AzureMLExecutePipelineActivityTypePropertiesExperimentName"] = None,
        ml_pipeline_parameters: Optional["AzureMLExecutePipelineActivityTypePropertiesMlPipelineParameters"] = None,
        ml_parent_run_id: Optional["AzureMLExecutePipelineActivityTypePropertiesMlParentRunId"] = None,
        continue_on_step_failure: Optional["AzureMLExecutePipelineActivityTypePropertiesContinueOnStepFailure"] = None,
        **kwargs
    ):
        super(AzureMLExecutePipelineActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'AzureMLExecutePipeline'
        self.ml_pipeline_id = ml_pipeline_id
        self.experiment_name = experiment_name
        self.ml_pipeline_parameters = ml_pipeline_parameters
        self.ml_parent_run_id = ml_parent_run_id
        self.continue_on_step_failure = continue_on_step_failure


class AzureMLExecutePipelineActivityTypeProperties(msrest.serialization.Model):
    """Azure ML Execute Pipeline activity properties.

    All required parameters must be populated in order to send to Azure.

    :param ml_pipeline_id: Required. ID of the published Azure ML pipeline. Type: string (or
     Expression with resultType string).
    :type ml_pipeline_id:
     ~data_factory_management_client.models.AzureMLExecutePipelineActivityTypePropertiesMlPipelineId
    :param experiment_name: Run history experiment name of the pipeline run. This information will
     be passed in the ExperimentName property of the published pipeline execution request. Type:
     string (or Expression with resultType string).
    :type experiment_name:
     ~data_factory_management_client.models.AzureMLExecutePipelineActivityTypePropertiesExperimentName
    :param ml_pipeline_parameters: Key,Value pairs to be passed to the published Azure ML pipeline
     endpoint. Keys must match the names of pipeline parameters defined in the published pipeline.
     Values will be passed in the ParameterAssignments property of the published pipeline execution
     request. Type: object with key value pairs (or Expression with resultType object).
    :type ml_pipeline_parameters:
     ~data_factory_management_client.models.AzureMLExecutePipelineActivityTypePropertiesMlPipelineParameters
    :param ml_parent_run_id: The parent Azure ML Service pipeline run id. This information will be
     passed in the ParentRunId property of the published pipeline execution request. Type: string
     (or Expression with resultType string).
    :type ml_parent_run_id:
     ~data_factory_management_client.models.AzureMLExecutePipelineActivityTypePropertiesMlParentRunId
    :param continue_on_step_failure: Whether to continue execution of other steps in the
     PipelineRun if a step fails. This information will be passed in the continueOnStepFailure
     property of the published pipeline execution request. Type: boolean (or Expression with
     resultType boolean).
    :type continue_on_step_failure:
     ~data_factory_management_client.models.AzureMLExecutePipelineActivityTypePropertiesContinueOnStepFailure
    """

    _validation = {
        'ml_pipeline_id': {'required': True},
    }

    _attribute_map = {
        'ml_pipeline_id': {'key': 'mlPipelineId', 'type': 'AzureMLExecutePipelineActivityTypePropertiesMlPipelineId'},
        'experiment_name': {'key': 'experimentName', 'type': 'AzureMLExecutePipelineActivityTypePropertiesExperimentName'},
        'ml_pipeline_parameters': {'key': 'mlPipelineParameters', 'type': 'AzureMLExecutePipelineActivityTypePropertiesMlPipelineParameters'},
        'ml_parent_run_id': {'key': 'mlParentRunId', 'type': 'AzureMLExecutePipelineActivityTypePropertiesMlParentRunId'},
        'continue_on_step_failure': {'key': 'continueOnStepFailure', 'type': 'AzureMLExecutePipelineActivityTypePropertiesContinueOnStepFailure'},
    }

    def __init__(
        self,
        *,
        ml_pipeline_id: "AzureMLExecutePipelineActivityTypePropertiesMlPipelineId",
        experiment_name: Optional["AzureMLExecutePipelineActivityTypePropertiesExperimentName"] = None,
        ml_pipeline_parameters: Optional["AzureMLExecutePipelineActivityTypePropertiesMlPipelineParameters"] = None,
        ml_parent_run_id: Optional["AzureMLExecutePipelineActivityTypePropertiesMlParentRunId"] = None,
        continue_on_step_failure: Optional["AzureMLExecutePipelineActivityTypePropertiesContinueOnStepFailure"] = None,
        **kwargs
    ):
        super(AzureMLExecutePipelineActivityTypeProperties, self).__init__(**kwargs)
        self.ml_pipeline_id = ml_pipeline_id
        self.experiment_name = experiment_name
        self.ml_pipeline_parameters = ml_pipeline_parameters
        self.ml_parent_run_id = ml_parent_run_id
        self.continue_on_step_failure = continue_on_step_failure


class AzureMLExecutePipelineActivityTypePropertiesContinueOnStepFailure(msrest.serialization.Model):
    """Whether to continue execution of other steps in the PipelineRun if a step fails. This information will be passed in the continueOnStepFailure property of the published pipeline execution request. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLExecutePipelineActivityTypePropertiesContinueOnStepFailure, self).__init__(**kwargs)


class AzureMLExecutePipelineActivityTypePropertiesExperimentName(msrest.serialization.Model):
    """Run history experiment name of the pipeline run. This information will be passed in the ExperimentName property of the published pipeline execution request. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLExecutePipelineActivityTypePropertiesExperimentName, self).__init__(**kwargs)


class AzureMLExecutePipelineActivityTypePropertiesMlParentRunId(msrest.serialization.Model):
    """The parent Azure ML Service pipeline run id. This information will be passed in the ParentRunId property of the published pipeline execution request. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLExecutePipelineActivityTypePropertiesMlParentRunId, self).__init__(**kwargs)


class AzureMLExecutePipelineActivityTypePropertiesMlPipelineId(msrest.serialization.Model):
    """ID of the published Azure ML pipeline. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLExecutePipelineActivityTypePropertiesMlPipelineId, self).__init__(**kwargs)


class AzureMLExecutePipelineActivityTypePropertiesMlPipelineParameters(msrest.serialization.Model):
    """Key,Value pairs to be passed to the published Azure ML pipeline endpoint. Keys must match the names of pipeline parameters defined in the published pipeline. Values will be passed in the ParameterAssignments property of the published pipeline execution request. Type: object with key value pairs (or Expression with resultType object).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLExecutePipelineActivityTypePropertiesMlPipelineParameters, self).__init__(**kwargs)


class AzureMLLinkedService(LinkedService):
    """Azure ML Studio Web Service linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param ml_endpoint: Required. The Batch Execution REST URL for an Azure ML Studio Web Service
     endpoint. Type: string (or Expression with resultType string).
    :type ml_endpoint:
     ~data_factory_management_client.models.AzureMLLinkedServiceTypePropertiesMlEndpoint
    :param api_key: Required. The base definition of a secret type.
    :type api_key: ~data_factory_management_client.models.SecretBase
    :param update_resource_endpoint: The Update Resource REST URL for an Azure ML Studio Web
     Service endpoint. Type: string (or Expression with resultType string).
    :type update_resource_endpoint:
     ~data_factory_management_client.models.AzureMLLinkedServiceTypePropertiesUpdateResourceEndpoint
    :param service_principal_id: The ID of the service principal used to authenticate against the
     ARM-based updateResourceEndpoint of an Azure ML Studio web service. Type: string (or Expression
     with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureMLLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant: ~data_factory_management_client.models.AzureMLLinkedServiceTypePropertiesTenant
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureMLLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'ml_endpoint': {'required': True},
        'api_key': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'ml_endpoint': {'key': 'typeProperties.mlEndpoint', 'type': 'AzureMLLinkedServiceTypePropertiesMlEndpoint'},
        'api_key': {'key': 'typeProperties.apiKey', 'type': 'SecretBase'},
        'update_resource_endpoint': {'key': 'typeProperties.updateResourceEndpoint', 'type': 'AzureMLLinkedServiceTypePropertiesUpdateResourceEndpoint'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'AzureMLLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'AzureMLLinkedServiceTypePropertiesTenant'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzureMLLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        ml_endpoint: "AzureMLLinkedServiceTypePropertiesMlEndpoint",
        api_key: "SecretBase",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        update_resource_endpoint: Optional["AzureMLLinkedServiceTypePropertiesUpdateResourceEndpoint"] = None,
        service_principal_id: Optional["AzureMLLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureMLLinkedServiceTypePropertiesTenant"] = None,
        encrypted_credential: Optional["AzureMLLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureMLLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureML'
        self.ml_endpoint = ml_endpoint
        self.api_key = api_key
        self.update_resource_endpoint = update_resource_endpoint
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential


class AzureMLLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure ML Studio Web Service linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param ml_endpoint: Required. The Batch Execution REST URL for an Azure ML Studio Web Service
     endpoint. Type: string (or Expression with resultType string).
    :type ml_endpoint:
     ~data_factory_management_client.models.AzureMLLinkedServiceTypePropertiesMlEndpoint
    :param api_key: Required. The base definition of a secret type.
    :type api_key: ~data_factory_management_client.models.SecretBase
    :param update_resource_endpoint: The Update Resource REST URL for an Azure ML Studio Web
     Service endpoint. Type: string (or Expression with resultType string).
    :type update_resource_endpoint:
     ~data_factory_management_client.models.AzureMLLinkedServiceTypePropertiesUpdateResourceEndpoint
    :param service_principal_id: The ID of the service principal used to authenticate against the
     ARM-based updateResourceEndpoint of an Azure ML Studio web service. Type: string (or Expression
     with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureMLLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant: ~data_factory_management_client.models.AzureMLLinkedServiceTypePropertiesTenant
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureMLLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'ml_endpoint': {'required': True},
        'api_key': {'required': True},
    }

    _attribute_map = {
        'ml_endpoint': {'key': 'mlEndpoint', 'type': 'AzureMLLinkedServiceTypePropertiesMlEndpoint'},
        'api_key': {'key': 'apiKey', 'type': 'SecretBase'},
        'update_resource_endpoint': {'key': 'updateResourceEndpoint', 'type': 'AzureMLLinkedServiceTypePropertiesUpdateResourceEndpoint'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'AzureMLLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'tenant', 'type': 'AzureMLLinkedServiceTypePropertiesTenant'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzureMLLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        ml_endpoint: "AzureMLLinkedServiceTypePropertiesMlEndpoint",
        api_key: "SecretBase",
        update_resource_endpoint: Optional["AzureMLLinkedServiceTypePropertiesUpdateResourceEndpoint"] = None,
        service_principal_id: Optional["AzureMLLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureMLLinkedServiceTypePropertiesTenant"] = None,
        encrypted_credential: Optional["AzureMLLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureMLLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.ml_endpoint = ml_endpoint
        self.api_key = api_key
        self.update_resource_endpoint = update_resource_endpoint
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential


class AzureMLLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzureMLLinkedServiceTypePropertiesMlEndpoint(msrest.serialization.Model):
    """The Batch Execution REST URL for an Azure ML Studio Web Service endpoint. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLLinkedServiceTypePropertiesMlEndpoint, self).__init__(**kwargs)


class AzureMLLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """The ID of the service principal used to authenticate against the ARM-based updateResourceEndpoint of an Azure ML Studio web service. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class AzureMLLinkedServiceTypePropertiesTenant(msrest.serialization.Model):
    """The name or ID of the tenant to which the service principal belongs. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLLinkedServiceTypePropertiesTenant, self).__init__(**kwargs)


class AzureMLLinkedServiceTypePropertiesUpdateResourceEndpoint(msrest.serialization.Model):
    """The Update Resource REST URL for an Azure ML Studio Web Service endpoint. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLLinkedServiceTypePropertiesUpdateResourceEndpoint, self).__init__(**kwargs)


class AzureMLServiceLinkedService(LinkedService):
    """Azure ML Service linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param subscription_id: Required. Azure ML Service workspace subscription ID. Type: string (or
     Expression with resultType string).
    :type subscription_id:
     ~data_factory_management_client.models.AzureMLServiceLinkedServiceTypePropertiesSubscriptionId
    :param resource_group_name: Required. Azure ML Service workspace resource group name. Type:
     string (or Expression with resultType string).
    :type resource_group_name:
     ~data_factory_management_client.models.AzureMLServiceLinkedServiceTypePropertiesResourceGroupName
    :param ml_workspace_name: Required. Azure ML Service workspace name. Type: string (or
     Expression with resultType string).
    :type ml_workspace_name:
     ~data_factory_management_client.models.AzureMLServiceLinkedServiceTypePropertiesMlWorkspaceName
    :param service_principal_id: The ID of the service principal used to authenticate against the
     endpoint of a published Azure ML Service pipeline. Type: string (or Expression with resultType
     string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureMLServiceLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureMLServiceLinkedServiceTypePropertiesTenant
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureMLServiceLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'subscription_id': {'required': True},
        'resource_group_name': {'required': True},
        'ml_workspace_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'subscription_id': {'key': 'typeProperties.subscriptionId', 'type': 'AzureMLServiceLinkedServiceTypePropertiesSubscriptionId'},
        'resource_group_name': {'key': 'typeProperties.resourceGroupName', 'type': 'AzureMLServiceLinkedServiceTypePropertiesResourceGroupName'},
        'ml_workspace_name': {'key': 'typeProperties.mlWorkspaceName', 'type': 'AzureMLServiceLinkedServiceTypePropertiesMlWorkspaceName'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'AzureMLServiceLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'AzureMLServiceLinkedServiceTypePropertiesTenant'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzureMLServiceLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        subscription_id: "AzureMLServiceLinkedServiceTypePropertiesSubscriptionId",
        resource_group_name: "AzureMLServiceLinkedServiceTypePropertiesResourceGroupName",
        ml_workspace_name: "AzureMLServiceLinkedServiceTypePropertiesMlWorkspaceName",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        service_principal_id: Optional["AzureMLServiceLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureMLServiceLinkedServiceTypePropertiesTenant"] = None,
        encrypted_credential: Optional["AzureMLServiceLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureMLServiceLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureMLService'
        self.subscription_id = subscription_id
        self.resource_group_name = resource_group_name
        self.ml_workspace_name = ml_workspace_name
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential


class AzureMLServiceLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure ML Service linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param subscription_id: Required. Azure ML Service workspace subscription ID. Type: string (or
     Expression with resultType string).
    :type subscription_id:
     ~data_factory_management_client.models.AzureMLServiceLinkedServiceTypePropertiesSubscriptionId
    :param resource_group_name: Required. Azure ML Service workspace resource group name. Type:
     string (or Expression with resultType string).
    :type resource_group_name:
     ~data_factory_management_client.models.AzureMLServiceLinkedServiceTypePropertiesResourceGroupName
    :param ml_workspace_name: Required. Azure ML Service workspace name. Type: string (or
     Expression with resultType string).
    :type ml_workspace_name:
     ~data_factory_management_client.models.AzureMLServiceLinkedServiceTypePropertiesMlWorkspaceName
    :param service_principal_id: The ID of the service principal used to authenticate against the
     endpoint of a published Azure ML Service pipeline. Type: string (or Expression with resultType
     string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureMLServiceLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureMLServiceLinkedServiceTypePropertiesTenant
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureMLServiceLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'subscription_id': {'required': True},
        'resource_group_name': {'required': True},
        'ml_workspace_name': {'required': True},
    }

    _attribute_map = {
        'subscription_id': {'key': 'subscriptionId', 'type': 'AzureMLServiceLinkedServiceTypePropertiesSubscriptionId'},
        'resource_group_name': {'key': 'resourceGroupName', 'type': 'AzureMLServiceLinkedServiceTypePropertiesResourceGroupName'},
        'ml_workspace_name': {'key': 'mlWorkspaceName', 'type': 'AzureMLServiceLinkedServiceTypePropertiesMlWorkspaceName'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'AzureMLServiceLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'tenant', 'type': 'AzureMLServiceLinkedServiceTypePropertiesTenant'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzureMLServiceLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        subscription_id: "AzureMLServiceLinkedServiceTypePropertiesSubscriptionId",
        resource_group_name: "AzureMLServiceLinkedServiceTypePropertiesResourceGroupName",
        ml_workspace_name: "AzureMLServiceLinkedServiceTypePropertiesMlWorkspaceName",
        service_principal_id: Optional["AzureMLServiceLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureMLServiceLinkedServiceTypePropertiesTenant"] = None,
        encrypted_credential: Optional["AzureMLServiceLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureMLServiceLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.subscription_id = subscription_id
        self.resource_group_name = resource_group_name
        self.ml_workspace_name = ml_workspace_name
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential


class AzureMLServiceLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLServiceLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzureMLServiceLinkedServiceTypePropertiesMlWorkspaceName(msrest.serialization.Model):
    """Azure ML Service workspace name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLServiceLinkedServiceTypePropertiesMlWorkspaceName, self).__init__(**kwargs)


class AzureMLServiceLinkedServiceTypePropertiesResourceGroupName(msrest.serialization.Model):
    """Azure ML Service workspace resource group name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLServiceLinkedServiceTypePropertiesResourceGroupName, self).__init__(**kwargs)


class AzureMLServiceLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """The ID of the service principal used to authenticate against the endpoint of a published Azure ML Service pipeline. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLServiceLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class AzureMLServiceLinkedServiceTypePropertiesSubscriptionId(msrest.serialization.Model):
    """Azure ML Service workspace subscription ID. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLServiceLinkedServiceTypePropertiesSubscriptionId, self).__init__(**kwargs)


class AzureMLServiceLinkedServiceTypePropertiesTenant(msrest.serialization.Model):
    """The name or ID of the tenant to which the service principal belongs. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLServiceLinkedServiceTypePropertiesTenant, self).__init__(**kwargs)


class AzureMLUpdateResourceActivity(ExecutionActivity):
    """Azure ML Update Resource management activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param trained_model_name: Required. Name of the Trained Model module in the Web Service
     experiment to be updated. Type: string (or Expression with resultType string).
    :type trained_model_name:
     ~data_factory_management_client.models.AzureMLUpdateResourceActivityTypePropertiesTrainedModelName
    :param trained_model_linked_service_name: Required. Linked service reference type.
    :type trained_model_linked_service_name:
     ~data_factory_management_client.models.LinkedServiceReference
    :param trained_model_file_path: Required. The relative file path in trainedModelLinkedService
     to represent the .ilearner file that will be uploaded by the update operation.  Type: string
     (or Expression with resultType string).
    :type trained_model_file_path:
     ~data_factory_management_client.models.AzureMLUpdateResourceActivityTypePropertiesTrainedModelFilePath
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'trained_model_name': {'required': True},
        'trained_model_linked_service_name': {'required': True},
        'trained_model_file_path': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'trained_model_name': {'key': 'typeProperties.trainedModelName', 'type': 'AzureMLUpdateResourceActivityTypePropertiesTrainedModelName'},
        'trained_model_linked_service_name': {'key': 'typeProperties.trainedModelLinkedServiceName', 'type': 'LinkedServiceReference'},
        'trained_model_file_path': {'key': 'typeProperties.trainedModelFilePath', 'type': 'AzureMLUpdateResourceActivityTypePropertiesTrainedModelFilePath'},
    }

    def __init__(
        self,
        *,
        name: str,
        trained_model_name: "AzureMLUpdateResourceActivityTypePropertiesTrainedModelName",
        trained_model_linked_service_name: "LinkedServiceReference",
        trained_model_file_path: "AzureMLUpdateResourceActivityTypePropertiesTrainedModelFilePath",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        **kwargs
    ):
        super(AzureMLUpdateResourceActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'AzureMLUpdateResource'
        self.trained_model_name = trained_model_name
        self.trained_model_linked_service_name = trained_model_linked_service_name
        self.trained_model_file_path = trained_model_file_path


class AzureMLUpdateResourceActivityTypeProperties(msrest.serialization.Model):
    """Azure ML Update Resource activity properties.

    All required parameters must be populated in order to send to Azure.

    :param trained_model_name: Required. Name of the Trained Model module in the Web Service
     experiment to be updated. Type: string (or Expression with resultType string).
    :type trained_model_name:
     ~data_factory_management_client.models.AzureMLUpdateResourceActivityTypePropertiesTrainedModelName
    :param trained_model_linked_service_name: Required. Linked service reference type.
    :type trained_model_linked_service_name:
     ~data_factory_management_client.models.LinkedServiceReference
    :param trained_model_file_path: Required. The relative file path in trainedModelLinkedService
     to represent the .ilearner file that will be uploaded by the update operation.  Type: string
     (or Expression with resultType string).
    :type trained_model_file_path:
     ~data_factory_management_client.models.AzureMLUpdateResourceActivityTypePropertiesTrainedModelFilePath
    """

    _validation = {
        'trained_model_name': {'required': True},
        'trained_model_linked_service_name': {'required': True},
        'trained_model_file_path': {'required': True},
    }

    _attribute_map = {
        'trained_model_name': {'key': 'trainedModelName', 'type': 'AzureMLUpdateResourceActivityTypePropertiesTrainedModelName'},
        'trained_model_linked_service_name': {'key': 'trainedModelLinkedServiceName', 'type': 'LinkedServiceReference'},
        'trained_model_file_path': {'key': 'trainedModelFilePath', 'type': 'AzureMLUpdateResourceActivityTypePropertiesTrainedModelFilePath'},
    }

    def __init__(
        self,
        *,
        trained_model_name: "AzureMLUpdateResourceActivityTypePropertiesTrainedModelName",
        trained_model_linked_service_name: "LinkedServiceReference",
        trained_model_file_path: "AzureMLUpdateResourceActivityTypePropertiesTrainedModelFilePath",
        **kwargs
    ):
        super(AzureMLUpdateResourceActivityTypeProperties, self).__init__(**kwargs)
        self.trained_model_name = trained_model_name
        self.trained_model_linked_service_name = trained_model_linked_service_name
        self.trained_model_file_path = trained_model_file_path


class AzureMLUpdateResourceActivityTypePropertiesTrainedModelFilePath(msrest.serialization.Model):
    """The relative file path in trainedModelLinkedService to represent the .ilearner file that will be uploaded by the update operation.  Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLUpdateResourceActivityTypePropertiesTrainedModelFilePath, self).__init__(**kwargs)


class AzureMLUpdateResourceActivityTypePropertiesTrainedModelName(msrest.serialization.Model):
    """Name of the Trained Model module in the Web Service experiment to be updated. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLUpdateResourceActivityTypePropertiesTrainedModelName, self).__init__(**kwargs)


class AzureMLWebServiceFile(msrest.serialization.Model):
    """Azure ML WebService Input/Output file.

    All required parameters must be populated in order to send to Azure.

    :param file_path: Required. The relative file path, including container name, in the Azure Blob
     Storage specified by the LinkedService. Type: string (or Expression with resultType string).
    :type file_path: ~data_factory_management_client.models.AzureMLWebServiceFileFilePath
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    """

    _validation = {
        'file_path': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'file_path': {'key': 'filePath', 'type': 'AzureMLWebServiceFileFilePath'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
    }

    def __init__(
        self,
        *,
        file_path: "AzureMLWebServiceFileFilePath",
        linked_service_name: "LinkedServiceReference",
        **kwargs
    ):
        super(AzureMLWebServiceFile, self).__init__(**kwargs)
        self.file_path = file_path
        self.linked_service_name = linked_service_name


class AzureMLWebServiceFileFilePath(msrest.serialization.Model):
    """The relative file path, including container name, in the Azure Blob Storage specified by the LinkedService. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMLWebServiceFileFilePath, self).__init__(**kwargs)


class AzureMySqlLinkedService(LinkedService):
    """Azure MySQL database linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzureMySqlLinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureMySqlLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'AzureMySqlLinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzureMySqlLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "AzureMySqlLinkedServiceTypePropertiesConnectionString",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["AzureMySqlLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureMySqlLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureMySql'
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class AzureMySqlLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure MySQL database linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzureMySqlLinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureMySqlLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'AzureMySqlLinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzureMySqlLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "AzureMySqlLinkedServiceTypePropertiesConnectionString",
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["AzureMySqlLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureMySqlLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class AzureMySqlLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMySqlLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class AzureMySqlLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMySqlLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzureMySqlSink(CopySink):
    """A copy activity Azure MySql sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param pre_copy_script: A query to execute before starting the copy. Type: string (or
     Expression with resultType string).
    :type pre_copy_script: ~data_factory_management_client.models.AzureMySqlSinkPreCopyScript
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'AzureMySqlSinkPreCopyScript'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        pre_copy_script: Optional["AzureMySqlSinkPreCopyScript"] = None,
        **kwargs
    ):
        super(AzureMySqlSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzureMySqlSink'
        self.pre_copy_script = pre_copy_script


class AzureMySqlSinkPreCopyScript(msrest.serialization.Model):
    """A query to execute before starting the copy. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMySqlSinkPreCopyScript, self).__init__(**kwargs)


class AzureMySqlSource(TabularSource):
    """A copy activity Azure MySQL source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: Database query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.AzureMySqlSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'AzureMySqlSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["AzureMySqlSourceQuery"] = None,
        **kwargs
    ):
        super(AzureMySqlSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'AzureMySqlSource'
        self.query = query


class AzureMySqlSourceQuery(msrest.serialization.Model):
    """Database query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMySqlSourceQuery, self).__init__(**kwargs)


class AzureMySqlTableDataset(Dataset):
    """The Azure MySQL database dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The Azure MySQL database table name. Type: string (or Expression with
     resultType string).
    :type table_name:
     ~data_factory_management_client.models.AzureMySqlTableDatasetTypePropertiesTableName
    :param table: The name of Azure MySQL database table. Type: string (or Expression with
     resultType string).
    :type table: ~data_factory_management_client.models.AzureMySqlTableDatasetTypePropertiesTable
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'AzureMySqlTableDatasetTypePropertiesTableName'},
        'table': {'key': 'typeProperties.table', 'type': 'AzureMySqlTableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["AzureMySqlTableDatasetTypePropertiesTableName"] = None,
        table: Optional["AzureMySqlTableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(AzureMySqlTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureMySqlTable'
        self.table_name = table_name
        self.table = table


class AzureMySqlTableDatasetTypeProperties(msrest.serialization.Model):
    """Azure MySQL database dataset properties.

    :param table_name: The Azure MySQL database table name. Type: string (or Expression with
     resultType string).
    :type table_name:
     ~data_factory_management_client.models.AzureMySqlTableDatasetTypePropertiesTableName
    :param table: The name of Azure MySQL database table. Type: string (or Expression with
     resultType string).
    :type table: ~data_factory_management_client.models.AzureMySqlTableDatasetTypePropertiesTable
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'AzureMySqlTableDatasetTypePropertiesTableName'},
        'table': {'key': 'table', 'type': 'AzureMySqlTableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["AzureMySqlTableDatasetTypePropertiesTableName"] = None,
        table: Optional["AzureMySqlTableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(AzureMySqlTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.table = table


class AzureMySqlTableDatasetTypePropertiesTable(msrest.serialization.Model):
    """The name of Azure MySQL database table. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMySqlTableDatasetTypePropertiesTable, self).__init__(**kwargs)


class AzureMySqlTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """The Azure MySQL database table name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureMySqlTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class AzurePostgreSqlLinkedService(LinkedService):
    """Azure PostgreSQL linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzurePostgreSqlLinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzurePostgreSqlLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'AzurePostgreSqlLinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzurePostgreSqlLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        connection_string: Optional["AzurePostgreSqlLinkedServiceTypePropertiesConnectionString"] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["AzurePostgreSqlLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzurePostgreSqlLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzurePostgreSql'
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class AzurePostgreSqlLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure PostgreSQL linked service properties.

    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzurePostgreSqlLinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzurePostgreSqlLinkedServiceTypePropertiesEncryptedCredential
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'AzurePostgreSqlLinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzurePostgreSqlLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional["AzurePostgreSqlLinkedServiceTypePropertiesConnectionString"] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["AzurePostgreSqlLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzurePostgreSqlLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class AzurePostgreSqlLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """An ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzurePostgreSqlLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class AzurePostgreSqlLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzurePostgreSqlLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzurePostgreSqlSink(CopySink):
    """A copy activity Azure PostgreSQL sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param pre_copy_script: A query to execute before starting the copy. Type: string (or
     Expression with resultType string).
    :type pre_copy_script: ~data_factory_management_client.models.AzurePostgreSqlSinkPreCopyScript
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'AzurePostgreSqlSinkPreCopyScript'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        pre_copy_script: Optional["AzurePostgreSqlSinkPreCopyScript"] = None,
        **kwargs
    ):
        super(AzurePostgreSqlSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzurePostgreSqlSink'
        self.pre_copy_script = pre_copy_script


class AzurePostgreSqlSinkPreCopyScript(msrest.serialization.Model):
    """A query to execute before starting the copy. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzurePostgreSqlSinkPreCopyScript, self).__init__(**kwargs)


class AzurePostgreSqlSource(TabularSource):
    """A copy activity Azure PostgreSQL source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.AzurePostgreSqlSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'AzurePostgreSqlSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["AzurePostgreSqlSourceQuery"] = None,
        **kwargs
    ):
        super(AzurePostgreSqlSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'AzurePostgreSqlSource'
        self.query = query


class AzurePostgreSqlSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzurePostgreSqlSourceQuery, self).__init__(**kwargs)


class AzurePostgreSqlTableDataset(Dataset):
    """Azure PostgreSQL dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name of the Azure PostgreSQL database which includes both schema
     and table. Type: string (or Expression with resultType string).
    :type table_name:
     ~data_factory_management_client.models.AzurePostgreSqlTableDatasetTypePropertiesTableName
    :param table: The table name of the Azure PostgreSQL database. Type: string (or Expression with
     resultType string).
    :type table:
     ~data_factory_management_client.models.AzurePostgreSqlTableDatasetTypePropertiesTable
    :param schema_type_properties_schema: The schema name of the Azure PostgreSQL database. Type:
     string (or Expression with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.AzurePostgreSqlTableDatasetTypePropertiesSchema
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'AzurePostgreSqlTableDatasetTypePropertiesTableName'},
        'table': {'key': 'typeProperties.table', 'type': 'AzurePostgreSqlTableDatasetTypePropertiesTable'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'AzurePostgreSqlTableDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["AzurePostgreSqlTableDatasetTypePropertiesTableName"] = None,
        table: Optional["AzurePostgreSqlTableDatasetTypePropertiesTable"] = None,
        schema_type_properties_schema: Optional["AzurePostgreSqlTableDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(AzurePostgreSqlTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzurePostgreSqlTable'
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class AzurePostgreSqlTableDatasetTypeProperties(msrest.serialization.Model):
    """Azure PostgreSQL dataset properties.

    :param table_name: The table name of the Azure PostgreSQL database which includes both schema
     and table. Type: string (or Expression with resultType string).
    :type table_name:
     ~data_factory_management_client.models.AzurePostgreSqlTableDatasetTypePropertiesTableName
    :param table: The table name of the Azure PostgreSQL database. Type: string (or Expression with
     resultType string).
    :type table:
     ~data_factory_management_client.models.AzurePostgreSqlTableDatasetTypePropertiesTable
    :param schema: The schema name of the Azure PostgreSQL database. Type: string (or Expression
     with resultType string).
    :type schema:
     ~data_factory_management_client.models.AzurePostgreSqlTableDatasetTypePropertiesSchema
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'AzurePostgreSqlTableDatasetTypePropertiesTableName'},
        'table': {'key': 'table', 'type': 'AzurePostgreSqlTableDatasetTypePropertiesTable'},
        'schema': {'key': 'schema', 'type': 'AzurePostgreSqlTableDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["AzurePostgreSqlTableDatasetTypePropertiesTableName"] = None,
        table: Optional["AzurePostgreSqlTableDatasetTypePropertiesTable"] = None,
        schema: Optional["AzurePostgreSqlTableDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(AzurePostgreSqlTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.table = table
        self.schema = schema


class AzurePostgreSqlTableDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of the Azure PostgreSQL database. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzurePostgreSqlTableDatasetTypePropertiesSchema, self).__init__(**kwargs)


class AzurePostgreSqlTableDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the Azure PostgreSQL database. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzurePostgreSqlTableDatasetTypePropertiesTable, self).__init__(**kwargs)


class AzurePostgreSqlTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """The table name of the Azure PostgreSQL database which includes both schema and table. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzurePostgreSqlTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class AzureQueueSink(CopySink):
    """A copy activity Azure Queue sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        **kwargs
    ):
        super(AzureQueueSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzureQueueSink'


class AzureSearchIndexDataset(Dataset):
    """The Azure Search Index.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param index_name: Required. The name of the Azure Search Index. Type: string (or Expression
     with resultType string).
    :type index_name:
     ~data_factory_management_client.models.AzureSearchIndexDatasetTypePropertiesIndexName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'index_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'index_name': {'key': 'typeProperties.indexName', 'type': 'AzureSearchIndexDatasetTypePropertiesIndexName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        index_name: "AzureSearchIndexDatasetTypePropertiesIndexName",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        super(AzureSearchIndexDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureSearchIndex'
        self.index_name = index_name


class AzureSearchIndexDatasetTypeProperties(msrest.serialization.Model):
    """Properties specific to this dataset type.

    All required parameters must be populated in order to send to Azure.

    :param index_name: Required. The name of the Azure Search Index. Type: string (or Expression
     with resultType string).
    :type index_name:
     ~data_factory_management_client.models.AzureSearchIndexDatasetTypePropertiesIndexName
    """

    _validation = {
        'index_name': {'required': True},
    }

    _attribute_map = {
        'index_name': {'key': 'indexName', 'type': 'AzureSearchIndexDatasetTypePropertiesIndexName'},
    }

    def __init__(
        self,
        *,
        index_name: "AzureSearchIndexDatasetTypePropertiesIndexName",
        **kwargs
    ):
        super(AzureSearchIndexDatasetTypeProperties, self).__init__(**kwargs)
        self.index_name = index_name


class AzureSearchIndexDatasetTypePropertiesIndexName(msrest.serialization.Model):
    """The name of the Azure Search Index. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSearchIndexDatasetTypePropertiesIndexName, self).__init__(**kwargs)


class AzureSearchIndexSink(CopySink):
    """A copy activity Azure Search Index sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param write_behavior: Specify the write behavior when upserting documents into Azure Search
     Index. Possible values include: 'Merge', 'Upload'.
    :type write_behavior: str or
     ~data_factory_management_client.models.AzureSearchIndexWriteBehaviorType
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        write_behavior: Optional[Union[str, "AzureSearchIndexWriteBehaviorType"]] = None,
        **kwargs
    ):
        super(AzureSearchIndexSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzureSearchIndexSink'
        self.write_behavior = write_behavior


class AzureSearchLinkedService(LinkedService):
    """Linked service for Windows Azure Search Service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param url: Required. URL for Azure Search service. Type: string (or Expression with resultType
     string).
    :type url: ~data_factory_management_client.models.AzureSearchLinkedServiceTypePropertiesUrl
    :param key: The base definition of a secret type.
    :type key: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureSearchLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'url': {'key': 'typeProperties.url', 'type': 'AzureSearchLinkedServiceTypePropertiesUrl'},
        'key': {'key': 'typeProperties.key', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzureSearchLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        url: "AzureSearchLinkedServiceTypePropertiesUrl",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        key: Optional["SecretBase"] = None,
        encrypted_credential: Optional["AzureSearchLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureSearchLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureSearch'
        self.url = url
        self.key = key
        self.encrypted_credential = encrypted_credential


class AzureSearchLinkedServiceTypeProperties(msrest.serialization.Model):
    """Windows Azure Search Service linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param url: Required. URL for Azure Search service. Type: string (or Expression with resultType
     string).
    :type url: ~data_factory_management_client.models.AzureSearchLinkedServiceTypePropertiesUrl
    :param key: The base definition of a secret type.
    :type key: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureSearchLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'url': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'AzureSearchLinkedServiceTypePropertiesUrl'},
        'key': {'key': 'key', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzureSearchLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        url: "AzureSearchLinkedServiceTypePropertiesUrl",
        key: Optional["SecretBase"] = None,
        encrypted_credential: Optional["AzureSearchLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureSearchLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.url = url
        self.key = key
        self.encrypted_credential = encrypted_credential


class AzureSearchLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSearchLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzureSearchLinkedServiceTypePropertiesUrl(msrest.serialization.Model):
    """URL for Azure Search service. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSearchLinkedServiceTypePropertiesUrl, self).__init__(**kwargs)


class AzureSqlDatabaseLinkedService(LinkedService):
    """Microsoft Azure SQL Database linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzureSqlDatabaseLinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param service_principal_id: The ID of the service principal used to authenticate against Azure
     SQL Database. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureSqlDatabaseLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureSqlDatabaseLinkedServiceTypePropertiesTenant
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureSqlDatabaseLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'AzureSqlDatabaseLinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'AzureSqlDatabaseLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'AzureSqlDatabaseLinkedServiceTypePropertiesTenant'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzureSqlDatabaseLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "AzureSqlDatabaseLinkedServiceTypePropertiesConnectionString",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        service_principal_id: Optional["AzureSqlDatabaseLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureSqlDatabaseLinkedServiceTypePropertiesTenant"] = None,
        encrypted_credential: Optional["AzureSqlDatabaseLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureSqlDatabaseLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureSqlDatabase'
        self.connection_string = connection_string
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential


class AzureSqlDatabaseLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure SQL Database linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzureSqlDatabaseLinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param service_principal_id: The ID of the service principal used to authenticate against Azure
     SQL Database. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureSqlDatabaseLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureSqlDatabaseLinkedServiceTypePropertiesTenant
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureSqlDatabaseLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'AzureSqlDatabaseLinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'password', 'type': 'AzureKeyVaultSecretReference'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'AzureSqlDatabaseLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'tenant', 'type': 'AzureSqlDatabaseLinkedServiceTypePropertiesTenant'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzureSqlDatabaseLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "AzureSqlDatabaseLinkedServiceTypePropertiesConnectionString",
        password: Optional["AzureKeyVaultSecretReference"] = None,
        service_principal_id: Optional["AzureSqlDatabaseLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureSqlDatabaseLinkedServiceTypePropertiesTenant"] = None,
        encrypted_credential: Optional["AzureSqlDatabaseLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureSqlDatabaseLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential


class AzureSqlDatabaseLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlDatabaseLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class AzureSqlDatabaseLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlDatabaseLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzureSqlDatabaseLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """The ID of the service principal used to authenticate against Azure SQL Database. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlDatabaseLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class AzureSqlDatabaseLinkedServiceTypePropertiesTenant(msrest.serialization.Model):
    """The name or ID of the tenant to which the service principal belongs. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlDatabaseLinkedServiceTypePropertiesTenant, self).__init__(**kwargs)


class AzureSqlDWLinkedService(LinkedService):
    """Azure SQL Data Warehouse linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference. Type: string, SecureString or AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzureSqlDWLinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param service_principal_id: The ID of the service principal used to authenticate against Azure
     SQL Data Warehouse. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureSqlDWLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureSqlDWLinkedServiceTypePropertiesTenant
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureSqlDWLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'AzureSqlDWLinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'AzureSqlDWLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'AzureSqlDWLinkedServiceTypePropertiesTenant'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzureSqlDWLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "AzureSqlDWLinkedServiceTypePropertiesConnectionString",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        service_principal_id: Optional["AzureSqlDWLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureSqlDWLinkedServiceTypePropertiesTenant"] = None,
        encrypted_credential: Optional["AzureSqlDWLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureSqlDWLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureSqlDW'
        self.connection_string = connection_string
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential


class AzureSqlDWLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure SQL Data Warehouse linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference. Type: string, SecureString or AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzureSqlDWLinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param service_principal_id: The ID of the service principal used to authenticate against Azure
     SQL Data Warehouse. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureSqlDWLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureSqlDWLinkedServiceTypePropertiesTenant
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureSqlDWLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'AzureSqlDWLinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'password', 'type': 'AzureKeyVaultSecretReference'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'AzureSqlDWLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'tenant', 'type': 'AzureSqlDWLinkedServiceTypePropertiesTenant'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzureSqlDWLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "AzureSqlDWLinkedServiceTypePropertiesConnectionString",
        password: Optional["AzureKeyVaultSecretReference"] = None,
        service_principal_id: Optional["AzureSqlDWLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureSqlDWLinkedServiceTypePropertiesTenant"] = None,
        encrypted_credential: Optional["AzureSqlDWLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureSqlDWLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential


class AzureSqlDWLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The connection string. Type: string, SecureString or AzureKeyVaultSecretReference. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlDWLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class AzureSqlDWLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlDWLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzureSqlDWLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """The ID of the service principal used to authenticate against Azure SQL Data Warehouse. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlDWLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class AzureSqlDWLinkedServiceTypePropertiesTenant(msrest.serialization.Model):
    """The name or ID of the tenant to which the service principal belongs. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlDWLinkedServiceTypePropertiesTenant, self).__init__(**kwargs)


class AzureSqlDWTableDataset(Dataset):
    """The Azure SQL Data Warehouse dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.AzureSqlDWTableDatasetTypePropertiesTableName
    :param schema_type_properties_schema: The schema name of the Azure SQL Data Warehouse. Type:
     string (or Expression with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.AzureSqlDWTableDatasetTypePropertiesSchema
    :param table: The table name of the Azure SQL Data Warehouse. Type: string (or Expression with
     resultType string).
    :type table: ~data_factory_management_client.models.AzureSqlDWTableDatasetTypePropertiesTable
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'AzureSqlDWTableDatasetTypePropertiesTableName'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'AzureSqlDWTableDatasetTypePropertiesSchema'},
        'table': {'key': 'typeProperties.table', 'type': 'AzureSqlDWTableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["AzureSqlDWTableDatasetTypePropertiesTableName"] = None,
        schema_type_properties_schema: Optional["AzureSqlDWTableDatasetTypePropertiesSchema"] = None,
        table: Optional["AzureSqlDWTableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(AzureSqlDWTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureSqlDWTable'
        self.table_name = table_name
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class AzureSqlDWTableDatasetTypeProperties(msrest.serialization.Model):
    """Azure SQL Data Warehouse dataset properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.AzureSqlDWTableDatasetTypePropertiesTableName
    :param schema: The schema name of the Azure SQL Data Warehouse. Type: string (or Expression
     with resultType string).
    :type schema: ~data_factory_management_client.models.AzureSqlDWTableDatasetTypePropertiesSchema
    :param table: The table name of the Azure SQL Data Warehouse. Type: string (or Expression with
     resultType string).
    :type table: ~data_factory_management_client.models.AzureSqlDWTableDatasetTypePropertiesTable
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'AzureSqlDWTableDatasetTypePropertiesTableName'},
        'schema': {'key': 'schema', 'type': 'AzureSqlDWTableDatasetTypePropertiesSchema'},
        'table': {'key': 'table', 'type': 'AzureSqlDWTableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["AzureSqlDWTableDatasetTypePropertiesTableName"] = None,
        schema: Optional["AzureSqlDWTableDatasetTypePropertiesSchema"] = None,
        table: Optional["AzureSqlDWTableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(AzureSqlDWTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.schema = schema
        self.table = table


class AzureSqlDWTableDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of the Azure SQL Data Warehouse. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlDWTableDatasetTypePropertiesSchema, self).__init__(**kwargs)


class AzureSqlDWTableDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the Azure SQL Data Warehouse. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlDWTableDatasetTypePropertiesTable, self).__init__(**kwargs)


class AzureSqlDWTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlDWTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class AzureSqlMILinkedService(LinkedService):
    """Azure SQL Managed Instance linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzureSqlMILinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param service_principal_id: The ID of the service principal used to authenticate against Azure
     SQL Managed Instance. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureSqlMILinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureSqlMILinkedServiceTypePropertiesTenant
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureSqlMILinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'AzureSqlMILinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'AzureSqlMILinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'AzureSqlMILinkedServiceTypePropertiesTenant'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'AzureSqlMILinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "AzureSqlMILinkedServiceTypePropertiesConnectionString",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        service_principal_id: Optional["AzureSqlMILinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureSqlMILinkedServiceTypePropertiesTenant"] = None,
        encrypted_credential: Optional["AzureSqlMILinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureSqlMILinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureSqlMI'
        self.connection_string = connection_string
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential


class AzureSqlMILinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure SQL Managed Instance linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzureSqlMILinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param service_principal_id: The ID of the service principal used to authenticate against Azure
     SQL Managed Instance. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.AzureSqlMILinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The name or ID of the tenant to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.AzureSqlMILinkedServiceTypePropertiesTenant
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.AzureSqlMILinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'AzureSqlMILinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'password', 'type': 'AzureKeyVaultSecretReference'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'AzureSqlMILinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'tenant', 'type': 'AzureSqlMILinkedServiceTypePropertiesTenant'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'AzureSqlMILinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "AzureSqlMILinkedServiceTypePropertiesConnectionString",
        password: Optional["AzureKeyVaultSecretReference"] = None,
        service_principal_id: Optional["AzureSqlMILinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["AzureSqlMILinkedServiceTypePropertiesTenant"] = None,
        encrypted_credential: Optional["AzureSqlMILinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(AzureSqlMILinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential


class AzureSqlMILinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlMILinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class AzureSqlMILinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlMILinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class AzureSqlMILinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """The ID of the service principal used to authenticate against Azure SQL Managed Instance. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlMILinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class AzureSqlMILinkedServiceTypePropertiesTenant(msrest.serialization.Model):
    """The name or ID of the tenant to which the service principal belongs. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlMILinkedServiceTypePropertiesTenant, self).__init__(**kwargs)


class AzureSqlMITableDataset(Dataset):
    """The Azure SQL Managed Instance dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.AzureSqlMITableDatasetTypePropertiesTableName
    :param schema_type_properties_schema: The schema name of the Azure SQL Managed Instance. Type:
     string (or Expression with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.AzureSqlMITableDatasetTypePropertiesSchema
    :param table: The table name of the Azure SQL Managed Instance dataset. Type: string (or
     Expression with resultType string).
    :type table: ~data_factory_management_client.models.AzureSqlMITableDatasetTypePropertiesTable
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'AzureSqlMITableDatasetTypePropertiesTableName'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'AzureSqlMITableDatasetTypePropertiesSchema'},
        'table': {'key': 'typeProperties.table', 'type': 'AzureSqlMITableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["AzureSqlMITableDatasetTypePropertiesTableName"] = None,
        schema_type_properties_schema: Optional["AzureSqlMITableDatasetTypePropertiesSchema"] = None,
        table: Optional["AzureSqlMITableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(AzureSqlMITableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureSqlMITable'
        self.table_name = table_name
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class AzureSqlMITableDatasetTypeProperties(msrest.serialization.Model):
    """Azure SQL Managed Instance dataset properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.AzureSqlMITableDatasetTypePropertiesTableName
    :param schema: The schema name of the Azure SQL Managed Instance. Type: string (or Expression
     with resultType string).
    :type schema: ~data_factory_management_client.models.AzureSqlMITableDatasetTypePropertiesSchema
    :param table: The table name of the Azure SQL Managed Instance dataset. Type: string (or
     Expression with resultType string).
    :type table: ~data_factory_management_client.models.AzureSqlMITableDatasetTypePropertiesTable
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'AzureSqlMITableDatasetTypePropertiesTableName'},
        'schema': {'key': 'schema', 'type': 'AzureSqlMITableDatasetTypePropertiesSchema'},
        'table': {'key': 'table', 'type': 'AzureSqlMITableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["AzureSqlMITableDatasetTypePropertiesTableName"] = None,
        schema: Optional["AzureSqlMITableDatasetTypePropertiesSchema"] = None,
        table: Optional["AzureSqlMITableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(AzureSqlMITableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.schema = schema
        self.table = table


class AzureSqlMITableDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of the Azure SQL Managed Instance. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlMITableDatasetTypePropertiesSchema, self).__init__(**kwargs)


class AzureSqlMITableDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the Azure SQL Managed Instance dataset. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlMITableDatasetTypePropertiesTable, self).__init__(**kwargs)


class AzureSqlMITableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlMITableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class AzureSqlSink(CopySink):
    """A copy activity Azure SQL sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param sql_writer_stored_procedure_name: SQL writer stored procedure name. Type: string (or
     Expression with resultType string).
    :type sql_writer_stored_procedure_name:
     ~data_factory_management_client.models.AzureSqlSinkSqlWriterStoredProcedureName
    :param sql_writer_table_type: SQL writer table type. Type: string (or Expression with
     resultType string).
    :type sql_writer_table_type:
     ~data_factory_management_client.models.AzureSqlSinkSqlWriterTableType
    :param pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
     string).
    :type pre_copy_script: ~data_factory_management_client.models.AzureSqlSinkPreCopyScript
    :param stored_procedure_parameters: SQL stored procedure parameters.
    :type stored_procedure_parameters: dict[str,
     ~data_factory_management_client.models.StoredProcedureParameter]
    :param stored_procedure_table_type_parameter_name: The stored procedure parameter name of the
     table type. Type: string (or Expression with resultType string).
    :type stored_procedure_table_type_parameter_name:
     ~data_factory_management_client.models.AzureSqlSinkStoredProcedureTableTypeParameterName
    :param table_option: The option to handle sink table, such as autoCreate. For now only
     'autoCreate' value is supported. Type: string (or Expression with resultType string).
    :type table_option: ~data_factory_management_client.models.AzureSqlSinkTableOption
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'sql_writer_stored_procedure_name': {'key': 'sqlWriterStoredProcedureName', 'type': 'AzureSqlSinkSqlWriterStoredProcedureName'},
        'sql_writer_table_type': {'key': 'sqlWriterTableType', 'type': 'AzureSqlSinkSqlWriterTableType'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'AzureSqlSinkPreCopyScript'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'stored_procedure_table_type_parameter_name': {'key': 'storedProcedureTableTypeParameterName', 'type': 'AzureSqlSinkStoredProcedureTableTypeParameterName'},
        'table_option': {'key': 'tableOption', 'type': 'AzureSqlSinkTableOption'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        sql_writer_stored_procedure_name: Optional["AzureSqlSinkSqlWriterStoredProcedureName"] = None,
        sql_writer_table_type: Optional["AzureSqlSinkSqlWriterTableType"] = None,
        pre_copy_script: Optional["AzureSqlSinkPreCopyScript"] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        stored_procedure_table_type_parameter_name: Optional["AzureSqlSinkStoredProcedureTableTypeParameterName"] = None,
        table_option: Optional["AzureSqlSinkTableOption"] = None,
        **kwargs
    ):
        super(AzureSqlSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzureSqlSink'
        self.sql_writer_stored_procedure_name = sql_writer_stored_procedure_name
        self.sql_writer_table_type = sql_writer_table_type
        self.pre_copy_script = pre_copy_script
        self.stored_procedure_parameters = stored_procedure_parameters
        self.stored_procedure_table_type_parameter_name = stored_procedure_table_type_parameter_name
        self.table_option = table_option


class AzureSqlSinkPreCopyScript(msrest.serialization.Model):
    """SQL pre-copy script. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlSinkPreCopyScript, self).__init__(**kwargs)


class AzureSqlSinkSqlWriterStoredProcedureName(msrest.serialization.Model):
    """SQL writer stored procedure name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlSinkSqlWriterStoredProcedureName, self).__init__(**kwargs)


class AzureSqlSinkSqlWriterTableType(msrest.serialization.Model):
    """SQL writer table type. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlSinkSqlWriterTableType, self).__init__(**kwargs)


class AzureSqlSinkStoredProcedureTableTypeParameterName(msrest.serialization.Model):
    """The stored procedure parameter name of the table type. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlSinkStoredProcedureTableTypeParameterName, self).__init__(**kwargs)


class AzureSqlSinkTableOption(msrest.serialization.Model):
    """The option to handle sink table, such as autoCreate. For now only 'autoCreate' value is supported. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlSinkTableOption, self).__init__(**kwargs)


class AzureSqlSource(TabularSource):
    """A copy activity Azure SQL source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param sql_reader_query: SQL reader query. Type: string (or Expression with resultType string).
    :type sql_reader_query: ~data_factory_management_client.models.AzureSqlSourceSqlReaderQuery
    :param sql_reader_stored_procedure_name: Name of the stored procedure for a SQL Database
     source. This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression
     with resultType string).
    :type sql_reader_stored_procedure_name:
     ~data_factory_management_client.models.AzureSqlSourceSqlReaderStoredProcedureName
    :param stored_procedure_parameters: Value and type setting for stored procedure parameters.
     Example: "{Parameter1: {value: "1", type: "int"}}".
    :type stored_procedure_parameters: dict[str,
     ~data_factory_management_client.models.StoredProcedureParameter]
    :param produce_additional_types: Which additional types to produce.
    :type produce_additional_types:
     ~data_factory_management_client.models.AzureSqlSourceProduceAdditionalTypes
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'sql_reader_query': {'key': 'sqlReaderQuery', 'type': 'AzureSqlSourceSqlReaderQuery'},
        'sql_reader_stored_procedure_name': {'key': 'sqlReaderStoredProcedureName', 'type': 'AzureSqlSourceSqlReaderStoredProcedureName'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'produce_additional_types': {'key': 'produceAdditionalTypes', 'type': 'AzureSqlSourceProduceAdditionalTypes'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        sql_reader_query: Optional["AzureSqlSourceSqlReaderQuery"] = None,
        sql_reader_stored_procedure_name: Optional["AzureSqlSourceSqlReaderStoredProcedureName"] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        produce_additional_types: Optional["AzureSqlSourceProduceAdditionalTypes"] = None,
        **kwargs
    ):
        super(AzureSqlSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'AzureSqlSource'
        self.sql_reader_query = sql_reader_query
        self.sql_reader_stored_procedure_name = sql_reader_stored_procedure_name
        self.stored_procedure_parameters = stored_procedure_parameters
        self.produce_additional_types = produce_additional_types


class AzureSqlSourceProduceAdditionalTypes(msrest.serialization.Model):
    """Which additional types to produce.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlSourceProduceAdditionalTypes, self).__init__(**kwargs)


class AzureSqlSourceSqlReaderQuery(msrest.serialization.Model):
    """SQL reader query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlSourceSqlReaderQuery, self).__init__(**kwargs)


class AzureSqlSourceSqlReaderStoredProcedureName(msrest.serialization.Model):
    """Name of the stored procedure for a SQL Database source. This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlSourceSqlReaderStoredProcedureName, self).__init__(**kwargs)


class AzureSqlTableDataset(Dataset):
    """The Azure SQL Server database dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.AzureSqlTableDatasetTypePropertiesTableName
    :param schema_type_properties_schema: The schema name of the Azure SQL database. Type: string
     (or Expression with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.AzureSqlTableDatasetTypePropertiesSchema
    :param table: The table name of the Azure SQL database. Type: string (or Expression with
     resultType string).
    :type table: ~data_factory_management_client.models.AzureSqlTableDatasetTypePropertiesTable
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'AzureSqlTableDatasetTypePropertiesTableName'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'AzureSqlTableDatasetTypePropertiesSchema'},
        'table': {'key': 'typeProperties.table', 'type': 'AzureSqlTableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["AzureSqlTableDatasetTypePropertiesTableName"] = None,
        schema_type_properties_schema: Optional["AzureSqlTableDatasetTypePropertiesSchema"] = None,
        table: Optional["AzureSqlTableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(AzureSqlTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureSqlTable'
        self.table_name = table_name
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class AzureSqlTableDatasetTypeProperties(msrest.serialization.Model):
    """Azure SQL dataset properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.AzureSqlTableDatasetTypePropertiesTableName
    :param schema: The schema name of the Azure SQL database. Type: string (or Expression with
     resultType string).
    :type schema: ~data_factory_management_client.models.AzureSqlTableDatasetTypePropertiesSchema
    :param table: The table name of the Azure SQL database. Type: string (or Expression with
     resultType string).
    :type table: ~data_factory_management_client.models.AzureSqlTableDatasetTypePropertiesTable
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'AzureSqlTableDatasetTypePropertiesTableName'},
        'schema': {'key': 'schema', 'type': 'AzureSqlTableDatasetTypePropertiesSchema'},
        'table': {'key': 'table', 'type': 'AzureSqlTableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["AzureSqlTableDatasetTypePropertiesTableName"] = None,
        schema: Optional["AzureSqlTableDatasetTypePropertiesSchema"] = None,
        table: Optional["AzureSqlTableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(AzureSqlTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.schema = schema
        self.table = table


class AzureSqlTableDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of the Azure SQL database. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlTableDatasetTypePropertiesSchema, self).__init__(**kwargs)


class AzureSqlTableDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the Azure SQL database. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlTableDatasetTypePropertiesTable, self).__init__(**kwargs)


class AzureSqlTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureSqlTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class AzureStorageLinkedService(LinkedService):
    """The storage account linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: The connection string. It is mutually exclusive with sasUri property.
     Type: string, SecureString or AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzureStorageLinkedServiceTypePropertiesConnectionString
    :param account_key: Azure Key Vault secret reference.
    :type account_key: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param sas_uri: SAS URI of the Azure Storage resource. It is mutually exclusive with
     connectionString property. Type: string, SecureString or AzureKeyVaultSecretReference.
    :type sas_uri:
     ~data_factory_management_client.models.AzureStorageLinkedServiceTypePropertiesSasUri
    :param sas_token: Azure Key Vault secret reference.
    :type sas_token: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'AzureStorageLinkedServiceTypePropertiesConnectionString'},
        'account_key': {'key': 'typeProperties.accountKey', 'type': 'AzureKeyVaultSecretReference'},
        'sas_uri': {'key': 'typeProperties.sasUri', 'type': 'AzureStorageLinkedServiceTypePropertiesSasUri'},
        'sas_token': {'key': 'typeProperties.sasToken', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        connection_string: Optional["AzureStorageLinkedServiceTypePropertiesConnectionString"] = None,
        account_key: Optional["AzureKeyVaultSecretReference"] = None,
        sas_uri: Optional["AzureStorageLinkedServiceTypePropertiesSasUri"] = None,
        sas_token: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[str] = None,
        **kwargs
    ):
        super(AzureStorageLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureStorage'
        self.connection_string = connection_string
        self.account_key = account_key
        self.sas_uri = sas_uri
        self.sas_token = sas_token
        self.encrypted_credential = encrypted_credential


class AzureStorageLinkedServiceTypeProperties(msrest.serialization.Model):
    """Azure Storage linked service properties.

    :param connection_string: The connection string. It is mutually exclusive with sasUri property.
     Type: string, SecureString or AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzureStorageLinkedServiceTypePropertiesConnectionString
    :param account_key: Azure Key Vault secret reference.
    :type account_key: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param sas_uri: SAS URI of the Azure Storage resource. It is mutually exclusive with
     connectionString property. Type: string, SecureString or AzureKeyVaultSecretReference.
    :type sas_uri:
     ~data_factory_management_client.models.AzureStorageLinkedServiceTypePropertiesSasUri
    :param sas_token: Azure Key Vault secret reference.
    :type sas_token: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential: str
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'AzureStorageLinkedServiceTypePropertiesConnectionString'},
        'account_key': {'key': 'accountKey', 'type': 'AzureKeyVaultSecretReference'},
        'sas_uri': {'key': 'sasUri', 'type': 'AzureStorageLinkedServiceTypePropertiesSasUri'},
        'sas_token': {'key': 'sasToken', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional["AzureStorageLinkedServiceTypePropertiesConnectionString"] = None,
        account_key: Optional["AzureKeyVaultSecretReference"] = None,
        sas_uri: Optional["AzureStorageLinkedServiceTypePropertiesSasUri"] = None,
        sas_token: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[str] = None,
        **kwargs
    ):
        super(AzureStorageLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.account_key = account_key
        self.sas_uri = sas_uri
        self.sas_token = sas_token
        self.encrypted_credential = encrypted_credential


class AzureStorageLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The connection string. It is mutually exclusive with sasUri property. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureStorageLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class AzureStorageLinkedServiceTypePropertiesSasUri(msrest.serialization.Model):
    """SAS URI of the Azure Storage resource. It is mutually exclusive with connectionString property. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureStorageLinkedServiceTypePropertiesSasUri, self).__init__(**kwargs)


class AzureTableDataset(Dataset):
    """The Azure Table storage dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: Required. The table name of the Azure Table storage. Type: string (or
     Expression with resultType string).
    :type table_name:
     ~data_factory_management_client.models.AzureTableDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'table_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'AzureTableDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        table_name: "AzureTableDatasetTypePropertiesTableName",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        super(AzureTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureTable'
        self.table_name = table_name


class AzureTableDatasetTypeProperties(msrest.serialization.Model):
    """Azure Table dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param table_name: Required. The table name of the Azure Table storage. Type: string (or
     Expression with resultType string).
    :type table_name:
     ~data_factory_management_client.models.AzureTableDatasetTypePropertiesTableName
    """

    _validation = {
        'table_name': {'required': True},
    }

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'AzureTableDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        table_name: "AzureTableDatasetTypePropertiesTableName",
        **kwargs
    ):
        super(AzureTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name


class AzureTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """The table name of the Azure Table storage. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class AzureTableSink(CopySink):
    """A copy activity Azure Table sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param azure_table_default_partition_key_value: Azure Table default partition key value. Type:
     string (or Expression with resultType string).
    :type azure_table_default_partition_key_value:
     ~data_factory_management_client.models.AzureTableSinkAzureTableDefaultPartitionKeyValue
    :param azure_table_partition_key_name: Azure Table partition key name. Type: string (or
     Expression with resultType string).
    :type azure_table_partition_key_name:
     ~data_factory_management_client.models.AzureTableSinkAzureTablePartitionKeyName
    :param azure_table_row_key_name: Azure Table row key name. Type: string (or Expression with
     resultType string).
    :type azure_table_row_key_name:
     ~data_factory_management_client.models.AzureTableSinkAzureTableRowKeyName
    :param azure_table_insert_type: Azure Table insert type. Type: string (or Expression with
     resultType string).
    :type azure_table_insert_type:
     ~data_factory_management_client.models.AzureTableSinkAzureTableInsertType
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'azure_table_default_partition_key_value': {'key': 'azureTableDefaultPartitionKeyValue', 'type': 'AzureTableSinkAzureTableDefaultPartitionKeyValue'},
        'azure_table_partition_key_name': {'key': 'azureTablePartitionKeyName', 'type': 'AzureTableSinkAzureTablePartitionKeyName'},
        'azure_table_row_key_name': {'key': 'azureTableRowKeyName', 'type': 'AzureTableSinkAzureTableRowKeyName'},
        'azure_table_insert_type': {'key': 'azureTableInsertType', 'type': 'AzureTableSinkAzureTableInsertType'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        azure_table_default_partition_key_value: Optional["AzureTableSinkAzureTableDefaultPartitionKeyValue"] = None,
        azure_table_partition_key_name: Optional["AzureTableSinkAzureTablePartitionKeyName"] = None,
        azure_table_row_key_name: Optional["AzureTableSinkAzureTableRowKeyName"] = None,
        azure_table_insert_type: Optional["AzureTableSinkAzureTableInsertType"] = None,
        **kwargs
    ):
        super(AzureTableSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'AzureTableSink'
        self.azure_table_default_partition_key_value = azure_table_default_partition_key_value
        self.azure_table_partition_key_name = azure_table_partition_key_name
        self.azure_table_row_key_name = azure_table_row_key_name
        self.azure_table_insert_type = azure_table_insert_type


class AzureTableSinkAzureTableDefaultPartitionKeyValue(msrest.serialization.Model):
    """Azure Table default partition key value. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureTableSinkAzureTableDefaultPartitionKeyValue, self).__init__(**kwargs)


class AzureTableSinkAzureTableInsertType(msrest.serialization.Model):
    """Azure Table insert type. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureTableSinkAzureTableInsertType, self).__init__(**kwargs)


class AzureTableSinkAzureTablePartitionKeyName(msrest.serialization.Model):
    """Azure Table partition key name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureTableSinkAzureTablePartitionKeyName, self).__init__(**kwargs)


class AzureTableSinkAzureTableRowKeyName(msrest.serialization.Model):
    """Azure Table row key name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureTableSinkAzureTableRowKeyName, self).__init__(**kwargs)


class AzureTableSource(TabularSource):
    """A copy activity Azure Table source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param azure_table_source_query: Azure Table source query. Type: string (or Expression with
     resultType string).
    :type azure_table_source_query:
     ~data_factory_management_client.models.AzureTableSourceAzureTableSourceQuery
    :param azure_table_source_ignore_table_not_found: Azure Table source ignore table not found.
     Type: boolean (or Expression with resultType boolean).
    :type azure_table_source_ignore_table_not_found:
     ~data_factory_management_client.models.AzureTableSourceAzureTableSourceIgnoreTableNotFound
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'azure_table_source_query': {'key': 'azureTableSourceQuery', 'type': 'AzureTableSourceAzureTableSourceQuery'},
        'azure_table_source_ignore_table_not_found': {'key': 'azureTableSourceIgnoreTableNotFound', 'type': 'AzureTableSourceAzureTableSourceIgnoreTableNotFound'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        azure_table_source_query: Optional["AzureTableSourceAzureTableSourceQuery"] = None,
        azure_table_source_ignore_table_not_found: Optional["AzureTableSourceAzureTableSourceIgnoreTableNotFound"] = None,
        **kwargs
    ):
        super(AzureTableSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'AzureTableSource'
        self.azure_table_source_query = azure_table_source_query
        self.azure_table_source_ignore_table_not_found = azure_table_source_ignore_table_not_found


class AzureTableSourceAzureTableSourceIgnoreTableNotFound(msrest.serialization.Model):
    """Azure Table source ignore table not found. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureTableSourceAzureTableSourceIgnoreTableNotFound, self).__init__(**kwargs)


class AzureTableSourceAzureTableSourceQuery(msrest.serialization.Model):
    """Azure Table source query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(AzureTableSourceAzureTableSourceQuery, self).__init__(**kwargs)


class AzureTableStorageLinkedService(LinkedService):
    """The azure table storage linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: The connection string. It is mutually exclusive with sasUri property.
     Type: string, SecureString or AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.AzureStorageLinkedServiceTypePropertiesConnectionString
    :param account_key: Azure Key Vault secret reference.
    :type account_key: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param sas_uri: SAS URI of the Azure Storage resource. It is mutually exclusive with
     connectionString property. Type: string, SecureString or AzureKeyVaultSecretReference.
    :type sas_uri:
     ~data_factory_management_client.models.AzureStorageLinkedServiceTypePropertiesSasUri
    :param sas_token: Azure Key Vault secret reference.
    :type sas_token: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'AzureStorageLinkedServiceTypePropertiesConnectionString'},
        'account_key': {'key': 'typeProperties.accountKey', 'type': 'AzureKeyVaultSecretReference'},
        'sas_uri': {'key': 'typeProperties.sasUri', 'type': 'AzureStorageLinkedServiceTypePropertiesSasUri'},
        'sas_token': {'key': 'typeProperties.sasToken', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        connection_string: Optional["AzureStorageLinkedServiceTypePropertiesConnectionString"] = None,
        account_key: Optional["AzureKeyVaultSecretReference"] = None,
        sas_uri: Optional["AzureStorageLinkedServiceTypePropertiesSasUri"] = None,
        sas_token: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[str] = None,
        **kwargs
    ):
        super(AzureTableStorageLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureTableStorage'
        self.connection_string = connection_string
        self.account_key = account_key
        self.sas_uri = sas_uri
        self.sas_token = sas_token
        self.encrypted_credential = encrypted_credential


class BinaryDataset(Dataset):
    """Binary dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param location: Dataset location.
    :type location: ~data_factory_management_client.models.DatasetLocation
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'location': {'key': 'typeProperties.location', 'type': 'DatasetLocation'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        location: Optional["DatasetLocation"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(BinaryDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Binary'
        self.location = location
        self.compression = compression


class BinaryDatasetTypeProperties(msrest.serialization.Model):
    """Binary dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param location: Required. Dataset location.
    :type location: ~data_factory_management_client.models.DatasetLocation
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _validation = {
        'location': {'required': True},
    }

    _attribute_map = {
        'location': {'key': 'location', 'type': 'DatasetLocation'},
        'compression': {'key': 'compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        location: "DatasetLocation",
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(BinaryDatasetTypeProperties, self).__init__(**kwargs)
        self.location = location
        self.compression = compression


class BinarySink(CopySink):
    """A copy activity Binary sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param store_settings: Connector write settings.
    :type store_settings: ~data_factory_management_client.models.StoreWriteSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreWriteSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        store_settings: Optional["StoreWriteSettings"] = None,
        **kwargs
    ):
        super(BinarySink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'BinarySink'
        self.store_settings = store_settings


class BinarySource(CopySource):
    """A copy activity Binary source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param store_settings: Connector read setting.
    :type store_settings: ~data_factory_management_client.models.StoreReadSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreReadSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        **kwargs
    ):
        super(BinarySource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'BinarySource'
        self.store_settings = store_settings


class Trigger(msrest.serialization.Model):
    """Azure data factory nested object which contains information about creating pipeline run.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: ChainingTrigger, MultiplePipelineTrigger, RerunTumblingWindowTrigger, TumblingWindowTrigger.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Trigger type.Constant filled by server.
    :type type: str
    :param description: Trigger description.
    :type description: str
    :ivar runtime_state: Enumerates possible state of Triggers. Possible values include: 'Started',
     'Stopped', 'Disabled'.
    :vartype runtime_state: str or ~data_factory_management_client.models.TriggerRuntimeState
    :param annotations: List of tags that can be used for describing the trigger.
    :type annotations: list[~data_factory_management_client.models.TriggerAnnotationsItem]
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[TriggerAnnotationsItem]'},
    }

    _subtype_map = {
        'type': {'ChainingTrigger': 'ChainingTrigger', 'MultiplePipelineTrigger': 'MultiplePipelineTrigger', 'RerunTumblingWindowTrigger': 'RerunTumblingWindowTrigger', 'TumblingWindowTrigger': 'TumblingWindowTrigger'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        annotations: Optional[List["TriggerAnnotationsItem"]] = None,
        **kwargs
    ):
        super(Trigger, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'Trigger'
        self.description = description
        self.runtime_state = None
        self.annotations = annotations


class MultiplePipelineTrigger(Trigger):
    """Base class for all triggers that support one to many model for trigger to pipeline.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: BlobEventsTrigger, BlobTrigger, ScheduleTrigger.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Trigger type.Constant filled by server.
    :type type: str
    :param description: Trigger description.
    :type description: str
    :ivar runtime_state: Enumerates possible state of Triggers. Possible values include: 'Started',
     'Stopped', 'Disabled'.
    :vartype runtime_state: str or ~data_factory_management_client.models.TriggerRuntimeState
    :param annotations: List of tags that can be used for describing the trigger.
    :type annotations: list[~data_factory_management_client.models.TriggerAnnotationsItem]
    :param pipelines: Pipelines that need to be started.
    :type pipelines: list[~data_factory_management_client.models.TriggerPipelineReference]
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[TriggerAnnotationsItem]'},
        'pipelines': {'key': 'pipelines', 'type': '[TriggerPipelineReference]'},
    }

    _subtype_map = {
        'type': {'BlobEventsTrigger': 'BlobEventsTrigger', 'BlobTrigger': 'BlobTrigger', 'ScheduleTrigger': 'ScheduleTrigger'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        annotations: Optional[List["TriggerAnnotationsItem"]] = None,
        pipelines: Optional[List["TriggerPipelineReference"]] = None,
        **kwargs
    ):
        super(MultiplePipelineTrigger, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, **kwargs)
        self.type = 'MultiplePipelineTrigger'
        self.pipelines = pipelines


class BlobEventsTrigger(MultiplePipelineTrigger):
    """Trigger that runs every time a Blob event occurs.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Trigger type.Constant filled by server.
    :type type: str
    :param description: Trigger description.
    :type description: str
    :ivar runtime_state: Enumerates possible state of Triggers. Possible values include: 'Started',
     'Stopped', 'Disabled'.
    :vartype runtime_state: str or ~data_factory_management_client.models.TriggerRuntimeState
    :param annotations: List of tags that can be used for describing the trigger.
    :type annotations: list[~data_factory_management_client.models.TriggerAnnotationsItem]
    :param pipelines: Pipelines that need to be started.
    :type pipelines: list[~data_factory_management_client.models.TriggerPipelineReference]
    :param blob_path_begins_with: The blob path must begin with the pattern provided for trigger to
     fire. For example, '/records/blobs/december/' will only fire the trigger for blobs in the
     december folder under the records container. At least one of these must be provided:
     blobPathBeginsWith, blobPathEndsWith.
    :type blob_path_begins_with: str
    :param blob_path_ends_with: The blob path must end with the pattern provided for trigger to
     fire. For example, 'december/boxes.csv' will only fire the trigger for blobs named boxes in a
     december folder. At least one of these must be provided: blobPathBeginsWith, blobPathEndsWith.
    :type blob_path_ends_with: str
    :param ignore_empty_blobs: If set to true, blobs with zero bytes will be ignored.
    :type ignore_empty_blobs: bool
    :param events: Required. Blob event types.
    :type events: list[str or ~data_factory_management_client.models.BlobEventTypes]
    :param scope: Required. The ARM resource ID of the Storage Account.
    :type scope: str
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
        'events': {'required': True},
        'scope': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[TriggerAnnotationsItem]'},
        'pipelines': {'key': 'pipelines', 'type': '[TriggerPipelineReference]'},
        'blob_path_begins_with': {'key': 'typeProperties.blobPathBeginsWith', 'type': 'str'},
        'blob_path_ends_with': {'key': 'typeProperties.blobPathEndsWith', 'type': 'str'},
        'ignore_empty_blobs': {'key': 'typeProperties.ignoreEmptyBlobs', 'type': 'bool'},
        'events': {'key': 'typeProperties.events', 'type': '[str]'},
        'scope': {'key': 'typeProperties.scope', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        events: List[Union[str, "BlobEventTypes"]],
        scope: str,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        annotations: Optional[List["TriggerAnnotationsItem"]] = None,
        pipelines: Optional[List["TriggerPipelineReference"]] = None,
        blob_path_begins_with: Optional[str] = None,
        blob_path_ends_with: Optional[str] = None,
        ignore_empty_blobs: Optional[bool] = None,
        **kwargs
    ):
        super(BlobEventsTrigger, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, pipelines=pipelines, **kwargs)
        self.type = 'BlobEventsTrigger'
        self.blob_path_begins_with = blob_path_begins_with
        self.blob_path_ends_with = blob_path_ends_with
        self.ignore_empty_blobs = ignore_empty_blobs
        self.events = events
        self.scope = scope


class BlobEventsTriggerTypeProperties(msrest.serialization.Model):
    """Blob Events Trigger properties.

    All required parameters must be populated in order to send to Azure.

    :param blob_path_begins_with: The blob path must begin with the pattern provided for trigger to
     fire. For example, '/records/blobs/december/' will only fire the trigger for blobs in the
     december folder under the records container. At least one of these must be provided:
     blobPathBeginsWith, blobPathEndsWith.
    :type blob_path_begins_with: str
    :param blob_path_ends_with: The blob path must end with the pattern provided for trigger to
     fire. For example, 'december/boxes.csv' will only fire the trigger for blobs named boxes in a
     december folder. At least one of these must be provided: blobPathBeginsWith, blobPathEndsWith.
    :type blob_path_ends_with: str
    :param ignore_empty_blobs: If set to true, blobs with zero bytes will be ignored.
    :type ignore_empty_blobs: bool
    :param events: Required. Blob event types.
    :type events: list[str or ~data_factory_management_client.models.BlobEventTypes]
    :param scope: Required. The ARM resource ID of the Storage Account.
    :type scope: str
    """

    _validation = {
        'events': {'required': True},
        'scope': {'required': True},
    }

    _attribute_map = {
        'blob_path_begins_with': {'key': 'blobPathBeginsWith', 'type': 'str'},
        'blob_path_ends_with': {'key': 'blobPathEndsWith', 'type': 'str'},
        'ignore_empty_blobs': {'key': 'ignoreEmptyBlobs', 'type': 'bool'},
        'events': {'key': 'events', 'type': '[str]'},
        'scope': {'key': 'scope', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        events: List[Union[str, "BlobEventTypes"]],
        scope: str,
        blob_path_begins_with: Optional[str] = None,
        blob_path_ends_with: Optional[str] = None,
        ignore_empty_blobs: Optional[bool] = None,
        **kwargs
    ):
        super(BlobEventsTriggerTypeProperties, self).__init__(**kwargs)
        self.blob_path_begins_with = blob_path_begins_with
        self.blob_path_ends_with = blob_path_ends_with
        self.ignore_empty_blobs = ignore_empty_blobs
        self.events = events
        self.scope = scope


class BlobSink(CopySink):
    """A copy activity Azure Blob sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param blob_writer_overwrite_files: Blob writer overwrite files. Type: boolean (or Expression
     with resultType boolean).
    :type blob_writer_overwrite_files:
     ~data_factory_management_client.models.BlobSinkBlobWriterOverwriteFiles
    :param blob_writer_date_time_format: Blob writer date time format. Type: string (or Expression
     with resultType string).
    :type blob_writer_date_time_format:
     ~data_factory_management_client.models.BlobSinkBlobWriterDateTimeFormat
    :param blob_writer_add_header: Blob writer add header. Type: boolean (or Expression with
     resultType boolean).
    :type blob_writer_add_header:
     ~data_factory_management_client.models.BlobSinkBlobWriterAddHeader
    :param copy_behavior: The type of copy behavior for copy sink.
    :type copy_behavior: ~data_factory_management_client.models.BlobSinkCopyBehavior
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'blob_writer_overwrite_files': {'key': 'blobWriterOverwriteFiles', 'type': 'BlobSinkBlobWriterOverwriteFiles'},
        'blob_writer_date_time_format': {'key': 'blobWriterDateTimeFormat', 'type': 'BlobSinkBlobWriterDateTimeFormat'},
        'blob_writer_add_header': {'key': 'blobWriterAddHeader', 'type': 'BlobSinkBlobWriterAddHeader'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'BlobSinkCopyBehavior'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        blob_writer_overwrite_files: Optional["BlobSinkBlobWriterOverwriteFiles"] = None,
        blob_writer_date_time_format: Optional["BlobSinkBlobWriterDateTimeFormat"] = None,
        blob_writer_add_header: Optional["BlobSinkBlobWriterAddHeader"] = None,
        copy_behavior: Optional["BlobSinkCopyBehavior"] = None,
        **kwargs
    ):
        super(BlobSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'BlobSink'
        self.blob_writer_overwrite_files = blob_writer_overwrite_files
        self.blob_writer_date_time_format = blob_writer_date_time_format
        self.blob_writer_add_header = blob_writer_add_header
        self.copy_behavior = copy_behavior


class BlobSinkBlobWriterAddHeader(msrest.serialization.Model):
    """Blob writer add header. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(BlobSinkBlobWriterAddHeader, self).__init__(**kwargs)


class BlobSinkBlobWriterDateTimeFormat(msrest.serialization.Model):
    """Blob writer date time format. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(BlobSinkBlobWriterDateTimeFormat, self).__init__(**kwargs)


class BlobSinkBlobWriterOverwriteFiles(msrest.serialization.Model):
    """Blob writer overwrite files. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(BlobSinkBlobWriterOverwriteFiles, self).__init__(**kwargs)


class BlobSinkCopyBehavior(msrest.serialization.Model):
    """The type of copy behavior for copy sink.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(BlobSinkCopyBehavior, self).__init__(**kwargs)


class BlobSource(CopySource):
    """A copy activity Azure Blob source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param treat_empty_as_null: Treat empty as null. Type: boolean (or Expression with resultType
     boolean).
    :type treat_empty_as_null: ~data_factory_management_client.models.BlobSourceTreatEmptyAsNull
    :param skip_header_line_count: Number of header lines to skip from each blob. Type: integer (or
     Expression with resultType integer).
    :type skip_header_line_count:
     ~data_factory_management_client.models.BlobSourceSkipHeaderLineCount
    :param recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.BlobSourceRecursive
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'treat_empty_as_null': {'key': 'treatEmptyAsNull', 'type': 'BlobSourceTreatEmptyAsNull'},
        'skip_header_line_count': {'key': 'skipHeaderLineCount', 'type': 'BlobSourceSkipHeaderLineCount'},
        'recursive': {'key': 'recursive', 'type': 'BlobSourceRecursive'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        treat_empty_as_null: Optional["BlobSourceTreatEmptyAsNull"] = None,
        skip_header_line_count: Optional["BlobSourceSkipHeaderLineCount"] = None,
        recursive: Optional["BlobSourceRecursive"] = None,
        **kwargs
    ):
        super(BlobSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'BlobSource'
        self.treat_empty_as_null = treat_empty_as_null
        self.skip_header_line_count = skip_header_line_count
        self.recursive = recursive


class BlobSourceRecursive(msrest.serialization.Model):
    """If true, files under the folder path will be read recursively. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(BlobSourceRecursive, self).__init__(**kwargs)


class BlobSourceSkipHeaderLineCount(msrest.serialization.Model):
    """Number of header lines to skip from each blob. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(BlobSourceSkipHeaderLineCount, self).__init__(**kwargs)


class BlobSourceTreatEmptyAsNull(msrest.serialization.Model):
    """Treat empty as null. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(BlobSourceTreatEmptyAsNull, self).__init__(**kwargs)


class BlobTrigger(MultiplePipelineTrigger):
    """Trigger that runs every time the selected Blob container changes.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Trigger type.Constant filled by server.
    :type type: str
    :param description: Trigger description.
    :type description: str
    :ivar runtime_state: Enumerates possible state of Triggers. Possible values include: 'Started',
     'Stopped', 'Disabled'.
    :vartype runtime_state: str or ~data_factory_management_client.models.TriggerRuntimeState
    :param annotations: List of tags that can be used for describing the trigger.
    :type annotations: list[~data_factory_management_client.models.TriggerAnnotationsItem]
    :param pipelines: Pipelines that need to be started.
    :type pipelines: list[~data_factory_management_client.models.TriggerPipelineReference]
    :param folder_path: Required. The path of the container/folder that will trigger the pipeline.
    :type folder_path: str
    :param max_concurrency: Required. The max number of parallel files to handle when it is
     triggered.
    :type max_concurrency: int
    :param linked_service: Required. Linked service reference type.
    :type linked_service: ~data_factory_management_client.models.LinkedServiceReference
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
        'folder_path': {'required': True},
        'max_concurrency': {'required': True},
        'linked_service': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[TriggerAnnotationsItem]'},
        'pipelines': {'key': 'pipelines', 'type': '[TriggerPipelineReference]'},
        'folder_path': {'key': 'typeProperties.folderPath', 'type': 'str'},
        'max_concurrency': {'key': 'typeProperties.maxConcurrency', 'type': 'int'},
        'linked_service': {'key': 'typeProperties.linkedService', 'type': 'LinkedServiceReference'},
    }

    def __init__(
        self,
        *,
        folder_path: str,
        max_concurrency: int,
        linked_service: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        annotations: Optional[List["TriggerAnnotationsItem"]] = None,
        pipelines: Optional[List["TriggerPipelineReference"]] = None,
        **kwargs
    ):
        super(BlobTrigger, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, pipelines=pipelines, **kwargs)
        self.type = 'BlobTrigger'
        self.folder_path = folder_path
        self.max_concurrency = max_concurrency
        self.linked_service = linked_service


class BlobTriggerTypeProperties(msrest.serialization.Model):
    """Blob Trigger properties.

    All required parameters must be populated in order to send to Azure.

    :param folder_path: Required. The path of the container/folder that will trigger the pipeline.
    :type folder_path: str
    :param max_concurrency: Required. The max number of parallel files to handle when it is
     triggered.
    :type max_concurrency: int
    :param linked_service: Required. Linked service reference type.
    :type linked_service: ~data_factory_management_client.models.LinkedServiceReference
    """

    _validation = {
        'folder_path': {'required': True},
        'max_concurrency': {'required': True},
        'linked_service': {'required': True},
    }

    _attribute_map = {
        'folder_path': {'key': 'folderPath', 'type': 'str'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'linked_service': {'key': 'linkedService', 'type': 'LinkedServiceReference'},
    }

    def __init__(
        self,
        *,
        folder_path: str,
        max_concurrency: int,
        linked_service: "LinkedServiceReference",
        **kwargs
    ):
        super(BlobTriggerTypeProperties, self).__init__(**kwargs)
        self.folder_path = folder_path
        self.max_concurrency = max_concurrency
        self.linked_service = linked_service


class CassandraLinkedService(LinkedService):
    """Linked service for Cassandra data source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. Host name for connection. Type: string (or Expression with resultType
     string).
    :type host: ~data_factory_management_client.models.CassandraLinkedServiceTypePropertiesHost
    :param authentication_type: AuthenticationType to be used for connection. Type: string (or
     Expression with resultType string).
    :type authentication_type:
     ~data_factory_management_client.models.CassandraLinkedServiceTypePropertiesAuthenticationType
    :param port: The port for the connection. Type: integer (or Expression with resultType
     integer).
    :type port: ~data_factory_management_client.models.CassandraLinkedServiceTypePropertiesPort
    :param username: Username for authentication. Type: string (or Expression with resultType
     string).
    :type username:
     ~data_factory_management_client.models.CassandraLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.CassandraLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'CassandraLinkedServiceTypePropertiesHost'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'CassandraLinkedServiceTypePropertiesAuthenticationType'},
        'port': {'key': 'typeProperties.port', 'type': 'CassandraLinkedServiceTypePropertiesPort'},
        'username': {'key': 'typeProperties.username', 'type': 'CassandraLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'CassandraLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "CassandraLinkedServiceTypePropertiesHost",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        authentication_type: Optional["CassandraLinkedServiceTypePropertiesAuthenticationType"] = None,
        port: Optional["CassandraLinkedServiceTypePropertiesPort"] = None,
        username: Optional["CassandraLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["CassandraLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(CassandraLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Cassandra'
        self.host = host
        self.authentication_type = authentication_type
        self.port = port
        self.username = username
        self.password = password
        self.encrypted_credential = encrypted_credential


class CassandraLinkedServiceTypeProperties(msrest.serialization.Model):
    """Cassandra linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. Host name for connection. Type: string (or Expression with resultType
     string).
    :type host: ~data_factory_management_client.models.CassandraLinkedServiceTypePropertiesHost
    :param authentication_type: AuthenticationType to be used for connection. Type: string (or
     Expression with resultType string).
    :type authentication_type:
     ~data_factory_management_client.models.CassandraLinkedServiceTypePropertiesAuthenticationType
    :param port: The port for the connection. Type: integer (or Expression with resultType
     integer).
    :type port: ~data_factory_management_client.models.CassandraLinkedServiceTypePropertiesPort
    :param username: Username for authentication. Type: string (or Expression with resultType
     string).
    :type username:
     ~data_factory_management_client.models.CassandraLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.CassandraLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'CassandraLinkedServiceTypePropertiesHost'},
        'authentication_type': {'key': 'authenticationType', 'type': 'CassandraLinkedServiceTypePropertiesAuthenticationType'},
        'port': {'key': 'port', 'type': 'CassandraLinkedServiceTypePropertiesPort'},
        'username': {'key': 'username', 'type': 'CassandraLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'CassandraLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "CassandraLinkedServiceTypePropertiesHost",
        authentication_type: Optional["CassandraLinkedServiceTypePropertiesAuthenticationType"] = None,
        port: Optional["CassandraLinkedServiceTypePropertiesPort"] = None,
        username: Optional["CassandraLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["CassandraLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(CassandraLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.authentication_type = authentication_type
        self.port = port
        self.username = username
        self.password = password
        self.encrypted_credential = encrypted_credential


class CassandraLinkedServiceTypePropertiesAuthenticationType(msrest.serialization.Model):
    """AuthenticationType to be used for connection. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CassandraLinkedServiceTypePropertiesAuthenticationType, self).__init__(**kwargs)


class CassandraLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CassandraLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class CassandraLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """Host name for connection. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CassandraLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class CassandraLinkedServiceTypePropertiesPort(msrest.serialization.Model):
    """The port for the connection. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CassandraLinkedServiceTypePropertiesPort, self).__init__(**kwargs)


class CassandraLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """Username for authentication. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CassandraLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class CassandraSource(TabularSource):
    """A copy activity source for a Cassandra database.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: Database query. Should be a SQL-92 query expression or Cassandra Query Language
     (CQL) command. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.CassandraSourceQuery
    :param consistency_level: The consistency level specifies how many Cassandra servers must
     respond to a read request before returning data to the client application. Cassandra checks the
     specified number of Cassandra servers for data to satisfy the read request. Must be one of
     cassandraSourceReadConsistencyLevels. The default value is 'ONE'. It is case-insensitive.
     Possible values include: 'ALL', 'EACH_QUORUM', 'QUORUM', 'LOCAL_QUORUM', 'ONE', 'TWO', 'THREE',
     'LOCAL_ONE', 'SERIAL', 'LOCAL_SERIAL'.
    :type consistency_level: str or
     ~data_factory_management_client.models.CassandraSourceReadConsistencyLevels
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'CassandraSourceQuery'},
        'consistency_level': {'key': 'consistencyLevel', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["CassandraSourceQuery"] = None,
        consistency_level: Optional[Union[str, "CassandraSourceReadConsistencyLevels"]] = None,
        **kwargs
    ):
        super(CassandraSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'CassandraSource'
        self.query = query
        self.consistency_level = consistency_level


class CassandraSourceQuery(msrest.serialization.Model):
    """Database query. Should be a SQL-92 query expression or Cassandra Query Language (CQL) command. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CassandraSourceQuery, self).__init__(**kwargs)


class CassandraTableDataset(Dataset):
    """The Cassandra database dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name of the Cassandra database. Type: string (or Expression with
     resultType string).
    :type table_name:
     ~data_factory_management_client.models.CassandraTableDatasetTypePropertiesTableName
    :param keyspace: The keyspace of the Cassandra database. Type: string (or Expression with
     resultType string).
    :type keyspace:
     ~data_factory_management_client.models.CassandraTableDatasetTypePropertiesKeyspace
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'CassandraTableDatasetTypePropertiesTableName'},
        'keyspace': {'key': 'typeProperties.keyspace', 'type': 'CassandraTableDatasetTypePropertiesKeyspace'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["CassandraTableDatasetTypePropertiesTableName"] = None,
        keyspace: Optional["CassandraTableDatasetTypePropertiesKeyspace"] = None,
        **kwargs
    ):
        super(CassandraTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'CassandraTable'
        self.table_name = table_name
        self.keyspace = keyspace


class CassandraTableDatasetTypeProperties(msrest.serialization.Model):
    """Cassandra dataset properties.

    :param table_name: The table name of the Cassandra database. Type: string (or Expression with
     resultType string).
    :type table_name:
     ~data_factory_management_client.models.CassandraTableDatasetTypePropertiesTableName
    :param keyspace: The keyspace of the Cassandra database. Type: string (or Expression with
     resultType string).
    :type keyspace:
     ~data_factory_management_client.models.CassandraTableDatasetTypePropertiesKeyspace
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'CassandraTableDatasetTypePropertiesTableName'},
        'keyspace': {'key': 'keyspace', 'type': 'CassandraTableDatasetTypePropertiesKeyspace'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["CassandraTableDatasetTypePropertiesTableName"] = None,
        keyspace: Optional["CassandraTableDatasetTypePropertiesKeyspace"] = None,
        **kwargs
    ):
        super(CassandraTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.keyspace = keyspace


class CassandraTableDatasetTypePropertiesKeyspace(msrest.serialization.Model):
    """The keyspace of the Cassandra database. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CassandraTableDatasetTypePropertiesKeyspace, self).__init__(**kwargs)


class CassandraTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """The table name of the Cassandra database. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CassandraTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class ChainingTrigger(Trigger):
    """Trigger that allows the referenced pipeline to depend on other pipeline runs based on runDimension Name/Value pairs. Upstream pipelines should declare the same runDimension Name and their runs should have the values for those runDimensions. The referenced pipeline run would be triggered if the values for the runDimension match for all upstream pipeline runs.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Trigger type.Constant filled by server.
    :type type: str
    :param description: Trigger description.
    :type description: str
    :ivar runtime_state: Enumerates possible state of Triggers. Possible values include: 'Started',
     'Stopped', 'Disabled'.
    :vartype runtime_state: str or ~data_factory_management_client.models.TriggerRuntimeState
    :param annotations: List of tags that can be used for describing the trigger.
    :type annotations: list[~data_factory_management_client.models.TriggerAnnotationsItem]
    :param pipeline: Required. Pipeline that needs to be triggered with the given parameters.
    :type pipeline: ~data_factory_management_client.models.TriggerPipelineReference
    :param depends_on: Required. Upstream Pipelines.
    :type depends_on: list[~data_factory_management_client.models.PipelineReference]
    :param run_dimension: Required. Run Dimension property that needs to be emitted by upstream
     pipelines.
    :type run_dimension: str
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
        'pipeline': {'required': True},
        'depends_on': {'required': True},
        'run_dimension': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[TriggerAnnotationsItem]'},
        'pipeline': {'key': 'pipeline', 'type': 'TriggerPipelineReference'},
        'depends_on': {'key': 'typeProperties.dependsOn', 'type': '[PipelineReference]'},
        'run_dimension': {'key': 'typeProperties.runDimension', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        pipeline: "TriggerPipelineReference",
        depends_on: List["PipelineReference"],
        run_dimension: str,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        annotations: Optional[List["TriggerAnnotationsItem"]] = None,
        **kwargs
    ):
        super(ChainingTrigger, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, **kwargs)
        self.type = 'ChainingTrigger'
        self.pipeline = pipeline
        self.depends_on = depends_on
        self.run_dimension = run_dimension


class ChainingTriggerTypeProperties(msrest.serialization.Model):
    """Chaining Trigger properties.

    All required parameters must be populated in order to send to Azure.

    :param depends_on: Required. Upstream Pipelines.
    :type depends_on: list[~data_factory_management_client.models.PipelineReference]
    :param run_dimension: Required. Run Dimension property that needs to be emitted by upstream
     pipelines.
    :type run_dimension: str
    """

    _validation = {
        'depends_on': {'required': True},
        'run_dimension': {'required': True},
    }

    _attribute_map = {
        'depends_on': {'key': 'dependsOn', 'type': '[PipelineReference]'},
        'run_dimension': {'key': 'runDimension', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        depends_on: List["PipelineReference"],
        run_dimension: str,
        **kwargs
    ):
        super(ChainingTriggerTypeProperties, self).__init__(**kwargs)
        self.depends_on = depends_on
        self.run_dimension = run_dimension


class CloudErrorException(HttpResponseError):
    """Server responded with exception of type: 'CloudError'.

    :param response: Server response to be deserialized.
    :param error_model: A deserialized model of the response body as model.
    """

    def __init__(self, response, error_model):
        self.error = error_model
        super(CloudErrorException, self).__init__(response=response, error_model=error_model)

    @classmethod
    def from_response(cls, response, deserialize):
        """Deserialize this response as this exception, or a subclass of this exception.

        :param response: Server response to be deserialized.
        :param deserialize: A deserializer
        """
        model_name = 'CloudError'
        error = deserialize(model_name, response)
        if error is None:
            error = deserialize.dependencies[model_name]()
        return error._EXCEPTION_TYPE(response, error)


class CloudError(msrest.serialization.Model):
    """The object that defines the structure of an Azure Data Factory error response.

    All required parameters must be populated in order to send to Azure.

    :param code: Required. Error code.
    :type code: str
    :param message: Required. Error message.
    :type message: str
    :param target: Property name/path in request associated with error.
    :type target: str
    :param details: Array with additional error details.
    :type details: list[~data_factory_management_client.models.CloudError]
    """
    _EXCEPTION_TYPE = CloudErrorException

    _validation = {
        'code': {'required': True},
        'message': {'required': True},
    }

    _attribute_map = {
        'code': {'key': 'error.code', 'type': 'str'},
        'message': {'key': 'error.message', 'type': 'str'},
        'target': {'key': 'error.target', 'type': 'str'},
        'details': {'key': 'error.details', 'type': '[CloudError]'},
    }

    def __init__(
        self,
        *,
        code: str,
        message: str,
        target: Optional[str] = None,
        details: Optional[List["CloudError"]] = None,
        **kwargs
    ):
        super(CloudError, self).__init__(**kwargs)
        self.code = code
        self.message = message
        self.target = target
        self.details = details


class CloudErrorBody(msrest.serialization.Model):
    """The object that defines the structure of an Azure Data Factory error.

    All required parameters must be populated in order to send to Azure.

    :param code: Required. Error code.
    :type code: str
    :param message: Required. Error message.
    :type message: str
    :param target: Property name/path in request associated with error.
    :type target: str
    :param details: Array with additional error details.
    :type details: list[~data_factory_management_client.models.CloudError]
    """

    _validation = {
        'code': {'required': True},
        'message': {'required': True},
    }

    _attribute_map = {
        'code': {'key': 'code', 'type': 'str'},
        'message': {'key': 'message', 'type': 'str'},
        'target': {'key': 'target', 'type': 'str'},
        'details': {'key': 'details', 'type': '[CloudError]'},
    }

    def __init__(
        self,
        *,
        code: str,
        message: str,
        target: Optional[str] = None,
        details: Optional[List["CloudError"]] = None,
        **kwargs
    ):
        super(CloudErrorBody, self).__init__(**kwargs)
        self.code = code
        self.message = message
        self.target = target
        self.details = details


class CustomSetupBase(msrest.serialization.Model):
    """The base definition of the custom setup.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: CmdkeySetup, ComponentSetup, EnvironmentVariableSetup.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. The type of custom setup.Constant filled by server.
    :type type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'CmdkeySetup': 'CmdkeySetup', 'ComponentSetup': 'ComponentSetup', 'EnvironmentVariableSetup': 'EnvironmentVariableSetup'}
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CustomSetupBase, self).__init__(**kwargs)
        self.type = None


class CmdkeySetup(CustomSetupBase):
    """The custom setup of running cmdkey commands.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. The type of custom setup.Constant filled by server.
    :type type: str
    :param target_name: Required. The server name of data source access.
    :type target_name: ~data_factory_management_client.models.CmdkeySetupTypePropertiesTargetName
    :param user_name: Required. The user name of data source access.
    :type user_name: ~data_factory_management_client.models.CmdkeySetupTypePropertiesUserName
    :param password: Required. The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    """

    _validation = {
        'type': {'required': True},
        'target_name': {'required': True},
        'user_name': {'required': True},
        'password': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'target_name': {'key': 'typeProperties.targetName', 'type': 'CmdkeySetupTypePropertiesTargetName'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'CmdkeySetupTypePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        target_name: "CmdkeySetupTypePropertiesTargetName",
        user_name: "CmdkeySetupTypePropertiesUserName",
        password: "SecretBase",
        **kwargs
    ):
        super(CmdkeySetup, self).__init__(**kwargs)
        self.type = 'CmdkeySetup'
        self.target_name = target_name
        self.user_name = user_name
        self.password = password


class CmdkeySetupTypeProperties(msrest.serialization.Model):
    """Cmdkey command custom setup type properties.

    All required parameters must be populated in order to send to Azure.

    :param target_name: Required. The server name of data source access.
    :type target_name: ~data_factory_management_client.models.CmdkeySetupTypePropertiesTargetName
    :param user_name: Required. The user name of data source access.
    :type user_name: ~data_factory_management_client.models.CmdkeySetupTypePropertiesUserName
    :param password: Required. The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    """

    _validation = {
        'target_name': {'required': True},
        'user_name': {'required': True},
        'password': {'required': True},
    }

    _attribute_map = {
        'target_name': {'key': 'targetName', 'type': 'CmdkeySetupTypePropertiesTargetName'},
        'user_name': {'key': 'userName', 'type': 'CmdkeySetupTypePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        target_name: "CmdkeySetupTypePropertiesTargetName",
        user_name: "CmdkeySetupTypePropertiesUserName",
        password: "SecretBase",
        **kwargs
    ):
        super(CmdkeySetupTypeProperties, self).__init__(**kwargs)
        self.target_name = target_name
        self.user_name = user_name
        self.password = password


class CmdkeySetupTypePropertiesTargetName(msrest.serialization.Model):
    """The server name of data source access.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CmdkeySetupTypePropertiesTargetName, self).__init__(**kwargs)


class CmdkeySetupTypePropertiesUserName(msrest.serialization.Model):
    """The user name of data source access.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CmdkeySetupTypePropertiesUserName, self).__init__(**kwargs)


class CommonDataServiceForAppsEntityDataset(Dataset):
    """The Common Data Service for Apps entity dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param entity_name: The logical name of the entity. Type: string (or Expression with resultType
     string).
    :type entity_name:
     ~data_factory_management_client.models.CommonDataServiceForAppsEntityDatasetTypePropertiesEntityName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'entity_name': {'key': 'typeProperties.entityName', 'type': 'CommonDataServiceForAppsEntityDatasetTypePropertiesEntityName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        entity_name: Optional["CommonDataServiceForAppsEntityDatasetTypePropertiesEntityName"] = None,
        **kwargs
    ):
        super(CommonDataServiceForAppsEntityDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'CommonDataServiceForAppsEntity'
        self.entity_name = entity_name


class CommonDataServiceForAppsEntityDatasetTypeProperties(msrest.serialization.Model):
    """Common Data Service for Apps entity dataset properties.

    :param entity_name: The logical name of the entity. Type: string (or Expression with resultType
     string).
    :type entity_name:
     ~data_factory_management_client.models.CommonDataServiceForAppsEntityDatasetTypePropertiesEntityName
    """

    _attribute_map = {
        'entity_name': {'key': 'entityName', 'type': 'CommonDataServiceForAppsEntityDatasetTypePropertiesEntityName'},
    }

    def __init__(
        self,
        *,
        entity_name: Optional["CommonDataServiceForAppsEntityDatasetTypePropertiesEntityName"] = None,
        **kwargs
    ):
        super(CommonDataServiceForAppsEntityDatasetTypeProperties, self).__init__(**kwargs)
        self.entity_name = entity_name


class CommonDataServiceForAppsEntityDatasetTypePropertiesEntityName(msrest.serialization.Model):
    """The logical name of the entity. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CommonDataServiceForAppsEntityDatasetTypePropertiesEntityName, self).__init__(**kwargs)


class CommonDataServiceForAppsLinkedService(LinkedService):
    """Common Data Service for Apps linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param deployment_type: Required. The deployment type of the Dynamics instance. 'Online' for
     Dynamics Online and 'OnPremisesWithIfd' for Dynamics on-premises with Ifd. Type: string (or
     Expression with resultType string). Possible values include: 'Online', 'OnPremisesWithIfd'.
    :type deployment_type: str or ~data_factory_management_client.models.DynamicsDeploymentType
    :param host_name: The host name of the on-premises Common Data Service for Apps server. The
     property is required for on-prem and not allowed for online. Type: string (or Expression with
     resultType string).
    :type host_name:
     ~data_factory_management_client.models.CommonDataServiceForAppsLinkedServiceTypePropertiesHostName
    :param port: The port of on-premises Common Data Service for Apps server. The property is
     required for on-prem and not allowed for online. Default is 443. Type: integer (or Expression
     with resultType integer), minimum: 0.
    :type port:
     ~data_factory_management_client.models.CommonDataServiceForAppsLinkedServiceTypePropertiesPort
    :param service_uri: The URL to the Microsoft Common Data Service for Apps server. The property
     is required for on-line and not allowed for on-prem. Type: string (or Expression with
     resultType string).
    :type service_uri:
     ~data_factory_management_client.models.CommonDataServiceForAppsLinkedServiceTypePropertiesServiceUri
    :param organization_name: The organization name of the Common Data Service for Apps instance.
     The property is required for on-prem and required for online when there are more than one
     Common Data Service for Apps instances associated with the user. Type: string (or Expression
     with resultType string).
    :type organization_name:
     ~data_factory_management_client.models.CommonDataServiceForAppsLinkedServiceTypePropertiesOrganizationName
    :param authentication_type: Required. The authentication type to connect to Dynamics server.
     'Office365' for online scenario, 'Ifd' for on-premises with Ifd scenario, 'AADServicePrincipal'
     for Server-To-Server authentication in online scenario. Type: string (or Expression with
     resultType string). Possible values include: 'Office365', 'Ifd', 'AADServicePrincipal'.
    :type authentication_type: str or
     ~data_factory_management_client.models.DynamicsAuthenticationType
    :param username: User name to access the Common Data Service for Apps instance. Type: string
     (or Expression with resultType string).
    :type username:
     ~data_factory_management_client.models.CommonDataServiceForAppsLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param service_principal_id: The client ID of the application in Azure Active Directory used
     for Server-To-Server authentication. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.CommonDataServiceForAppsLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_credential_type: The service principal credential type to use in
     Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
     for certificate. Type: string (or Expression with resultType string). Possible values include:
     'ServicePrincipalKey', 'ServicePrincipalCert'.
    :type service_principal_credential_type: str or
     ~data_factory_management_client.models.DynamicsServicePrincipalCredentialType
    :param service_principal_credential: The base definition of a secret type.
    :type service_principal_credential: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.CommonDataServiceForAppsLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'deployment_type': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'deployment_type': {'key': 'typeProperties.deploymentType', 'type': 'str'},
        'host_name': {'key': 'typeProperties.hostName', 'type': 'CommonDataServiceForAppsLinkedServiceTypePropertiesHostName'},
        'port': {'key': 'typeProperties.port', 'type': 'CommonDataServiceForAppsLinkedServiceTypePropertiesPort'},
        'service_uri': {'key': 'typeProperties.serviceUri', 'type': 'CommonDataServiceForAppsLinkedServiceTypePropertiesServiceUri'},
        'organization_name': {'key': 'typeProperties.organizationName', 'type': 'CommonDataServiceForAppsLinkedServiceTypePropertiesOrganizationName'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'CommonDataServiceForAppsLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'CommonDataServiceForAppsLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_credential_type': {'key': 'typeProperties.servicePrincipalCredentialType', 'type': 'str'},
        'service_principal_credential': {'key': 'typeProperties.servicePrincipalCredential', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'CommonDataServiceForAppsLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        deployment_type: Union[str, "DynamicsDeploymentType"],
        authentication_type: Union[str, "DynamicsAuthenticationType"],
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        host_name: Optional["CommonDataServiceForAppsLinkedServiceTypePropertiesHostName"] = None,
        port: Optional["CommonDataServiceForAppsLinkedServiceTypePropertiesPort"] = None,
        service_uri: Optional["CommonDataServiceForAppsLinkedServiceTypePropertiesServiceUri"] = None,
        organization_name: Optional["CommonDataServiceForAppsLinkedServiceTypePropertiesOrganizationName"] = None,
        username: Optional["CommonDataServiceForAppsLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        service_principal_id: Optional["CommonDataServiceForAppsLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_credential_type: Optional[Union[str, "DynamicsServicePrincipalCredentialType"]] = None,
        service_principal_credential: Optional["SecretBase"] = None,
        encrypted_credential: Optional["CommonDataServiceForAppsLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(CommonDataServiceForAppsLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'CommonDataServiceForApps'
        self.deployment_type = deployment_type
        self.host_name = host_name
        self.port = port
        self.service_uri = service_uri
        self.organization_name = organization_name
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_credential_type = service_principal_credential_type
        self.service_principal_credential = service_principal_credential
        self.encrypted_credential = encrypted_credential


class CommonDataServiceForAppsLinkedServiceTypeProperties(msrest.serialization.Model):
    """Common Data Service for Apps linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param deployment_type: Required. The deployment type of the Dynamics instance. 'Online' for
     Dynamics Online and 'OnPremisesWithIfd' for Dynamics on-premises with Ifd. Type: string (or
     Expression with resultType string). Possible values include: 'Online', 'OnPremisesWithIfd'.
    :type deployment_type: str or ~data_factory_management_client.models.DynamicsDeploymentType
    :param host_name: The host name of the on-premises Common Data Service for Apps server. The
     property is required for on-prem and not allowed for online. Type: string (or Expression with
     resultType string).
    :type host_name:
     ~data_factory_management_client.models.CommonDataServiceForAppsLinkedServiceTypePropertiesHostName
    :param port: The port of on-premises Common Data Service for Apps server. The property is
     required for on-prem and not allowed for online. Default is 443. Type: integer (or Expression
     with resultType integer), minimum: 0.
    :type port:
     ~data_factory_management_client.models.CommonDataServiceForAppsLinkedServiceTypePropertiesPort
    :param service_uri: The URL to the Microsoft Common Data Service for Apps server. The property
     is required for on-line and not allowed for on-prem. Type: string (or Expression with
     resultType string).
    :type service_uri:
     ~data_factory_management_client.models.CommonDataServiceForAppsLinkedServiceTypePropertiesServiceUri
    :param organization_name: The organization name of the Common Data Service for Apps instance.
     The property is required for on-prem and required for online when there are more than one
     Common Data Service for Apps instances associated with the user. Type: string (or Expression
     with resultType string).
    :type organization_name:
     ~data_factory_management_client.models.CommonDataServiceForAppsLinkedServiceTypePropertiesOrganizationName
    :param authentication_type: Required. The authentication type to connect to Dynamics server.
     'Office365' for online scenario, 'Ifd' for on-premises with Ifd scenario, 'AADServicePrincipal'
     for Server-To-Server authentication in online scenario. Type: string (or Expression with
     resultType string). Possible values include: 'Office365', 'Ifd', 'AADServicePrincipal'.
    :type authentication_type: str or
     ~data_factory_management_client.models.DynamicsAuthenticationType
    :param username: User name to access the Common Data Service for Apps instance. Type: string
     (or Expression with resultType string).
    :type username:
     ~data_factory_management_client.models.CommonDataServiceForAppsLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param service_principal_id: The client ID of the application in Azure Active Directory used
     for Server-To-Server authentication. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.CommonDataServiceForAppsLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_credential_type: The service principal credential type to use in
     Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
     for certificate. Type: string (or Expression with resultType string). Possible values include:
     'ServicePrincipalKey', 'ServicePrincipalCert'.
    :type service_principal_credential_type: str or
     ~data_factory_management_client.models.DynamicsServicePrincipalCredentialType
    :param service_principal_credential: The base definition of a secret type.
    :type service_principal_credential: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.CommonDataServiceForAppsLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'deployment_type': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'deployment_type': {'key': 'deploymentType', 'type': 'str'},
        'host_name': {'key': 'hostName', 'type': 'CommonDataServiceForAppsLinkedServiceTypePropertiesHostName'},
        'port': {'key': 'port', 'type': 'CommonDataServiceForAppsLinkedServiceTypePropertiesPort'},
        'service_uri': {'key': 'serviceUri', 'type': 'CommonDataServiceForAppsLinkedServiceTypePropertiesServiceUri'},
        'organization_name': {'key': 'organizationName', 'type': 'CommonDataServiceForAppsLinkedServiceTypePropertiesOrganizationName'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'username': {'key': 'username', 'type': 'CommonDataServiceForAppsLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'CommonDataServiceForAppsLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_credential_type': {'key': 'servicePrincipalCredentialType', 'type': 'str'},
        'service_principal_credential': {'key': 'servicePrincipalCredential', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'CommonDataServiceForAppsLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        deployment_type: Union[str, "DynamicsDeploymentType"],
        authentication_type: Union[str, "DynamicsAuthenticationType"],
        host_name: Optional["CommonDataServiceForAppsLinkedServiceTypePropertiesHostName"] = None,
        port: Optional["CommonDataServiceForAppsLinkedServiceTypePropertiesPort"] = None,
        service_uri: Optional["CommonDataServiceForAppsLinkedServiceTypePropertiesServiceUri"] = None,
        organization_name: Optional["CommonDataServiceForAppsLinkedServiceTypePropertiesOrganizationName"] = None,
        username: Optional["CommonDataServiceForAppsLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        service_principal_id: Optional["CommonDataServiceForAppsLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_credential_type: Optional[Union[str, "DynamicsServicePrincipalCredentialType"]] = None,
        service_principal_credential: Optional["SecretBase"] = None,
        encrypted_credential: Optional["CommonDataServiceForAppsLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(CommonDataServiceForAppsLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.deployment_type = deployment_type
        self.host_name = host_name
        self.port = port
        self.service_uri = service_uri
        self.organization_name = organization_name
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_credential_type = service_principal_credential_type
        self.service_principal_credential = service_principal_credential
        self.encrypted_credential = encrypted_credential


class CommonDataServiceForAppsLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CommonDataServiceForAppsLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class CommonDataServiceForAppsLinkedServiceTypePropertiesHostName(msrest.serialization.Model):
    """The host name of the on-premises Common Data Service for Apps server. The property is required for on-prem and not allowed for online. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CommonDataServiceForAppsLinkedServiceTypePropertiesHostName, self).__init__(**kwargs)


class CommonDataServiceForAppsLinkedServiceTypePropertiesOrganizationName(msrest.serialization.Model):
    """The organization name of the Common Data Service for Apps instance. The property is required for on-prem and required for online when there are more than one Common Data Service for Apps instances associated with the user. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CommonDataServiceForAppsLinkedServiceTypePropertiesOrganizationName, self).__init__(**kwargs)


class CommonDataServiceForAppsLinkedServiceTypePropertiesPort(msrest.serialization.Model):
    """The port of on-premises Common Data Service for Apps server. The property is required for on-prem and not allowed for online. Default is 443. Type: integer (or Expression with resultType integer), minimum: 0.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CommonDataServiceForAppsLinkedServiceTypePropertiesPort, self).__init__(**kwargs)


class CommonDataServiceForAppsLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """The client ID of the application in Azure Active Directory used for Server-To-Server authentication. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CommonDataServiceForAppsLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class CommonDataServiceForAppsLinkedServiceTypePropertiesServiceUri(msrest.serialization.Model):
    """The URL to the Microsoft Common Data Service for Apps server. The property is required for on-line and not allowed for on-prem. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CommonDataServiceForAppsLinkedServiceTypePropertiesServiceUri, self).__init__(**kwargs)


class CommonDataServiceForAppsLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """User name to access the Common Data Service for Apps instance. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CommonDataServiceForAppsLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class CommonDataServiceForAppsSink(CopySink):
    """A copy activity Common Data Service for Apps sink.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :ivar write_behavior: Required. The write behavior for the operation. Default value: "Upsert".
    :vartype write_behavior: str
    :param ignore_null_values: The flag indicating whether to ignore null values from input dataset
     (except key fields) during write operation. Default is false. Type: boolean (or Expression with
     resultType boolean).
    :type ignore_null_values:
     ~data_factory_management_client.models.CommonDataServiceForAppsSinkIgnoreNullValues
    :param alternate_key_name: The logical name of the alternate key which will be used when
     upserting records. Type: string (or Expression with resultType string).
    :type alternate_key_name:
     ~data_factory_management_client.models.CommonDataServiceForAppsSinkAlternateKeyName
    """

    _validation = {
        'type': {'required': True},
        'write_behavior': {'required': True, 'constant': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'str'},
        'ignore_null_values': {'key': 'ignoreNullValues', 'type': 'CommonDataServiceForAppsSinkIgnoreNullValues'},
        'alternate_key_name': {'key': 'alternateKeyName', 'type': 'CommonDataServiceForAppsSinkAlternateKeyName'},
    }

    write_behavior = "Upsert"

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        ignore_null_values: Optional["CommonDataServiceForAppsSinkIgnoreNullValues"] = None,
        alternate_key_name: Optional["CommonDataServiceForAppsSinkAlternateKeyName"] = None,
        **kwargs
    ):
        super(CommonDataServiceForAppsSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'CommonDataServiceForAppsSink'
        self.ignore_null_values = ignore_null_values
        self.alternate_key_name = alternate_key_name


class CommonDataServiceForAppsSinkAlternateKeyName(msrest.serialization.Model):
    """The logical name of the alternate key which will be used when upserting records. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CommonDataServiceForAppsSinkAlternateKeyName, self).__init__(**kwargs)


class CommonDataServiceForAppsSinkIgnoreNullValues(msrest.serialization.Model):
    """The flag indicating whether to ignore null values from input dataset (except key fields) during write operation. Default is false. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CommonDataServiceForAppsSinkIgnoreNullValues, self).__init__(**kwargs)


class CommonDataServiceForAppsSource(CopySource):
    """A copy activity Common Data Service for Apps source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query: FetchXML is a proprietary query language that is used in Microsoft Common Data
     Service for Apps (online & on-premises). Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.CommonDataServiceForAppsSourceQuery
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query': {'key': 'query', 'type': 'CommonDataServiceForAppsSourceQuery'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query: Optional["CommonDataServiceForAppsSourceQuery"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(CommonDataServiceForAppsSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'CommonDataServiceForAppsSource'
        self.query = query
        self.additional_columns = additional_columns


class CommonDataServiceForAppsSourceQuery(msrest.serialization.Model):
    """FetchXML is a proprietary query language that is used in Microsoft Common Data Service for Apps (online & on-premises). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CommonDataServiceForAppsSourceQuery, self).__init__(**kwargs)


class ComponentSetup(CustomSetupBase):
    """The custom setup of installing 3rd party components.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. The type of custom setup.Constant filled by server.
    :type type: str
    :param component_name: Required. The name of the 3rd party component.
    :type component_name: str
    :param license_key: The base definition of a secret type.
    :type license_key: ~data_factory_management_client.models.SecretBase
    """

    _validation = {
        'type': {'required': True},
        'component_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'component_name': {'key': 'typeProperties.componentName', 'type': 'str'},
        'license_key': {'key': 'typeProperties.licenseKey', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        component_name: str,
        license_key: Optional["SecretBase"] = None,
        **kwargs
    ):
        super(ComponentSetup, self).__init__(**kwargs)
        self.type = 'ComponentSetup'
        self.component_name = component_name
        self.license_key = license_key


class ConcurLinkedService(LinkedService):
    """Concur Service linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param client_id: Required. Application client_id supplied by Concur App Management.
    :type client_id:
     ~data_factory_management_client.models.ConcurLinkedServiceTypePropertiesClientId
    :param username: Required. The user name that you use to access Concur Service.
    :type username:
     ~data_factory_management_client.models.ConcurLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.ConcurLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.ConcurLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.ConcurLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.ConcurLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'client_id': {'required': True},
        'username': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'ConcurLinkedServiceTypePropertiesClientId'},
        'username': {'key': 'typeProperties.username', 'type': 'ConcurLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'ConcurLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'ConcurLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'ConcurLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'ConcurLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        client_id: "ConcurLinkedServiceTypePropertiesClientId",
        username: "ConcurLinkedServiceTypePropertiesUsername",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        password: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["ConcurLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["ConcurLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["ConcurLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["ConcurLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(ConcurLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Concur'
        self.client_id = client_id
        self.username = username
        self.password = password
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class ConcurLinkedServiceTypeProperties(msrest.serialization.Model):
    """Concur Service linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param client_id: Required. Application client_id supplied by Concur App Management.
    :type client_id:
     ~data_factory_management_client.models.ConcurLinkedServiceTypePropertiesClientId
    :param username: Required. The user name that you use to access Concur Service.
    :type username:
     ~data_factory_management_client.models.ConcurLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.ConcurLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.ConcurLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.ConcurLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.ConcurLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'client_id': {'required': True},
        'username': {'required': True},
    }

    _attribute_map = {
        'client_id': {'key': 'clientId', 'type': 'ConcurLinkedServiceTypePropertiesClientId'},
        'username': {'key': 'username', 'type': 'ConcurLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'ConcurLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'ConcurLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'ConcurLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'ConcurLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        client_id: "ConcurLinkedServiceTypePropertiesClientId",
        username: "ConcurLinkedServiceTypePropertiesUsername",
        password: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["ConcurLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["ConcurLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["ConcurLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["ConcurLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(ConcurLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.client_id = client_id
        self.username = username
        self.password = password
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class ConcurLinkedServiceTypePropertiesClientId(msrest.serialization.Model):
    """Application client_id supplied by Concur App Management.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ConcurLinkedServiceTypePropertiesClientId, self).__init__(**kwargs)


class ConcurLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ConcurLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class ConcurLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ConcurLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class ConcurLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ConcurLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class ConcurLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ConcurLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class ConcurLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """The user name that you use to access Concur Service.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ConcurLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class ConcurObjectDataset(Dataset):
    """Concur Service dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(ConcurObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'ConcurObject'
        self.table_name = table_name


class ConcurSource(TabularSource):
    """A copy activity Concur Service source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.ConcurSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'ConcurSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["ConcurSourceQuery"] = None,
        **kwargs
    ):
        super(ConcurSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'ConcurSource'
        self.query = query


class ConcurSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ConcurSourceQuery, self).__init__(**kwargs)


class CopyActivity(ExecutionActivity):
    """Copy activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param inputs: List of inputs for the activity.
    :type inputs: list[~data_factory_management_client.models.DatasetReference]
    :param outputs: List of outputs for the activity.
    :type outputs: list[~data_factory_management_client.models.DatasetReference]
    :param source: Required. A copy activity source.
    :type source: ~data_factory_management_client.models.CopySource
    :param sink: Required. A copy activity sink.
    :type sink: ~data_factory_management_client.models.CopySink
    :param translator: Copy activity translator. If not specified, tabular translator is used.
    :type translator: ~data_factory_management_client.models.CopyActivityTypePropertiesTranslator
    :param enable_staging: Specifies whether to copy data via an interim staging. Default value is
     false. Type: boolean (or Expression with resultType boolean).
    :type enable_staging:
     ~data_factory_management_client.models.CopyActivityTypePropertiesEnableStaging
    :param staging_settings: Staging settings.
    :type staging_settings: ~data_factory_management_client.models.StagingSettings
    :param parallel_copies: Maximum number of concurrent sessions opened on the source or sink to
     avoid overloading the data store. Type: integer (or Expression with resultType integer),
     minimum: 0.
    :type parallel_copies:
     ~data_factory_management_client.models.CopyActivityTypePropertiesParallelCopies
    :param data_integration_units: Maximum number of data integration units that can be used to
     perform this data movement. Type: integer (or Expression with resultType integer), minimum: 0.
    :type data_integration_units:
     ~data_factory_management_client.models.CopyActivityTypePropertiesDataIntegrationUnits
    :param enable_skip_incompatible_row: Whether to skip incompatible row. Default value is false.
     Type: boolean (or Expression with resultType boolean).
    :type enable_skip_incompatible_row:
     ~data_factory_management_client.models.CopyActivityTypePropertiesEnableSkipIncompatibleRow
    :param redirect_incompatible_row_settings: Redirect incompatible row settings.
    :type redirect_incompatible_row_settings:
     ~data_factory_management_client.models.RedirectIncompatibleRowSettings
    :param log_storage_settings: Log storage settings.
    :type log_storage_settings: ~data_factory_management_client.models.LogStorageSettings
    :param preserve_rules: Preserve Rules.
    :type preserve_rules:
     list[~data_factory_management_client.models.CopyActivityTypePropertiesPreserveRulesItem]
    :param preserve: Preserve rules.
    :type preserve:
     list[~data_factory_management_client.models.CopyActivityTypePropertiesPreserveItem]
    :param validate_data_consistency: Whether to enable Data Consistency validation. Type: boolean
     (or Expression with resultType boolean).
    :type validate_data_consistency:
     ~data_factory_management_client.models.CopyActivityTypePropertiesValidateDataConsistency
    :param skip_error_file: Skip error file.
    :type skip_error_file: ~data_factory_management_client.models.SkipErrorFile
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'source': {'required': True},
        'sink': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'inputs': {'key': 'inputs', 'type': '[DatasetReference]'},
        'outputs': {'key': 'outputs', 'type': '[DatasetReference]'},
        'source': {'key': 'typeProperties.source', 'type': 'CopySource'},
        'sink': {'key': 'typeProperties.sink', 'type': 'CopySink'},
        'translator': {'key': 'typeProperties.translator', 'type': 'CopyActivityTypePropertiesTranslator'},
        'enable_staging': {'key': 'typeProperties.enableStaging', 'type': 'CopyActivityTypePropertiesEnableStaging'},
        'staging_settings': {'key': 'typeProperties.stagingSettings', 'type': 'StagingSettings'},
        'parallel_copies': {'key': 'typeProperties.parallelCopies', 'type': 'CopyActivityTypePropertiesParallelCopies'},
        'data_integration_units': {'key': 'typeProperties.dataIntegrationUnits', 'type': 'CopyActivityTypePropertiesDataIntegrationUnits'},
        'enable_skip_incompatible_row': {'key': 'typeProperties.enableSkipIncompatibleRow', 'type': 'CopyActivityTypePropertiesEnableSkipIncompatibleRow'},
        'redirect_incompatible_row_settings': {'key': 'typeProperties.redirectIncompatibleRowSettings', 'type': 'RedirectIncompatibleRowSettings'},
        'log_storage_settings': {'key': 'typeProperties.logStorageSettings', 'type': 'LogStorageSettings'},
        'preserve_rules': {'key': 'typeProperties.preserveRules', 'type': '[CopyActivityTypePropertiesPreserveRulesItem]'},
        'preserve': {'key': 'typeProperties.preserve', 'type': '[CopyActivityTypePropertiesPreserveItem]'},
        'validate_data_consistency': {'key': 'typeProperties.validateDataConsistency', 'type': 'CopyActivityTypePropertiesValidateDataConsistency'},
        'skip_error_file': {'key': 'typeProperties.skipErrorFile', 'type': 'SkipErrorFile'},
    }

    def __init__(
        self,
        *,
        name: str,
        source: "CopySource",
        sink: "CopySink",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        inputs: Optional[List["DatasetReference"]] = None,
        outputs: Optional[List["DatasetReference"]] = None,
        translator: Optional["CopyActivityTypePropertiesTranslator"] = None,
        enable_staging: Optional["CopyActivityTypePropertiesEnableStaging"] = None,
        staging_settings: Optional["StagingSettings"] = None,
        parallel_copies: Optional["CopyActivityTypePropertiesParallelCopies"] = None,
        data_integration_units: Optional["CopyActivityTypePropertiesDataIntegrationUnits"] = None,
        enable_skip_incompatible_row: Optional["CopyActivityTypePropertiesEnableSkipIncompatibleRow"] = None,
        redirect_incompatible_row_settings: Optional["RedirectIncompatibleRowSettings"] = None,
        log_storage_settings: Optional["LogStorageSettings"] = None,
        preserve_rules: Optional[List["CopyActivityTypePropertiesPreserveRulesItem"]] = None,
        preserve: Optional[List["CopyActivityTypePropertiesPreserveItem"]] = None,
        validate_data_consistency: Optional["CopyActivityTypePropertiesValidateDataConsistency"] = None,
        skip_error_file: Optional["SkipErrorFile"] = None,
        **kwargs
    ):
        super(CopyActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'Copy'
        self.inputs = inputs
        self.outputs = outputs
        self.source = source
        self.sink = sink
        self.translator = translator
        self.enable_staging = enable_staging
        self.staging_settings = staging_settings
        self.parallel_copies = parallel_copies
        self.data_integration_units = data_integration_units
        self.enable_skip_incompatible_row = enable_skip_incompatible_row
        self.redirect_incompatible_row_settings = redirect_incompatible_row_settings
        self.log_storage_settings = log_storage_settings
        self.preserve_rules = preserve_rules
        self.preserve = preserve
        self.validate_data_consistency = validate_data_consistency
        self.skip_error_file = skip_error_file


class CopyActivityTypeProperties(msrest.serialization.Model):
    """Copy activity properties.

    All required parameters must be populated in order to send to Azure.

    :param source: Required. A copy activity source.
    :type source: ~data_factory_management_client.models.CopySource
    :param sink: Required. A copy activity sink.
    :type sink: ~data_factory_management_client.models.CopySink
    :param translator: Copy activity translator. If not specified, tabular translator is used.
    :type translator: ~data_factory_management_client.models.CopyActivityTypePropertiesTranslator
    :param enable_staging: Specifies whether to copy data via an interim staging. Default value is
     false. Type: boolean (or Expression with resultType boolean).
    :type enable_staging:
     ~data_factory_management_client.models.CopyActivityTypePropertiesEnableStaging
    :param staging_settings: Staging settings.
    :type staging_settings: ~data_factory_management_client.models.StagingSettings
    :param parallel_copies: Maximum number of concurrent sessions opened on the source or sink to
     avoid overloading the data store. Type: integer (or Expression with resultType integer),
     minimum: 0.
    :type parallel_copies:
     ~data_factory_management_client.models.CopyActivityTypePropertiesParallelCopies
    :param data_integration_units: Maximum number of data integration units that can be used to
     perform this data movement. Type: integer (or Expression with resultType integer), minimum: 0.
    :type data_integration_units:
     ~data_factory_management_client.models.CopyActivityTypePropertiesDataIntegrationUnits
    :param enable_skip_incompatible_row: Whether to skip incompatible row. Default value is false.
     Type: boolean (or Expression with resultType boolean).
    :type enable_skip_incompatible_row:
     ~data_factory_management_client.models.CopyActivityTypePropertiesEnableSkipIncompatibleRow
    :param redirect_incompatible_row_settings: Redirect incompatible row settings.
    :type redirect_incompatible_row_settings:
     ~data_factory_management_client.models.RedirectIncompatibleRowSettings
    :param log_storage_settings: Log storage settings.
    :type log_storage_settings: ~data_factory_management_client.models.LogStorageSettings
    :param preserve_rules: Preserve Rules.
    :type preserve_rules:
     list[~data_factory_management_client.models.CopyActivityTypePropertiesPreserveRulesItem]
    :param preserve: Preserve rules.
    :type preserve:
     list[~data_factory_management_client.models.CopyActivityTypePropertiesPreserveItem]
    :param validate_data_consistency: Whether to enable Data Consistency validation. Type: boolean
     (or Expression with resultType boolean).
    :type validate_data_consistency:
     ~data_factory_management_client.models.CopyActivityTypePropertiesValidateDataConsistency
    :param skip_error_file: Skip error file.
    :type skip_error_file: ~data_factory_management_client.models.SkipErrorFile
    """

    _validation = {
        'source': {'required': True},
        'sink': {'required': True},
    }

    _attribute_map = {
        'source': {'key': 'source', 'type': 'CopySource'},
        'sink': {'key': 'sink', 'type': 'CopySink'},
        'translator': {'key': 'translator', 'type': 'CopyActivityTypePropertiesTranslator'},
        'enable_staging': {'key': 'enableStaging', 'type': 'CopyActivityTypePropertiesEnableStaging'},
        'staging_settings': {'key': 'stagingSettings', 'type': 'StagingSettings'},
        'parallel_copies': {'key': 'parallelCopies', 'type': 'CopyActivityTypePropertiesParallelCopies'},
        'data_integration_units': {'key': 'dataIntegrationUnits', 'type': 'CopyActivityTypePropertiesDataIntegrationUnits'},
        'enable_skip_incompatible_row': {'key': 'enableSkipIncompatibleRow', 'type': 'CopyActivityTypePropertiesEnableSkipIncompatibleRow'},
        'redirect_incompatible_row_settings': {'key': 'redirectIncompatibleRowSettings', 'type': 'RedirectIncompatibleRowSettings'},
        'log_storage_settings': {'key': 'logStorageSettings', 'type': 'LogStorageSettings'},
        'preserve_rules': {'key': 'preserveRules', 'type': '[CopyActivityTypePropertiesPreserveRulesItem]'},
        'preserve': {'key': 'preserve', 'type': '[CopyActivityTypePropertiesPreserveItem]'},
        'validate_data_consistency': {'key': 'validateDataConsistency', 'type': 'CopyActivityTypePropertiesValidateDataConsistency'},
        'skip_error_file': {'key': 'skipErrorFile', 'type': 'SkipErrorFile'},
    }

    def __init__(
        self,
        *,
        source: "CopySource",
        sink: "CopySink",
        translator: Optional["CopyActivityTypePropertiesTranslator"] = None,
        enable_staging: Optional["CopyActivityTypePropertiesEnableStaging"] = None,
        staging_settings: Optional["StagingSettings"] = None,
        parallel_copies: Optional["CopyActivityTypePropertiesParallelCopies"] = None,
        data_integration_units: Optional["CopyActivityTypePropertiesDataIntegrationUnits"] = None,
        enable_skip_incompatible_row: Optional["CopyActivityTypePropertiesEnableSkipIncompatibleRow"] = None,
        redirect_incompatible_row_settings: Optional["RedirectIncompatibleRowSettings"] = None,
        log_storage_settings: Optional["LogStorageSettings"] = None,
        preserve_rules: Optional[List["CopyActivityTypePropertiesPreserveRulesItem"]] = None,
        preserve: Optional[List["CopyActivityTypePropertiesPreserveItem"]] = None,
        validate_data_consistency: Optional["CopyActivityTypePropertiesValidateDataConsistency"] = None,
        skip_error_file: Optional["SkipErrorFile"] = None,
        **kwargs
    ):
        super(CopyActivityTypeProperties, self).__init__(**kwargs)
        self.source = source
        self.sink = sink
        self.translator = translator
        self.enable_staging = enable_staging
        self.staging_settings = staging_settings
        self.parallel_copies = parallel_copies
        self.data_integration_units = data_integration_units
        self.enable_skip_incompatible_row = enable_skip_incompatible_row
        self.redirect_incompatible_row_settings = redirect_incompatible_row_settings
        self.log_storage_settings = log_storage_settings
        self.preserve_rules = preserve_rules
        self.preserve = preserve
        self.validate_data_consistency = validate_data_consistency
        self.skip_error_file = skip_error_file


class CopyActivityTypePropertiesDataIntegrationUnits(msrest.serialization.Model):
    """Maximum number of data integration units that can be used to perform this data movement. Type: integer (or Expression with resultType integer), minimum: 0.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopyActivityTypePropertiesDataIntegrationUnits, self).__init__(**kwargs)


class CopyActivityTypePropertiesEnableSkipIncompatibleRow(msrest.serialization.Model):
    """Whether to skip incompatible row. Default value is false. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopyActivityTypePropertiesEnableSkipIncompatibleRow, self).__init__(**kwargs)


class CopyActivityTypePropertiesEnableStaging(msrest.serialization.Model):
    """Specifies whether to copy data via an interim staging. Default value is false. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopyActivityTypePropertiesEnableStaging, self).__init__(**kwargs)


class CopyActivityTypePropertiesParallelCopies(msrest.serialization.Model):
    """Maximum number of concurrent sessions opened on the source or sink to avoid overloading the data store. Type: integer (or Expression with resultType integer), minimum: 0.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopyActivityTypePropertiesParallelCopies, self).__init__(**kwargs)


class CopyActivityTypePropertiesPreserveItem(msrest.serialization.Model):
    """Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopyActivityTypePropertiesPreserveItem, self).__init__(**kwargs)


class CopyActivityTypePropertiesPreserveRulesItem(msrest.serialization.Model):
    """Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopyActivityTypePropertiesPreserveRulesItem, self).__init__(**kwargs)


class CopyActivityTypePropertiesTranslator(msrest.serialization.Model):
    """Copy activity translator. If not specified, tabular translator is used.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopyActivityTypePropertiesTranslator, self).__init__(**kwargs)


class CopyActivityTypePropertiesValidateDataConsistency(msrest.serialization.Model):
    """Whether to enable Data Consistency validation. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopyActivityTypePropertiesValidateDataConsistency, self).__init__(**kwargs)


class CopySinkMaxConcurrentConnections(msrest.serialization.Model):
    """The maximum concurrent connection count for the sink data store. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopySinkMaxConcurrentConnections, self).__init__(**kwargs)


class CopySinkSinkRetryCount(msrest.serialization.Model):
    """Sink retry count. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopySinkSinkRetryCount, self).__init__(**kwargs)


class CopySinkSinkRetryWait(msrest.serialization.Model):
    """Sink retry wait. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopySinkSinkRetryWait, self).__init__(**kwargs)


class CopySinkWriteBatchSize(msrest.serialization.Model):
    """Write batch size. Type: integer (or Expression with resultType integer), minimum: 0.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopySinkWriteBatchSize, self).__init__(**kwargs)


class CopySinkWriteBatchTimeout(msrest.serialization.Model):
    """Write batch timeout. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopySinkWriteBatchTimeout, self).__init__(**kwargs)


class CopySourceMaxConcurrentConnections(msrest.serialization.Model):
    """The maximum concurrent connection count for the source data store. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopySourceMaxConcurrentConnections, self).__init__(**kwargs)


class CopySourceSourceRetryCount(msrest.serialization.Model):
    """Source retry count. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopySourceSourceRetryCount, self).__init__(**kwargs)


class CopySourceSourceRetryWait(msrest.serialization.Model):
    """Source retry wait. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CopySourceSourceRetryWait, self).__init__(**kwargs)


class CosmosDbLinkedService(LinkedService):
    """Microsoft Azure Cosmos Database (CosmosDB) linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.CosmosDbLinkedServiceTypePropertiesConnectionString
    :param account_endpoint: The endpoint of the Azure CosmosDB account. Type: string (or
     Expression with resultType string).
    :type account_endpoint:
     ~data_factory_management_client.models.CosmosDbLinkedServiceTypePropertiesAccountEndpoint
    :param database: The name of the database. Type: string (or Expression with resultType string).
    :type database:
     ~data_factory_management_client.models.CosmosDbLinkedServiceTypePropertiesDatabase
    :param account_key: The base definition of a secret type.
    :type account_key: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.CosmosDbLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'CosmosDbLinkedServiceTypePropertiesConnectionString'},
        'account_endpoint': {'key': 'typeProperties.accountEndpoint', 'type': 'CosmosDbLinkedServiceTypePropertiesAccountEndpoint'},
        'database': {'key': 'typeProperties.database', 'type': 'CosmosDbLinkedServiceTypePropertiesDatabase'},
        'account_key': {'key': 'typeProperties.accountKey', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'CosmosDbLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        connection_string: Optional["CosmosDbLinkedServiceTypePropertiesConnectionString"] = None,
        account_endpoint: Optional["CosmosDbLinkedServiceTypePropertiesAccountEndpoint"] = None,
        database: Optional["CosmosDbLinkedServiceTypePropertiesDatabase"] = None,
        account_key: Optional["SecretBase"] = None,
        encrypted_credential: Optional["CosmosDbLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(CosmosDbLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'CosmosDb'
        self.connection_string = connection_string
        self.account_endpoint = account_endpoint
        self.database = database
        self.account_key = account_key
        self.encrypted_credential = encrypted_credential


class CosmosDbLinkedServiceTypeProperties(msrest.serialization.Model):
    """CosmosDB linked service properties.

    :param connection_string: The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.CosmosDbLinkedServiceTypePropertiesConnectionString
    :param account_endpoint: The endpoint of the Azure CosmosDB account. Type: string (or
     Expression with resultType string).
    :type account_endpoint:
     ~data_factory_management_client.models.CosmosDbLinkedServiceTypePropertiesAccountEndpoint
    :param database: The name of the database. Type: string (or Expression with resultType string).
    :type database:
     ~data_factory_management_client.models.CosmosDbLinkedServiceTypePropertiesDatabase
    :param account_key: The base definition of a secret type.
    :type account_key: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.CosmosDbLinkedServiceTypePropertiesEncryptedCredential
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'CosmosDbLinkedServiceTypePropertiesConnectionString'},
        'account_endpoint': {'key': 'accountEndpoint', 'type': 'CosmosDbLinkedServiceTypePropertiesAccountEndpoint'},
        'database': {'key': 'database', 'type': 'CosmosDbLinkedServiceTypePropertiesDatabase'},
        'account_key': {'key': 'accountKey', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'CosmosDbLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional["CosmosDbLinkedServiceTypePropertiesConnectionString"] = None,
        account_endpoint: Optional["CosmosDbLinkedServiceTypePropertiesAccountEndpoint"] = None,
        database: Optional["CosmosDbLinkedServiceTypePropertiesDatabase"] = None,
        account_key: Optional["SecretBase"] = None,
        encrypted_credential: Optional["CosmosDbLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(CosmosDbLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.account_endpoint = account_endpoint
        self.database = database
        self.account_key = account_key
        self.encrypted_credential = encrypted_credential


class CosmosDbLinkedServiceTypePropertiesAccountEndpoint(msrest.serialization.Model):
    """The endpoint of the Azure CosmosDB account. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbLinkedServiceTypePropertiesAccountEndpoint, self).__init__(**kwargs)


class CosmosDbLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class CosmosDbLinkedServiceTypePropertiesDatabase(msrest.serialization.Model):
    """The name of the database. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbLinkedServiceTypePropertiesDatabase, self).__init__(**kwargs)


class CosmosDbLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class CosmosDbMongoDbApiCollectionDataset(Dataset):
    """The CosmosDB (MongoDB API) database dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param collection: Required. The collection name of the CosmosDB (MongoDB API) database. Type:
     string (or Expression with resultType string).
    :type collection:
     ~data_factory_management_client.models.CosmosDbMongoDbApiCollectionDatasetTypePropertiesCollection
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'collection': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'collection': {'key': 'typeProperties.collection', 'type': 'CosmosDbMongoDbApiCollectionDatasetTypePropertiesCollection'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        collection: "CosmosDbMongoDbApiCollectionDatasetTypePropertiesCollection",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        super(CosmosDbMongoDbApiCollectionDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'CosmosDbMongoDbApiCollection'
        self.collection = collection


class CosmosDbMongoDbApiCollectionDatasetTypeProperties(msrest.serialization.Model):
    """CosmosDB (MongoDB API) database dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param collection: Required. The collection name of the CosmosDB (MongoDB API) database. Type:
     string (or Expression with resultType string).
    :type collection:
     ~data_factory_management_client.models.CosmosDbMongoDbApiCollectionDatasetTypePropertiesCollection
    """

    _validation = {
        'collection': {'required': True},
    }

    _attribute_map = {
        'collection': {'key': 'collection', 'type': 'CosmosDbMongoDbApiCollectionDatasetTypePropertiesCollection'},
    }

    def __init__(
        self,
        *,
        collection: "CosmosDbMongoDbApiCollectionDatasetTypePropertiesCollection",
        **kwargs
    ):
        super(CosmosDbMongoDbApiCollectionDatasetTypeProperties, self).__init__(**kwargs)
        self.collection = collection


class CosmosDbMongoDbApiCollectionDatasetTypePropertiesCollection(msrest.serialization.Model):
    """The collection name of the CosmosDB (MongoDB API) database. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbMongoDbApiCollectionDatasetTypePropertiesCollection, self).__init__(**kwargs)


class CosmosDbMongoDbApiLinkedService(LinkedService):
    """Linked service for CosmosDB (MongoDB API) data source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: Required. The CosmosDB (MongoDB API) connection string. Type: string,
     SecureString or AzureKeyVaultSecretReference. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.CosmosDbMongoDbApiLinkedServiceTypePropertiesConnectionString
    :param database: Required. The name of the CosmosDB (MongoDB API) database that you want to
     access. Type: string (or Expression with resultType string).
    :type database:
     ~data_factory_management_client.models.CosmosDbMongoDbApiLinkedServiceTypePropertiesDatabase
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
        'database': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'CosmosDbMongoDbApiLinkedServiceTypePropertiesConnectionString'},
        'database': {'key': 'typeProperties.database', 'type': 'CosmosDbMongoDbApiLinkedServiceTypePropertiesDatabase'},
    }

    def __init__(
        self,
        *,
        connection_string: "CosmosDbMongoDbApiLinkedServiceTypePropertiesConnectionString",
        database: "CosmosDbMongoDbApiLinkedServiceTypePropertiesDatabase",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        **kwargs
    ):
        super(CosmosDbMongoDbApiLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'CosmosDbMongoDbApi'
        self.connection_string = connection_string
        self.database = database


class CosmosDbMongoDbApiLinkedServiceTypeProperties(msrest.serialization.Model):
    """CosmosDB (MongoDB API) linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param connection_string: Required. The CosmosDB (MongoDB API) connection string. Type: string,
     SecureString or AzureKeyVaultSecretReference. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.CosmosDbMongoDbApiLinkedServiceTypePropertiesConnectionString
    :param database: Required. The name of the CosmosDB (MongoDB API) database that you want to
     access. Type: string (or Expression with resultType string).
    :type database:
     ~data_factory_management_client.models.CosmosDbMongoDbApiLinkedServiceTypePropertiesDatabase
    """

    _validation = {
        'connection_string': {'required': True},
        'database': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'CosmosDbMongoDbApiLinkedServiceTypePropertiesConnectionString'},
        'database': {'key': 'database', 'type': 'CosmosDbMongoDbApiLinkedServiceTypePropertiesDatabase'},
    }

    def __init__(
        self,
        *,
        connection_string: "CosmosDbMongoDbApiLinkedServiceTypePropertiesConnectionString",
        database: "CosmosDbMongoDbApiLinkedServiceTypePropertiesDatabase",
        **kwargs
    ):
        super(CosmosDbMongoDbApiLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.database = database


class CosmosDbMongoDbApiLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The CosmosDB (MongoDB API) connection string. Type: string, SecureString or AzureKeyVaultSecretReference. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbMongoDbApiLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class CosmosDbMongoDbApiLinkedServiceTypePropertiesDatabase(msrest.serialization.Model):
    """The name of the CosmosDB (MongoDB API) database that you want to access. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbMongoDbApiLinkedServiceTypePropertiesDatabase, self).__init__(**kwargs)


class CosmosDbMongoDbApiSink(CopySink):
    """A copy activity sink for a CosmosDB (MongoDB API) database.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param write_behavior: Specifies whether the document with same key to be overwritten (upsert)
     rather than throw exception (insert). The default value is "insert". Type: string (or
     Expression with resultType string). Type: string (or Expression with resultType string).
    :type write_behavior:
     ~data_factory_management_client.models.CosmosDbMongoDbApiSinkWriteBehavior
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'CosmosDbMongoDbApiSinkWriteBehavior'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        write_behavior: Optional["CosmosDbMongoDbApiSinkWriteBehavior"] = None,
        **kwargs
    ):
        super(CosmosDbMongoDbApiSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'CosmosDbMongoDbApiSink'
        self.write_behavior = write_behavior


class CosmosDbMongoDbApiSinkWriteBehavior(msrest.serialization.Model):
    """Specifies whether the document with same key to be overwritten (upsert) rather than throw exception (insert). The default value is "insert". Type: string (or Expression with resultType string). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbMongoDbApiSinkWriteBehavior, self).__init__(**kwargs)


class CosmosDbMongoDbApiSource(CopySource):
    """A copy activity source for a CosmosDB (MongoDB API) database.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param filter: Specifies selection filter using query operators. To return all documents in a
     collection, omit this parameter or pass an empty document ({}). Type: string (or Expression
     with resultType string).
    :type filter: ~data_factory_management_client.models.CosmosDbMongoDbApiSourceFilter
    :param cursor_methods: Cursor methods for Mongodb query.
    :type cursor_methods: ~data_factory_management_client.models.MongoDbCursorMethodsProperties
    :param batch_size: Specifies the number of documents to return in each batch of the response
     from MongoDB instance. In most cases, modifying the batch size will not affect the user or the
     application. This property's main purpose is to avoid hit the limitation of response size.
     Type: integer (or Expression with resultType integer).
    :type batch_size: ~data_factory_management_client.models.CosmosDbMongoDbApiSourceBatchSize
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout:
     ~data_factory_management_client.models.CosmosDbMongoDbApiSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'filter': {'key': 'filter', 'type': 'CosmosDbMongoDbApiSourceFilter'},
        'cursor_methods': {'key': 'cursorMethods', 'type': 'MongoDbCursorMethodsProperties'},
        'batch_size': {'key': 'batchSize', 'type': 'CosmosDbMongoDbApiSourceBatchSize'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'CosmosDbMongoDbApiSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        filter: Optional["CosmosDbMongoDbApiSourceFilter"] = None,
        cursor_methods: Optional["MongoDbCursorMethodsProperties"] = None,
        batch_size: Optional["CosmosDbMongoDbApiSourceBatchSize"] = None,
        query_timeout: Optional["CosmosDbMongoDbApiSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(CosmosDbMongoDbApiSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'CosmosDbMongoDbApiSource'
        self.filter = filter
        self.cursor_methods = cursor_methods
        self.batch_size = batch_size
        self.query_timeout = query_timeout
        self.additional_columns = additional_columns


class CosmosDbMongoDbApiSourceBatchSize(msrest.serialization.Model):
    """Specifies the number of documents to return in each batch of the response from MongoDB instance. In most cases, modifying the batch size will not affect the user or the application. This property's main purpose is to avoid hit the limitation of response size. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbMongoDbApiSourceBatchSize, self).__init__(**kwargs)


class CosmosDbMongoDbApiSourceFilter(msrest.serialization.Model):
    """Specifies selection filter using query operators. To return all documents in a collection, omit this parameter or pass an empty document ({}). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbMongoDbApiSourceFilter, self).__init__(**kwargs)


class CosmosDbMongoDbApiSourceQueryTimeout(msrest.serialization.Model):
    """Query timeout. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbMongoDbApiSourceQueryTimeout, self).__init__(**kwargs)


class CosmosDbSqlApiCollectionDataset(Dataset):
    """Microsoft Azure CosmosDB (SQL API) Collection dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param collection_name: Required. CosmosDB (SQL API) collection name. Type: string (or
     Expression with resultType string).
    :type collection_name:
     ~data_factory_management_client.models.CosmosDbSqlApiCollectionDatasetTypePropertiesCollectionName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'collection_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'collection_name': {'key': 'typeProperties.collectionName', 'type': 'CosmosDbSqlApiCollectionDatasetTypePropertiesCollectionName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        collection_name: "CosmosDbSqlApiCollectionDatasetTypePropertiesCollectionName",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        super(CosmosDbSqlApiCollectionDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'CosmosDbSqlApiCollection'
        self.collection_name = collection_name


class CosmosDbSqlApiCollectionDatasetTypeProperties(msrest.serialization.Model):
    """CosmosDB (SQL API) Collection dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param collection_name: Required. CosmosDB (SQL API) collection name. Type: string (or
     Expression with resultType string).
    :type collection_name:
     ~data_factory_management_client.models.CosmosDbSqlApiCollectionDatasetTypePropertiesCollectionName
    """

    _validation = {
        'collection_name': {'required': True},
    }

    _attribute_map = {
        'collection_name': {'key': 'collectionName', 'type': 'CosmosDbSqlApiCollectionDatasetTypePropertiesCollectionName'},
    }

    def __init__(
        self,
        *,
        collection_name: "CosmosDbSqlApiCollectionDatasetTypePropertiesCollectionName",
        **kwargs
    ):
        super(CosmosDbSqlApiCollectionDatasetTypeProperties, self).__init__(**kwargs)
        self.collection_name = collection_name


class CosmosDbSqlApiCollectionDatasetTypePropertiesCollectionName(msrest.serialization.Model):
    """CosmosDB (SQL API) collection name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbSqlApiCollectionDatasetTypePropertiesCollectionName, self).__init__(**kwargs)


class CosmosDbSqlApiSink(CopySink):
    """A copy activity Azure CosmosDB (SQL API) Collection sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param write_behavior: Describes how to write data to Azure Cosmos DB. Type: string (or
     Expression with resultType string). Allowed values: insert and upsert.
    :type write_behavior: ~data_factory_management_client.models.CosmosDbSqlApiSinkWriteBehavior
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'CosmosDbSqlApiSinkWriteBehavior'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        write_behavior: Optional["CosmosDbSqlApiSinkWriteBehavior"] = None,
        **kwargs
    ):
        super(CosmosDbSqlApiSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'CosmosDbSqlApiSink'
        self.write_behavior = write_behavior


class CosmosDbSqlApiSinkWriteBehavior(msrest.serialization.Model):
    """Describes how to write data to Azure Cosmos DB. Type: string (or Expression with resultType string). Allowed values: insert and upsert.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbSqlApiSinkWriteBehavior, self).__init__(**kwargs)


class CosmosDbSqlApiSource(CopySource):
    """A copy activity Azure CosmosDB (SQL API) Collection source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query: SQL API query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.CosmosDbSqlApiSourceQuery
    :param page_size: Page size of the result. Type: integer (or Expression with resultType
     integer).
    :type page_size: ~data_factory_management_client.models.CosmosDbSqlApiSourcePageSize
    :param preferred_regions: Preferred regions. Type: array of strings (or Expression with
     resultType array of strings).
    :type preferred_regions:
     ~data_factory_management_client.models.CosmosDbSqlApiSourcePreferredRegions
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query': {'key': 'query', 'type': 'CosmosDbSqlApiSourceQuery'},
        'page_size': {'key': 'pageSize', 'type': 'CosmosDbSqlApiSourcePageSize'},
        'preferred_regions': {'key': 'preferredRegions', 'type': 'CosmosDbSqlApiSourcePreferredRegions'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query: Optional["CosmosDbSqlApiSourceQuery"] = None,
        page_size: Optional["CosmosDbSqlApiSourcePageSize"] = None,
        preferred_regions: Optional["CosmosDbSqlApiSourcePreferredRegions"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(CosmosDbSqlApiSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'CosmosDbSqlApiSource'
        self.query = query
        self.page_size = page_size
        self.preferred_regions = preferred_regions
        self.additional_columns = additional_columns


class CosmosDbSqlApiSourcePageSize(msrest.serialization.Model):
    """Page size of the result. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbSqlApiSourcePageSize, self).__init__(**kwargs)


class CosmosDbSqlApiSourcePreferredRegions(msrest.serialization.Model):
    """Preferred regions. Type: array of strings (or Expression with resultType array of strings).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbSqlApiSourcePreferredRegions, self).__init__(**kwargs)


class CosmosDbSqlApiSourceQuery(msrest.serialization.Model):
    """SQL API query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CosmosDbSqlApiSourceQuery, self).__init__(**kwargs)


class CouchbaseLinkedService(LinkedService):
    """Couchbase server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.CouchbaseLinkedServiceTypePropertiesConnectionString
    :param cred_string: Azure Key Vault secret reference.
    :type cred_string: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.CouchbaseLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'CouchbaseLinkedServiceTypePropertiesConnectionString'},
        'cred_string': {'key': 'typeProperties.credString', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'CouchbaseLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        connection_string: Optional["CouchbaseLinkedServiceTypePropertiesConnectionString"] = None,
        cred_string: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["CouchbaseLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(CouchbaseLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Couchbase'
        self.connection_string = connection_string
        self.cred_string = cred_string
        self.encrypted_credential = encrypted_credential


class CouchbaseLinkedServiceTypeProperties(msrest.serialization.Model):
    """Couchbase server linked service properties.

    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.CouchbaseLinkedServiceTypePropertiesConnectionString
    :param cred_string: Azure Key Vault secret reference.
    :type cred_string: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.CouchbaseLinkedServiceTypePropertiesEncryptedCredential
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'CouchbaseLinkedServiceTypePropertiesConnectionString'},
        'cred_string': {'key': 'credString', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'CouchbaseLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional["CouchbaseLinkedServiceTypePropertiesConnectionString"] = None,
        cred_string: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["CouchbaseLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(CouchbaseLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.cred_string = cred_string
        self.encrypted_credential = encrypted_credential


class CouchbaseLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """An ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CouchbaseLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class CouchbaseLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CouchbaseLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class CouchbaseSource(TabularSource):
    """A copy activity Couchbase server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.CouchbaseSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'CouchbaseSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["CouchbaseSourceQuery"] = None,
        **kwargs
    ):
        super(CouchbaseSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'CouchbaseSource'
        self.query = query


class CouchbaseSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CouchbaseSourceQuery, self).__init__(**kwargs)


class CouchbaseTableDataset(Dataset):
    """Couchbase server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(CouchbaseTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'CouchbaseTable'
        self.table_name = table_name


class CreateDataFlowDebugSessionRequest(msrest.serialization.Model):
    """Request body structure for creating data flow debug session.

    :param compute_type: Compute type of the cluster. The value will be overwritten by the same
     setting in integration runtime if provided.
    :type compute_type: str
    :param core_count: Core count of the cluster. The value will be overwritten by the same setting
     in integration runtime if provided.
    :type core_count: int
    :param time_to_live: Time to live setting of the cluster in minutes.
    :type time_to_live: int
    :param integration_runtime: Integration runtime debug resource.
    :type integration_runtime:
     ~data_factory_management_client.models.IntegrationRuntimeDebugResource
    """

    _attribute_map = {
        'compute_type': {'key': 'computeType', 'type': 'str'},
        'core_count': {'key': 'coreCount', 'type': 'int'},
        'time_to_live': {'key': 'timeToLive', 'type': 'int'},
        'integration_runtime': {'key': 'integrationRuntime', 'type': 'IntegrationRuntimeDebugResource'},
    }

    def __init__(
        self,
        *,
        compute_type: Optional[str] = None,
        core_count: Optional[int] = None,
        time_to_live: Optional[int] = None,
        integration_runtime: Optional["IntegrationRuntimeDebugResource"] = None,
        **kwargs
    ):
        super(CreateDataFlowDebugSessionRequest, self).__init__(**kwargs)
        self.compute_type = compute_type
        self.core_count = core_count
        self.time_to_live = time_to_live
        self.integration_runtime = integration_runtime


class CreateDataFlowDebugSessionResponse(msrest.serialization.Model):
    """Response body structure for creating data flow debug session.

    :param status: The state of the debug session.
    :type status: str
    :param session_id: The ID of data flow debug session.
    :type session_id: str
    """

    _attribute_map = {
        'status': {'key': 'status', 'type': 'str'},
        'session_id': {'key': 'sessionId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        status: Optional[str] = None,
        session_id: Optional[str] = None,
        **kwargs
    ):
        super(CreateDataFlowDebugSessionResponse, self).__init__(**kwargs)
        self.status = status
        self.session_id = session_id


class CreateLinkedIntegrationRuntimeRequest(msrest.serialization.Model):
    """The linked integration runtime information.

    :param name: The name of the linked integration runtime.
    :type name: str
    :param subscription_id: The ID of the subscription that the linked integration runtime belongs
     to.
    :type subscription_id: str
    :param data_factory_name: The name of the data factory that the linked integration runtime
     belongs to.
    :type data_factory_name: str
    :param data_factory_location: The location of the data factory that the linked integration
     runtime belongs to.
    :type data_factory_location: str
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'subscription_id': {'key': 'subscriptionId', 'type': 'str'},
        'data_factory_name': {'key': 'dataFactoryName', 'type': 'str'},
        'data_factory_location': {'key': 'dataFactoryLocation', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        subscription_id: Optional[str] = None,
        data_factory_name: Optional[str] = None,
        data_factory_location: Optional[str] = None,
        **kwargs
    ):
        super(CreateLinkedIntegrationRuntimeRequest, self).__init__(**kwargs)
        self.name = name
        self.subscription_id = subscription_id
        self.data_factory_name = data_factory_name
        self.data_factory_location = data_factory_location


class CreateRunResponse(msrest.serialization.Model):
    """Response body with a run identifier.

    All required parameters must be populated in order to send to Azure.

    :param run_id: Required. Identifier of a run.
    :type run_id: str
    """

    _validation = {
        'run_id': {'required': True},
    }

    _attribute_map = {
        'run_id': {'key': 'runId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        run_id: str,
        **kwargs
    ):
        super(CreateRunResponse, self).__init__(**kwargs)
        self.run_id = run_id


class CustomActivity(ExecutionActivity):
    """Custom activity type.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param command: Required. Command for custom activity Type: string (or Expression with
     resultType string).
    :type command: ~data_factory_management_client.models.CustomActivityTypePropertiesCommand
    :param resource_linked_service: Linked service reference type.
    :type resource_linked_service: ~data_factory_management_client.models.LinkedServiceReference
    :param folder_path: Folder path for resource files Type: string (or Expression with resultType
     string).
    :type folder_path:
     ~data_factory_management_client.models.CustomActivityTypePropertiesFolderPath
    :param reference_objects: Reference objects for custom activity.
    :type reference_objects: ~data_factory_management_client.models.CustomActivityReferenceObject
    :param extended_properties: User defined property bag. There is no restriction on the keys or
     values that can be used. The user specified custom activity has the full responsibility to
     consume and interpret the content defined.
    :type extended_properties: dict[str, object]
    :param retention_time_in_days: The retention time for the files submitted for custom activity.
     Type: double (or Expression with resultType double).
    :type retention_time_in_days:
     ~data_factory_management_client.models.CustomActivityTypePropertiesRetentionTimeInDays
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'command': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'command': {'key': 'typeProperties.command', 'type': 'CustomActivityTypePropertiesCommand'},
        'resource_linked_service': {'key': 'typeProperties.resourceLinkedService', 'type': 'LinkedServiceReference'},
        'folder_path': {'key': 'typeProperties.folderPath', 'type': 'CustomActivityTypePropertiesFolderPath'},
        'reference_objects': {'key': 'typeProperties.referenceObjects', 'type': 'CustomActivityReferenceObject'},
        'extended_properties': {'key': 'typeProperties.extendedProperties', 'type': '{object}'},
        'retention_time_in_days': {'key': 'typeProperties.retentionTimeInDays', 'type': 'CustomActivityTypePropertiesRetentionTimeInDays'},
    }

    def __init__(
        self,
        *,
        name: str,
        command: "CustomActivityTypePropertiesCommand",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        resource_linked_service: Optional["LinkedServiceReference"] = None,
        folder_path: Optional["CustomActivityTypePropertiesFolderPath"] = None,
        reference_objects: Optional["CustomActivityReferenceObject"] = None,
        extended_properties: Optional[Dict[str, object]] = None,
        retention_time_in_days: Optional["CustomActivityTypePropertiesRetentionTimeInDays"] = None,
        **kwargs
    ):
        super(CustomActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'Custom'
        self.command = command
        self.resource_linked_service = resource_linked_service
        self.folder_path = folder_path
        self.reference_objects = reference_objects
        self.extended_properties = extended_properties
        self.retention_time_in_days = retention_time_in_days


class CustomActivityReferenceObject(msrest.serialization.Model):
    """Reference objects for custom activity.

    :param linked_services: Linked service references.
    :type linked_services: list[~data_factory_management_client.models.LinkedServiceReference]
    :param datasets: Dataset references.
    :type datasets: list[~data_factory_management_client.models.DatasetReference]
    """

    _attribute_map = {
        'linked_services': {'key': 'linkedServices', 'type': '[LinkedServiceReference]'},
        'datasets': {'key': 'datasets', 'type': '[DatasetReference]'},
    }

    def __init__(
        self,
        *,
        linked_services: Optional[List["LinkedServiceReference"]] = None,
        datasets: Optional[List["DatasetReference"]] = None,
        **kwargs
    ):
        super(CustomActivityReferenceObject, self).__init__(**kwargs)
        self.linked_services = linked_services
        self.datasets = datasets


class CustomActivityTypeProperties(msrest.serialization.Model):
    """Custom activity properties.

    All required parameters must be populated in order to send to Azure.

    :param command: Required. Command for custom activity Type: string (or Expression with
     resultType string).
    :type command: ~data_factory_management_client.models.CustomActivityTypePropertiesCommand
    :param resource_linked_service: Linked service reference type.
    :type resource_linked_service: ~data_factory_management_client.models.LinkedServiceReference
    :param folder_path: Folder path for resource files Type: string (or Expression with resultType
     string).
    :type folder_path:
     ~data_factory_management_client.models.CustomActivityTypePropertiesFolderPath
    :param reference_objects: Reference objects for custom activity.
    :type reference_objects: ~data_factory_management_client.models.CustomActivityReferenceObject
    :param extended_properties: User defined property bag. There is no restriction on the keys or
     values that can be used. The user specified custom activity has the full responsibility to
     consume and interpret the content defined.
    :type extended_properties: dict[str, object]
    :param retention_time_in_days: The retention time for the files submitted for custom activity.
     Type: double (or Expression with resultType double).
    :type retention_time_in_days:
     ~data_factory_management_client.models.CustomActivityTypePropertiesRetentionTimeInDays
    """

    _validation = {
        'command': {'required': True},
    }

    _attribute_map = {
        'command': {'key': 'command', 'type': 'CustomActivityTypePropertiesCommand'},
        'resource_linked_service': {'key': 'resourceLinkedService', 'type': 'LinkedServiceReference'},
        'folder_path': {'key': 'folderPath', 'type': 'CustomActivityTypePropertiesFolderPath'},
        'reference_objects': {'key': 'referenceObjects', 'type': 'CustomActivityReferenceObject'},
        'extended_properties': {'key': 'extendedProperties', 'type': '{object}'},
        'retention_time_in_days': {'key': 'retentionTimeInDays', 'type': 'CustomActivityTypePropertiesRetentionTimeInDays'},
    }

    def __init__(
        self,
        *,
        command: "CustomActivityTypePropertiesCommand",
        resource_linked_service: Optional["LinkedServiceReference"] = None,
        folder_path: Optional["CustomActivityTypePropertiesFolderPath"] = None,
        reference_objects: Optional["CustomActivityReferenceObject"] = None,
        extended_properties: Optional[Dict[str, object]] = None,
        retention_time_in_days: Optional["CustomActivityTypePropertiesRetentionTimeInDays"] = None,
        **kwargs
    ):
        super(CustomActivityTypeProperties, self).__init__(**kwargs)
        self.command = command
        self.resource_linked_service = resource_linked_service
        self.folder_path = folder_path
        self.reference_objects = reference_objects
        self.extended_properties = extended_properties
        self.retention_time_in_days = retention_time_in_days


class CustomActivityTypePropertiesCommand(msrest.serialization.Model):
    """Command for custom activity Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CustomActivityTypePropertiesCommand, self).__init__(**kwargs)


class CustomActivityTypePropertiesFolderPath(msrest.serialization.Model):
    """Folder path for resource files Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CustomActivityTypePropertiesFolderPath, self).__init__(**kwargs)


class CustomActivityTypePropertiesRetentionTimeInDays(msrest.serialization.Model):
    """The retention time for the files submitted for custom activity. Type: double (or Expression with resultType double).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CustomActivityTypePropertiesRetentionTimeInDays, self).__init__(**kwargs)


class CustomDataset(Dataset):
    """The custom dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        super(CustomDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'CustomDataset'


class CustomDatasetTypeProperties(msrest.serialization.Model):
    """Custom dataset properties.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CustomDatasetTypeProperties, self).__init__(**kwargs)


class CustomDataSourceLinkedService(LinkedService):
    """Custom linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        **kwargs
    ):
        super(CustomDataSourceLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'CustomDataSource'


class CustomDataSourceLinkedServiceTypeProperties(msrest.serialization.Model):
    """Custom linked service properties.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(CustomDataSourceLinkedServiceTypeProperties, self).__init__(**kwargs)


class DatabricksNotebookActivity(ExecutionActivity):
    """DatabricksNotebook activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param notebook_path: Required. The absolute path of the notebook to be run in the Databricks
     Workspace. This path must begin with a slash. Type: string (or Expression with resultType
     string).
    :type notebook_path:
     ~data_factory_management_client.models.DatabricksNotebookActivityTypePropertiesNotebookPath
    :param base_parameters: Base parameters to be used for each run of this job.If the notebook
     takes a parameter that is not specified, the default value from the notebook will be used.
    :type base_parameters: dict[str, object]
    :param libraries: A list of libraries to be installed on the cluster that will execute the job.
    :type libraries: list[dict[str, object]]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'notebook_path': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'notebook_path': {'key': 'typeProperties.notebookPath', 'type': 'DatabricksNotebookActivityTypePropertiesNotebookPath'},
        'base_parameters': {'key': 'typeProperties.baseParameters', 'type': '{object}'},
        'libraries': {'key': 'typeProperties.libraries', 'type': '[{object}]'},
    }

    def __init__(
        self,
        *,
        name: str,
        notebook_path: "DatabricksNotebookActivityTypePropertiesNotebookPath",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        base_parameters: Optional[Dict[str, object]] = None,
        libraries: Optional[List[Dict[str, object]]] = None,
        **kwargs
    ):
        super(DatabricksNotebookActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'DatabricksNotebook'
        self.notebook_path = notebook_path
        self.base_parameters = base_parameters
        self.libraries = libraries


class DatabricksNotebookActivityTypeProperties(msrest.serialization.Model):
    """Databricks Notebook activity properties.

    All required parameters must be populated in order to send to Azure.

    :param notebook_path: Required. The absolute path of the notebook to be run in the Databricks
     Workspace. This path must begin with a slash. Type: string (or Expression with resultType
     string).
    :type notebook_path:
     ~data_factory_management_client.models.DatabricksNotebookActivityTypePropertiesNotebookPath
    :param base_parameters: Base parameters to be used for each run of this job.If the notebook
     takes a parameter that is not specified, the default value from the notebook will be used.
    :type base_parameters: dict[str, object]
    :param libraries: A list of libraries to be installed on the cluster that will execute the job.
    :type libraries: list[dict[str, object]]
    """

    _validation = {
        'notebook_path': {'required': True},
    }

    _attribute_map = {
        'notebook_path': {'key': 'notebookPath', 'type': 'DatabricksNotebookActivityTypePropertiesNotebookPath'},
        'base_parameters': {'key': 'baseParameters', 'type': '{object}'},
        'libraries': {'key': 'libraries', 'type': '[{object}]'},
    }

    def __init__(
        self,
        *,
        notebook_path: "DatabricksNotebookActivityTypePropertiesNotebookPath",
        base_parameters: Optional[Dict[str, object]] = None,
        libraries: Optional[List[Dict[str, object]]] = None,
        **kwargs
    ):
        super(DatabricksNotebookActivityTypeProperties, self).__init__(**kwargs)
        self.notebook_path = notebook_path
        self.base_parameters = base_parameters
        self.libraries = libraries


class DatabricksNotebookActivityTypePropertiesNotebookPath(msrest.serialization.Model):
    """The absolute path of the notebook to be run in the Databricks Workspace. This path must begin with a slash. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DatabricksNotebookActivityTypePropertiesNotebookPath, self).__init__(**kwargs)


class DatabricksSparkJarActivity(ExecutionActivity):
    """DatabricksSparkJar activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param main_class_name: Required. The full name of the class containing the main method to be
     executed. This class must be contained in a JAR provided as a library. Type: string (or
     Expression with resultType string).
    :type main_class_name:
     ~data_factory_management_client.models.DatabricksSparkJarActivityTypePropertiesMainClassName
    :param parameters: Parameters that will be passed to the main method.
    :type parameters:
     list[~data_factory_management_client.models.DatabricksSparkJarActivityTypePropertiesParametersItem]
    :param libraries: A list of libraries to be installed on the cluster that will execute the job.
    :type libraries: list[dict[str, object]]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'main_class_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'main_class_name': {'key': 'typeProperties.mainClassName', 'type': 'DatabricksSparkJarActivityTypePropertiesMainClassName'},
        'parameters': {'key': 'typeProperties.parameters', 'type': '[DatabricksSparkJarActivityTypePropertiesParametersItem]'},
        'libraries': {'key': 'typeProperties.libraries', 'type': '[{object}]'},
    }

    def __init__(
        self,
        *,
        name: str,
        main_class_name: "DatabricksSparkJarActivityTypePropertiesMainClassName",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        parameters: Optional[List["DatabricksSparkJarActivityTypePropertiesParametersItem"]] = None,
        libraries: Optional[List[Dict[str, object]]] = None,
        **kwargs
    ):
        super(DatabricksSparkJarActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'DatabricksSparkJar'
        self.main_class_name = main_class_name
        self.parameters = parameters
        self.libraries = libraries


class DatabricksSparkJarActivityTypeProperties(msrest.serialization.Model):
    """Databricks SparkJar activity properties.

    All required parameters must be populated in order to send to Azure.

    :param main_class_name: Required. The full name of the class containing the main method to be
     executed. This class must be contained in a JAR provided as a library. Type: string (or
     Expression with resultType string).
    :type main_class_name:
     ~data_factory_management_client.models.DatabricksSparkJarActivityTypePropertiesMainClassName
    :param parameters: Parameters that will be passed to the main method.
    :type parameters:
     list[~data_factory_management_client.models.DatabricksSparkJarActivityTypePropertiesParametersItem]
    :param libraries: A list of libraries to be installed on the cluster that will execute the job.
    :type libraries: list[dict[str, object]]
    """

    _validation = {
        'main_class_name': {'required': True},
    }

    _attribute_map = {
        'main_class_name': {'key': 'mainClassName', 'type': 'DatabricksSparkJarActivityTypePropertiesMainClassName'},
        'parameters': {'key': 'parameters', 'type': '[DatabricksSparkJarActivityTypePropertiesParametersItem]'},
        'libraries': {'key': 'libraries', 'type': '[{object}]'},
    }

    def __init__(
        self,
        *,
        main_class_name: "DatabricksSparkJarActivityTypePropertiesMainClassName",
        parameters: Optional[List["DatabricksSparkJarActivityTypePropertiesParametersItem"]] = None,
        libraries: Optional[List[Dict[str, object]]] = None,
        **kwargs
    ):
        super(DatabricksSparkJarActivityTypeProperties, self).__init__(**kwargs)
        self.main_class_name = main_class_name
        self.parameters = parameters
        self.libraries = libraries


class DatabricksSparkJarActivityTypePropertiesMainClassName(msrest.serialization.Model):
    """The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DatabricksSparkJarActivityTypePropertiesMainClassName, self).__init__(**kwargs)


class DatabricksSparkJarActivityTypePropertiesParametersItem(msrest.serialization.Model):
    """Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DatabricksSparkJarActivityTypePropertiesParametersItem, self).__init__(**kwargs)


class DatabricksSparkPythonActivity(ExecutionActivity):
    """DatabricksSparkPython activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param python_file: Required. The URI of the Python file to be executed. DBFS paths are
     supported. Type: string (or Expression with resultType string).
    :type python_file:
     ~data_factory_management_client.models.DatabricksSparkPythonActivityTypePropertiesPythonFile
    :param parameters: Command line parameters that will be passed to the Python file.
    :type parameters:
     list[~data_factory_management_client.models.DatabricksSparkPythonActivityTypePropertiesParametersItem]
    :param libraries: A list of libraries to be installed on the cluster that will execute the job.
    :type libraries: list[dict[str, object]]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'python_file': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'python_file': {'key': 'typeProperties.pythonFile', 'type': 'DatabricksSparkPythonActivityTypePropertiesPythonFile'},
        'parameters': {'key': 'typeProperties.parameters', 'type': '[DatabricksSparkPythonActivityTypePropertiesParametersItem]'},
        'libraries': {'key': 'typeProperties.libraries', 'type': '[{object}]'},
    }

    def __init__(
        self,
        *,
        name: str,
        python_file: "DatabricksSparkPythonActivityTypePropertiesPythonFile",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        parameters: Optional[List["DatabricksSparkPythonActivityTypePropertiesParametersItem"]] = None,
        libraries: Optional[List[Dict[str, object]]] = None,
        **kwargs
    ):
        super(DatabricksSparkPythonActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'DatabricksSparkPython'
        self.python_file = python_file
        self.parameters = parameters
        self.libraries = libraries


class DatabricksSparkPythonActivityTypeProperties(msrest.serialization.Model):
    """Databricks SparkPython activity properties.

    All required parameters must be populated in order to send to Azure.

    :param python_file: Required. The URI of the Python file to be executed. DBFS paths are
     supported. Type: string (or Expression with resultType string).
    :type python_file:
     ~data_factory_management_client.models.DatabricksSparkPythonActivityTypePropertiesPythonFile
    :param parameters: Command line parameters that will be passed to the Python file.
    :type parameters:
     list[~data_factory_management_client.models.DatabricksSparkPythonActivityTypePropertiesParametersItem]
    :param libraries: A list of libraries to be installed on the cluster that will execute the job.
    :type libraries: list[dict[str, object]]
    """

    _validation = {
        'python_file': {'required': True},
    }

    _attribute_map = {
        'python_file': {'key': 'pythonFile', 'type': 'DatabricksSparkPythonActivityTypePropertiesPythonFile'},
        'parameters': {'key': 'parameters', 'type': '[DatabricksSparkPythonActivityTypePropertiesParametersItem]'},
        'libraries': {'key': 'libraries', 'type': '[{object}]'},
    }

    def __init__(
        self,
        *,
        python_file: "DatabricksSparkPythonActivityTypePropertiesPythonFile",
        parameters: Optional[List["DatabricksSparkPythonActivityTypePropertiesParametersItem"]] = None,
        libraries: Optional[List[Dict[str, object]]] = None,
        **kwargs
    ):
        super(DatabricksSparkPythonActivityTypeProperties, self).__init__(**kwargs)
        self.python_file = python_file
        self.parameters = parameters
        self.libraries = libraries


class DatabricksSparkPythonActivityTypePropertiesParametersItem(msrest.serialization.Model):
    """Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DatabricksSparkPythonActivityTypePropertiesParametersItem, self).__init__(**kwargs)


class DatabricksSparkPythonActivityTypePropertiesPythonFile(msrest.serialization.Model):
    """The URI of the Python file to be executed. DBFS paths are supported. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DatabricksSparkPythonActivityTypePropertiesPythonFile, self).__init__(**kwargs)


class DataFlow(msrest.serialization.Model):
    """Azure Data Factory nested object which contains a flow with data movements and transformations.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: MappingDataFlow.

    :param type: Type of data flow.Constant filled by server.
    :type type: str
    :param description: The description of the data flow.
    :type description: str
    :param annotations: List of tags that can be used for describing the data flow.
    :type annotations: list[~data_factory_management_client.models.DataFlowAnnotationsItem]
    :param folder: The folder that this data flow is in. If not specified, Data flow will appear at
     the root level.
    :type folder: ~data_factory_management_client.models.DataFlowFolder
    """

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[DataFlowAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DataFlowFolder'},
    }

    _subtype_map = {
        'type': {'MappingDataFlow': 'MappingDataFlow'}
    }

    def __init__(
        self,
        *,
        description: Optional[str] = None,
        annotations: Optional[List["DataFlowAnnotationsItem"]] = None,
        folder: Optional["DataFlowFolder"] = None,
        **kwargs
    ):
        super(DataFlow, self).__init__(**kwargs)
        self.type = None
        self.description = description
        self.annotations = annotations
        self.folder = folder


class DataFlowAnnotationsItem(msrest.serialization.Model):
    """DataFlowAnnotationsItem.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DataFlowAnnotationsItem, self).__init__(**kwargs)


class DataFlowDebugCommandPayload(msrest.serialization.Model):
    """Structure of command payload.

    All required parameters must be populated in order to send to Azure.

    :param stream_name: Required. The stream name which is used for preview.
    :type stream_name: str
    :param row_limits: Row limits for preview response.
    :type row_limits: int
    :param columns: Array of column names.
    :type columns: list[str]
    :param expression: The expression which is used for preview.
    :type expression: str
    """

    _validation = {
        'stream_name': {'required': True},
    }

    _attribute_map = {
        'stream_name': {'key': 'streamName', 'type': 'str'},
        'row_limits': {'key': 'rowLimits', 'type': 'int'},
        'columns': {'key': 'columns', 'type': '[str]'},
        'expression': {'key': 'expression', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        stream_name: str,
        row_limits: Optional[int] = None,
        columns: Optional[List[str]] = None,
        expression: Optional[str] = None,
        **kwargs
    ):
        super(DataFlowDebugCommandPayload, self).__init__(**kwargs)
        self.stream_name = stream_name
        self.row_limits = row_limits
        self.columns = columns
        self.expression = expression


class DataFlowDebugCommandRequest(msrest.serialization.Model):
    """Request body structure for data flow debug command.

    :param session_id: The ID of data flow debug session.
    :type session_id: str
    :param command: The command type. Possible values include: 'executePreviewQuery',
     'executeStatisticsQuery', 'executeExpressionQuery'.
    :type command: str or ~data_factory_management_client.models.DataFlowDebugCommandType
    :param command_payload: Structure of command payload.
    :type command_payload: ~data_factory_management_client.models.DataFlowDebugCommandPayload
    """

    _attribute_map = {
        'session_id': {'key': 'sessionId', 'type': 'str'},
        'command': {'key': 'command', 'type': 'str'},
        'command_payload': {'key': 'commandPayload', 'type': 'DataFlowDebugCommandPayload'},
    }

    def __init__(
        self,
        *,
        session_id: Optional[str] = None,
        command: Optional[Union[str, "DataFlowDebugCommandType"]] = None,
        command_payload: Optional["DataFlowDebugCommandPayload"] = None,
        **kwargs
    ):
        super(DataFlowDebugCommandRequest, self).__init__(**kwargs)
        self.session_id = session_id
        self.command = command
        self.command_payload = command_payload


class DataFlowDebugCommandResponse(msrest.serialization.Model):
    """Response body structure of data flow result for data preview, statistics or expression preview.

    :param status: The run status of data preview, statistics or expression preview.
    :type status: str
    :param data: The result data of data preview, statistics or expression preview.
    :type data: str
    """

    _attribute_map = {
        'status': {'key': 'status', 'type': 'str'},
        'data': {'key': 'data', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        status: Optional[str] = None,
        data: Optional[str] = None,
        **kwargs
    ):
        super(DataFlowDebugCommandResponse, self).__init__(**kwargs)
        self.status = status
        self.data = data


class DataFlowDebugPackage(msrest.serialization.Model):
    """Request body structure for starting data flow debug session.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param session_id: The ID of data flow debug session.
    :type session_id: str
    :param data_flow: Data flow debug resource.
    :type data_flow: ~data_factory_management_client.models.DataFlowDebugResource
    :param datasets: List of datasets.
    :type datasets: list[~data_factory_management_client.models.DatasetDebugResource]
    :param linked_services: List of linked services.
    :type linked_services: list[~data_factory_management_client.models.LinkedServiceDebugResource]
    :param staging: Staging info for execute data flow activity.
    :type staging: ~data_factory_management_client.models.DataFlowStagingInfo
    :param debug_settings: Data flow debug settings.
    :type debug_settings: ~data_factory_management_client.models.DataFlowDebugPackageDebugSettings
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'session_id': {'key': 'sessionId', 'type': 'str'},
        'data_flow': {'key': 'dataFlow', 'type': 'DataFlowDebugResource'},
        'datasets': {'key': 'datasets', 'type': '[DatasetDebugResource]'},
        'linked_services': {'key': 'linkedServices', 'type': '[LinkedServiceDebugResource]'},
        'staging': {'key': 'staging', 'type': 'DataFlowStagingInfo'},
        'debug_settings': {'key': 'debugSettings', 'type': 'DataFlowDebugPackageDebugSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        session_id: Optional[str] = None,
        data_flow: Optional["DataFlowDebugResource"] = None,
        datasets: Optional[List["DatasetDebugResource"]] = None,
        linked_services: Optional[List["LinkedServiceDebugResource"]] = None,
        staging: Optional["DataFlowStagingInfo"] = None,
        debug_settings: Optional["DataFlowDebugPackageDebugSettings"] = None,
        **kwargs
    ):
        super(DataFlowDebugPackage, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.session_id = session_id
        self.data_flow = data_flow
        self.datasets = datasets
        self.linked_services = linked_services
        self.staging = staging
        self.debug_settings = debug_settings


class DataFlowDebugPackageDebugSettings(msrest.serialization.Model):
    """Data flow debug settings.

    :param source_settings: Source setting for data flow debug.
    :type source_settings: list[~data_factory_management_client.models.DataFlowSourceSetting]
    :param parameters: An object mapping parameter names to argument values.
    :type parameters: dict[str, object]
    :param dataset_parameters: Parameters for dataset.
    :type dataset_parameters:
     ~data_factory_management_client.models.DataFlowDebugPackageDebugSettingsDatasetParameters
    """

    _attribute_map = {
        'source_settings': {'key': 'sourceSettings', 'type': '[DataFlowSourceSetting]'},
        'parameters': {'key': 'parameters', 'type': '{object}'},
        'dataset_parameters': {'key': 'datasetParameters', 'type': 'DataFlowDebugPackageDebugSettingsDatasetParameters'},
    }

    def __init__(
        self,
        *,
        source_settings: Optional[List["DataFlowSourceSetting"]] = None,
        parameters: Optional[Dict[str, object]] = None,
        dataset_parameters: Optional["DataFlowDebugPackageDebugSettingsDatasetParameters"] = None,
        **kwargs
    ):
        super(DataFlowDebugPackageDebugSettings, self).__init__(**kwargs)
        self.source_settings = source_settings
        self.parameters = parameters
        self.dataset_parameters = dataset_parameters


class DataFlowDebugPackageDebugSettingsDatasetParameters(msrest.serialization.Model):
    """Parameters for dataset.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DataFlowDebugPackageDebugSettingsDatasetParameters, self).__init__(**kwargs)


class SubResourceDebugResource(msrest.serialization.Model):
    """Azure Data Factory nested debug resource.

    :param name: The resource name.
    :type name: str
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        **kwargs
    ):
        super(SubResourceDebugResource, self).__init__(**kwargs)
        self.name = name


class DataFlowDebugResource(SubResourceDebugResource):
    """Data flow debug resource.

    All required parameters must be populated in order to send to Azure.

    :param name: The resource name.
    :type name: str
    :param properties: Required. Azure Data Factory nested object which contains a flow with data
     movements and transformations.
    :type properties: ~data_factory_management_client.models.DataFlow
    """

    _validation = {
        'properties': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'DataFlow'},
    }

    def __init__(
        self,
        *,
        properties: "DataFlow",
        name: Optional[str] = None,
        **kwargs
    ):
        super(DataFlowDebugResource, self).__init__(name=name, **kwargs)
        self.properties = properties


class DataFlowDebugSessionInfo(msrest.serialization.Model):
    """Data flow debug session info.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param data_flow_name: The name of the data flow.
    :type data_flow_name: str
    :param compute_type: Compute type of the cluster.
    :type compute_type: str
    :param core_count: Core count of the cluster.
    :type core_count: int
    :param node_count: Node count of the cluster. (deprecated property).
    :type node_count: int
    :param integration_runtime_name: Attached integration runtime name of data flow debug session.
    :type integration_runtime_name: str
    :param session_id: The ID of data flow debug session.
    :type session_id: str
    :param start_time: Start time of data flow debug session.
    :type start_time: str
    :param time_to_live_in_minutes: Compute type of the cluster.
    :type time_to_live_in_minutes: int
    :param last_activity_time: Last activity time of data flow debug session.
    :type last_activity_time: str
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'data_flow_name': {'key': 'dataFlowName', 'type': 'str'},
        'compute_type': {'key': 'computeType', 'type': 'str'},
        'core_count': {'key': 'coreCount', 'type': 'int'},
        'node_count': {'key': 'nodeCount', 'type': 'int'},
        'integration_runtime_name': {'key': 'integrationRuntimeName', 'type': 'str'},
        'session_id': {'key': 'sessionId', 'type': 'str'},
        'start_time': {'key': 'startTime', 'type': 'str'},
        'time_to_live_in_minutes': {'key': 'timeToLiveInMinutes', 'type': 'int'},
        'last_activity_time': {'key': 'lastActivityTime', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        data_flow_name: Optional[str] = None,
        compute_type: Optional[str] = None,
        core_count: Optional[int] = None,
        node_count: Optional[int] = None,
        integration_runtime_name: Optional[str] = None,
        session_id: Optional[str] = None,
        start_time: Optional[str] = None,
        time_to_live_in_minutes: Optional[int] = None,
        last_activity_time: Optional[str] = None,
        **kwargs
    ):
        super(DataFlowDebugSessionInfo, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.data_flow_name = data_flow_name
        self.compute_type = compute_type
        self.core_count = core_count
        self.node_count = node_count
        self.integration_runtime_name = integration_runtime_name
        self.session_id = session_id
        self.start_time = start_time
        self.time_to_live_in_minutes = time_to_live_in_minutes
        self.last_activity_time = last_activity_time


class DataFlowFolder(msrest.serialization.Model):
    """The folder that this data flow is in. If not specified, Data flow will appear at the root level.

    :param name: The name of the folder that this data flow is in.
    :type name: str
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        **kwargs
    ):
        super(DataFlowFolder, self).__init__(**kwargs)
        self.name = name


class DataFlowListResponse(msrest.serialization.Model):
    """A list of data flow resources.

    All required parameters must be populated in order to send to Azure.

    :param value: Required. List of data flows.
    :type value: list[~data_factory_management_client.models.DataFlowResource]
    :param next_link: The link to the next page of results, if any remaining results exist.
    :type next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[DataFlowResource]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["DataFlowResource"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        super(DataFlowListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class DataFlowReference(msrest.serialization.Model):
    """Data flow reference type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :ivar type: Required. Data flow reference type. Default value: "DataFlowReference".
    :vartype type: str
    :param reference_name: Required. Reference data flow name.
    :type reference_name: str
    :param dataset_parameters: Reference data flow parameters from dataset.
    :type dataset_parameters:
     ~data_factory_management_client.models.DataFlowReferenceDatasetParameters
    """

    _validation = {
        'type': {'required': True, 'constant': True},
        'reference_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
        'dataset_parameters': {'key': 'datasetParameters', 'type': 'DataFlowReferenceDatasetParameters'},
    }

    type = "DataFlowReference"

    def __init__(
        self,
        *,
        reference_name: str,
        additional_properties: Optional[Dict[str, object]] = None,
        dataset_parameters: Optional["DataFlowReferenceDatasetParameters"] = None,
        **kwargs
    ):
        super(DataFlowReference, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.reference_name = reference_name
        self.dataset_parameters = dataset_parameters


class DataFlowReferenceDatasetParameters(msrest.serialization.Model):
    """Reference data flow parameters from dataset.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DataFlowReferenceDatasetParameters, self).__init__(**kwargs)


class SubResource(msrest.serialization.Model):
    """Azure Data Factory nested resource, which belongs to a factory.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SubResource, self).__init__(**kwargs)
        self.id = None
        self.name = None
        self.type = None
        self.etag = None


class DataFlowResource(SubResource):
    """Data flow resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :param properties: Required. Azure Data Factory nested object which contains a flow with data
     movements and transformations.
    :type properties: ~data_factory_management_client.models.DataFlow
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
        'properties': {'required': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'DataFlow'},
    }

    def __init__(
        self,
        *,
        properties: "DataFlow",
        **kwargs
    ):
        super(DataFlowResource, self).__init__(**kwargs)
        self.properties = properties


class Transformation(msrest.serialization.Model):
    """A data flow transformation.

    All required parameters must be populated in order to send to Azure.

    :param name: Required. Transformation name.
    :type name: str
    :param description: Transformation description.
    :type description: str
    """

    _validation = {
        'name': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: str,
        description: Optional[str] = None,
        **kwargs
    ):
        super(Transformation, self).__init__(**kwargs)
        self.name = name
        self.description = description


class DataFlowSink(Transformation):
    """Transformation for data flow sink.

    All required parameters must be populated in order to send to Azure.

    :param name: Required. Transformation name.
    :type name: str
    :param description: Transformation description.
    :type description: str
    :param dataset: Dataset reference type.
    :type dataset: ~data_factory_management_client.models.DatasetReference
    """

    _validation = {
        'name': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'dataset': {'key': 'dataset', 'type': 'DatasetReference'},
    }

    def __init__(
        self,
        *,
        name: str,
        description: Optional[str] = None,
        dataset: Optional["DatasetReference"] = None,
        **kwargs
    ):
        super(DataFlowSink, self).__init__(name=name, description=description, **kwargs)
        self.dataset = dataset


class DataFlowSource(Transformation):
    """Transformation for data flow source.

    All required parameters must be populated in order to send to Azure.

    :param name: Required. Transformation name.
    :type name: str
    :param description: Transformation description.
    :type description: str
    :param dataset: Dataset reference type.
    :type dataset: ~data_factory_management_client.models.DatasetReference
    """

    _validation = {
        'name': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'dataset': {'key': 'dataset', 'type': 'DatasetReference'},
    }

    def __init__(
        self,
        *,
        name: str,
        description: Optional[str] = None,
        dataset: Optional["DatasetReference"] = None,
        **kwargs
    ):
        super(DataFlowSource, self).__init__(name=name, description=description, **kwargs)
        self.dataset = dataset


class DataFlowSourceSetting(msrest.serialization.Model):
    """Definition of data flow source setting for debug.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param source_name: The data flow source name.
    :type source_name: str
    :param row_limit: Defines the row limit of data flow source in debug.
    :type row_limit: int
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'source_name': {'key': 'sourceName', 'type': 'str'},
        'row_limit': {'key': 'rowLimit', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_name: Optional[str] = None,
        row_limit: Optional[int] = None,
        **kwargs
    ):
        super(DataFlowSourceSetting, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.source_name = source_name
        self.row_limit = row_limit


class DataFlowStagingInfo(msrest.serialization.Model):
    """Staging info for execute data flow activity.

    :param linked_service: Linked service reference type.
    :type linked_service: ~data_factory_management_client.models.LinkedServiceReference
    :param folder_path: Folder path for staging blob.
    :type folder_path: str
    """

    _attribute_map = {
        'linked_service': {'key': 'linkedService', 'type': 'LinkedServiceReference'},
        'folder_path': {'key': 'folderPath', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        linked_service: Optional["LinkedServiceReference"] = None,
        folder_path: Optional[str] = None,
        **kwargs
    ):
        super(DataFlowStagingInfo, self).__init__(**kwargs)
        self.linked_service = linked_service
        self.folder_path = folder_path


class DataLakeAnalyticsUSQLActivity(ExecutionActivity):
    """Data Lake Analytics U-SQL activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param script_path: Required. Case-sensitive path to folder that contains the U-SQL script.
     Type: string (or Expression with resultType string).
    :type script_path:
     ~data_factory_management_client.models.DataLakeAnalyticsUSQLActivityTypePropertiesScriptPath
    :param script_linked_service: Required. Linked service reference type.
    :type script_linked_service: ~data_factory_management_client.models.LinkedServiceReference
    :param degree_of_parallelism: The maximum number of nodes simultaneously used to run the job.
     Default value is 1. Type: integer (or Expression with resultType integer), minimum: 1.
    :type degree_of_parallelism:
     ~data_factory_management_client.models.DataLakeAnalyticsUSQLActivityTypePropertiesDegreeOfParallelism
    :param priority: Determines which jobs out of all that are queued should be selected to run
     first. The lower the number, the higher the priority. Default value is 1000. Type: integer (or
     Expression with resultType integer), minimum: 1.
    :type priority:
     ~data_factory_management_client.models.DataLakeAnalyticsUSQLActivityTypePropertiesPriority
    :param parameters: Parameters for U-SQL job request.
    :type parameters: dict[str, object]
    :param runtime_version: Runtime version of the U-SQL engine to use. Type: string (or Expression
     with resultType string).
    :type runtime_version:
     ~data_factory_management_client.models.DataLakeAnalyticsUSQLActivityTypePropertiesRuntimeVersion
    :param compilation_mode: Compilation mode of U-SQL. Must be one of these values : Semantic,
     Full and SingleBox. Type: string (or Expression with resultType string).
    :type compilation_mode:
     ~data_factory_management_client.models.DataLakeAnalyticsUSQLActivityTypePropertiesCompilationMode
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'script_path': {'required': True},
        'script_linked_service': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'script_path': {'key': 'typeProperties.scriptPath', 'type': 'DataLakeAnalyticsUSQLActivityTypePropertiesScriptPath'},
        'script_linked_service': {'key': 'typeProperties.scriptLinkedService', 'type': 'LinkedServiceReference'},
        'degree_of_parallelism': {'key': 'typeProperties.degreeOfParallelism', 'type': 'DataLakeAnalyticsUSQLActivityTypePropertiesDegreeOfParallelism'},
        'priority': {'key': 'typeProperties.priority', 'type': 'DataLakeAnalyticsUSQLActivityTypePropertiesPriority'},
        'parameters': {'key': 'typeProperties.parameters', 'type': '{object}'},
        'runtime_version': {'key': 'typeProperties.runtimeVersion', 'type': 'DataLakeAnalyticsUSQLActivityTypePropertiesRuntimeVersion'},
        'compilation_mode': {'key': 'typeProperties.compilationMode', 'type': 'DataLakeAnalyticsUSQLActivityTypePropertiesCompilationMode'},
    }

    def __init__(
        self,
        *,
        name: str,
        script_path: "DataLakeAnalyticsUSQLActivityTypePropertiesScriptPath",
        script_linked_service: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        degree_of_parallelism: Optional["DataLakeAnalyticsUSQLActivityTypePropertiesDegreeOfParallelism"] = None,
        priority: Optional["DataLakeAnalyticsUSQLActivityTypePropertiesPriority"] = None,
        parameters: Optional[Dict[str, object]] = None,
        runtime_version: Optional["DataLakeAnalyticsUSQLActivityTypePropertiesRuntimeVersion"] = None,
        compilation_mode: Optional["DataLakeAnalyticsUSQLActivityTypePropertiesCompilationMode"] = None,
        **kwargs
    ):
        super(DataLakeAnalyticsUSQLActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'DataLakeAnalyticsU-SQL'
        self.script_path = script_path
        self.script_linked_service = script_linked_service
        self.degree_of_parallelism = degree_of_parallelism
        self.priority = priority
        self.parameters = parameters
        self.runtime_version = runtime_version
        self.compilation_mode = compilation_mode


class DataLakeAnalyticsUSQLActivityTypeProperties(msrest.serialization.Model):
    """DataLakeAnalyticsU-SQL activity properties.

    All required parameters must be populated in order to send to Azure.

    :param script_path: Required. Case-sensitive path to folder that contains the U-SQL script.
     Type: string (or Expression with resultType string).
    :type script_path:
     ~data_factory_management_client.models.DataLakeAnalyticsUSQLActivityTypePropertiesScriptPath
    :param script_linked_service: Required. Linked service reference type.
    :type script_linked_service: ~data_factory_management_client.models.LinkedServiceReference
    :param degree_of_parallelism: The maximum number of nodes simultaneously used to run the job.
     Default value is 1. Type: integer (or Expression with resultType integer), minimum: 1.
    :type degree_of_parallelism:
     ~data_factory_management_client.models.DataLakeAnalyticsUSQLActivityTypePropertiesDegreeOfParallelism
    :param priority: Determines which jobs out of all that are queued should be selected to run
     first. The lower the number, the higher the priority. Default value is 1000. Type: integer (or
     Expression with resultType integer), minimum: 1.
    :type priority:
     ~data_factory_management_client.models.DataLakeAnalyticsUSQLActivityTypePropertiesPriority
    :param parameters: Parameters for U-SQL job request.
    :type parameters: dict[str, object]
    :param runtime_version: Runtime version of the U-SQL engine to use. Type: string (or Expression
     with resultType string).
    :type runtime_version:
     ~data_factory_management_client.models.DataLakeAnalyticsUSQLActivityTypePropertiesRuntimeVersion
    :param compilation_mode: Compilation mode of U-SQL. Must be one of these values : Semantic,
     Full and SingleBox. Type: string (or Expression with resultType string).
    :type compilation_mode:
     ~data_factory_management_client.models.DataLakeAnalyticsUSQLActivityTypePropertiesCompilationMode
    """

    _validation = {
        'script_path': {'required': True},
        'script_linked_service': {'required': True},
    }

    _attribute_map = {
        'script_path': {'key': 'scriptPath', 'type': 'DataLakeAnalyticsUSQLActivityTypePropertiesScriptPath'},
        'script_linked_service': {'key': 'scriptLinkedService', 'type': 'LinkedServiceReference'},
        'degree_of_parallelism': {'key': 'degreeOfParallelism', 'type': 'DataLakeAnalyticsUSQLActivityTypePropertiesDegreeOfParallelism'},
        'priority': {'key': 'priority', 'type': 'DataLakeAnalyticsUSQLActivityTypePropertiesPriority'},
        'parameters': {'key': 'parameters', 'type': '{object}'},
        'runtime_version': {'key': 'runtimeVersion', 'type': 'DataLakeAnalyticsUSQLActivityTypePropertiesRuntimeVersion'},
        'compilation_mode': {'key': 'compilationMode', 'type': 'DataLakeAnalyticsUSQLActivityTypePropertiesCompilationMode'},
    }

    def __init__(
        self,
        *,
        script_path: "DataLakeAnalyticsUSQLActivityTypePropertiesScriptPath",
        script_linked_service: "LinkedServiceReference",
        degree_of_parallelism: Optional["DataLakeAnalyticsUSQLActivityTypePropertiesDegreeOfParallelism"] = None,
        priority: Optional["DataLakeAnalyticsUSQLActivityTypePropertiesPriority"] = None,
        parameters: Optional[Dict[str, object]] = None,
        runtime_version: Optional["DataLakeAnalyticsUSQLActivityTypePropertiesRuntimeVersion"] = None,
        compilation_mode: Optional["DataLakeAnalyticsUSQLActivityTypePropertiesCompilationMode"] = None,
        **kwargs
    ):
        super(DataLakeAnalyticsUSQLActivityTypeProperties, self).__init__(**kwargs)
        self.script_path = script_path
        self.script_linked_service = script_linked_service
        self.degree_of_parallelism = degree_of_parallelism
        self.priority = priority
        self.parameters = parameters
        self.runtime_version = runtime_version
        self.compilation_mode = compilation_mode


class DataLakeAnalyticsUSQLActivityTypePropertiesCompilationMode(msrest.serialization.Model):
    """Compilation mode of U-SQL. Must be one of these values : Semantic, Full and SingleBox. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DataLakeAnalyticsUSQLActivityTypePropertiesCompilationMode, self).__init__(**kwargs)


class DataLakeAnalyticsUSQLActivityTypePropertiesDegreeOfParallelism(msrest.serialization.Model):
    """The maximum number of nodes simultaneously used to run the job. Default value is 1. Type: integer (or Expression with resultType integer), minimum: 1.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DataLakeAnalyticsUSQLActivityTypePropertiesDegreeOfParallelism, self).__init__(**kwargs)


class DataLakeAnalyticsUSQLActivityTypePropertiesPriority(msrest.serialization.Model):
    """Determines which jobs out of all that are queued should be selected to run first. The lower the number, the higher the priority. Default value is 1000. Type: integer (or Expression with resultType integer), minimum: 1.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DataLakeAnalyticsUSQLActivityTypePropertiesPriority, self).__init__(**kwargs)


class DataLakeAnalyticsUSQLActivityTypePropertiesRuntimeVersion(msrest.serialization.Model):
    """Runtime version of the U-SQL engine to use. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DataLakeAnalyticsUSQLActivityTypePropertiesRuntimeVersion, self).__init__(**kwargs)


class DataLakeAnalyticsUSQLActivityTypePropertiesScriptPath(msrest.serialization.Model):
    """Case-sensitive path to folder that contains the U-SQL script. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DataLakeAnalyticsUSQLActivityTypePropertiesScriptPath, self).__init__(**kwargs)


class DatasetAnnotationsItem(msrest.serialization.Model):
    """DatasetAnnotationsItem.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DatasetAnnotationsItem, self).__init__(**kwargs)


class DatasetCompression(msrest.serialization.Model):
    """The compression method used on a dataset.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: DatasetBZip2Compression, DatasetDeflateCompression, DatasetGZipCompression, DatasetZipDeflateCompression.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset compression.Constant filled by server.
    :type type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'BZip2': 'DatasetBZip2Compression', 'Deflate': 'DatasetDeflateCompression', 'GZip': 'DatasetGZipCompression', 'ZipDeflate': 'DatasetZipDeflateCompression'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(DatasetCompression, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'DatasetCompression'


class DatasetBZip2Compression(DatasetCompression):
    """The BZip2 compression method used on a dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset compression.Constant filled by server.
    :type type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(DatasetBZip2Compression, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'BZip2'


class DatasetDebugResource(SubResourceDebugResource):
    """Dataset debug resource.

    All required parameters must be populated in order to send to Azure.

    :param name: The resource name.
    :type name: str
    :param properties: Required. The Azure Data Factory nested object which identifies data within
     different data stores, such as tables, files, folders, and documents.
    :type properties: ~data_factory_management_client.models.Dataset
    """

    _validation = {
        'properties': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'Dataset'},
    }

    def __init__(
        self,
        *,
        properties: "Dataset",
        name: Optional[str] = None,
        **kwargs
    ):
        super(DatasetDebugResource, self).__init__(name=name, **kwargs)
        self.properties = properties


class DatasetDeflateCompression(DatasetCompression):
    """The Deflate compression method used on a dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset compression.Constant filled by server.
    :type type: str
    :param level: All available compression levels. Possible values include: 'Optimal', 'Fastest'.
    :type level: str or ~data_factory_management_client.models.DatasetCompressionLevel
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'level': {'key': 'level', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        level: Optional[Union[str, "DatasetCompressionLevel"]] = None,
        **kwargs
    ):
        super(DatasetDeflateCompression, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'Deflate'
        self.level = level


class DatasetFolder(msrest.serialization.Model):
    """The folder that this Dataset is in. If not specified, Dataset will appear at the root level.

    :param name: The name of the folder that this Dataset is in.
    :type name: str
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        **kwargs
    ):
        super(DatasetFolder, self).__init__(**kwargs)
        self.name = name


class DatasetGZipCompression(DatasetCompression):
    """The GZip compression method used on a dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset compression.Constant filled by server.
    :type type: str
    :param level: All available compression levels. Possible values include: 'Optimal', 'Fastest'.
    :type level: str or ~data_factory_management_client.models.DatasetCompressionLevel
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'level': {'key': 'level', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        level: Optional[Union[str, "DatasetCompressionLevel"]] = None,
        **kwargs
    ):
        super(DatasetGZipCompression, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'GZip'
        self.level = level


class DatasetListResponse(msrest.serialization.Model):
    """A list of dataset resources.

    All required parameters must be populated in order to send to Azure.

    :param value: Required. List of datasets.
    :type value: list[~data_factory_management_client.models.DatasetResource]
    :param next_link: The link to the next page of results, if any remaining results exist.
    :type next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[DatasetResource]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["DatasetResource"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        super(DatasetListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class DatasetLocationFileName(msrest.serialization.Model):
    """Specify the file name of dataset. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DatasetLocationFileName, self).__init__(**kwargs)


class DatasetLocationFolderPath(msrest.serialization.Model):
    """Specify the folder path of dataset. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DatasetLocationFolderPath, self).__init__(**kwargs)


class DatasetReference(msrest.serialization.Model):
    """Dataset reference type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Dataset reference type. Default value: "DatasetReference".
    :vartype type: str
    :param reference_name: Required. Reference dataset name.
    :type reference_name: str
    :param parameters: An object mapping parameter names to argument values.
    :type parameters: dict[str, object]
    """

    _validation = {
        'type': {'required': True, 'constant': True},
        'reference_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{object}'},
    }

    type = "DatasetReference"

    def __init__(
        self,
        *,
        reference_name: str,
        parameters: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(DatasetReference, self).__init__(**kwargs)
        self.reference_name = reference_name
        self.parameters = parameters


class DatasetResource(SubResource):
    """Dataset resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :param properties: Required. The Azure Data Factory nested object which identifies data within
     different data stores, such as tables, files, folders, and documents.
    :type properties: ~data_factory_management_client.models.Dataset
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
        'properties': {'required': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'Dataset'},
    }

    def __init__(
        self,
        *,
        properties: "Dataset",
        **kwargs
    ):
        super(DatasetResource, self).__init__(**kwargs)
        self.properties = properties


class DatasetSchema(msrest.serialization.Model):
    """Columns that define the physical type schema of the dataset. Type: array (or Expression with resultType array), itemType: DatasetSchemaDataElement.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DatasetSchema, self).__init__(**kwargs)


class DatasetStorageFormatDeserializer(msrest.serialization.Model):
    """Deserializer. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DatasetStorageFormatDeserializer, self).__init__(**kwargs)


class DatasetStorageFormatSerializer(msrest.serialization.Model):
    """Serializer. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DatasetStorageFormatSerializer, self).__init__(**kwargs)


class DatasetStructure(msrest.serialization.Model):
    """Columns that define the structure of the dataset. Type: array (or Expression with resultType array), itemType: DatasetDataElement.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DatasetStructure, self).__init__(**kwargs)


class DatasetZipDeflateCompression(DatasetCompression):
    """The ZipDeflate compression method used on a dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset compression.Constant filled by server.
    :type type: str
    :param level: All available compression levels. Possible values include: 'Optimal', 'Fastest'.
    :type level: str or ~data_factory_management_client.models.DatasetCompressionLevel
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'level': {'key': 'level', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        level: Optional[Union[str, "DatasetCompressionLevel"]] = None,
        **kwargs
    ):
        super(DatasetZipDeflateCompression, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'ZipDeflate'
        self.level = level


class Db2LinkedService(LinkedService):
    """Linked service for DB2 data source.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: The connection string. It is mutually exclusive with server,
     database, authenticationType, userName, packageCollection and certificateCommonName property.
     Type: string, SecureString or AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.Db2LinkedServiceTypePropertiesConnectionString
    :param server: Server name for connection. It is mutually exclusive with connectionString
     property. Type: string (or Expression with resultType string).
    :type server: ~data_factory_management_client.models.Db2LinkedServiceTypePropertiesServer
    :param database: Database name for connection. It is mutually exclusive with connectionString
     property. Type: string (or Expression with resultType string).
    :type database: ~data_factory_management_client.models.Db2LinkedServiceTypePropertiesDatabase
    :ivar authentication_type: AuthenticationType to be used for connection. It is mutually
     exclusive with connectionString property. Default value: "Basic".
    :vartype authentication_type: str
    :param username: Username for authentication. It is mutually exclusive with connectionString
     property. Type: string (or Expression with resultType string).
    :type username: ~data_factory_management_client.models.Db2LinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param package_collection: Under where packages are created when querying database. It is
     mutually exclusive with connectionString property. Type: string (or Expression with resultType
     string).
    :type package_collection:
     ~data_factory_management_client.models.Db2LinkedServiceTypePropertiesPackageCollection
    :param certificate_common_name: Certificate Common Name when TLS is enabled. It is mutually
     exclusive with connectionString property. Type: string (or Expression with resultType string).
    :type certificate_common_name:
     ~data_factory_management_client.models.Db2LinkedServiceTypePropertiesCertificateCommonName
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. It is mutually exclusive with
     connectionString property. Type: string (or Expression with resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.Db2LinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'authentication_type': {'constant': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'Db2LinkedServiceTypePropertiesConnectionString'},
        'server': {'key': 'typeProperties.server', 'type': 'Db2LinkedServiceTypePropertiesServer'},
        'database': {'key': 'typeProperties.database', 'type': 'Db2LinkedServiceTypePropertiesDatabase'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'Db2LinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'package_collection': {'key': 'typeProperties.packageCollection', 'type': 'Db2LinkedServiceTypePropertiesPackageCollection'},
        'certificate_common_name': {'key': 'typeProperties.certificateCommonName', 'type': 'Db2LinkedServiceTypePropertiesCertificateCommonName'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'Db2LinkedServiceTypePropertiesEncryptedCredential'},
    }

    authentication_type = "Basic"

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        connection_string: Optional["Db2LinkedServiceTypePropertiesConnectionString"] = None,
        server: Optional["Db2LinkedServiceTypePropertiesServer"] = None,
        database: Optional["Db2LinkedServiceTypePropertiesDatabase"] = None,
        username: Optional["Db2LinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        package_collection: Optional["Db2LinkedServiceTypePropertiesPackageCollection"] = None,
        certificate_common_name: Optional["Db2LinkedServiceTypePropertiesCertificateCommonName"] = None,
        encrypted_credential: Optional["Db2LinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(Db2LinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Db2'
        self.connection_string = connection_string
        self.server = server
        self.database = database
        self.username = username
        self.password = password
        self.package_collection = package_collection
        self.certificate_common_name = certificate_common_name
        self.encrypted_credential = encrypted_credential


class Db2LinkedServiceTypeProperties(msrest.serialization.Model):
    """DB2 linked service properties.

    Variables are only populated by the server, and will be ignored when sending a request.

    :param connection_string: The connection string. It is mutually exclusive with server,
     database, authenticationType, userName, packageCollection and certificateCommonName property.
     Type: string, SecureString or AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.Db2LinkedServiceTypePropertiesConnectionString
    :param server: Server name for connection. It is mutually exclusive with connectionString
     property. Type: string (or Expression with resultType string).
    :type server: ~data_factory_management_client.models.Db2LinkedServiceTypePropertiesServer
    :param database: Database name for connection. It is mutually exclusive with connectionString
     property. Type: string (or Expression with resultType string).
    :type database: ~data_factory_management_client.models.Db2LinkedServiceTypePropertiesDatabase
    :ivar authentication_type: AuthenticationType to be used for connection. It is mutually
     exclusive with connectionString property. Default value: "Basic".
    :vartype authentication_type: str
    :param username: Username for authentication. It is mutually exclusive with connectionString
     property. Type: string (or Expression with resultType string).
    :type username: ~data_factory_management_client.models.Db2LinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param package_collection: Under where packages are created when querying database. It is
     mutually exclusive with connectionString property. Type: string (or Expression with resultType
     string).
    :type package_collection:
     ~data_factory_management_client.models.Db2LinkedServiceTypePropertiesPackageCollection
    :param certificate_common_name: Certificate Common Name when TLS is enabled. It is mutually
     exclusive with connectionString property. Type: string (or Expression with resultType string).
    :type certificate_common_name:
     ~data_factory_management_client.models.Db2LinkedServiceTypePropertiesCertificateCommonName
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. It is mutually exclusive with
     connectionString property. Type: string (or Expression with resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.Db2LinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'authentication_type': {'constant': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'Db2LinkedServiceTypePropertiesConnectionString'},
        'server': {'key': 'server', 'type': 'Db2LinkedServiceTypePropertiesServer'},
        'database': {'key': 'database', 'type': 'Db2LinkedServiceTypePropertiesDatabase'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'username': {'key': 'username', 'type': 'Db2LinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'package_collection': {'key': 'packageCollection', 'type': 'Db2LinkedServiceTypePropertiesPackageCollection'},
        'certificate_common_name': {'key': 'certificateCommonName', 'type': 'Db2LinkedServiceTypePropertiesCertificateCommonName'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'Db2LinkedServiceTypePropertiesEncryptedCredential'},
    }

    authentication_type = "Basic"

    def __init__(
        self,
        *,
        connection_string: Optional["Db2LinkedServiceTypePropertiesConnectionString"] = None,
        server: Optional["Db2LinkedServiceTypePropertiesServer"] = None,
        database: Optional["Db2LinkedServiceTypePropertiesDatabase"] = None,
        username: Optional["Db2LinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        package_collection: Optional["Db2LinkedServiceTypePropertiesPackageCollection"] = None,
        certificate_common_name: Optional["Db2LinkedServiceTypePropertiesCertificateCommonName"] = None,
        encrypted_credential: Optional["Db2LinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(Db2LinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.server = server
        self.database = database
        self.username = username
        self.password = password
        self.package_collection = package_collection
        self.certificate_common_name = certificate_common_name
        self.encrypted_credential = encrypted_credential


class Db2LinkedServiceTypePropertiesCertificateCommonName(msrest.serialization.Model):
    """Certificate Common Name when TLS is enabled. It is mutually exclusive with connectionString property. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Db2LinkedServiceTypePropertiesCertificateCommonName, self).__init__(**kwargs)


class Db2LinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The connection string. It is mutually exclusive with server, database, authenticationType, userName, packageCollection and certificateCommonName property. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Db2LinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class Db2LinkedServiceTypePropertiesDatabase(msrest.serialization.Model):
    """Database name for connection. It is mutually exclusive with connectionString property. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Db2LinkedServiceTypePropertiesDatabase, self).__init__(**kwargs)


class Db2LinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. It is mutually exclusive with connectionString property. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Db2LinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class Db2LinkedServiceTypePropertiesPackageCollection(msrest.serialization.Model):
    """Under where packages are created when querying database. It is mutually exclusive with connectionString property. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Db2LinkedServiceTypePropertiesPackageCollection, self).__init__(**kwargs)


class Db2LinkedServiceTypePropertiesServer(msrest.serialization.Model):
    """Server name for connection. It is mutually exclusive with connectionString property. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Db2LinkedServiceTypePropertiesServer, self).__init__(**kwargs)


class Db2LinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """Username for authentication. It is mutually exclusive with connectionString property. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Db2LinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class Db2Source(TabularSource):
    """A copy activity source for Db2 databases.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: Database query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.Db2SourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'Db2SourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["Db2SourceQuery"] = None,
        **kwargs
    ):
        super(Db2Source, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'Db2Source'
        self.query = query


class Db2SourceQuery(msrest.serialization.Model):
    """Database query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Db2SourceQuery, self).__init__(**kwargs)


class Db2TableDataset(Dataset):
    """The Db2 table dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.Db2TableDatasetTypePropertiesTableName
    :param schema_type_properties_schema: The Db2 schema name. Type: string (or Expression with
     resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.Db2TableDatasetTypePropertiesSchema
    :param table: The Db2 table name. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.Db2TableDatasetTypePropertiesTable
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'Db2TableDatasetTypePropertiesTableName'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'Db2TableDatasetTypePropertiesSchema'},
        'table': {'key': 'typeProperties.table', 'type': 'Db2TableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["Db2TableDatasetTypePropertiesTableName"] = None,
        schema_type_properties_schema: Optional["Db2TableDatasetTypePropertiesSchema"] = None,
        table: Optional["Db2TableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(Db2TableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Db2Table'
        self.table_name = table_name
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class Db2TableDatasetTypeProperties(msrest.serialization.Model):
    """Db2 table dataset properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.Db2TableDatasetTypePropertiesTableName
    :param schema: The Db2 schema name. Type: string (or Expression with resultType string).
    :type schema: ~data_factory_management_client.models.Db2TableDatasetTypePropertiesSchema
    :param table: The Db2 table name. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.Db2TableDatasetTypePropertiesTable
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'Db2TableDatasetTypePropertiesTableName'},
        'schema': {'key': 'schema', 'type': 'Db2TableDatasetTypePropertiesSchema'},
        'table': {'key': 'table', 'type': 'Db2TableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["Db2TableDatasetTypePropertiesTableName"] = None,
        schema: Optional["Db2TableDatasetTypePropertiesSchema"] = None,
        table: Optional["Db2TableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(Db2TableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.schema = schema
        self.table = table


class Db2TableDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The Db2 schema name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Db2TableDatasetTypePropertiesSchema, self).__init__(**kwargs)


class Db2TableDatasetTypePropertiesTable(msrest.serialization.Model):
    """The Db2 table name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Db2TableDatasetTypePropertiesTable, self).__init__(**kwargs)


class Db2TableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Db2TableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class DeleteActivity(ExecutionActivity):
    """Delete activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param recursive: If true, files or sub-folders under current folder path will be deleted
     recursively. Default is false. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.DeleteActivityTypePropertiesRecursive
    :param max_concurrent_connections: The max concurrent connections to connect data source at the
     same time.
    :type max_concurrent_connections: int
    :param enable_logging: Whether to record detailed logs of delete-activity execution. Default
     value is false. Type: boolean (or Expression with resultType boolean).
    :type enable_logging:
     ~data_factory_management_client.models.DeleteActivityTypePropertiesEnableLogging
    :param log_storage_settings: Log storage settings.
    :type log_storage_settings: ~data_factory_management_client.models.LogStorageSettings
    :param dataset: Required. Dataset reference type.
    :type dataset: ~data_factory_management_client.models.DatasetReference
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'max_concurrent_connections': {'minimum': 1},
        'dataset': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'recursive': {'key': 'typeProperties.recursive', 'type': 'DeleteActivityTypePropertiesRecursive'},
        'max_concurrent_connections': {'key': 'typeProperties.maxConcurrentConnections', 'type': 'int'},
        'enable_logging': {'key': 'typeProperties.enableLogging', 'type': 'DeleteActivityTypePropertiesEnableLogging'},
        'log_storage_settings': {'key': 'typeProperties.logStorageSettings', 'type': 'LogStorageSettings'},
        'dataset': {'key': 'typeProperties.dataset', 'type': 'DatasetReference'},
    }

    def __init__(
        self,
        *,
        name: str,
        dataset: "DatasetReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        recursive: Optional["DeleteActivityTypePropertiesRecursive"] = None,
        max_concurrent_connections: Optional[int] = None,
        enable_logging: Optional["DeleteActivityTypePropertiesEnableLogging"] = None,
        log_storage_settings: Optional["LogStorageSettings"] = None,
        **kwargs
    ):
        super(DeleteActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'Delete'
        self.recursive = recursive
        self.max_concurrent_connections = max_concurrent_connections
        self.enable_logging = enable_logging
        self.log_storage_settings = log_storage_settings
        self.dataset = dataset


class DeleteActivityTypeProperties(msrest.serialization.Model):
    """Delete activity properties.

    All required parameters must be populated in order to send to Azure.

    :param recursive: If true, files or sub-folders under current folder path will be deleted
     recursively. Default is false. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.DeleteActivityTypePropertiesRecursive
    :param max_concurrent_connections: The max concurrent connections to connect data source at the
     same time.
    :type max_concurrent_connections: int
    :param enable_logging: Whether to record detailed logs of delete-activity execution. Default
     value is false. Type: boolean (or Expression with resultType boolean).
    :type enable_logging:
     ~data_factory_management_client.models.DeleteActivityTypePropertiesEnableLogging
    :param log_storage_settings: Log storage settings.
    :type log_storage_settings: ~data_factory_management_client.models.LogStorageSettings
    :param dataset: Required. Dataset reference type.
    :type dataset: ~data_factory_management_client.models.DatasetReference
    """

    _validation = {
        'max_concurrent_connections': {'minimum': 1},
        'dataset': {'required': True},
    }

    _attribute_map = {
        'recursive': {'key': 'recursive', 'type': 'DeleteActivityTypePropertiesRecursive'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'int'},
        'enable_logging': {'key': 'enableLogging', 'type': 'DeleteActivityTypePropertiesEnableLogging'},
        'log_storage_settings': {'key': 'logStorageSettings', 'type': 'LogStorageSettings'},
        'dataset': {'key': 'dataset', 'type': 'DatasetReference'},
    }

    def __init__(
        self,
        *,
        dataset: "DatasetReference",
        recursive: Optional["DeleteActivityTypePropertiesRecursive"] = None,
        max_concurrent_connections: Optional[int] = None,
        enable_logging: Optional["DeleteActivityTypePropertiesEnableLogging"] = None,
        log_storage_settings: Optional["LogStorageSettings"] = None,
        **kwargs
    ):
        super(DeleteActivityTypeProperties, self).__init__(**kwargs)
        self.recursive = recursive
        self.max_concurrent_connections = max_concurrent_connections
        self.enable_logging = enable_logging
        self.log_storage_settings = log_storage_settings
        self.dataset = dataset


class DeleteActivityTypePropertiesEnableLogging(msrest.serialization.Model):
    """Whether to record detailed logs of delete-activity execution. Default value is false. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DeleteActivityTypePropertiesEnableLogging, self).__init__(**kwargs)


class DeleteActivityTypePropertiesRecursive(msrest.serialization.Model):
    """If true, files or sub-folders under current folder path will be deleted recursively. Default is false. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DeleteActivityTypePropertiesRecursive, self).__init__(**kwargs)


class DeleteDataFlowDebugSessionRequest(msrest.serialization.Model):
    """Request body structure for deleting data flow debug session.

    :param session_id: The ID of data flow debug session.
    :type session_id: str
    """

    _attribute_map = {
        'session_id': {'key': 'sessionId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        session_id: Optional[str] = None,
        **kwargs
    ):
        super(DeleteDataFlowDebugSessionRequest, self).__init__(**kwargs)
        self.session_id = session_id


class DelimitedTextDataset(Dataset):
    """Delimited text dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param location: Dataset location.
    :type location: ~data_factory_management_client.models.DatasetLocation
    :param column_delimiter: The column delimiter. Type: string (or Expression with resultType
     string).
    :type column_delimiter:
     ~data_factory_management_client.models.DelimitedTextDatasetTypePropertiesColumnDelimiter
    :param row_delimiter: The row delimiter. Type: string (or Expression with resultType string).
    :type row_delimiter:
     ~data_factory_management_client.models.DelimitedTextDatasetTypePropertiesRowDelimiter
    :param encoding_name: The code page name of the preferred encoding. If miss, the default value
     is UTF-8, unless BOM denotes another Unicode encoding. Refer to the name column of the table in
     the following link to set supported values:
     https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with
     resultType string).
    :type encoding_name:
     ~data_factory_management_client.models.DelimitedTextDatasetTypePropertiesEncodingName
    :param compression_codec:  Possible values include: 'none', 'gzip', 'snappy', 'lzo', 'bzip2',
     'deflate', 'zipDeflate', 'lz4'.
    :type compression_codec: str or ~data_factory_management_client.models.CompressionCodec
    :param compression_level: All available compression levels. Possible values include: 'Optimal',
     'Fastest'.
    :type compression_level: str or ~data_factory_management_client.models.DatasetCompressionLevel
    :param quote_char: The quote character. Type: string (or Expression with resultType string).
    :type quote_char:
     ~data_factory_management_client.models.DelimitedTextDatasetTypePropertiesQuoteChar
    :param escape_char: The escape character. Type: string (or Expression with resultType string).
    :type escape_char:
     ~data_factory_management_client.models.DelimitedTextDatasetTypePropertiesEscapeChar
    :param first_row_as_header: When used as input, treat the first row of data as headers. When
     used as output,write the headers into the output as the first row of data. The default value is
     false. Type: boolean (or Expression with resultType boolean).
    :type first_row_as_header:
     ~data_factory_management_client.models.DelimitedTextDatasetTypePropertiesFirstRowAsHeader
    :param null_value: The null value string. Type: string (or Expression with resultType string).
    :type null_value:
     ~data_factory_management_client.models.DelimitedTextDatasetTypePropertiesNullValue
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'location': {'key': 'typeProperties.location', 'type': 'DatasetLocation'},
        'column_delimiter': {'key': 'typeProperties.columnDelimiter', 'type': 'DelimitedTextDatasetTypePropertiesColumnDelimiter'},
        'row_delimiter': {'key': 'typeProperties.rowDelimiter', 'type': 'DelimitedTextDatasetTypePropertiesRowDelimiter'},
        'encoding_name': {'key': 'typeProperties.encodingName', 'type': 'DelimitedTextDatasetTypePropertiesEncodingName'},
        'compression_codec': {'key': 'typeProperties.compressionCodec', 'type': 'str'},
        'compression_level': {'key': 'typeProperties.compressionLevel', 'type': 'str'},
        'quote_char': {'key': 'typeProperties.quoteChar', 'type': 'DelimitedTextDatasetTypePropertiesQuoteChar'},
        'escape_char': {'key': 'typeProperties.escapeChar', 'type': 'DelimitedTextDatasetTypePropertiesEscapeChar'},
        'first_row_as_header': {'key': 'typeProperties.firstRowAsHeader', 'type': 'DelimitedTextDatasetTypePropertiesFirstRowAsHeader'},
        'null_value': {'key': 'typeProperties.nullValue', 'type': 'DelimitedTextDatasetTypePropertiesNullValue'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        location: Optional["DatasetLocation"] = None,
        column_delimiter: Optional["DelimitedTextDatasetTypePropertiesColumnDelimiter"] = None,
        row_delimiter: Optional["DelimitedTextDatasetTypePropertiesRowDelimiter"] = None,
        encoding_name: Optional["DelimitedTextDatasetTypePropertiesEncodingName"] = None,
        compression_codec: Optional[Union[str, "CompressionCodec"]] = None,
        compression_level: Optional[Union[str, "DatasetCompressionLevel"]] = None,
        quote_char: Optional["DelimitedTextDatasetTypePropertiesQuoteChar"] = None,
        escape_char: Optional["DelimitedTextDatasetTypePropertiesEscapeChar"] = None,
        first_row_as_header: Optional["DelimitedTextDatasetTypePropertiesFirstRowAsHeader"] = None,
        null_value: Optional["DelimitedTextDatasetTypePropertiesNullValue"] = None,
        **kwargs
    ):
        super(DelimitedTextDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'DelimitedText'
        self.location = location
        self.column_delimiter = column_delimiter
        self.row_delimiter = row_delimiter
        self.encoding_name = encoding_name
        self.compression_codec = compression_codec
        self.compression_level = compression_level
        self.quote_char = quote_char
        self.escape_char = escape_char
        self.first_row_as_header = first_row_as_header
        self.null_value = null_value


class DelimitedTextDatasetTypeProperties(msrest.serialization.Model):
    """DelimitedText dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param location: Required. Dataset location.
    :type location: ~data_factory_management_client.models.DatasetLocation
    :param column_delimiter: The column delimiter. Type: string (or Expression with resultType
     string).
    :type column_delimiter:
     ~data_factory_management_client.models.DelimitedTextDatasetTypePropertiesColumnDelimiter
    :param row_delimiter: The row delimiter. Type: string (or Expression with resultType string).
    :type row_delimiter:
     ~data_factory_management_client.models.DelimitedTextDatasetTypePropertiesRowDelimiter
    :param encoding_name: The code page name of the preferred encoding. If miss, the default value
     is UTF-8, unless BOM denotes another Unicode encoding. Refer to the name column of the table in
     the following link to set supported values:
     https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with
     resultType string).
    :type encoding_name:
     ~data_factory_management_client.models.DelimitedTextDatasetTypePropertiesEncodingName
    :param compression_codec:  Possible values include: 'none', 'gzip', 'snappy', 'lzo', 'bzip2',
     'deflate', 'zipDeflate', 'lz4'.
    :type compression_codec: str or ~data_factory_management_client.models.CompressionCodec
    :param compression_level: All available compression levels. Possible values include: 'Optimal',
     'Fastest'.
    :type compression_level: str or ~data_factory_management_client.models.DatasetCompressionLevel
    :param quote_char: The quote character. Type: string (or Expression with resultType string).
    :type quote_char:
     ~data_factory_management_client.models.DelimitedTextDatasetTypePropertiesQuoteChar
    :param escape_char: The escape character. Type: string (or Expression with resultType string).
    :type escape_char:
     ~data_factory_management_client.models.DelimitedTextDatasetTypePropertiesEscapeChar
    :param first_row_as_header: When used as input, treat the first row of data as headers. When
     used as output,write the headers into the output as the first row of data. The default value is
     false. Type: boolean (or Expression with resultType boolean).
    :type first_row_as_header:
     ~data_factory_management_client.models.DelimitedTextDatasetTypePropertiesFirstRowAsHeader
    :param null_value: The null value string. Type: string (or Expression with resultType string).
    :type null_value:
     ~data_factory_management_client.models.DelimitedTextDatasetTypePropertiesNullValue
    """

    _validation = {
        'location': {'required': True},
    }

    _attribute_map = {
        'location': {'key': 'location', 'type': 'DatasetLocation'},
        'column_delimiter': {'key': 'columnDelimiter', 'type': 'DelimitedTextDatasetTypePropertiesColumnDelimiter'},
        'row_delimiter': {'key': 'rowDelimiter', 'type': 'DelimitedTextDatasetTypePropertiesRowDelimiter'},
        'encoding_name': {'key': 'encodingName', 'type': 'DelimitedTextDatasetTypePropertiesEncodingName'},
        'compression_codec': {'key': 'compressionCodec', 'type': 'str'},
        'compression_level': {'key': 'compressionLevel', 'type': 'str'},
        'quote_char': {'key': 'quoteChar', 'type': 'DelimitedTextDatasetTypePropertiesQuoteChar'},
        'escape_char': {'key': 'escapeChar', 'type': 'DelimitedTextDatasetTypePropertiesEscapeChar'},
        'first_row_as_header': {'key': 'firstRowAsHeader', 'type': 'DelimitedTextDatasetTypePropertiesFirstRowAsHeader'},
        'null_value': {'key': 'nullValue', 'type': 'DelimitedTextDatasetTypePropertiesNullValue'},
    }

    def __init__(
        self,
        *,
        location: "DatasetLocation",
        column_delimiter: Optional["DelimitedTextDatasetTypePropertiesColumnDelimiter"] = None,
        row_delimiter: Optional["DelimitedTextDatasetTypePropertiesRowDelimiter"] = None,
        encoding_name: Optional["DelimitedTextDatasetTypePropertiesEncodingName"] = None,
        compression_codec: Optional[Union[str, "CompressionCodec"]] = None,
        compression_level: Optional[Union[str, "DatasetCompressionLevel"]] = None,
        quote_char: Optional["DelimitedTextDatasetTypePropertiesQuoteChar"] = None,
        escape_char: Optional["DelimitedTextDatasetTypePropertiesEscapeChar"] = None,
        first_row_as_header: Optional["DelimitedTextDatasetTypePropertiesFirstRowAsHeader"] = None,
        null_value: Optional["DelimitedTextDatasetTypePropertiesNullValue"] = None,
        **kwargs
    ):
        super(DelimitedTextDatasetTypeProperties, self).__init__(**kwargs)
        self.location = location
        self.column_delimiter = column_delimiter
        self.row_delimiter = row_delimiter
        self.encoding_name = encoding_name
        self.compression_codec = compression_codec
        self.compression_level = compression_level
        self.quote_char = quote_char
        self.escape_char = escape_char
        self.first_row_as_header = first_row_as_header
        self.null_value = null_value


class DelimitedTextDatasetTypePropertiesColumnDelimiter(msrest.serialization.Model):
    """The column delimiter. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DelimitedTextDatasetTypePropertiesColumnDelimiter, self).__init__(**kwargs)


class DelimitedTextDatasetTypePropertiesEncodingName(msrest.serialization.Model):
    """The code page name of the preferred encoding. If miss, the default value is UTF-8, unless BOM denotes another Unicode encoding. Refer to the name column of the table in the following link to set supported values: https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DelimitedTextDatasetTypePropertiesEncodingName, self).__init__(**kwargs)


class DelimitedTextDatasetTypePropertiesEscapeChar(msrest.serialization.Model):
    """The escape character. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DelimitedTextDatasetTypePropertiesEscapeChar, self).__init__(**kwargs)


class DelimitedTextDatasetTypePropertiesFirstRowAsHeader(msrest.serialization.Model):
    """When used as input, treat the first row of data as headers. When used as output,write the headers into the output as the first row of data. The default value is false. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DelimitedTextDatasetTypePropertiesFirstRowAsHeader, self).__init__(**kwargs)


class DelimitedTextDatasetTypePropertiesNullValue(msrest.serialization.Model):
    """The null value string. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DelimitedTextDatasetTypePropertiesNullValue, self).__init__(**kwargs)


class DelimitedTextDatasetTypePropertiesQuoteChar(msrest.serialization.Model):
    """The quote character. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DelimitedTextDatasetTypePropertiesQuoteChar, self).__init__(**kwargs)


class DelimitedTextDatasetTypePropertiesRowDelimiter(msrest.serialization.Model):
    """The row delimiter. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DelimitedTextDatasetTypePropertiesRowDelimiter, self).__init__(**kwargs)


class FormatReadSettings(msrest.serialization.Model):
    """Format read settings.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: DelimitedTextReadSettings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The read setting type.Constant filled by server.
    :type type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'DelimitedTextReadSettings': 'DelimitedTextReadSettings'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(FormatReadSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'FormatReadSettings'


class DelimitedTextReadSettings(FormatReadSettings):
    """Delimited text read settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The read setting type.Constant filled by server.
    :type type: str
    :param skip_line_count: Indicates the number of non-empty rows to skip when reading data from
     input files. Type: integer (or Expression with resultType integer).
    :type skip_line_count:
     ~data_factory_management_client.models.DelimitedTextReadSettingsSkipLineCount
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'skip_line_count': {'key': 'skipLineCount', 'type': 'DelimitedTextReadSettingsSkipLineCount'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        skip_line_count: Optional["DelimitedTextReadSettingsSkipLineCount"] = None,
        **kwargs
    ):
        super(DelimitedTextReadSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'DelimitedTextReadSettings'
        self.skip_line_count = skip_line_count


class DelimitedTextReadSettingsSkipLineCount(msrest.serialization.Model):
    """Indicates the number of non-empty rows to skip when reading data from input files. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DelimitedTextReadSettingsSkipLineCount, self).__init__(**kwargs)


class DelimitedTextSink(CopySink):
    """A copy activity DelimitedText sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param store_settings: Connector write settings.
    :type store_settings: ~data_factory_management_client.models.StoreWriteSettings
    :param format_settings: Delimited text write settings.
    :type format_settings: ~data_factory_management_client.models.DelimitedTextWriteSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreWriteSettings'},
        'format_settings': {'key': 'formatSettings', 'type': 'DelimitedTextWriteSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        store_settings: Optional["StoreWriteSettings"] = None,
        format_settings: Optional["DelimitedTextWriteSettings"] = None,
        **kwargs
    ):
        super(DelimitedTextSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'DelimitedTextSink'
        self.store_settings = store_settings
        self.format_settings = format_settings


class DelimitedTextSource(CopySource):
    """A copy activity DelimitedText source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param store_settings: Connector read setting.
    :type store_settings: ~data_factory_management_client.models.StoreReadSettings
    :param format_settings: Delimited text read settings.
    :type format_settings: ~data_factory_management_client.models.DelimitedTextReadSettings
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreReadSettings'},
        'format_settings': {'key': 'formatSettings', 'type': 'DelimitedTextReadSettings'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        format_settings: Optional["DelimitedTextReadSettings"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(DelimitedTextSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'DelimitedTextSource'
        self.store_settings = store_settings
        self.format_settings = format_settings
        self.additional_columns = additional_columns


class DelimitedTextWriteSettings(FormatWriteSettings):
    """Delimited text write settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The write setting type.Constant filled by server.
    :type type: str
    :param quote_all_text: Indicates whether string values should always be enclosed with quotes.
     Type: boolean (or Expression with resultType boolean).
    :type quote_all_text:
     ~data_factory_management_client.models.DelimitedTextWriteSettingsQuoteAllText
    :param file_extension: Required. The file extension used to create the files. Type: string (or
     Expression with resultType string).
    :type file_extension:
     ~data_factory_management_client.models.DelimitedTextWriteSettingsFileExtension
    """

    _validation = {
        'type': {'required': True},
        'file_extension': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'quote_all_text': {'key': 'quoteAllText', 'type': 'DelimitedTextWriteSettingsQuoteAllText'},
        'file_extension': {'key': 'fileExtension', 'type': 'DelimitedTextWriteSettingsFileExtension'},
    }

    def __init__(
        self,
        *,
        file_extension: "DelimitedTextWriteSettingsFileExtension",
        additional_properties: Optional[Dict[str, object]] = None,
        quote_all_text: Optional["DelimitedTextWriteSettingsQuoteAllText"] = None,
        **kwargs
    ):
        super(DelimitedTextWriteSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'DelimitedTextWriteSettings'
        self.quote_all_text = quote_all_text
        self.file_extension = file_extension


class DelimitedTextWriteSettingsFileExtension(msrest.serialization.Model):
    """The file extension used to create the files. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DelimitedTextWriteSettingsFileExtension, self).__init__(**kwargs)


class DelimitedTextWriteSettingsQuoteAllText(msrest.serialization.Model):
    """Indicates whether string values should always be enclosed with quotes. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DelimitedTextWriteSettingsQuoteAllText, self).__init__(**kwargs)


class DependencyReference(msrest.serialization.Model):
    """Referenced dependency.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: SelfDependencyTumblingWindowTriggerReference, TriggerDependencyReference.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. The type of dependency reference.Constant filled by server.
    :type type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'SelfDependencyTumblingWindowTriggerReference': 'SelfDependencyTumblingWindowTriggerReference', 'TriggerDependencyReference': 'TriggerDependencyReference'}
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DependencyReference, self).__init__(**kwargs)
        self.type = None


class DistcpSettings(msrest.serialization.Model):
    """Distcp settings.

    All required parameters must be populated in order to send to Azure.

    :param resource_manager_endpoint: Required. Specifies the Yarn ResourceManager endpoint. Type:
     string (or Expression with resultType string).
    :type resource_manager_endpoint:
     ~data_factory_management_client.models.DistcpSettingsResourceManagerEndpoint
    :param temp_script_path: Required. Specifies an existing folder path which will be used to
     store temp Distcp command script. The script file is generated by ADF and will be removed after
     Copy job finished. Type: string (or Expression with resultType string).
    :type temp_script_path: ~data_factory_management_client.models.DistcpSettingsTempScriptPath
    :param distcp_options: Specifies the Distcp options. Type: string (or Expression with
     resultType string).
    :type distcp_options: ~data_factory_management_client.models.DistcpSettingsDistcpOptions
    """

    _validation = {
        'resource_manager_endpoint': {'required': True},
        'temp_script_path': {'required': True},
    }

    _attribute_map = {
        'resource_manager_endpoint': {'key': 'resourceManagerEndpoint', 'type': 'DistcpSettingsResourceManagerEndpoint'},
        'temp_script_path': {'key': 'tempScriptPath', 'type': 'DistcpSettingsTempScriptPath'},
        'distcp_options': {'key': 'distcpOptions', 'type': 'DistcpSettingsDistcpOptions'},
    }

    def __init__(
        self,
        *,
        resource_manager_endpoint: "DistcpSettingsResourceManagerEndpoint",
        temp_script_path: "DistcpSettingsTempScriptPath",
        distcp_options: Optional["DistcpSettingsDistcpOptions"] = None,
        **kwargs
    ):
        super(DistcpSettings, self).__init__(**kwargs)
        self.resource_manager_endpoint = resource_manager_endpoint
        self.temp_script_path = temp_script_path
        self.distcp_options = distcp_options


class DistcpSettingsDistcpOptions(msrest.serialization.Model):
    """Specifies the Distcp options. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DistcpSettingsDistcpOptions, self).__init__(**kwargs)


class DistcpSettingsResourceManagerEndpoint(msrest.serialization.Model):
    """Specifies the Yarn ResourceManager endpoint. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DistcpSettingsResourceManagerEndpoint, self).__init__(**kwargs)


class DistcpSettingsTempScriptPath(msrest.serialization.Model):
    """Specifies an existing folder path which will be used to store temp Distcp command script. The script file is generated by ADF and will be removed after Copy job finished. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DistcpSettingsTempScriptPath, self).__init__(**kwargs)


class DocumentDbCollectionDataset(Dataset):
    """Microsoft Azure Document Database Collection dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param collection_name: Required. Document Database collection name. Type: string (or
     Expression with resultType string).
    :type collection_name:
     ~data_factory_management_client.models.DocumentDbCollectionDatasetTypePropertiesCollectionName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'collection_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'collection_name': {'key': 'typeProperties.collectionName', 'type': 'DocumentDbCollectionDatasetTypePropertiesCollectionName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        collection_name: "DocumentDbCollectionDatasetTypePropertiesCollectionName",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        super(DocumentDbCollectionDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'DocumentDbCollection'
        self.collection_name = collection_name


class DocumentDbCollectionDatasetTypeProperties(msrest.serialization.Model):
    """DocumentDB Collection dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param collection_name: Required. Document Database collection name. Type: string (or
     Expression with resultType string).
    :type collection_name:
     ~data_factory_management_client.models.DocumentDbCollectionDatasetTypePropertiesCollectionName
    """

    _validation = {
        'collection_name': {'required': True},
    }

    _attribute_map = {
        'collection_name': {'key': 'collectionName', 'type': 'DocumentDbCollectionDatasetTypePropertiesCollectionName'},
    }

    def __init__(
        self,
        *,
        collection_name: "DocumentDbCollectionDatasetTypePropertiesCollectionName",
        **kwargs
    ):
        super(DocumentDbCollectionDatasetTypeProperties, self).__init__(**kwargs)
        self.collection_name = collection_name


class DocumentDbCollectionDatasetTypePropertiesCollectionName(msrest.serialization.Model):
    """Document Database collection name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DocumentDbCollectionDatasetTypePropertiesCollectionName, self).__init__(**kwargs)


class DocumentDbCollectionSink(CopySink):
    """A copy activity Document Database Collection sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param nesting_separator: Nested properties separator. Default is . (dot). Type: string (or
     Expression with resultType string).
    :type nesting_separator:
     ~data_factory_management_client.models.DocumentDbCollectionSinkNestingSeparator
    :param write_behavior: Describes how to write data to Azure Cosmos DB. Type: string (or
     Expression with resultType string). Allowed values: insert and upsert.
    :type write_behavior:
     ~data_factory_management_client.models.DocumentDbCollectionSinkWriteBehavior
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'nesting_separator': {'key': 'nestingSeparator', 'type': 'DocumentDbCollectionSinkNestingSeparator'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'DocumentDbCollectionSinkWriteBehavior'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        nesting_separator: Optional["DocumentDbCollectionSinkNestingSeparator"] = None,
        write_behavior: Optional["DocumentDbCollectionSinkWriteBehavior"] = None,
        **kwargs
    ):
        super(DocumentDbCollectionSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'DocumentDbCollectionSink'
        self.nesting_separator = nesting_separator
        self.write_behavior = write_behavior


class DocumentDbCollectionSinkNestingSeparator(msrest.serialization.Model):
    """Nested properties separator. Default is . (dot). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DocumentDbCollectionSinkNestingSeparator, self).__init__(**kwargs)


class DocumentDbCollectionSinkWriteBehavior(msrest.serialization.Model):
    """Describes how to write data to Azure Cosmos DB. Type: string (or Expression with resultType string). Allowed values: insert and upsert.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DocumentDbCollectionSinkWriteBehavior, self).__init__(**kwargs)


class DocumentDbCollectionSource(CopySource):
    """A copy activity Document Database Collection source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query: Documents query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.DocumentDbCollectionSourceQuery
    :param nesting_separator: Nested properties separator. Type: string (or Expression with
     resultType string).
    :type nesting_separator:
     ~data_factory_management_client.models.DocumentDbCollectionSourceNestingSeparator
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout:
     ~data_factory_management_client.models.DocumentDbCollectionSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query': {'key': 'query', 'type': 'DocumentDbCollectionSourceQuery'},
        'nesting_separator': {'key': 'nestingSeparator', 'type': 'DocumentDbCollectionSourceNestingSeparator'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'DocumentDbCollectionSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query: Optional["DocumentDbCollectionSourceQuery"] = None,
        nesting_separator: Optional["DocumentDbCollectionSourceNestingSeparator"] = None,
        query_timeout: Optional["DocumentDbCollectionSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(DocumentDbCollectionSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'DocumentDbCollectionSource'
        self.query = query
        self.nesting_separator = nesting_separator
        self.query_timeout = query_timeout
        self.additional_columns = additional_columns


class DocumentDbCollectionSourceNestingSeparator(msrest.serialization.Model):
    """Nested properties separator. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DocumentDbCollectionSourceNestingSeparator, self).__init__(**kwargs)


class DocumentDbCollectionSourceQuery(msrest.serialization.Model):
    """Documents query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DocumentDbCollectionSourceQuery, self).__init__(**kwargs)


class DocumentDbCollectionSourceQueryTimeout(msrest.serialization.Model):
    """Query timeout. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DocumentDbCollectionSourceQueryTimeout, self).__init__(**kwargs)


class DrillDatasetTypeProperties(msrest.serialization.Model):
    """Drill Dataset Properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.DrillDatasetTypePropertiesTableName
    :param table: The table name of the Drill. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.DrillDatasetTypePropertiesTable
    :param schema: The schema name of the Drill. Type: string (or Expression with resultType
     string).
    :type schema: ~data_factory_management_client.models.DrillDatasetTypePropertiesSchema
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'DrillDatasetTypePropertiesTableName'},
        'table': {'key': 'table', 'type': 'DrillDatasetTypePropertiesTable'},
        'schema': {'key': 'schema', 'type': 'DrillDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["DrillDatasetTypePropertiesTableName"] = None,
        table: Optional["DrillDatasetTypePropertiesTable"] = None,
        schema: Optional["DrillDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(DrillDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.table = table
        self.schema = schema


class DrillDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of the Drill. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DrillDatasetTypePropertiesSchema, self).__init__(**kwargs)


class DrillDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the Drill. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DrillDatasetTypePropertiesTable, self).__init__(**kwargs)


class DrillDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DrillDatasetTypePropertiesTableName, self).__init__(**kwargs)


class DrillLinkedService(LinkedService):
    """Drill server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.DrillLinkedServiceTypePropertiesConnectionString
    :param pwd: Azure Key Vault secret reference.
    :type pwd: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.DrillLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'DrillLinkedServiceTypePropertiesConnectionString'},
        'pwd': {'key': 'typeProperties.pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'DrillLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        connection_string: Optional["DrillLinkedServiceTypePropertiesConnectionString"] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["DrillLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(DrillLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Drill'
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class DrillLinkedServiceTypeProperties(msrest.serialization.Model):
    """Drill server linked service properties.

    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.DrillLinkedServiceTypePropertiesConnectionString
    :param pwd: Azure Key Vault secret reference.
    :type pwd: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.DrillLinkedServiceTypePropertiesEncryptedCredential
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'DrillLinkedServiceTypePropertiesConnectionString'},
        'pwd': {'key': 'pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'DrillLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional["DrillLinkedServiceTypePropertiesConnectionString"] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["DrillLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(DrillLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class DrillLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """An ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DrillLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class DrillLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DrillLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class DrillSource(TabularSource):
    """A copy activity Drill server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.DrillSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'DrillSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["DrillSourceQuery"] = None,
        **kwargs
    ):
        super(DrillSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'DrillSource'
        self.query = query


class DrillSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DrillSourceQuery, self).__init__(**kwargs)


class DrillTableDataset(Dataset):
    """Drill server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.DrillDatasetTypePropertiesTableName
    :param table: The table name of the Drill. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.DrillDatasetTypePropertiesTable
    :param schema_type_properties_schema: The schema name of the Drill. Type: string (or Expression
     with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.DrillDatasetTypePropertiesSchema
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'DrillDatasetTypePropertiesTableName'},
        'table': {'key': 'typeProperties.table', 'type': 'DrillDatasetTypePropertiesTable'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'DrillDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["DrillDatasetTypePropertiesTableName"] = None,
        table: Optional["DrillDatasetTypePropertiesTable"] = None,
        schema_type_properties_schema: Optional["DrillDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(DrillTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'DrillTable'
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class DWCopyCommandDefaultValue(msrest.serialization.Model):
    """Default value.

    :param column_name: Column name. Type: object (or Expression with resultType string).
    :type column_name: ~data_factory_management_client.models.DWCopyCommandDefaultValueColumnName
    :param default_value: The default value of the column. Type: object (or Expression with
     resultType string).
    :type default_value:
     ~data_factory_management_client.models.DWCopyCommandDefaultValueDefaultValue
    """

    _attribute_map = {
        'column_name': {'key': 'columnName', 'type': 'DWCopyCommandDefaultValueColumnName'},
        'default_value': {'key': 'defaultValue', 'type': 'DWCopyCommandDefaultValueDefaultValue'},
    }

    def __init__(
        self,
        *,
        column_name: Optional["DWCopyCommandDefaultValueColumnName"] = None,
        default_value: Optional["DWCopyCommandDefaultValueDefaultValue"] = None,
        **kwargs
    ):
        super(DWCopyCommandDefaultValue, self).__init__(**kwargs)
        self.column_name = column_name
        self.default_value = default_value


class DWCopyCommandDefaultValueColumnName(msrest.serialization.Model):
    """Column name. Type: object (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DWCopyCommandDefaultValueColumnName, self).__init__(**kwargs)


class DWCopyCommandDefaultValueDefaultValue(msrest.serialization.Model):
    """The default value of the column. Type: object (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DWCopyCommandDefaultValueDefaultValue, self).__init__(**kwargs)


class DWCopyCommandSettings(msrest.serialization.Model):
    """DW Copy Command settings.

    :param default_values: Specifies the default values for each target column in SQL DW. The
     default values in the property overwrite the DEFAULT constraint set in the DB, and identity
     column cannot have a default value. Type: array of objects (or Expression with resultType array
     of objects).
    :type default_values: list[~data_factory_management_client.models.DWCopyCommandDefaultValue]
    :param additional_options: Additional options directly passed to SQL DW in Copy Command. Type:
     key value pairs (value should be string type) (or Expression with resultType object). Example:
     "additionalOptions": { "MAXERRORS": "1000", "DATEFORMAT": "'ymd'" }.
    :type additional_options: dict[str, str]
    """

    _attribute_map = {
        'default_values': {'key': 'defaultValues', 'type': '[DWCopyCommandDefaultValue]'},
        'additional_options': {'key': 'additionalOptions', 'type': '{str}'},
    }

    def __init__(
        self,
        *,
        default_values: Optional[List["DWCopyCommandDefaultValue"]] = None,
        additional_options: Optional[Dict[str, str]] = None,
        **kwargs
    ):
        super(DWCopyCommandSettings, self).__init__(**kwargs)
        self.default_values = default_values
        self.additional_options = additional_options


class DynamicsAXLinkedService(LinkedService):
    """Dynamics AX linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param url: Required. The Dynamics AX (or Dynamics 365 Finance and Operations) instance OData
     endpoint.
    :type url: ~data_factory_management_client.models.DynamicsAXLinkedServiceTypePropertiesUrl
    :param service_principal_id: Required. Specify the application's client ID. Type: string (or
     Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.DynamicsAXLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: Required. The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: Required. Specify the tenant information (domain name or tenant ID) under which
     your application resides. Retrieve it by hovering the mouse in the top-right corner of the
     Azure portal. Type: string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.DynamicsAXLinkedServiceTypePropertiesTenant
    :param aad_resource_id: Required. Specify the resource you are requesting authorization. Type:
     string (or Expression with resultType string).
    :type aad_resource_id:
     ~data_factory_management_client.models.DynamicsAXLinkedServiceTypePropertiesAadResourceId
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.DynamicsAXLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
        'service_principal_id': {'required': True},
        'service_principal_key': {'required': True},
        'tenant': {'required': True},
        'aad_resource_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'url': {'key': 'typeProperties.url', 'type': 'DynamicsAXLinkedServiceTypePropertiesUrl'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'DynamicsAXLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'DynamicsAXLinkedServiceTypePropertiesTenant'},
        'aad_resource_id': {'key': 'typeProperties.aadResourceId', 'type': 'DynamicsAXLinkedServiceTypePropertiesAadResourceId'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'DynamicsAXLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        url: "DynamicsAXLinkedServiceTypePropertiesUrl",
        service_principal_id: "DynamicsAXLinkedServiceTypePropertiesServicePrincipalId",
        service_principal_key: "SecretBase",
        tenant: "DynamicsAXLinkedServiceTypePropertiesTenant",
        aad_resource_id: "DynamicsAXLinkedServiceTypePropertiesAadResourceId",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        encrypted_credential: Optional["DynamicsAXLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(DynamicsAXLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'DynamicsAX'
        self.url = url
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.aad_resource_id = aad_resource_id
        self.encrypted_credential = encrypted_credential


class DynamicsAXLinkedServiceTypeProperties(msrest.serialization.Model):
    """Dynamics AX linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param url: Required. The Dynamics AX (or Dynamics 365 Finance and Operations) instance OData
     endpoint.
    :type url: ~data_factory_management_client.models.DynamicsAXLinkedServiceTypePropertiesUrl
    :param service_principal_id: Required. Specify the application's client ID. Type: string (or
     Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.DynamicsAXLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: Required. The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: Required. Specify the tenant information (domain name or tenant ID) under which
     your application resides. Retrieve it by hovering the mouse in the top-right corner of the
     Azure portal. Type: string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.DynamicsAXLinkedServiceTypePropertiesTenant
    :param aad_resource_id: Required. Specify the resource you are requesting authorization. Type:
     string (or Expression with resultType string).
    :type aad_resource_id:
     ~data_factory_management_client.models.DynamicsAXLinkedServiceTypePropertiesAadResourceId
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.DynamicsAXLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'url': {'required': True},
        'service_principal_id': {'required': True},
        'service_principal_key': {'required': True},
        'tenant': {'required': True},
        'aad_resource_id': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'DynamicsAXLinkedServiceTypePropertiesUrl'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'DynamicsAXLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'tenant', 'type': 'DynamicsAXLinkedServiceTypePropertiesTenant'},
        'aad_resource_id': {'key': 'aadResourceId', 'type': 'DynamicsAXLinkedServiceTypePropertiesAadResourceId'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'DynamicsAXLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        url: "DynamicsAXLinkedServiceTypePropertiesUrl",
        service_principal_id: "DynamicsAXLinkedServiceTypePropertiesServicePrincipalId",
        service_principal_key: "SecretBase",
        tenant: "DynamicsAXLinkedServiceTypePropertiesTenant",
        aad_resource_id: "DynamicsAXLinkedServiceTypePropertiesAadResourceId",
        encrypted_credential: Optional["DynamicsAXLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(DynamicsAXLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.url = url
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.aad_resource_id = aad_resource_id
        self.encrypted_credential = encrypted_credential


class DynamicsAXLinkedServiceTypePropertiesAadResourceId(msrest.serialization.Model):
    """Specify the resource you are requesting authorization. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsAXLinkedServiceTypePropertiesAadResourceId, self).__init__(**kwargs)


class DynamicsAXLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsAXLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class DynamicsAXLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """Specify the application's client ID. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsAXLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class DynamicsAXLinkedServiceTypePropertiesTenant(msrest.serialization.Model):
    """Specify the tenant information (domain name or tenant ID) under which your application resides. Retrieve it by hovering the mouse in the top-right corner of the Azure portal. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsAXLinkedServiceTypePropertiesTenant, self).__init__(**kwargs)


class DynamicsAXLinkedServiceTypePropertiesUrl(msrest.serialization.Model):
    """The Dynamics AX (or Dynamics 365 Finance and Operations) instance OData endpoint.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsAXLinkedServiceTypePropertiesUrl, self).__init__(**kwargs)


class DynamicsAXResourceDataset(Dataset):
    """The path of the Dynamics AX OData entity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param path: Required. The path of the Dynamics AX OData entity. Type: string (or Expression
     with resultType string).
    :type path: ~data_factory_management_client.models.DynamicsAXResourceDatasetTypePropertiesPath
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'path': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'path': {'key': 'typeProperties.path', 'type': 'DynamicsAXResourceDatasetTypePropertiesPath'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        path: "DynamicsAXResourceDatasetTypePropertiesPath",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        super(DynamicsAXResourceDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'DynamicsAXResource'
        self.path = path


class DynamicsAXResourceDatasetTypeProperties(msrest.serialization.Model):
    """Dynamics AX OData resource dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param path: Required. The path of the Dynamics AX OData entity. Type: string (or Expression
     with resultType string).
    :type path: ~data_factory_management_client.models.DynamicsAXResourceDatasetTypePropertiesPath
    """

    _validation = {
        'path': {'required': True},
    }

    _attribute_map = {
        'path': {'key': 'path', 'type': 'DynamicsAXResourceDatasetTypePropertiesPath'},
    }

    def __init__(
        self,
        *,
        path: "DynamicsAXResourceDatasetTypePropertiesPath",
        **kwargs
    ):
        super(DynamicsAXResourceDatasetTypeProperties, self).__init__(**kwargs)
        self.path = path


class DynamicsAXResourceDatasetTypePropertiesPath(msrest.serialization.Model):
    """The path of the Dynamics AX OData entity. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsAXResourceDatasetTypePropertiesPath, self).__init__(**kwargs)


class DynamicsAXSource(TabularSource):
    """A copy activity Dynamics AX source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.DynamicsAXSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'DynamicsAXSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["DynamicsAXSourceQuery"] = None,
        **kwargs
    ):
        super(DynamicsAXSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'DynamicsAXSource'
        self.query = query


class DynamicsAXSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsAXSourceQuery, self).__init__(**kwargs)


class DynamicsCrmEntityDataset(Dataset):
    """The Dynamics CRM entity dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param entity_name: The logical name of the entity. Type: string (or Expression with resultType
     string).
    :type entity_name:
     ~data_factory_management_client.models.DynamicsCrmEntityDatasetTypePropertiesEntityName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'entity_name': {'key': 'typeProperties.entityName', 'type': 'DynamicsCrmEntityDatasetTypePropertiesEntityName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        entity_name: Optional["DynamicsCrmEntityDatasetTypePropertiesEntityName"] = None,
        **kwargs
    ):
        super(DynamicsCrmEntityDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'DynamicsCrmEntity'
        self.entity_name = entity_name


class DynamicsCrmEntityDatasetTypeProperties(msrest.serialization.Model):
    """Dynamics CRM entity dataset properties.

    :param entity_name: The logical name of the entity. Type: string (or Expression with resultType
     string).
    :type entity_name:
     ~data_factory_management_client.models.DynamicsCrmEntityDatasetTypePropertiesEntityName
    """

    _attribute_map = {
        'entity_name': {'key': 'entityName', 'type': 'DynamicsCrmEntityDatasetTypePropertiesEntityName'},
    }

    def __init__(
        self,
        *,
        entity_name: Optional["DynamicsCrmEntityDatasetTypePropertiesEntityName"] = None,
        **kwargs
    ):
        super(DynamicsCrmEntityDatasetTypeProperties, self).__init__(**kwargs)
        self.entity_name = entity_name


class DynamicsCrmEntityDatasetTypePropertiesEntityName(msrest.serialization.Model):
    """The logical name of the entity. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsCrmEntityDatasetTypePropertiesEntityName, self).__init__(**kwargs)


class DynamicsCrmLinkedService(LinkedService):
    """Dynamics CRM linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param deployment_type: Required. The deployment type of the Dynamics instance. 'Online' for
     Dynamics Online and 'OnPremisesWithIfd' for Dynamics on-premises with Ifd. Type: string (or
     Expression with resultType string). Possible values include: 'Online', 'OnPremisesWithIfd'.
    :type deployment_type: str or ~data_factory_management_client.models.DynamicsDeploymentType
    :param host_name: The host name of the on-premises Dynamics CRM server. The property is
     required for on-prem and not allowed for online. Type: string (or Expression with resultType
     string).
    :type host_name:
     ~data_factory_management_client.models.DynamicsCrmLinkedServiceTypePropertiesHostName
    :param port: The port of on-premises Dynamics CRM server. The property is required for on-prem
     and not allowed for online. Default is 443. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type port: ~data_factory_management_client.models.DynamicsCrmLinkedServiceTypePropertiesPort
    :param service_uri: The URL to the Microsoft Dynamics CRM server. The property is required for
     on-line and not allowed for on-prem. Type: string (or Expression with resultType string).
    :type service_uri:
     ~data_factory_management_client.models.DynamicsCrmLinkedServiceTypePropertiesServiceUri
    :param organization_name: The organization name of the Dynamics CRM instance. The property is
     required for on-prem and required for online when there are more than one Dynamics CRM
     instances associated with the user. Type: string (or Expression with resultType string).
    :type organization_name:
     ~data_factory_management_client.models.DynamicsCrmLinkedServiceTypePropertiesOrganizationName
    :param authentication_type: Required. The authentication type to connect to Dynamics server.
     'Office365' for online scenario, 'Ifd' for on-premises with Ifd scenario, 'AADServicePrincipal'
     for Server-To-Server authentication in online scenario. Type: string (or Expression with
     resultType string). Possible values include: 'Office365', 'Ifd', 'AADServicePrincipal'.
    :type authentication_type: str or
     ~data_factory_management_client.models.DynamicsAuthenticationType
    :param username: User name to access the Dynamics CRM instance. Type: string (or Expression
     with resultType string).
    :type username:
     ~data_factory_management_client.models.DynamicsCrmLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param service_principal_id: The client ID of the application in Azure Active Directory used
     for Server-To-Server authentication. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.DynamicsCrmLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_credential_type: The service principal credential type to use in
     Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
     for certificate. Type: string (or Expression with resultType string). Possible values include:
     'ServicePrincipalKey', 'ServicePrincipalCert'.
    :type service_principal_credential_type: str or
     ~data_factory_management_client.models.DynamicsServicePrincipalCredentialType
    :param service_principal_credential: The base definition of a secret type.
    :type service_principal_credential: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.DynamicsCrmLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'deployment_type': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'deployment_type': {'key': 'typeProperties.deploymentType', 'type': 'str'},
        'host_name': {'key': 'typeProperties.hostName', 'type': 'DynamicsCrmLinkedServiceTypePropertiesHostName'},
        'port': {'key': 'typeProperties.port', 'type': 'DynamicsCrmLinkedServiceTypePropertiesPort'},
        'service_uri': {'key': 'typeProperties.serviceUri', 'type': 'DynamicsCrmLinkedServiceTypePropertiesServiceUri'},
        'organization_name': {'key': 'typeProperties.organizationName', 'type': 'DynamicsCrmLinkedServiceTypePropertiesOrganizationName'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'DynamicsCrmLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'DynamicsCrmLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_credential_type': {'key': 'typeProperties.servicePrincipalCredentialType', 'type': 'str'},
        'service_principal_credential': {'key': 'typeProperties.servicePrincipalCredential', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'DynamicsCrmLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        deployment_type: Union[str, "DynamicsDeploymentType"],
        authentication_type: Union[str, "DynamicsAuthenticationType"],
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        host_name: Optional["DynamicsCrmLinkedServiceTypePropertiesHostName"] = None,
        port: Optional["DynamicsCrmLinkedServiceTypePropertiesPort"] = None,
        service_uri: Optional["DynamicsCrmLinkedServiceTypePropertiesServiceUri"] = None,
        organization_name: Optional["DynamicsCrmLinkedServiceTypePropertiesOrganizationName"] = None,
        username: Optional["DynamicsCrmLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        service_principal_id: Optional["DynamicsCrmLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_credential_type: Optional[Union[str, "DynamicsServicePrincipalCredentialType"]] = None,
        service_principal_credential: Optional["SecretBase"] = None,
        encrypted_credential: Optional["DynamicsCrmLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(DynamicsCrmLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'DynamicsCrm'
        self.deployment_type = deployment_type
        self.host_name = host_name
        self.port = port
        self.service_uri = service_uri
        self.organization_name = organization_name
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_credential_type = service_principal_credential_type
        self.service_principal_credential = service_principal_credential
        self.encrypted_credential = encrypted_credential


class DynamicsCrmLinkedServiceTypeProperties(msrest.serialization.Model):
    """Dynamics CRM linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param deployment_type: Required. The deployment type of the Dynamics instance. 'Online' for
     Dynamics Online and 'OnPremisesWithIfd' for Dynamics on-premises with Ifd. Type: string (or
     Expression with resultType string). Possible values include: 'Online', 'OnPremisesWithIfd'.
    :type deployment_type: str or ~data_factory_management_client.models.DynamicsDeploymentType
    :param host_name: The host name of the on-premises Dynamics CRM server. The property is
     required for on-prem and not allowed for online. Type: string (or Expression with resultType
     string).
    :type host_name:
     ~data_factory_management_client.models.DynamicsCrmLinkedServiceTypePropertiesHostName
    :param port: The port of on-premises Dynamics CRM server. The property is required for on-prem
     and not allowed for online. Default is 443. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type port: ~data_factory_management_client.models.DynamicsCrmLinkedServiceTypePropertiesPort
    :param service_uri: The URL to the Microsoft Dynamics CRM server. The property is required for
     on-line and not allowed for on-prem. Type: string (or Expression with resultType string).
    :type service_uri:
     ~data_factory_management_client.models.DynamicsCrmLinkedServiceTypePropertiesServiceUri
    :param organization_name: The organization name of the Dynamics CRM instance. The property is
     required for on-prem and required for online when there are more than one Dynamics CRM
     instances associated with the user. Type: string (or Expression with resultType string).
    :type organization_name:
     ~data_factory_management_client.models.DynamicsCrmLinkedServiceTypePropertiesOrganizationName
    :param authentication_type: Required. The authentication type to connect to Dynamics server.
     'Office365' for online scenario, 'Ifd' for on-premises with Ifd scenario, 'AADServicePrincipal'
     for Server-To-Server authentication in online scenario. Type: string (or Expression with
     resultType string). Possible values include: 'Office365', 'Ifd', 'AADServicePrincipal'.
    :type authentication_type: str or
     ~data_factory_management_client.models.DynamicsAuthenticationType
    :param username: User name to access the Dynamics CRM instance. Type: string (or Expression
     with resultType string).
    :type username:
     ~data_factory_management_client.models.DynamicsCrmLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param service_principal_id: The client ID of the application in Azure Active Directory used
     for Server-To-Server authentication. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.DynamicsCrmLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_credential_type: The service principal credential type to use in
     Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
     for certificate. Type: string (or Expression with resultType string). Possible values include:
     'ServicePrincipalKey', 'ServicePrincipalCert'.
    :type service_principal_credential_type: str or
     ~data_factory_management_client.models.DynamicsServicePrincipalCredentialType
    :param service_principal_credential: The base definition of a secret type.
    :type service_principal_credential: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.DynamicsCrmLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'deployment_type': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'deployment_type': {'key': 'deploymentType', 'type': 'str'},
        'host_name': {'key': 'hostName', 'type': 'DynamicsCrmLinkedServiceTypePropertiesHostName'},
        'port': {'key': 'port', 'type': 'DynamicsCrmLinkedServiceTypePropertiesPort'},
        'service_uri': {'key': 'serviceUri', 'type': 'DynamicsCrmLinkedServiceTypePropertiesServiceUri'},
        'organization_name': {'key': 'organizationName', 'type': 'DynamicsCrmLinkedServiceTypePropertiesOrganizationName'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'username': {'key': 'username', 'type': 'DynamicsCrmLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'DynamicsCrmLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_credential_type': {'key': 'servicePrincipalCredentialType', 'type': 'str'},
        'service_principal_credential': {'key': 'servicePrincipalCredential', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'DynamicsCrmLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        deployment_type: Union[str, "DynamicsDeploymentType"],
        authentication_type: Union[str, "DynamicsAuthenticationType"],
        host_name: Optional["DynamicsCrmLinkedServiceTypePropertiesHostName"] = None,
        port: Optional["DynamicsCrmLinkedServiceTypePropertiesPort"] = None,
        service_uri: Optional["DynamicsCrmLinkedServiceTypePropertiesServiceUri"] = None,
        organization_name: Optional["DynamicsCrmLinkedServiceTypePropertiesOrganizationName"] = None,
        username: Optional["DynamicsCrmLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        service_principal_id: Optional["DynamicsCrmLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_credential_type: Optional[Union[str, "DynamicsServicePrincipalCredentialType"]] = None,
        service_principal_credential: Optional["SecretBase"] = None,
        encrypted_credential: Optional["DynamicsCrmLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(DynamicsCrmLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.deployment_type = deployment_type
        self.host_name = host_name
        self.port = port
        self.service_uri = service_uri
        self.organization_name = organization_name
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_credential_type = service_principal_credential_type
        self.service_principal_credential = service_principal_credential
        self.encrypted_credential = encrypted_credential


class DynamicsCrmLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsCrmLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class DynamicsCrmLinkedServiceTypePropertiesHostName(msrest.serialization.Model):
    """The host name of the on-premises Dynamics CRM server. The property is required for on-prem and not allowed for online. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsCrmLinkedServiceTypePropertiesHostName, self).__init__(**kwargs)


class DynamicsCrmLinkedServiceTypePropertiesOrganizationName(msrest.serialization.Model):
    """The organization name of the Dynamics CRM instance. The property is required for on-prem and required for online when there are more than one Dynamics CRM instances associated with the user. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsCrmLinkedServiceTypePropertiesOrganizationName, self).__init__(**kwargs)


class DynamicsCrmLinkedServiceTypePropertiesPort(msrest.serialization.Model):
    """The port of on-premises Dynamics CRM server. The property is required for on-prem and not allowed for online. Default is 443. Type: integer (or Expression with resultType integer), minimum: 0.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsCrmLinkedServiceTypePropertiesPort, self).__init__(**kwargs)


class DynamicsCrmLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """The client ID of the application in Azure Active Directory used for Server-To-Server authentication. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsCrmLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class DynamicsCrmLinkedServiceTypePropertiesServiceUri(msrest.serialization.Model):
    """The URL to the Microsoft Dynamics CRM server. The property is required for on-line and not allowed for on-prem. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsCrmLinkedServiceTypePropertiesServiceUri, self).__init__(**kwargs)


class DynamicsCrmLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """User name to access the Dynamics CRM instance. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsCrmLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class DynamicsCrmSink(CopySink):
    """A copy activity Dynamics CRM sink.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :ivar write_behavior: Required. The write behavior for the operation. Default value: "Upsert".
    :vartype write_behavior: str
    :param ignore_null_values: The flag indicating whether to ignore null values from input dataset
     (except key fields) during write operation. Default is false. Type: boolean (or Expression with
     resultType boolean).
    :type ignore_null_values:
     ~data_factory_management_client.models.DynamicsCrmSinkIgnoreNullValues
    :param alternate_key_name: The logical name of the alternate key which will be used when
     upserting records. Type: string (or Expression with resultType string).
    :type alternate_key_name:
     ~data_factory_management_client.models.DynamicsCrmSinkAlternateKeyName
    """

    _validation = {
        'type': {'required': True},
        'write_behavior': {'required': True, 'constant': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'str'},
        'ignore_null_values': {'key': 'ignoreNullValues', 'type': 'DynamicsCrmSinkIgnoreNullValues'},
        'alternate_key_name': {'key': 'alternateKeyName', 'type': 'DynamicsCrmSinkAlternateKeyName'},
    }

    write_behavior = "Upsert"

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        ignore_null_values: Optional["DynamicsCrmSinkIgnoreNullValues"] = None,
        alternate_key_name: Optional["DynamicsCrmSinkAlternateKeyName"] = None,
        **kwargs
    ):
        super(DynamicsCrmSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'DynamicsCrmSink'
        self.ignore_null_values = ignore_null_values
        self.alternate_key_name = alternate_key_name


class DynamicsCrmSinkAlternateKeyName(msrest.serialization.Model):
    """The logical name of the alternate key which will be used when upserting records. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsCrmSinkAlternateKeyName, self).__init__(**kwargs)


class DynamicsCrmSinkIgnoreNullValues(msrest.serialization.Model):
    """The flag indicating whether to ignore null values from input dataset (except key fields) during write operation. Default is false. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsCrmSinkIgnoreNullValues, self).__init__(**kwargs)


class DynamicsCrmSource(CopySource):
    """A copy activity Dynamics CRM source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query: FetchXML is a proprietary query language that is used in Microsoft Dynamics CRM
     (online & on-premises). Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.DynamicsCrmSourceQuery
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query': {'key': 'query', 'type': 'DynamicsCrmSourceQuery'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query: Optional["DynamicsCrmSourceQuery"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(DynamicsCrmSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'DynamicsCrmSource'
        self.query = query
        self.additional_columns = additional_columns


class DynamicsCrmSourceQuery(msrest.serialization.Model):
    """FetchXML is a proprietary query language that is used in Microsoft Dynamics CRM (online & on-premises). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsCrmSourceQuery, self).__init__(**kwargs)


class DynamicsEntityDataset(Dataset):
    """The Dynamics entity dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param entity_name: The logical name of the entity. Type: string (or Expression with resultType
     string).
    :type entity_name:
     ~data_factory_management_client.models.DynamicsEntityDatasetTypePropertiesEntityName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'entity_name': {'key': 'typeProperties.entityName', 'type': 'DynamicsEntityDatasetTypePropertiesEntityName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        entity_name: Optional["DynamicsEntityDatasetTypePropertiesEntityName"] = None,
        **kwargs
    ):
        super(DynamicsEntityDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'DynamicsEntity'
        self.entity_name = entity_name


class DynamicsEntityDatasetTypeProperties(msrest.serialization.Model):
    """Dynamics entity dataset properties.

    :param entity_name: The logical name of the entity. Type: string (or Expression with resultType
     string).
    :type entity_name:
     ~data_factory_management_client.models.DynamicsEntityDatasetTypePropertiesEntityName
    """

    _attribute_map = {
        'entity_name': {'key': 'entityName', 'type': 'DynamicsEntityDatasetTypePropertiesEntityName'},
    }

    def __init__(
        self,
        *,
        entity_name: Optional["DynamicsEntityDatasetTypePropertiesEntityName"] = None,
        **kwargs
    ):
        super(DynamicsEntityDatasetTypeProperties, self).__init__(**kwargs)
        self.entity_name = entity_name


class DynamicsEntityDatasetTypePropertiesEntityName(msrest.serialization.Model):
    """The logical name of the entity. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsEntityDatasetTypePropertiesEntityName, self).__init__(**kwargs)


class DynamicsLinkedService(LinkedService):
    """Dynamics linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param deployment_type: Required. The deployment type of the Dynamics instance. 'Online' for
     Dynamics Online and 'OnPremisesWithIfd' for Dynamics on-premises with Ifd. Type: string (or
     Expression with resultType string). Possible values include: 'Online', 'OnPremisesWithIfd'.
    :type deployment_type: str or ~data_factory_management_client.models.DynamicsDeploymentType
    :param host_name: The host name of the on-premises Dynamics server. The property is required
     for on-prem and not allowed for online. Type: string (or Expression with resultType string).
    :type host_name:
     ~data_factory_management_client.models.DynamicsLinkedServiceTypePropertiesHostName
    :param port: The port of on-premises Dynamics server. The property is required for on-prem and
     not allowed for online. Default is 443. Type: integer (or Expression with resultType integer),
     minimum: 0.
    :type port: ~data_factory_management_client.models.DynamicsLinkedServiceTypePropertiesPort
    :param service_uri: The URL to the Microsoft Dynamics server. The property is required for on-
     line and not allowed for on-prem. Type: string (or Expression with resultType string).
    :type service_uri:
     ~data_factory_management_client.models.DynamicsLinkedServiceTypePropertiesServiceUri
    :param organization_name: The organization name of the Dynamics instance. The property is
     required for on-prem and required for online when there are more than one Dynamics instances
     associated with the user. Type: string (or Expression with resultType string).
    :type organization_name:
     ~data_factory_management_client.models.DynamicsLinkedServiceTypePropertiesOrganizationName
    :param authentication_type: Required. The authentication type to connect to Dynamics server.
     'Office365' for online scenario, 'Ifd' for on-premises with Ifd scenario, 'AADServicePrincipal'
     for Server-To-Server authentication in online scenario. Type: string (or Expression with
     resultType string). Possible values include: 'Office365', 'Ifd', 'AADServicePrincipal'.
    :type authentication_type: str or
     ~data_factory_management_client.models.DynamicsAuthenticationType
    :param username: User name to access the Dynamics instance. Type: string (or Expression with
     resultType string).
    :type username:
     ~data_factory_management_client.models.DynamicsLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param service_principal_id: The client ID of the application in Azure Active Directory used
     for Server-To-Server authentication. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.DynamicsLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_credential_type: The service principal credential type to use in
     Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
     for certificate. Type: string (or Expression with resultType string). Possible values include:
     'ServicePrincipalKey', 'ServicePrincipalCert'.
    :type service_principal_credential_type: str or
     ~data_factory_management_client.models.DynamicsServicePrincipalCredentialType
    :param service_principal_credential: The base definition of a secret type.
    :type service_principal_credential: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.DynamicsLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'deployment_type': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'deployment_type': {'key': 'typeProperties.deploymentType', 'type': 'str'},
        'host_name': {'key': 'typeProperties.hostName', 'type': 'DynamicsLinkedServiceTypePropertiesHostName'},
        'port': {'key': 'typeProperties.port', 'type': 'DynamicsLinkedServiceTypePropertiesPort'},
        'service_uri': {'key': 'typeProperties.serviceUri', 'type': 'DynamicsLinkedServiceTypePropertiesServiceUri'},
        'organization_name': {'key': 'typeProperties.organizationName', 'type': 'DynamicsLinkedServiceTypePropertiesOrganizationName'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'DynamicsLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'DynamicsLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_credential_type': {'key': 'typeProperties.servicePrincipalCredentialType', 'type': 'str'},
        'service_principal_credential': {'key': 'typeProperties.servicePrincipalCredential', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'DynamicsLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        deployment_type: Union[str, "DynamicsDeploymentType"],
        authentication_type: Union[str, "DynamicsAuthenticationType"],
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        host_name: Optional["DynamicsLinkedServiceTypePropertiesHostName"] = None,
        port: Optional["DynamicsLinkedServiceTypePropertiesPort"] = None,
        service_uri: Optional["DynamicsLinkedServiceTypePropertiesServiceUri"] = None,
        organization_name: Optional["DynamicsLinkedServiceTypePropertiesOrganizationName"] = None,
        username: Optional["DynamicsLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        service_principal_id: Optional["DynamicsLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_credential_type: Optional[Union[str, "DynamicsServicePrincipalCredentialType"]] = None,
        service_principal_credential: Optional["SecretBase"] = None,
        encrypted_credential: Optional["DynamicsLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(DynamicsLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Dynamics'
        self.deployment_type = deployment_type
        self.host_name = host_name
        self.port = port
        self.service_uri = service_uri
        self.organization_name = organization_name
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_credential_type = service_principal_credential_type
        self.service_principal_credential = service_principal_credential
        self.encrypted_credential = encrypted_credential


class DynamicsLinkedServiceTypeProperties(msrest.serialization.Model):
    """Dynamics linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param deployment_type: Required. The deployment type of the Dynamics instance. 'Online' for
     Dynamics Online and 'OnPremisesWithIfd' for Dynamics on-premises with Ifd. Type: string (or
     Expression with resultType string). Possible values include: 'Online', 'OnPremisesWithIfd'.
    :type deployment_type: str or ~data_factory_management_client.models.DynamicsDeploymentType
    :param host_name: The host name of the on-premises Dynamics server. The property is required
     for on-prem and not allowed for online. Type: string (or Expression with resultType string).
    :type host_name:
     ~data_factory_management_client.models.DynamicsLinkedServiceTypePropertiesHostName
    :param port: The port of on-premises Dynamics server. The property is required for on-prem and
     not allowed for online. Default is 443. Type: integer (or Expression with resultType integer),
     minimum: 0.
    :type port: ~data_factory_management_client.models.DynamicsLinkedServiceTypePropertiesPort
    :param service_uri: The URL to the Microsoft Dynamics server. The property is required for on-
     line and not allowed for on-prem. Type: string (or Expression with resultType string).
    :type service_uri:
     ~data_factory_management_client.models.DynamicsLinkedServiceTypePropertiesServiceUri
    :param organization_name: The organization name of the Dynamics instance. The property is
     required for on-prem and required for online when there are more than one Dynamics instances
     associated with the user. Type: string (or Expression with resultType string).
    :type organization_name:
     ~data_factory_management_client.models.DynamicsLinkedServiceTypePropertiesOrganizationName
    :param authentication_type: Required. The authentication type to connect to Dynamics server.
     'Office365' for online scenario, 'Ifd' for on-premises with Ifd scenario, 'AADServicePrincipal'
     for Server-To-Server authentication in online scenario. Type: string (or Expression with
     resultType string). Possible values include: 'Office365', 'Ifd', 'AADServicePrincipal'.
    :type authentication_type: str or
     ~data_factory_management_client.models.DynamicsAuthenticationType
    :param username: User name to access the Dynamics instance. Type: string (or Expression with
     resultType string).
    :type username:
     ~data_factory_management_client.models.DynamicsLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param service_principal_id: The client ID of the application in Azure Active Directory used
     for Server-To-Server authentication. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.DynamicsLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_credential_type: The service principal credential type to use in
     Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
     for certificate. Type: string (or Expression with resultType string). Possible values include:
     'ServicePrincipalKey', 'ServicePrincipalCert'.
    :type service_principal_credential_type: str or
     ~data_factory_management_client.models.DynamicsServicePrincipalCredentialType
    :param service_principal_credential: The base definition of a secret type.
    :type service_principal_credential: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.DynamicsLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'deployment_type': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'deployment_type': {'key': 'deploymentType', 'type': 'str'},
        'host_name': {'key': 'hostName', 'type': 'DynamicsLinkedServiceTypePropertiesHostName'},
        'port': {'key': 'port', 'type': 'DynamicsLinkedServiceTypePropertiesPort'},
        'service_uri': {'key': 'serviceUri', 'type': 'DynamicsLinkedServiceTypePropertiesServiceUri'},
        'organization_name': {'key': 'organizationName', 'type': 'DynamicsLinkedServiceTypePropertiesOrganizationName'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'username': {'key': 'username', 'type': 'DynamicsLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'DynamicsLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_credential_type': {'key': 'servicePrincipalCredentialType', 'type': 'str'},
        'service_principal_credential': {'key': 'servicePrincipalCredential', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'DynamicsLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        deployment_type: Union[str, "DynamicsDeploymentType"],
        authentication_type: Union[str, "DynamicsAuthenticationType"],
        host_name: Optional["DynamicsLinkedServiceTypePropertiesHostName"] = None,
        port: Optional["DynamicsLinkedServiceTypePropertiesPort"] = None,
        service_uri: Optional["DynamicsLinkedServiceTypePropertiesServiceUri"] = None,
        organization_name: Optional["DynamicsLinkedServiceTypePropertiesOrganizationName"] = None,
        username: Optional["DynamicsLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        service_principal_id: Optional["DynamicsLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_credential_type: Optional[Union[str, "DynamicsServicePrincipalCredentialType"]] = None,
        service_principal_credential: Optional["SecretBase"] = None,
        encrypted_credential: Optional["DynamicsLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(DynamicsLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.deployment_type = deployment_type
        self.host_name = host_name
        self.port = port
        self.service_uri = service_uri
        self.organization_name = organization_name
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_credential_type = service_principal_credential_type
        self.service_principal_credential = service_principal_credential
        self.encrypted_credential = encrypted_credential


class DynamicsLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class DynamicsLinkedServiceTypePropertiesHostName(msrest.serialization.Model):
    """The host name of the on-premises Dynamics server. The property is required for on-prem and not allowed for online. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsLinkedServiceTypePropertiesHostName, self).__init__(**kwargs)


class DynamicsLinkedServiceTypePropertiesOrganizationName(msrest.serialization.Model):
    """The organization name of the Dynamics instance. The property is required for on-prem and required for online when there are more than one Dynamics instances associated with the user. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsLinkedServiceTypePropertiesOrganizationName, self).__init__(**kwargs)


class DynamicsLinkedServiceTypePropertiesPort(msrest.serialization.Model):
    """The port of on-premises Dynamics server. The property is required for on-prem and not allowed for online. Default is 443. Type: integer (or Expression with resultType integer), minimum: 0.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsLinkedServiceTypePropertiesPort, self).__init__(**kwargs)


class DynamicsLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """The client ID of the application in Azure Active Directory used for Server-To-Server authentication. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class DynamicsLinkedServiceTypePropertiesServiceUri(msrest.serialization.Model):
    """The URL to the Microsoft Dynamics server. The property is required for on-line and not allowed for on-prem. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsLinkedServiceTypePropertiesServiceUri, self).__init__(**kwargs)


class DynamicsLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """User name to access the Dynamics instance. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class DynamicsSink(CopySink):
    """A copy activity Dynamics sink.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :ivar write_behavior: Required. The write behavior for the operation. Default value: "Upsert".
    :vartype write_behavior: str
    :param ignore_null_values: The flag indicating whether ignore null values from input dataset
     (except key fields) during write operation. Default is false. Type: boolean (or Expression with
     resultType boolean).
    :type ignore_null_values: ~data_factory_management_client.models.DynamicsSinkIgnoreNullValues
    :param alternate_key_name: The logical name of the alternate key which will be used when
     upserting records. Type: string (or Expression with resultType string).
    :type alternate_key_name: ~data_factory_management_client.models.DynamicsSinkAlternateKeyName
    """

    _validation = {
        'type': {'required': True},
        'write_behavior': {'required': True, 'constant': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'str'},
        'ignore_null_values': {'key': 'ignoreNullValues', 'type': 'DynamicsSinkIgnoreNullValues'},
        'alternate_key_name': {'key': 'alternateKeyName', 'type': 'DynamicsSinkAlternateKeyName'},
    }

    write_behavior = "Upsert"

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        ignore_null_values: Optional["DynamicsSinkIgnoreNullValues"] = None,
        alternate_key_name: Optional["DynamicsSinkAlternateKeyName"] = None,
        **kwargs
    ):
        super(DynamicsSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'DynamicsSink'
        self.ignore_null_values = ignore_null_values
        self.alternate_key_name = alternate_key_name


class DynamicsSinkAlternateKeyName(msrest.serialization.Model):
    """The logical name of the alternate key which will be used when upserting records. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsSinkAlternateKeyName, self).__init__(**kwargs)


class DynamicsSinkIgnoreNullValues(msrest.serialization.Model):
    """The flag indicating whether ignore null values from input dataset (except key fields) during write operation. Default is false. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsSinkIgnoreNullValues, self).__init__(**kwargs)


class DynamicsSource(CopySource):
    """A copy activity Dynamics source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query: FetchXML is a proprietary query language that is used in Microsoft Dynamics
     (online & on-premises). Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.DynamicsSourceQuery
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query': {'key': 'query', 'type': 'DynamicsSourceQuery'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query: Optional["DynamicsSourceQuery"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(DynamicsSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'DynamicsSource'
        self.query = query
        self.additional_columns = additional_columns


class DynamicsSourceQuery(msrest.serialization.Model):
    """FetchXML is a proprietary query language that is used in Microsoft Dynamics (online & on-premises). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(DynamicsSourceQuery, self).__init__(**kwargs)


class EloquaLinkedService(LinkedService):
    """Eloqua server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param endpoint: Required. The endpoint of the Eloqua server. (i.e. eloqua.example.com).
    :type endpoint:
     ~data_factory_management_client.models.EloquaLinkedServiceTypePropertiesEndpoint
    :param username: Required. The site name and user name of your Eloqua account in the form:
     sitename/username. (i.e. Eloqua/Alice).
    :type username:
     ~data_factory_management_client.models.EloquaLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.EloquaLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.EloquaLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.EloquaLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.EloquaLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'endpoint': {'required': True},
        'username': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'EloquaLinkedServiceTypePropertiesEndpoint'},
        'username': {'key': 'typeProperties.username', 'type': 'EloquaLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'EloquaLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'EloquaLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'EloquaLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'EloquaLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        endpoint: "EloquaLinkedServiceTypePropertiesEndpoint",
        username: "EloquaLinkedServiceTypePropertiesUsername",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        password: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["EloquaLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["EloquaLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["EloquaLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["EloquaLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(EloquaLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Eloqua'
        self.endpoint = endpoint
        self.username = username
        self.password = password
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class EloquaLinkedServiceTypeProperties(msrest.serialization.Model):
    """Eloqua server linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param endpoint: Required. The endpoint of the Eloqua server. (i.e. eloqua.example.com).
    :type endpoint:
     ~data_factory_management_client.models.EloquaLinkedServiceTypePropertiesEndpoint
    :param username: Required. The site name and user name of your Eloqua account in the form:
     sitename/username. (i.e. Eloqua/Alice).
    :type username:
     ~data_factory_management_client.models.EloquaLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.EloquaLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.EloquaLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.EloquaLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.EloquaLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'endpoint': {'required': True},
        'username': {'required': True},
    }

    _attribute_map = {
        'endpoint': {'key': 'endpoint', 'type': 'EloquaLinkedServiceTypePropertiesEndpoint'},
        'username': {'key': 'username', 'type': 'EloquaLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'EloquaLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'EloquaLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'EloquaLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'EloquaLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        endpoint: "EloquaLinkedServiceTypePropertiesEndpoint",
        username: "EloquaLinkedServiceTypePropertiesUsername",
        password: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["EloquaLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["EloquaLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["EloquaLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["EloquaLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(EloquaLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.endpoint = endpoint
        self.username = username
        self.password = password
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class EloquaLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(EloquaLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class EloquaLinkedServiceTypePropertiesEndpoint(msrest.serialization.Model):
    """The endpoint of the Eloqua server. (i.e. eloqua.example.com).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(EloquaLinkedServiceTypePropertiesEndpoint, self).__init__(**kwargs)


class EloquaLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(EloquaLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class EloquaLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(EloquaLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class EloquaLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(EloquaLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class EloquaLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """The site name and user name of your Eloqua account in the form: sitename/username. (i.e. Eloqua/Alice).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(EloquaLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class EloquaObjectDataset(Dataset):
    """Eloqua server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(EloquaObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'EloquaObject'
        self.table_name = table_name


class EloquaSource(TabularSource):
    """A copy activity Eloqua server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.EloquaSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'EloquaSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["EloquaSourceQuery"] = None,
        **kwargs
    ):
        super(EloquaSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'EloquaSource'
        self.query = query


class EloquaSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(EloquaSourceQuery, self).__init__(**kwargs)


class EntityReference(msrest.serialization.Model):
    """The entity reference.

    :param type: The type of this referenced entity. Possible values include:
     'IntegrationRuntimeReference', 'LinkedServiceReference'.
    :type type: str or ~data_factory_management_client.models.IntegrationRuntimeEntityReferenceType
    :param reference_name: The name of this referenced entity.
    :type reference_name: str
    """

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        type: Optional[Union[str, "IntegrationRuntimeEntityReferenceType"]] = None,
        reference_name: Optional[str] = None,
        **kwargs
    ):
        super(EntityReference, self).__init__(**kwargs)
        self.type = type
        self.reference_name = reference_name


class EnvironmentVariableSetup(CustomSetupBase):
    """The custom setup of setting environment variable.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. The type of custom setup.Constant filled by server.
    :type type: str
    :param variable_name: Required. The name of the environment variable.
    :type variable_name: str
    :param variable_value: Required. The value of the environment variable.
    :type variable_value: str
    """

    _validation = {
        'type': {'required': True},
        'variable_name': {'required': True},
        'variable_value': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'variable_name': {'key': 'typeProperties.variableName', 'type': 'str'},
        'variable_value': {'key': 'typeProperties.variableValue', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        variable_name: str,
        variable_value: str,
        **kwargs
    ):
        super(EnvironmentVariableSetup, self).__init__(**kwargs)
        self.type = 'EnvironmentVariableSetup'
        self.variable_name = variable_name
        self.variable_value = variable_value


class EnvironmentVariableSetupTypeProperties(msrest.serialization.Model):
    """Environment variable custom setup type properties.

    All required parameters must be populated in order to send to Azure.

    :param variable_name: Required. The name of the environment variable.
    :type variable_name: str
    :param variable_value: Required. The value of the environment variable.
    :type variable_value: str
    """

    _validation = {
        'variable_name': {'required': True},
        'variable_value': {'required': True},
    }

    _attribute_map = {
        'variable_name': {'key': 'variableName', 'type': 'str'},
        'variable_value': {'key': 'variableValue', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        variable_name: str,
        variable_value: str,
        **kwargs
    ):
        super(EnvironmentVariableSetupTypeProperties, self).__init__(**kwargs)
        self.variable_name = variable_name
        self.variable_value = variable_value


class ExecuteDataFlowActivity(ExecutionActivity):
    """Execute data flow activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param data_flow: Required. Data flow reference type.
    :type data_flow: ~data_factory_management_client.models.DataFlowReference
    :param staging: Staging info for execute data flow activity.
    :type staging: ~data_factory_management_client.models.DataFlowStagingInfo
    :param integration_runtime: Integration runtime reference type.
    :type integration_runtime: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param compute: Compute properties for data flow activity.
    :type compute:
     ~data_factory_management_client.models.ExecuteDataFlowActivityTypePropertiesCompute
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'data_flow': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'data_flow': {'key': 'typeProperties.dataFlow', 'type': 'DataFlowReference'},
        'staging': {'key': 'typeProperties.staging', 'type': 'DataFlowStagingInfo'},
        'integration_runtime': {'key': 'typeProperties.integrationRuntime', 'type': 'IntegrationRuntimeReference'},
        'compute': {'key': 'typeProperties.compute', 'type': 'ExecuteDataFlowActivityTypePropertiesCompute'},
    }

    def __init__(
        self,
        *,
        name: str,
        data_flow: "DataFlowReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        staging: Optional["DataFlowStagingInfo"] = None,
        integration_runtime: Optional["IntegrationRuntimeReference"] = None,
        compute: Optional["ExecuteDataFlowActivityTypePropertiesCompute"] = None,
        **kwargs
    ):
        super(ExecuteDataFlowActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'ExecuteDataFlow'
        self.data_flow = data_flow
        self.staging = staging
        self.integration_runtime = integration_runtime
        self.compute = compute


class ExecuteDataFlowActivityTypeProperties(msrest.serialization.Model):
    """Execute data flow activity properties.

    All required parameters must be populated in order to send to Azure.

    :param data_flow: Required. Data flow reference type.
    :type data_flow: ~data_factory_management_client.models.DataFlowReference
    :param staging: Staging info for execute data flow activity.
    :type staging: ~data_factory_management_client.models.DataFlowStagingInfo
    :param integration_runtime: Integration runtime reference type.
    :type integration_runtime: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param compute: Compute properties for data flow activity.
    :type compute:
     ~data_factory_management_client.models.ExecuteDataFlowActivityTypePropertiesCompute
    """

    _validation = {
        'data_flow': {'required': True},
    }

    _attribute_map = {
        'data_flow': {'key': 'dataFlow', 'type': 'DataFlowReference'},
        'staging': {'key': 'staging', 'type': 'DataFlowStagingInfo'},
        'integration_runtime': {'key': 'integrationRuntime', 'type': 'IntegrationRuntimeReference'},
        'compute': {'key': 'compute', 'type': 'ExecuteDataFlowActivityTypePropertiesCompute'},
    }

    def __init__(
        self,
        *,
        data_flow: "DataFlowReference",
        staging: Optional["DataFlowStagingInfo"] = None,
        integration_runtime: Optional["IntegrationRuntimeReference"] = None,
        compute: Optional["ExecuteDataFlowActivityTypePropertiesCompute"] = None,
        **kwargs
    ):
        super(ExecuteDataFlowActivityTypeProperties, self).__init__(**kwargs)
        self.data_flow = data_flow
        self.staging = staging
        self.integration_runtime = integration_runtime
        self.compute = compute


class ExecuteDataFlowActivityTypePropertiesCompute(msrest.serialization.Model):
    """Compute properties for data flow activity.

    :param compute_type: Compute type of the cluster which will execute data flow job. Possible
     values include: 'General', 'MemoryOptimized', 'ComputeOptimized'.
    :type compute_type: str or ~data_factory_management_client.models.DataFlowComputeType
    :param core_count: Core count of the cluster which will execute data flow job. Supported values
     are: 8, 16, 32, 48, 80, 144 and 272.
    :type core_count: int
    """

    _attribute_map = {
        'compute_type': {'key': 'computeType', 'type': 'str'},
        'core_count': {'key': 'coreCount', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        compute_type: Optional[Union[str, "DataFlowComputeType"]] = None,
        core_count: Optional[int] = None,
        **kwargs
    ):
        super(ExecuteDataFlowActivityTypePropertiesCompute, self).__init__(**kwargs)
        self.compute_type = compute_type
        self.core_count = core_count


class ExecutePipelineActivity(ControlActivity):
    """Execute pipeline activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param pipeline: Required. Pipeline reference type.
    :type pipeline: ~data_factory_management_client.models.PipelineReference
    :param parameters: An object mapping parameter names to argument values.
    :type parameters: dict[str, object]
    :param wait_on_completion: Defines whether activity execution will wait for the dependent
     pipeline execution to finish. Default is false.
    :type wait_on_completion: bool
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'pipeline': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'pipeline': {'key': 'typeProperties.pipeline', 'type': 'PipelineReference'},
        'parameters': {'key': 'typeProperties.parameters', 'type': '{object}'},
        'wait_on_completion': {'key': 'typeProperties.waitOnCompletion', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        name: str,
        pipeline: "PipelineReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        parameters: Optional[Dict[str, object]] = None,
        wait_on_completion: Optional[bool] = None,
        **kwargs
    ):
        super(ExecutePipelineActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'ExecutePipeline'
        self.pipeline = pipeline
        self.parameters = parameters
        self.wait_on_completion = wait_on_completion


class ExecutePipelineActivityTypeProperties(msrest.serialization.Model):
    """Execute pipeline activity properties.

    All required parameters must be populated in order to send to Azure.

    :param pipeline: Required. Pipeline reference type.
    :type pipeline: ~data_factory_management_client.models.PipelineReference
    :param parameters: An object mapping parameter names to argument values.
    :type parameters: dict[str, object]
    :param wait_on_completion: Defines whether activity execution will wait for the dependent
     pipeline execution to finish. Default is false.
    :type wait_on_completion: bool
    """

    _validation = {
        'pipeline': {'required': True},
    }

    _attribute_map = {
        'pipeline': {'key': 'pipeline', 'type': 'PipelineReference'},
        'parameters': {'key': 'parameters', 'type': '{object}'},
        'wait_on_completion': {'key': 'waitOnCompletion', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        pipeline: "PipelineReference",
        parameters: Optional[Dict[str, object]] = None,
        wait_on_completion: Optional[bool] = None,
        **kwargs
    ):
        super(ExecutePipelineActivityTypeProperties, self).__init__(**kwargs)
        self.pipeline = pipeline
        self.parameters = parameters
        self.wait_on_completion = wait_on_completion


class ExecuteSSISPackageActivity(ExecutionActivity):
    """Execute SSIS package activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param package_location: Required. SSIS package location.
    :type package_location: ~data_factory_management_client.models.SSISPackageLocation
    :param runtime: Specifies the runtime to execute SSIS package. The value should be "x86" or
     "x64". Type: string (or Expression with resultType string).
    :type runtime:
     ~data_factory_management_client.models.ExecuteSSISPackageActivityTypePropertiesRuntime
    :param logging_level: The logging level of SSIS package execution. Type: string (or Expression
     with resultType string).
    :type logging_level:
     ~data_factory_management_client.models.ExecuteSSISPackageActivityTypePropertiesLoggingLevel
    :param environment_path: The environment path to execute the SSIS package. Type: string (or
     Expression with resultType string).
    :type environment_path:
     ~data_factory_management_client.models.ExecuteSSISPackageActivityTypePropertiesEnvironmentPath
    :param execution_credential: SSIS package execution credential.
    :type execution_credential: ~data_factory_management_client.models.SSISExecutionCredential
    :param connect_via: Required. Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param project_parameters: The project level parameters to execute the SSIS package.
    :type project_parameters: dict[str,
     ~data_factory_management_client.models.SSISExecutionParameter]
    :param package_parameters: The package level parameters to execute the SSIS package.
    :type package_parameters: dict[str,
     ~data_factory_management_client.models.SSISExecutionParameter]
    :param project_connection_managers: The project level connection managers to execute the SSIS
     package.
    :type project_connection_managers: dict[str, object]
    :param package_connection_managers: The package level connection managers to execute the SSIS
     package.
    :type package_connection_managers: dict[str, object]
    :param property_overrides: The property overrides to execute the SSIS package.
    :type property_overrides: dict[str,
     ~data_factory_management_client.models.SSISPropertyOverride]
    :param log_location: SSIS package execution log location.
    :type log_location: ~data_factory_management_client.models.SSISLogLocation
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'package_location': {'required': True},
        'connect_via': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'package_location': {'key': 'typeProperties.packageLocation', 'type': 'SSISPackageLocation'},
        'runtime': {'key': 'typeProperties.runtime', 'type': 'ExecuteSSISPackageActivityTypePropertiesRuntime'},
        'logging_level': {'key': 'typeProperties.loggingLevel', 'type': 'ExecuteSSISPackageActivityTypePropertiesLoggingLevel'},
        'environment_path': {'key': 'typeProperties.environmentPath', 'type': 'ExecuteSSISPackageActivityTypePropertiesEnvironmentPath'},
        'execution_credential': {'key': 'typeProperties.executionCredential', 'type': 'SSISExecutionCredential'},
        'connect_via': {'key': 'typeProperties.connectVia', 'type': 'IntegrationRuntimeReference'},
        'project_parameters': {'key': 'typeProperties.projectParameters', 'type': '{SSISExecutionParameter}'},
        'package_parameters': {'key': 'typeProperties.packageParameters', 'type': '{SSISExecutionParameter}'},
        'project_connection_managers': {'key': 'typeProperties.projectConnectionManagers', 'type': '{object}'},
        'package_connection_managers': {'key': 'typeProperties.packageConnectionManagers', 'type': '{object}'},
        'property_overrides': {'key': 'typeProperties.propertyOverrides', 'type': '{SSISPropertyOverride}'},
        'log_location': {'key': 'typeProperties.logLocation', 'type': 'SSISLogLocation'},
    }

    def __init__(
        self,
        *,
        name: str,
        package_location: "SSISPackageLocation",
        connect_via: "IntegrationRuntimeReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        runtime: Optional["ExecuteSSISPackageActivityTypePropertiesRuntime"] = None,
        logging_level: Optional["ExecuteSSISPackageActivityTypePropertiesLoggingLevel"] = None,
        environment_path: Optional["ExecuteSSISPackageActivityTypePropertiesEnvironmentPath"] = None,
        execution_credential: Optional["SSISExecutionCredential"] = None,
        project_parameters: Optional[Dict[str, "SSISExecutionParameter"]] = None,
        package_parameters: Optional[Dict[str, "SSISExecutionParameter"]] = None,
        project_connection_managers: Optional[Dict[str, object]] = None,
        package_connection_managers: Optional[Dict[str, object]] = None,
        property_overrides: Optional[Dict[str, "SSISPropertyOverride"]] = None,
        log_location: Optional["SSISLogLocation"] = None,
        **kwargs
    ):
        super(ExecuteSSISPackageActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'ExecuteSSISPackage'
        self.package_location = package_location
        self.runtime = runtime
        self.logging_level = logging_level
        self.environment_path = environment_path
        self.execution_credential = execution_credential
        self.connect_via = connect_via
        self.project_parameters = project_parameters
        self.package_parameters = package_parameters
        self.project_connection_managers = project_connection_managers
        self.package_connection_managers = package_connection_managers
        self.property_overrides = property_overrides
        self.log_location = log_location


class ExecuteSSISPackageActivityTypeProperties(msrest.serialization.Model):
    """Execute SSIS package activity properties.

    All required parameters must be populated in order to send to Azure.

    :param package_location: Required. SSIS package location.
    :type package_location: ~data_factory_management_client.models.SSISPackageLocation
    :param runtime: Specifies the runtime to execute SSIS package. The value should be "x86" or
     "x64". Type: string (or Expression with resultType string).
    :type runtime:
     ~data_factory_management_client.models.ExecuteSSISPackageActivityTypePropertiesRuntime
    :param logging_level: The logging level of SSIS package execution. Type: string (or Expression
     with resultType string).
    :type logging_level:
     ~data_factory_management_client.models.ExecuteSSISPackageActivityTypePropertiesLoggingLevel
    :param environment_path: The environment path to execute the SSIS package. Type: string (or
     Expression with resultType string).
    :type environment_path:
     ~data_factory_management_client.models.ExecuteSSISPackageActivityTypePropertiesEnvironmentPath
    :param execution_credential: SSIS package execution credential.
    :type execution_credential: ~data_factory_management_client.models.SSISExecutionCredential
    :param connect_via: Required. Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param project_parameters: The project level parameters to execute the SSIS package.
    :type project_parameters: dict[str,
     ~data_factory_management_client.models.SSISExecutionParameter]
    :param package_parameters: The package level parameters to execute the SSIS package.
    :type package_parameters: dict[str,
     ~data_factory_management_client.models.SSISExecutionParameter]
    :param project_connection_managers: The project level connection managers to execute the SSIS
     package.
    :type project_connection_managers: dict[str, object]
    :param package_connection_managers: The package level connection managers to execute the SSIS
     package.
    :type package_connection_managers: dict[str, object]
    :param property_overrides: The property overrides to execute the SSIS package.
    :type property_overrides: dict[str,
     ~data_factory_management_client.models.SSISPropertyOverride]
    :param log_location: SSIS package execution log location.
    :type log_location: ~data_factory_management_client.models.SSISLogLocation
    """

    _validation = {
        'package_location': {'required': True},
        'connect_via': {'required': True},
    }

    _attribute_map = {
        'package_location': {'key': 'packageLocation', 'type': 'SSISPackageLocation'},
        'runtime': {'key': 'runtime', 'type': 'ExecuteSSISPackageActivityTypePropertiesRuntime'},
        'logging_level': {'key': 'loggingLevel', 'type': 'ExecuteSSISPackageActivityTypePropertiesLoggingLevel'},
        'environment_path': {'key': 'environmentPath', 'type': 'ExecuteSSISPackageActivityTypePropertiesEnvironmentPath'},
        'execution_credential': {'key': 'executionCredential', 'type': 'SSISExecutionCredential'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'project_parameters': {'key': 'projectParameters', 'type': '{SSISExecutionParameter}'},
        'package_parameters': {'key': 'packageParameters', 'type': '{SSISExecutionParameter}'},
        'project_connection_managers': {'key': 'projectConnectionManagers', 'type': '{object}'},
        'package_connection_managers': {'key': 'packageConnectionManagers', 'type': '{object}'},
        'property_overrides': {'key': 'propertyOverrides', 'type': '{SSISPropertyOverride}'},
        'log_location': {'key': 'logLocation', 'type': 'SSISLogLocation'},
    }

    def __init__(
        self,
        *,
        package_location: "SSISPackageLocation",
        connect_via: "IntegrationRuntimeReference",
        runtime: Optional["ExecuteSSISPackageActivityTypePropertiesRuntime"] = None,
        logging_level: Optional["ExecuteSSISPackageActivityTypePropertiesLoggingLevel"] = None,
        environment_path: Optional["ExecuteSSISPackageActivityTypePropertiesEnvironmentPath"] = None,
        execution_credential: Optional["SSISExecutionCredential"] = None,
        project_parameters: Optional[Dict[str, "SSISExecutionParameter"]] = None,
        package_parameters: Optional[Dict[str, "SSISExecutionParameter"]] = None,
        project_connection_managers: Optional[Dict[str, object]] = None,
        package_connection_managers: Optional[Dict[str, object]] = None,
        property_overrides: Optional[Dict[str, "SSISPropertyOverride"]] = None,
        log_location: Optional["SSISLogLocation"] = None,
        **kwargs
    ):
        super(ExecuteSSISPackageActivityTypeProperties, self).__init__(**kwargs)
        self.package_location = package_location
        self.runtime = runtime
        self.logging_level = logging_level
        self.environment_path = environment_path
        self.execution_credential = execution_credential
        self.connect_via = connect_via
        self.project_parameters = project_parameters
        self.package_parameters = package_parameters
        self.project_connection_managers = project_connection_managers
        self.package_connection_managers = package_connection_managers
        self.property_overrides = property_overrides
        self.log_location = log_location


class ExecuteSSISPackageActivityTypePropertiesEnvironmentPath(msrest.serialization.Model):
    """The environment path to execute the SSIS package. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ExecuteSSISPackageActivityTypePropertiesEnvironmentPath, self).__init__(**kwargs)


class ExecuteSSISPackageActivityTypePropertiesLoggingLevel(msrest.serialization.Model):
    """The logging level of SSIS package execution. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ExecuteSSISPackageActivityTypePropertiesLoggingLevel, self).__init__(**kwargs)


class ExecuteSSISPackageActivityTypePropertiesRuntime(msrest.serialization.Model):
    """Specifies the runtime to execute SSIS package. The value should be "x86" or "x64". Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ExecuteSSISPackageActivityTypePropertiesRuntime, self).__init__(**kwargs)


class ExposureControlRequest(msrest.serialization.Model):
    """The exposure control request.

    :param feature_name: The feature name.
    :type feature_name: str
    :param feature_type: The feature type.
    :type feature_type: str
    """

    _attribute_map = {
        'feature_name': {'key': 'featureName', 'type': 'str'},
        'feature_type': {'key': 'featureType', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        feature_name: Optional[str] = None,
        feature_type: Optional[str] = None,
        **kwargs
    ):
        super(ExposureControlRequest, self).__init__(**kwargs)
        self.feature_name = feature_name
        self.feature_type = feature_type


class ExposureControlResponse(msrest.serialization.Model):
    """The exposure control response.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar feature_name: The feature name.
    :vartype feature_name: str
    :ivar value: The feature value.
    :vartype value: str
    """

    _validation = {
        'feature_name': {'readonly': True},
        'value': {'readonly': True},
    }

    _attribute_map = {
        'feature_name': {'key': 'featureName', 'type': 'str'},
        'value': {'key': 'value', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ExposureControlResponse, self).__init__(**kwargs)
        self.feature_name = None
        self.value = None


class Expression(msrest.serialization.Model):
    """Azure Data Factory expression definition.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Expression type. Default value: "Expression".
    :vartype type: str
    :param value: Required. Expression value.
    :type value: str
    """

    _validation = {
        'type': {'required': True, 'constant': True},
        'value': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'value': {'key': 'value', 'type': 'str'},
    }

    type = "Expression"

    def __init__(
        self,
        *,
        value: str,
        **kwargs
    ):
        super(Expression, self).__init__(**kwargs)
        self.value = value


class Resource(msrest.serialization.Model):
    """Azure Data Factory top-level resource.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :param location: The resource location.
    :type location: str
    :param tags: A set of tags. The resource tags.
    :type tags: dict[str, str]
    :ivar e_tag: Etag identifies change in the resource.
    :vartype e_tag: str
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'e_tag': {'readonly': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'location': {'key': 'location', 'type': 'str'},
        'tags': {'key': 'tags', 'type': '{str}'},
        'e_tag': {'key': 'eTag', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        location: Optional[str] = None,
        tags: Optional[Dict[str, str]] = None,
        **kwargs
    ):
        super(Resource, self).__init__(**kwargs)
        self.id = None
        self.name = None
        self.type = None
        self.location = location
        self.tags = tags
        self.e_tag = None


class Factory(Resource):
    """Factory resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :param location: The resource location.
    :type location: str
    :param tags: A set of tags. The resource tags.
    :type tags: dict[str, str]
    :ivar e_tag: Etag identifies change in the resource.
    :vartype e_tag: str
    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param identity: Identity properties of the factory resource.
    :type identity: ~data_factory_management_client.models.FactoryIdentity
    :ivar provisioning_state: Factory provisioning state, example Succeeded.
    :vartype provisioning_state: str
    :ivar create_time: Time the factory was created in ISO8601 format.
    :vartype create_time: ~datetime.datetime
    :ivar version: Version of the factory.
    :vartype version: str
    :param repo_configuration: Factory's git repo information.
    :type repo_configuration: ~data_factory_management_client.models.FactoryRepoConfiguration
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'e_tag': {'readonly': True},
        'provisioning_state': {'readonly': True},
        'create_time': {'readonly': True},
        'version': {'readonly': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'location': {'key': 'location', 'type': 'str'},
        'tags': {'key': 'tags', 'type': '{str}'},
        'e_tag': {'key': 'eTag', 'type': 'str'},
        'additional_properties': {'key': '', 'type': '{object}'},
        'identity': {'key': 'identity', 'type': 'FactoryIdentity'},
        'provisioning_state': {'key': 'properties.provisioningState', 'type': 'str'},
        'create_time': {'key': 'properties.createTime', 'type': 'iso-8601'},
        'version': {'key': 'properties.version', 'type': 'str'},
        'repo_configuration': {'key': 'properties.repoConfiguration', 'type': 'FactoryRepoConfiguration'},
    }

    def __init__(
        self,
        *,
        location: Optional[str] = None,
        tags: Optional[Dict[str, str]] = None,
        additional_properties: Optional[Dict[str, object]] = None,
        identity: Optional["FactoryIdentity"] = None,
        repo_configuration: Optional["FactoryRepoConfiguration"] = None,
        **kwargs
    ):
        super(Factory, self).__init__(location=location, tags=tags, **kwargs)
        self.additional_properties = additional_properties
        self.identity = identity
        self.provisioning_state = None
        self.create_time = None
        self.version = None
        self.repo_configuration = repo_configuration


class FactoryRepoConfiguration(msrest.serialization.Model):
    """Factory's git repo information.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: FactoryGitHubConfiguration, FactoryVSTSConfiguration.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. Type of repo configuration.Constant filled by server.
    :type type: str
    :param account_name: Required. Account name.
    :type account_name: str
    :param repository_name: Required. Repository name.
    :type repository_name: str
    :param collaboration_branch: Required. Collaboration branch.
    :type collaboration_branch: str
    :param root_folder: Required. Root folder.
    :type root_folder: str
    :param last_commit_id: Last commit id.
    :type last_commit_id: str
    """

    _validation = {
        'type': {'required': True},
        'account_name': {'required': True},
        'repository_name': {'required': True},
        'collaboration_branch': {'required': True},
        'root_folder': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'account_name': {'key': 'accountName', 'type': 'str'},
        'repository_name': {'key': 'repositoryName', 'type': 'str'},
        'collaboration_branch': {'key': 'collaborationBranch', 'type': 'str'},
        'root_folder': {'key': 'rootFolder', 'type': 'str'},
        'last_commit_id': {'key': 'lastCommitId', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'FactoryGitHubConfiguration': 'FactoryGitHubConfiguration', 'FactoryVSTSConfiguration': 'FactoryVSTSConfiguration'}
    }

    def __init__(
        self,
        *,
        account_name: str,
        repository_name: str,
        collaboration_branch: str,
        root_folder: str,
        last_commit_id: Optional[str] = None,
        **kwargs
    ):
        super(FactoryRepoConfiguration, self).__init__(**kwargs)
        self.type = None
        self.account_name = account_name
        self.repository_name = repository_name
        self.collaboration_branch = collaboration_branch
        self.root_folder = root_folder
        self.last_commit_id = last_commit_id


class FactoryGitHubConfiguration(FactoryRepoConfiguration):
    """Factory's GitHub repo information.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. Type of repo configuration.Constant filled by server.
    :type type: str
    :param account_name: Required. Account name.
    :type account_name: str
    :param repository_name: Required. Repository name.
    :type repository_name: str
    :param collaboration_branch: Required. Collaboration branch.
    :type collaboration_branch: str
    :param root_folder: Required. Root folder.
    :type root_folder: str
    :param last_commit_id: Last commit id.
    :type last_commit_id: str
    :param host_name: GitHub Enterprise host name. For example: https://github.mydomain.com.
    :type host_name: str
    """

    _validation = {
        'type': {'required': True},
        'account_name': {'required': True},
        'repository_name': {'required': True},
        'collaboration_branch': {'required': True},
        'root_folder': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'account_name': {'key': 'accountName', 'type': 'str'},
        'repository_name': {'key': 'repositoryName', 'type': 'str'},
        'collaboration_branch': {'key': 'collaborationBranch', 'type': 'str'},
        'root_folder': {'key': 'rootFolder', 'type': 'str'},
        'last_commit_id': {'key': 'lastCommitId', 'type': 'str'},
        'host_name': {'key': 'hostName', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        account_name: str,
        repository_name: str,
        collaboration_branch: str,
        root_folder: str,
        last_commit_id: Optional[str] = None,
        host_name: Optional[str] = None,
        **kwargs
    ):
        super(FactoryGitHubConfiguration, self).__init__(account_name=account_name, repository_name=repository_name, collaboration_branch=collaboration_branch, root_folder=root_folder, last_commit_id=last_commit_id, **kwargs)
        self.type = 'FactoryGitHubConfiguration'
        self.host_name = host_name


class FactoryIdentity(msrest.serialization.Model):
    """Identity properties of the factory resource.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. The identity type. Currently the only supported type is 'SystemAssigned'.
     Default value: "SystemAssigned".
    :vartype type: str
    :ivar principal_id: The principal id of the identity.
    :vartype principal_id: str
    :ivar tenant_id: The client tenant id of the identity.
    :vartype tenant_id: str
    """

    _validation = {
        'type': {'required': True, 'constant': True},
        'principal_id': {'readonly': True},
        'tenant_id': {'readonly': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'principal_id': {'key': 'principalId', 'type': 'str'},
        'tenant_id': {'key': 'tenantId', 'type': 'str'},
    }

    type = "SystemAssigned"

    def __init__(
        self,
        **kwargs
    ):
        super(FactoryIdentity, self).__init__(**kwargs)
        self.principal_id = None
        self.tenant_id = None


class FactoryListResponse(msrest.serialization.Model):
    """A list of factory resources.

    All required parameters must be populated in order to send to Azure.

    :param value: Required. List of factories.
    :type value: list[~data_factory_management_client.models.Factory]
    :param next_link: The link to the next page of results, if any remaining results exist.
    :type next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[Factory]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["Factory"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        super(FactoryListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class FactoryProperties(msrest.serialization.Model):
    """Factory resource properties.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar provisioning_state: Factory provisioning state, example Succeeded.
    :vartype provisioning_state: str
    :ivar create_time: Time the factory was created in ISO8601 format.
    :vartype create_time: ~datetime.datetime
    :ivar version: Version of the factory.
    :vartype version: str
    :param repo_configuration: Factory's git repo information.
    :type repo_configuration: ~data_factory_management_client.models.FactoryRepoConfiguration
    """

    _validation = {
        'provisioning_state': {'readonly': True},
        'create_time': {'readonly': True},
        'version': {'readonly': True},
    }

    _attribute_map = {
        'provisioning_state': {'key': 'provisioningState', 'type': 'str'},
        'create_time': {'key': 'createTime', 'type': 'iso-8601'},
        'version': {'key': 'version', 'type': 'str'},
        'repo_configuration': {'key': 'repoConfiguration', 'type': 'FactoryRepoConfiguration'},
    }

    def __init__(
        self,
        *,
        repo_configuration: Optional["FactoryRepoConfiguration"] = None,
        **kwargs
    ):
        super(FactoryProperties, self).__init__(**kwargs)
        self.provisioning_state = None
        self.create_time = None
        self.version = None
        self.repo_configuration = repo_configuration


class FactoryRepoUpdate(msrest.serialization.Model):
    """Factory's git repo information.

    :param factory_resource_id: The factory resource id.
    :type factory_resource_id: str
    :param repo_configuration: Factory's git repo information.
    :type repo_configuration: ~data_factory_management_client.models.FactoryRepoConfiguration
    """

    _attribute_map = {
        'factory_resource_id': {'key': 'factoryResourceId', 'type': 'str'},
        'repo_configuration': {'key': 'repoConfiguration', 'type': 'FactoryRepoConfiguration'},
    }

    def __init__(
        self,
        *,
        factory_resource_id: Optional[str] = None,
        repo_configuration: Optional["FactoryRepoConfiguration"] = None,
        **kwargs
    ):
        super(FactoryRepoUpdate, self).__init__(**kwargs)
        self.factory_resource_id = factory_resource_id
        self.repo_configuration = repo_configuration


class FactoryUpdateParameters(msrest.serialization.Model):
    """Parameters for updating a factory resource.

    :param tags: A set of tags. The resource tags.
    :type tags: dict[str, str]
    :param identity: Identity properties of the factory resource.
    :type identity: ~data_factory_management_client.models.FactoryIdentity
    """

    _attribute_map = {
        'tags': {'key': 'tags', 'type': '{str}'},
        'identity': {'key': 'identity', 'type': 'FactoryIdentity'},
    }

    def __init__(
        self,
        *,
        tags: Optional[Dict[str, str]] = None,
        identity: Optional["FactoryIdentity"] = None,
        **kwargs
    ):
        super(FactoryUpdateParameters, self).__init__(**kwargs)
        self.tags = tags
        self.identity = identity


class FactoryVSTSConfiguration(FactoryRepoConfiguration):
    """Factory's VSTS repo information.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. Type of repo configuration.Constant filled by server.
    :type type: str
    :param account_name: Required. Account name.
    :type account_name: str
    :param repository_name: Required. Repository name.
    :type repository_name: str
    :param collaboration_branch: Required. Collaboration branch.
    :type collaboration_branch: str
    :param root_folder: Required. Root folder.
    :type root_folder: str
    :param last_commit_id: Last commit id.
    :type last_commit_id: str
    :param project_name: Required. VSTS project name.
    :type project_name: str
    :param tenant_id: VSTS tenant id.
    :type tenant_id: str
    """

    _validation = {
        'type': {'required': True},
        'account_name': {'required': True},
        'repository_name': {'required': True},
        'collaboration_branch': {'required': True},
        'root_folder': {'required': True},
        'project_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'account_name': {'key': 'accountName', 'type': 'str'},
        'repository_name': {'key': 'repositoryName', 'type': 'str'},
        'collaboration_branch': {'key': 'collaborationBranch', 'type': 'str'},
        'root_folder': {'key': 'rootFolder', 'type': 'str'},
        'last_commit_id': {'key': 'lastCommitId', 'type': 'str'},
        'project_name': {'key': 'projectName', 'type': 'str'},
        'tenant_id': {'key': 'tenantId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        account_name: str,
        repository_name: str,
        collaboration_branch: str,
        root_folder: str,
        project_name: str,
        last_commit_id: Optional[str] = None,
        tenant_id: Optional[str] = None,
        **kwargs
    ):
        super(FactoryVSTSConfiguration, self).__init__(account_name=account_name, repository_name=repository_name, collaboration_branch=collaboration_branch, root_folder=root_folder, last_commit_id=last_commit_id, **kwargs)
        self.type = 'FactoryVSTSConfiguration'
        self.project_name = project_name
        self.tenant_id = tenant_id


class FileServerLinkedService(LinkedService):
    """File system linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. Host name of the server. Type: string (or Expression with resultType
     string).
    :type host: ~data_factory_management_client.models.FileServerLinkedServiceTypePropertiesHost
    :param user_id: User ID to logon the server. Type: string (or Expression with resultType
     string).
    :type user_id:
     ~data_factory_management_client.models.FileServerLinkedServiceTypePropertiesUserId
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.FileServerLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'FileServerLinkedServiceTypePropertiesHost'},
        'user_id': {'key': 'typeProperties.userId', 'type': 'FileServerLinkedServiceTypePropertiesUserId'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'FileServerLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "FileServerLinkedServiceTypePropertiesHost",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        user_id: Optional["FileServerLinkedServiceTypePropertiesUserId"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["FileServerLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(FileServerLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'FileServer'
        self.host = host
        self.user_id = user_id
        self.password = password
        self.encrypted_credential = encrypted_credential


class FileServerLinkedServiceTypeProperties(msrest.serialization.Model):
    """File system linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. Host name of the server. Type: string (or Expression with resultType
     string).
    :type host: ~data_factory_management_client.models.FileServerLinkedServiceTypePropertiesHost
    :param user_id: User ID to logon the server. Type: string (or Expression with resultType
     string).
    :type user_id:
     ~data_factory_management_client.models.FileServerLinkedServiceTypePropertiesUserId
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.FileServerLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'FileServerLinkedServiceTypePropertiesHost'},
        'user_id': {'key': 'userId', 'type': 'FileServerLinkedServiceTypePropertiesUserId'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'FileServerLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "FileServerLinkedServiceTypePropertiesHost",
        user_id: Optional["FileServerLinkedServiceTypePropertiesUserId"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["FileServerLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(FileServerLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.user_id = user_id
        self.password = password
        self.encrypted_credential = encrypted_credential


class FileServerLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileServerLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class FileServerLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """Host name of the server. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileServerLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class FileServerLinkedServiceTypePropertiesUserId(msrest.serialization.Model):
    """User ID to logon the server. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileServerLinkedServiceTypePropertiesUserId, self).__init__(**kwargs)


class FileServerLocation(DatasetLocation):
    """The location of file server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage location.Constant filled by server.
    :type type: str
    :param folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :type folder_path: ~data_factory_management_client.models.DatasetLocationFolderPath
    :param file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :type file_name: ~data_factory_management_client.models.DatasetLocationFileName
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'DatasetLocationFolderPath'},
        'file_name': {'key': 'fileName', 'type': 'DatasetLocationFileName'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        folder_path: Optional["DatasetLocationFolderPath"] = None,
        file_name: Optional["DatasetLocationFileName"] = None,
        **kwargs
    ):
        super(FileServerLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'FileServerLocation'


class FileServerReadSettings(StoreReadSettings):
    """File server read settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The read setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreReadSettingsMaxConcurrentConnections
    :param recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.FileServerReadSettingsRecursive
    :param wildcard_folder_path: FileServer wildcardFolderPath. Type: string (or Expression with
     resultType string).
    :type wildcard_folder_path:
     ~data_factory_management_client.models.FileServerReadSettingsWildcardFolderPath
    :param wildcard_file_name: FileServer wildcardFileName. Type: string (or Expression with
     resultType string).
    :type wildcard_file_name:
     ~data_factory_management_client.models.FileServerReadSettingsWildcardFileName
    :param file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :type file_list_path: ~data_factory_management_client.models.FileServerReadSettingsFileListPath
    :param enable_partition_discovery: Indicates whether to enable partition discovery.
    :type enable_partition_discovery: bool
    :param modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_start:
     ~data_factory_management_client.models.FileServerReadSettingsModifiedDatetimeStart
    :param modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :type modified_datetime_end:
     ~data_factory_management_client.models.FileServerReadSettingsModifiedDatetimeEnd
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreReadSettingsMaxConcurrentConnections'},
        'recursive': {'key': 'recursive', 'type': 'FileServerReadSettingsRecursive'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'FileServerReadSettingsWildcardFolderPath'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'FileServerReadSettingsWildcardFileName'},
        'file_list_path': {'key': 'fileListPath', 'type': 'FileServerReadSettingsFileListPath'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'FileServerReadSettingsModifiedDatetimeStart'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'FileServerReadSettingsModifiedDatetimeEnd'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreReadSettingsMaxConcurrentConnections"] = None,
        recursive: Optional["FileServerReadSettingsRecursive"] = None,
        wildcard_folder_path: Optional["FileServerReadSettingsWildcardFolderPath"] = None,
        wildcard_file_name: Optional["FileServerReadSettingsWildcardFileName"] = None,
        file_list_path: Optional["FileServerReadSettingsFileListPath"] = None,
        enable_partition_discovery: Optional[bool] = None,
        modified_datetime_start: Optional["FileServerReadSettingsModifiedDatetimeStart"] = None,
        modified_datetime_end: Optional["FileServerReadSettingsModifiedDatetimeEnd"] = None,
        **kwargs
    ):
        super(FileServerReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'FileServerReadSettings'
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class FileServerReadSettingsFileListPath(msrest.serialization.Model):
    """Point to a text file that lists each file (relative path to the path configured in the dataset) that you want to copy. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileServerReadSettingsFileListPath, self).__init__(**kwargs)


class FileServerReadSettingsModifiedDatetimeEnd(msrest.serialization.Model):
    """The end of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileServerReadSettingsModifiedDatetimeEnd, self).__init__(**kwargs)


class FileServerReadSettingsModifiedDatetimeStart(msrest.serialization.Model):
    """The start of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileServerReadSettingsModifiedDatetimeStart, self).__init__(**kwargs)


class FileServerReadSettingsRecursive(msrest.serialization.Model):
    """If true, files under the folder path will be read recursively. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileServerReadSettingsRecursive, self).__init__(**kwargs)


class FileServerReadSettingsWildcardFileName(msrest.serialization.Model):
    """FileServer wildcardFileName. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileServerReadSettingsWildcardFileName, self).__init__(**kwargs)


class FileServerReadSettingsWildcardFolderPath(msrest.serialization.Model):
    """FileServer wildcardFolderPath. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileServerReadSettingsWildcardFolderPath, self).__init__(**kwargs)


class FileServerWriteSettings(StoreWriteSettings):
    """File server write settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The write setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreWriteSettingsMaxConcurrentConnections
    :param copy_behavior: The type of copy behavior for copy sink.
    :type copy_behavior: ~data_factory_management_client.models.StoreWriteSettingsCopyBehavior
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreWriteSettingsMaxConcurrentConnections'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'StoreWriteSettingsCopyBehavior'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreWriteSettingsMaxConcurrentConnections"] = None,
        copy_behavior: Optional["StoreWriteSettingsCopyBehavior"] = None,
        **kwargs
    ):
        super(FileServerWriteSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, copy_behavior=copy_behavior, **kwargs)
        self.type = 'FileServerWriteSettings'


class FileShareDataset(Dataset):
    """An on-premises file system dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param folder_path: The path of the on-premises file system. Type: string (or Expression with
     resultType string).
    :type folder_path:
     ~data_factory_management_client.models.FileShareDatasetTypePropertiesFolderPath
    :param file_name: The name of the on-premises file system. Type: string (or Expression with
     resultType string).
    :type file_name: ~data_factory_management_client.models.FileShareDatasetTypePropertiesFileName
    :param modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_start:
     ~data_factory_management_client.models.FileShareDatasetTypePropertiesModifiedDatetimeStart
    :param modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :type modified_datetime_end:
     ~data_factory_management_client.models.FileShareDatasetTypePropertiesModifiedDatetimeEnd
    :param format: The format definition of a storage.
    :type format: ~data_factory_management_client.models.DatasetStorageFormat
    :param file_filter: Specify a filter to be used to select a subset of files in the folderPath
     rather than all files. Type: string (or Expression with resultType string).
    :type file_filter:
     ~data_factory_management_client.models.FileShareDatasetTypePropertiesFileFilter
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'folder_path': {'key': 'typeProperties.folderPath', 'type': 'FileShareDatasetTypePropertiesFolderPath'},
        'file_name': {'key': 'typeProperties.fileName', 'type': 'FileShareDatasetTypePropertiesFileName'},
        'modified_datetime_start': {'key': 'typeProperties.modifiedDatetimeStart', 'type': 'FileShareDatasetTypePropertiesModifiedDatetimeStart'},
        'modified_datetime_end': {'key': 'typeProperties.modifiedDatetimeEnd', 'type': 'FileShareDatasetTypePropertiesModifiedDatetimeEnd'},
        'format': {'key': 'typeProperties.format', 'type': 'DatasetStorageFormat'},
        'file_filter': {'key': 'typeProperties.fileFilter', 'type': 'FileShareDatasetTypePropertiesFileFilter'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        folder_path: Optional["FileShareDatasetTypePropertiesFolderPath"] = None,
        file_name: Optional["FileShareDatasetTypePropertiesFileName"] = None,
        modified_datetime_start: Optional["FileShareDatasetTypePropertiesModifiedDatetimeStart"] = None,
        modified_datetime_end: Optional["FileShareDatasetTypePropertiesModifiedDatetimeEnd"] = None,
        format: Optional["DatasetStorageFormat"] = None,
        file_filter: Optional["FileShareDatasetTypePropertiesFileFilter"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(FileShareDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'FileShare'
        self.folder_path = folder_path
        self.file_name = file_name
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end
        self.format = format
        self.file_filter = file_filter
        self.compression = compression


class FileShareDatasetTypeProperties(msrest.serialization.Model):
    """On-premises file system dataset properties.

    :param folder_path: The path of the on-premises file system. Type: string (or Expression with
     resultType string).
    :type folder_path:
     ~data_factory_management_client.models.FileShareDatasetTypePropertiesFolderPath
    :param file_name: The name of the on-premises file system. Type: string (or Expression with
     resultType string).
    :type file_name: ~data_factory_management_client.models.FileShareDatasetTypePropertiesFileName
    :param modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_start:
     ~data_factory_management_client.models.FileShareDatasetTypePropertiesModifiedDatetimeStart
    :param modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :type modified_datetime_end:
     ~data_factory_management_client.models.FileShareDatasetTypePropertiesModifiedDatetimeEnd
    :param format: The format definition of a storage.
    :type format: ~data_factory_management_client.models.DatasetStorageFormat
    :param file_filter: Specify a filter to be used to select a subset of files in the folderPath
     rather than all files. Type: string (or Expression with resultType string).
    :type file_filter:
     ~data_factory_management_client.models.FileShareDatasetTypePropertiesFileFilter
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _attribute_map = {
        'folder_path': {'key': 'folderPath', 'type': 'FileShareDatasetTypePropertiesFolderPath'},
        'file_name': {'key': 'fileName', 'type': 'FileShareDatasetTypePropertiesFileName'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'FileShareDatasetTypePropertiesModifiedDatetimeStart'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'FileShareDatasetTypePropertiesModifiedDatetimeEnd'},
        'format': {'key': 'format', 'type': 'DatasetStorageFormat'},
        'file_filter': {'key': 'fileFilter', 'type': 'FileShareDatasetTypePropertiesFileFilter'},
        'compression': {'key': 'compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        folder_path: Optional["FileShareDatasetTypePropertiesFolderPath"] = None,
        file_name: Optional["FileShareDatasetTypePropertiesFileName"] = None,
        modified_datetime_start: Optional["FileShareDatasetTypePropertiesModifiedDatetimeStart"] = None,
        modified_datetime_end: Optional["FileShareDatasetTypePropertiesModifiedDatetimeEnd"] = None,
        format: Optional["DatasetStorageFormat"] = None,
        file_filter: Optional["FileShareDatasetTypePropertiesFileFilter"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(FileShareDatasetTypeProperties, self).__init__(**kwargs)
        self.folder_path = folder_path
        self.file_name = file_name
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end
        self.format = format
        self.file_filter = file_filter
        self.compression = compression


class FileShareDatasetTypePropertiesFileFilter(msrest.serialization.Model):
    """Specify a filter to be used to select a subset of files in the folderPath rather than all files. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileShareDatasetTypePropertiesFileFilter, self).__init__(**kwargs)


class FileShareDatasetTypePropertiesFileName(msrest.serialization.Model):
    """The name of the on-premises file system. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileShareDatasetTypePropertiesFileName, self).__init__(**kwargs)


class FileShareDatasetTypePropertiesFolderPath(msrest.serialization.Model):
    """The path of the on-premises file system. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileShareDatasetTypePropertiesFolderPath, self).__init__(**kwargs)


class FileShareDatasetTypePropertiesModifiedDatetimeEnd(msrest.serialization.Model):
    """The end of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileShareDatasetTypePropertiesModifiedDatetimeEnd, self).__init__(**kwargs)


class FileShareDatasetTypePropertiesModifiedDatetimeStart(msrest.serialization.Model):
    """The start of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileShareDatasetTypePropertiesModifiedDatetimeStart, self).__init__(**kwargs)


class FileSystemSink(CopySink):
    """A copy activity file system sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param copy_behavior: The type of copy behavior for copy sink.
    :type copy_behavior: ~data_factory_management_client.models.FileSystemSinkCopyBehavior
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'FileSystemSinkCopyBehavior'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        copy_behavior: Optional["FileSystemSinkCopyBehavior"] = None,
        **kwargs
    ):
        super(FileSystemSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'FileSystemSink'
        self.copy_behavior = copy_behavior


class FileSystemSinkCopyBehavior(msrest.serialization.Model):
    """The type of copy behavior for copy sink.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileSystemSinkCopyBehavior, self).__init__(**kwargs)


class FileSystemSource(CopySource):
    """A copy activity file system source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.FileSystemSourceRecursive
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'recursive': {'key': 'recursive', 'type': 'FileSystemSourceRecursive'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        recursive: Optional["FileSystemSourceRecursive"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(FileSystemSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'FileSystemSource'
        self.recursive = recursive
        self.additional_columns = additional_columns


class FileSystemSourceRecursive(msrest.serialization.Model):
    """If true, files under the folder path will be read recursively. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FileSystemSourceRecursive, self).__init__(**kwargs)


class FilterActivity(ControlActivity):
    """Filter and return results from input array based on the conditions.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param items: Required. Azure Data Factory expression definition.
    :type items: ~data_factory_management_client.models.Expression
    :param condition: Required. Azure Data Factory expression definition.
    :type condition: ~data_factory_management_client.models.Expression
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'items': {'required': True},
        'condition': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'items': {'key': 'typeProperties.items', 'type': 'Expression'},
        'condition': {'key': 'typeProperties.condition', 'type': 'Expression'},
    }

    def __init__(
        self,
        *,
        name: str,
        items: "Expression",
        condition: "Expression",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        **kwargs
    ):
        super(FilterActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'Filter'
        self.items = items
        self.condition = condition


class FilterActivityTypeProperties(msrest.serialization.Model):
    """Filter activity properties.

    All required parameters must be populated in order to send to Azure.

    :param items: Required. Azure Data Factory expression definition.
    :type items: ~data_factory_management_client.models.Expression
    :param condition: Required. Azure Data Factory expression definition.
    :type condition: ~data_factory_management_client.models.Expression
    """

    _validation = {
        'items': {'required': True},
        'condition': {'required': True},
    }

    _attribute_map = {
        'items': {'key': 'items', 'type': 'Expression'},
        'condition': {'key': 'condition', 'type': 'Expression'},
    }

    def __init__(
        self,
        *,
        items: "Expression",
        condition: "Expression",
        **kwargs
    ):
        super(FilterActivityTypeProperties, self).__init__(**kwargs)
        self.items = items
        self.condition = condition


class ForEachActivity(ControlActivity):
    """This activity is used for iterating over a collection and execute given activities.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param is_sequential: Should the loop be executed in sequence or in parallel (max 50).
    :type is_sequential: bool
    :param batch_count: Batch count to be used for controlling the number of parallel execution
     (when isSequential is set to false).
    :type batch_count: int
    :param items: Required. Azure Data Factory expression definition.
    :type items: ~data_factory_management_client.models.Expression
    :param activities: Required. List of activities to execute .
    :type activities: list[~data_factory_management_client.models.Activity]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'batch_count': {'maximum': 50},
        'items': {'required': True},
        'activities': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'is_sequential': {'key': 'typeProperties.isSequential', 'type': 'bool'},
        'batch_count': {'key': 'typeProperties.batchCount', 'type': 'int'},
        'items': {'key': 'typeProperties.items', 'type': 'Expression'},
        'activities': {'key': 'typeProperties.activities', 'type': '[Activity]'},
    }

    def __init__(
        self,
        *,
        name: str,
        items: "Expression",
        activities: List["Activity"],
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        is_sequential: Optional[bool] = None,
        batch_count: Optional[int] = None,
        **kwargs
    ):
        super(ForEachActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'ForEach'
        self.is_sequential = is_sequential
        self.batch_count = batch_count
        self.items = items
        self.activities = activities


class ForEachActivityTypeProperties(msrest.serialization.Model):
    """ForEach activity properties.

    All required parameters must be populated in order to send to Azure.

    :param is_sequential: Should the loop be executed in sequence or in parallel (max 50).
    :type is_sequential: bool
    :param batch_count: Batch count to be used for controlling the number of parallel execution
     (when isSequential is set to false).
    :type batch_count: int
    :param items: Required. Azure Data Factory expression definition.
    :type items: ~data_factory_management_client.models.Expression
    :param activities: Required. List of activities to execute .
    :type activities: list[~data_factory_management_client.models.Activity]
    """

    _validation = {
        'batch_count': {'maximum': 50},
        'items': {'required': True},
        'activities': {'required': True},
    }

    _attribute_map = {
        'is_sequential': {'key': 'isSequential', 'type': 'bool'},
        'batch_count': {'key': 'batchCount', 'type': 'int'},
        'items': {'key': 'items', 'type': 'Expression'},
        'activities': {'key': 'activities', 'type': '[Activity]'},
    }

    def __init__(
        self,
        *,
        items: "Expression",
        activities: List["Activity"],
        is_sequential: Optional[bool] = None,
        batch_count: Optional[int] = None,
        **kwargs
    ):
        super(ForEachActivityTypeProperties, self).__init__(**kwargs)
        self.is_sequential = is_sequential
        self.batch_count = batch_count
        self.items = items
        self.activities = activities


class FtpReadSettings(StoreReadSettings):
    """Ftp read settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The read setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreReadSettingsMaxConcurrentConnections
    :param recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.FtpReadSettingsRecursive
    :param wildcard_folder_path: Ftp wildcardFolderPath. Type: string (or Expression with
     resultType string).
    :type wildcard_folder_path:
     ~data_factory_management_client.models.FtpReadSettingsWildcardFolderPath
    :param wildcard_file_name: Ftp wildcardFileName. Type: string (or Expression with resultType
     string).
    :type wildcard_file_name:
     ~data_factory_management_client.models.FtpReadSettingsWildcardFileName
    :param file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :type file_list_path: ~data_factory_management_client.models.FtpReadSettingsFileListPath
    :param use_binary_transfer: Specify whether to use binary transfer mode for FTP stores.
    :type use_binary_transfer: bool
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreReadSettingsMaxConcurrentConnections'},
        'recursive': {'key': 'recursive', 'type': 'FtpReadSettingsRecursive'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'FtpReadSettingsWildcardFolderPath'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'FtpReadSettingsWildcardFileName'},
        'file_list_path': {'key': 'fileListPath', 'type': 'FtpReadSettingsFileListPath'},
        'use_binary_transfer': {'key': 'useBinaryTransfer', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreReadSettingsMaxConcurrentConnections"] = None,
        recursive: Optional["FtpReadSettingsRecursive"] = None,
        wildcard_folder_path: Optional["FtpReadSettingsWildcardFolderPath"] = None,
        wildcard_file_name: Optional["FtpReadSettingsWildcardFileName"] = None,
        file_list_path: Optional["FtpReadSettingsFileListPath"] = None,
        use_binary_transfer: Optional[bool] = None,
        **kwargs
    ):
        super(FtpReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'FtpReadSettings'
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.file_list_path = file_list_path
        self.use_binary_transfer = use_binary_transfer


class FtpReadSettingsFileListPath(msrest.serialization.Model):
    """Point to a text file that lists each file (relative path to the path configured in the dataset) that you want to copy. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FtpReadSettingsFileListPath, self).__init__(**kwargs)


class FtpReadSettingsRecursive(msrest.serialization.Model):
    """If true, files under the folder path will be read recursively. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FtpReadSettingsRecursive, self).__init__(**kwargs)


class FtpReadSettingsWildcardFileName(msrest.serialization.Model):
    """Ftp wildcardFileName. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FtpReadSettingsWildcardFileName, self).__init__(**kwargs)


class FtpReadSettingsWildcardFolderPath(msrest.serialization.Model):
    """Ftp wildcardFolderPath. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FtpReadSettingsWildcardFolderPath, self).__init__(**kwargs)


class FtpServerLinkedService(LinkedService):
    """A FTP server Linked Service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. Host name of the FTP server. Type: string (or Expression with resultType
     string).
    :type host: ~data_factory_management_client.models.FtpServerLinkedServiceTypePropertiesHost
    :param port: The TCP port number that the FTP server uses to listen for client connections.
     Default value is 21. Type: integer (or Expression with resultType integer), minimum: 0.
    :type port: ~data_factory_management_client.models.FtpServerLinkedServiceTypePropertiesPort
    :param authentication_type: The authentication type to be used to connect to the FTP server.
     Possible values include: 'Basic', 'Anonymous'.
    :type authentication_type: str or ~data_factory_management_client.models.FtpAuthenticationType
    :param user_name: Username to logon the FTP server. Type: string (or Expression with resultType
     string).
    :type user_name:
     ~data_factory_management_client.models.FtpServerLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.FtpServerLinkedServiceTypePropertiesEncryptedCredential
    :param enable_ssl: If true, connect to the FTP server over SSL/TLS channel. Default value is
     true. Type: boolean (or Expression with resultType boolean).
    :type enable_ssl:
     ~data_factory_management_client.models.FtpServerLinkedServiceTypePropertiesEnableSsl
    :param enable_server_certificate_validation: If true, validate the FTP server SSL certificate
     when connect over SSL/TLS channel. Default value is true. Type: boolean (or Expression with
     resultType boolean).
    :type enable_server_certificate_validation:
     ~data_factory_management_client.models.FtpServerLinkedServiceTypePropertiesEnableServerCertificateValidation
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'FtpServerLinkedServiceTypePropertiesHost'},
        'port': {'key': 'typeProperties.port', 'type': 'FtpServerLinkedServiceTypePropertiesPort'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'FtpServerLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'FtpServerLinkedServiceTypePropertiesEncryptedCredential'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'FtpServerLinkedServiceTypePropertiesEnableSsl'},
        'enable_server_certificate_validation': {'key': 'typeProperties.enableServerCertificateValidation', 'type': 'FtpServerLinkedServiceTypePropertiesEnableServerCertificateValidation'},
    }

    def __init__(
        self,
        *,
        host: "FtpServerLinkedServiceTypePropertiesHost",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        port: Optional["FtpServerLinkedServiceTypePropertiesPort"] = None,
        authentication_type: Optional[Union[str, "FtpAuthenticationType"]] = None,
        user_name: Optional["FtpServerLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["FtpServerLinkedServiceTypePropertiesEncryptedCredential"] = None,
        enable_ssl: Optional["FtpServerLinkedServiceTypePropertiesEnableSsl"] = None,
        enable_server_certificate_validation: Optional["FtpServerLinkedServiceTypePropertiesEnableServerCertificateValidation"] = None,
        **kwargs
    ):
        super(FtpServerLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'FtpServer'
        self.host = host
        self.port = port
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential
        self.enable_ssl = enable_ssl
        self.enable_server_certificate_validation = enable_server_certificate_validation


class FtpServerLinkedServiceTypeProperties(msrest.serialization.Model):
    """Properties specific to this linked service type.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. Host name of the FTP server. Type: string (or Expression with resultType
     string).
    :type host: ~data_factory_management_client.models.FtpServerLinkedServiceTypePropertiesHost
    :param port: The TCP port number that the FTP server uses to listen for client connections.
     Default value is 21. Type: integer (or Expression with resultType integer), minimum: 0.
    :type port: ~data_factory_management_client.models.FtpServerLinkedServiceTypePropertiesPort
    :param authentication_type: The authentication type to be used to connect to the FTP server.
     Possible values include: 'Basic', 'Anonymous'.
    :type authentication_type: str or ~data_factory_management_client.models.FtpAuthenticationType
    :param user_name: Username to logon the FTP server. Type: string (or Expression with resultType
     string).
    :type user_name:
     ~data_factory_management_client.models.FtpServerLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.FtpServerLinkedServiceTypePropertiesEncryptedCredential
    :param enable_ssl: If true, connect to the FTP server over SSL/TLS channel. Default value is
     true. Type: boolean (or Expression with resultType boolean).
    :type enable_ssl:
     ~data_factory_management_client.models.FtpServerLinkedServiceTypePropertiesEnableSsl
    :param enable_server_certificate_validation: If true, validate the FTP server SSL certificate
     when connect over SSL/TLS channel. Default value is true. Type: boolean (or Expression with
     resultType boolean).
    :type enable_server_certificate_validation:
     ~data_factory_management_client.models.FtpServerLinkedServiceTypePropertiesEnableServerCertificateValidation
    """

    _validation = {
        'host': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'FtpServerLinkedServiceTypePropertiesHost'},
        'port': {'key': 'port', 'type': 'FtpServerLinkedServiceTypePropertiesPort'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'user_name': {'key': 'userName', 'type': 'FtpServerLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'FtpServerLinkedServiceTypePropertiesEncryptedCredential'},
        'enable_ssl': {'key': 'enableSsl', 'type': 'FtpServerLinkedServiceTypePropertiesEnableSsl'},
        'enable_server_certificate_validation': {'key': 'enableServerCertificateValidation', 'type': 'FtpServerLinkedServiceTypePropertiesEnableServerCertificateValidation'},
    }

    def __init__(
        self,
        *,
        host: "FtpServerLinkedServiceTypePropertiesHost",
        port: Optional["FtpServerLinkedServiceTypePropertiesPort"] = None,
        authentication_type: Optional[Union[str, "FtpAuthenticationType"]] = None,
        user_name: Optional["FtpServerLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["FtpServerLinkedServiceTypePropertiesEncryptedCredential"] = None,
        enable_ssl: Optional["FtpServerLinkedServiceTypePropertiesEnableSsl"] = None,
        enable_server_certificate_validation: Optional["FtpServerLinkedServiceTypePropertiesEnableServerCertificateValidation"] = None,
        **kwargs
    ):
        super(FtpServerLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.port = port
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential
        self.enable_ssl = enable_ssl
        self.enable_server_certificate_validation = enable_server_certificate_validation


class FtpServerLinkedServiceTypePropertiesEnableServerCertificateValidation(msrest.serialization.Model):
    """If true, validate the FTP server SSL certificate when connect over SSL/TLS channel. Default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FtpServerLinkedServiceTypePropertiesEnableServerCertificateValidation, self).__init__(**kwargs)


class FtpServerLinkedServiceTypePropertiesEnableSsl(msrest.serialization.Model):
    """If true, connect to the FTP server over SSL/TLS channel. Default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FtpServerLinkedServiceTypePropertiesEnableSsl, self).__init__(**kwargs)


class FtpServerLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FtpServerLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class FtpServerLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """Host name of the FTP server. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FtpServerLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class FtpServerLinkedServiceTypePropertiesPort(msrest.serialization.Model):
    """The TCP port number that the FTP server uses to listen for client connections. Default value is 21. Type: integer (or Expression with resultType integer), minimum: 0.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FtpServerLinkedServiceTypePropertiesPort, self).__init__(**kwargs)


class FtpServerLinkedServiceTypePropertiesUserName(msrest.serialization.Model):
    """Username to logon the FTP server. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(FtpServerLinkedServiceTypePropertiesUserName, self).__init__(**kwargs)


class FtpServerLocation(DatasetLocation):
    """The location of ftp server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage location.Constant filled by server.
    :type type: str
    :param folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :type folder_path: ~data_factory_management_client.models.DatasetLocationFolderPath
    :param file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :type file_name: ~data_factory_management_client.models.DatasetLocationFileName
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'DatasetLocationFolderPath'},
        'file_name': {'key': 'fileName', 'type': 'DatasetLocationFileName'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        folder_path: Optional["DatasetLocationFolderPath"] = None,
        file_name: Optional["DatasetLocationFileName"] = None,
        **kwargs
    ):
        super(FtpServerLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'FtpServerLocation'


class GenericDatasetTypeProperties(msrest.serialization.Model):
    """Properties specific to this dataset type.

    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(GenericDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name


class GenericDatasetTypePropertiesTableName(msrest.serialization.Model):
    """The table name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GenericDatasetTypePropertiesTableName, self).__init__(**kwargs)


class GetDataFactoryOperationStatusResponse(msrest.serialization.Model):
    """Response body structure for get data factory operation status.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param status: Status of the operation.
    :type status: str
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'status': {'key': 'status', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        status: Optional[str] = None,
        **kwargs
    ):
        super(GetDataFactoryOperationStatusResponse, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.status = status


class GetMetadataActivity(ExecutionActivity):
    """Activity to get metadata of dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param dataset: Required. Dataset reference type.
    :type dataset: ~data_factory_management_client.models.DatasetReference
    :param field_list: Fields of metadata to get from dataset.
    :type field_list:
     list[~data_factory_management_client.models.GetMetadataActivityTypePropertiesFieldListItem]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'dataset': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'dataset': {'key': 'typeProperties.dataset', 'type': 'DatasetReference'},
        'field_list': {'key': 'typeProperties.fieldList', 'type': '[GetMetadataActivityTypePropertiesFieldListItem]'},
    }

    def __init__(
        self,
        *,
        name: str,
        dataset: "DatasetReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        field_list: Optional[List["GetMetadataActivityTypePropertiesFieldListItem"]] = None,
        **kwargs
    ):
        super(GetMetadataActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'GetMetadata'
        self.dataset = dataset
        self.field_list = field_list


class GetMetadataActivityTypeProperties(msrest.serialization.Model):
    """GetMetadata activity properties.

    All required parameters must be populated in order to send to Azure.

    :param dataset: Required. Dataset reference type.
    :type dataset: ~data_factory_management_client.models.DatasetReference
    :param field_list: Fields of metadata to get from dataset.
    :type field_list:
     list[~data_factory_management_client.models.GetMetadataActivityTypePropertiesFieldListItem]
    """

    _validation = {
        'dataset': {'required': True},
    }

    _attribute_map = {
        'dataset': {'key': 'dataset', 'type': 'DatasetReference'},
        'field_list': {'key': 'fieldList', 'type': '[GetMetadataActivityTypePropertiesFieldListItem]'},
    }

    def __init__(
        self,
        *,
        dataset: "DatasetReference",
        field_list: Optional[List["GetMetadataActivityTypePropertiesFieldListItem"]] = None,
        **kwargs
    ):
        super(GetMetadataActivityTypeProperties, self).__init__(**kwargs)
        self.dataset = dataset
        self.field_list = field_list


class GetMetadataActivityTypePropertiesFieldListItem(msrest.serialization.Model):
    """Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GetMetadataActivityTypePropertiesFieldListItem, self).__init__(**kwargs)


class GetSsisObjectMetadataRequest(msrest.serialization.Model):
    """The request payload of get SSIS object metadata.

    :param metadata_path: Metadata path.
    :type metadata_path: str
    """

    _attribute_map = {
        'metadata_path': {'key': 'metadataPath', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        metadata_path: Optional[str] = None,
        **kwargs
    ):
        super(GetSsisObjectMetadataRequest, self).__init__(**kwargs)
        self.metadata_path = metadata_path


class GitHubAccessTokenRequest(msrest.serialization.Model):
    """Get GitHub access token request definition.

    All required parameters must be populated in order to send to Azure.

    :param git_hub_access_code: Required. GitHub access code.
    :type git_hub_access_code: str
    :param git_hub_client_id: GitHub application client ID.
    :type git_hub_client_id: str
    :param git_hub_access_token_base_url: Required. GitHub access token base URL.
    :type git_hub_access_token_base_url: str
    """

    _validation = {
        'git_hub_access_code': {'required': True},
        'git_hub_access_token_base_url': {'required': True},
    }

    _attribute_map = {
        'git_hub_access_code': {'key': 'gitHubAccessCode', 'type': 'str'},
        'git_hub_client_id': {'key': 'gitHubClientId', 'type': 'str'},
        'git_hub_access_token_base_url': {'key': 'gitHubAccessTokenBaseUrl', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        git_hub_access_code: str,
        git_hub_access_token_base_url: str,
        git_hub_client_id: Optional[str] = None,
        **kwargs
    ):
        super(GitHubAccessTokenRequest, self).__init__(**kwargs)
        self.git_hub_access_code = git_hub_access_code
        self.git_hub_client_id = git_hub_client_id
        self.git_hub_access_token_base_url = git_hub_access_token_base_url


class GitHubAccessTokenResponse(msrest.serialization.Model):
    """Get GitHub access token response definition.

    :param git_hub_access_token: GitHub access token.
    :type git_hub_access_token: str
    """

    _attribute_map = {
        'git_hub_access_token': {'key': 'gitHubAccessToken', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        git_hub_access_token: Optional[str] = None,
        **kwargs
    ):
        super(GitHubAccessTokenResponse, self).__init__(**kwargs)
        self.git_hub_access_token = git_hub_access_token


class GoogleAdWordsLinkedService(LinkedService):
    """Google AdWords service linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param client_customer_id: Required. The Client customer ID of the AdWords account that you
     want to fetch report data for.
    :type client_customer_id:
     ~data_factory_management_client.models.GoogleAdWordsLinkedServiceTypePropertiesClientCustomerID
    :param developer_token: Required. The base definition of a secret type.
    :type developer_token: ~data_factory_management_client.models.SecretBase
    :param authentication_type: Required. The OAuth 2.0 authentication mechanism used for
     authentication. ServiceAuthentication can only be used on self-hosted IR. Possible values
     include: 'ServiceAuthentication', 'UserAuthentication'.
    :type authentication_type: str or
     ~data_factory_management_client.models.GoogleAdWordsAuthenticationType
    :param refresh_token: The base definition of a secret type.
    :type refresh_token: ~data_factory_management_client.models.SecretBase
    :param client_id: The client id of the google application used to acquire the refresh token.
     Type: string (or Expression with resultType string).
    :type client_id:
     ~data_factory_management_client.models.GoogleAdWordsLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param email: The service account email ID that is used for ServiceAuthentication and can only
     be used on self-hosted IR.
    :type email:
     ~data_factory_management_client.models.GoogleAdWordsLinkedServiceTypePropertiesEmail
    :param key_file_path: The full path to the .p12 key file that is used to authenticate the
     service account email address and can only be used on self-hosted IR.
    :type key_file_path:
     ~data_factory_management_client.models.GoogleAdWordsLinkedServiceTypePropertiesKeyFilePath
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.GoogleAdWordsLinkedServiceTypePropertiesTrustedCertPath
    :param use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :type use_system_trust_store:
     ~data_factory_management_client.models.GoogleAdWordsLinkedServiceTypePropertiesUseSystemTrustStore
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.GoogleAdWordsLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'client_customer_id': {'required': True},
        'developer_token': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'client_customer_id': {'key': 'typeProperties.clientCustomerID', 'type': 'GoogleAdWordsLinkedServiceTypePropertiesClientCustomerID'},
        'developer_token': {'key': 'typeProperties.developerToken', 'type': 'SecretBase'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'refresh_token': {'key': 'typeProperties.refreshToken', 'type': 'SecretBase'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'GoogleAdWordsLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'email': {'key': 'typeProperties.email', 'type': 'GoogleAdWordsLinkedServiceTypePropertiesEmail'},
        'key_file_path': {'key': 'typeProperties.keyFilePath', 'type': 'GoogleAdWordsLinkedServiceTypePropertiesKeyFilePath'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'GoogleAdWordsLinkedServiceTypePropertiesTrustedCertPath'},
        'use_system_trust_store': {'key': 'typeProperties.useSystemTrustStore', 'type': 'GoogleAdWordsLinkedServiceTypePropertiesUseSystemTrustStore'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'GoogleAdWordsLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        client_customer_id: "GoogleAdWordsLinkedServiceTypePropertiesClientCustomerID",
        developer_token: "SecretBase",
        authentication_type: Union[str, "GoogleAdWordsAuthenticationType"],
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        refresh_token: Optional["SecretBase"] = None,
        client_id: Optional["GoogleAdWordsLinkedServiceTypePropertiesClientId"] = None,
        client_secret: Optional["SecretBase"] = None,
        email: Optional["GoogleAdWordsLinkedServiceTypePropertiesEmail"] = None,
        key_file_path: Optional["GoogleAdWordsLinkedServiceTypePropertiesKeyFilePath"] = None,
        trusted_cert_path: Optional["GoogleAdWordsLinkedServiceTypePropertiesTrustedCertPath"] = None,
        use_system_trust_store: Optional["GoogleAdWordsLinkedServiceTypePropertiesUseSystemTrustStore"] = None,
        encrypted_credential: Optional["GoogleAdWordsLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(GoogleAdWordsLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'GoogleAdWords'
        self.client_customer_id = client_customer_id
        self.developer_token = developer_token
        self.authentication_type = authentication_type
        self.refresh_token = refresh_token
        self.client_id = client_id
        self.client_secret = client_secret
        self.email = email
        self.key_file_path = key_file_path
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.encrypted_credential = encrypted_credential


class GoogleAdWordsLinkedServiceTypeProperties(msrest.serialization.Model):
    """Google AdWords service linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param client_customer_id: Required. The Client customer ID of the AdWords account that you
     want to fetch report data for.
    :type client_customer_id:
     ~data_factory_management_client.models.GoogleAdWordsLinkedServiceTypePropertiesClientCustomerID
    :param developer_token: Required. The base definition of a secret type.
    :type developer_token: ~data_factory_management_client.models.SecretBase
    :param authentication_type: Required. The OAuth 2.0 authentication mechanism used for
     authentication. ServiceAuthentication can only be used on self-hosted IR. Possible values
     include: 'ServiceAuthentication', 'UserAuthentication'.
    :type authentication_type: str or
     ~data_factory_management_client.models.GoogleAdWordsAuthenticationType
    :param refresh_token: The base definition of a secret type.
    :type refresh_token: ~data_factory_management_client.models.SecretBase
    :param client_id: The client id of the google application used to acquire the refresh token.
     Type: string (or Expression with resultType string).
    :type client_id:
     ~data_factory_management_client.models.GoogleAdWordsLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param email: The service account email ID that is used for ServiceAuthentication and can only
     be used on self-hosted IR.
    :type email:
     ~data_factory_management_client.models.GoogleAdWordsLinkedServiceTypePropertiesEmail
    :param key_file_path: The full path to the .p12 key file that is used to authenticate the
     service account email address and can only be used on self-hosted IR.
    :type key_file_path:
     ~data_factory_management_client.models.GoogleAdWordsLinkedServiceTypePropertiesKeyFilePath
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.GoogleAdWordsLinkedServiceTypePropertiesTrustedCertPath
    :param use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :type use_system_trust_store:
     ~data_factory_management_client.models.GoogleAdWordsLinkedServiceTypePropertiesUseSystemTrustStore
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.GoogleAdWordsLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'client_customer_id': {'required': True},
        'developer_token': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'client_customer_id': {'key': 'clientCustomerID', 'type': 'GoogleAdWordsLinkedServiceTypePropertiesClientCustomerID'},
        'developer_token': {'key': 'developerToken', 'type': 'SecretBase'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'refresh_token': {'key': 'refreshToken', 'type': 'SecretBase'},
        'client_id': {'key': 'clientId', 'type': 'GoogleAdWordsLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'clientSecret', 'type': 'SecretBase'},
        'email': {'key': 'email', 'type': 'GoogleAdWordsLinkedServiceTypePropertiesEmail'},
        'key_file_path': {'key': 'keyFilePath', 'type': 'GoogleAdWordsLinkedServiceTypePropertiesKeyFilePath'},
        'trusted_cert_path': {'key': 'trustedCertPath', 'type': 'GoogleAdWordsLinkedServiceTypePropertiesTrustedCertPath'},
        'use_system_trust_store': {'key': 'useSystemTrustStore', 'type': 'GoogleAdWordsLinkedServiceTypePropertiesUseSystemTrustStore'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'GoogleAdWordsLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        client_customer_id: "GoogleAdWordsLinkedServiceTypePropertiesClientCustomerID",
        developer_token: "SecretBase",
        authentication_type: Union[str, "GoogleAdWordsAuthenticationType"],
        refresh_token: Optional["SecretBase"] = None,
        client_id: Optional["GoogleAdWordsLinkedServiceTypePropertiesClientId"] = None,
        client_secret: Optional["SecretBase"] = None,
        email: Optional["GoogleAdWordsLinkedServiceTypePropertiesEmail"] = None,
        key_file_path: Optional["GoogleAdWordsLinkedServiceTypePropertiesKeyFilePath"] = None,
        trusted_cert_path: Optional["GoogleAdWordsLinkedServiceTypePropertiesTrustedCertPath"] = None,
        use_system_trust_store: Optional["GoogleAdWordsLinkedServiceTypePropertiesUseSystemTrustStore"] = None,
        encrypted_credential: Optional["GoogleAdWordsLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(GoogleAdWordsLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.client_customer_id = client_customer_id
        self.developer_token = developer_token
        self.authentication_type = authentication_type
        self.refresh_token = refresh_token
        self.client_id = client_id
        self.client_secret = client_secret
        self.email = email
        self.key_file_path = key_file_path
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.encrypted_credential = encrypted_credential


class GoogleAdWordsLinkedServiceTypePropertiesClientCustomerID(msrest.serialization.Model):
    """The Client customer ID of the AdWords account that you want to fetch report data for.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleAdWordsLinkedServiceTypePropertiesClientCustomerID, self).__init__(**kwargs)


class GoogleAdWordsLinkedServiceTypePropertiesClientId(msrest.serialization.Model):
    """The client id of the google application used to acquire the refresh token. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleAdWordsLinkedServiceTypePropertiesClientId, self).__init__(**kwargs)


class GoogleAdWordsLinkedServiceTypePropertiesEmail(msrest.serialization.Model):
    """The service account email ID that is used for ServiceAuthentication and can only be used on self-hosted IR.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleAdWordsLinkedServiceTypePropertiesEmail, self).__init__(**kwargs)


class GoogleAdWordsLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleAdWordsLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class GoogleAdWordsLinkedServiceTypePropertiesKeyFilePath(msrest.serialization.Model):
    """The full path to the .p12 key file that is used to authenticate the service account email address and can only be used on self-hosted IR.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleAdWordsLinkedServiceTypePropertiesKeyFilePath, self).__init__(**kwargs)


class GoogleAdWordsLinkedServiceTypePropertiesTrustedCertPath(msrest.serialization.Model):
    """The full path of the .pem file containing trusted CA certificates for verifying the server when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The default value is the cacerts.pem file installed with the IR.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleAdWordsLinkedServiceTypePropertiesTrustedCertPath, self).__init__(**kwargs)


class GoogleAdWordsLinkedServiceTypePropertiesUseSystemTrustStore(msrest.serialization.Model):
    """Specifies whether to use a CA certificate from the system trust store or from a specified PEM file. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleAdWordsLinkedServiceTypePropertiesUseSystemTrustStore, self).__init__(**kwargs)


class GoogleAdWordsObjectDataset(Dataset):
    """Google AdWords service dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(GoogleAdWordsObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'GoogleAdWordsObject'
        self.table_name = table_name


class GoogleAdWordsSource(TabularSource):
    """A copy activity Google AdWords service source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.GoogleAdWordsSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'GoogleAdWordsSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["GoogleAdWordsSourceQuery"] = None,
        **kwargs
    ):
        super(GoogleAdWordsSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'GoogleAdWordsSource'
        self.query = query


class GoogleAdWordsSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleAdWordsSourceQuery, self).__init__(**kwargs)


class GoogleBigQueryDatasetTypeProperties(msrest.serialization.Model):
    """Google BigQuery Dataset Properties.

    :param table_name: This property will be retired. Please consider using database + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.GoogleBigQueryDatasetTypePropertiesTableName
    :param table: The table name of the Google BigQuery. Type: string (or Expression with
     resultType string).
    :type table: ~data_factory_management_client.models.GoogleBigQueryDatasetTypePropertiesTable
    :param dataset: The database name of the Google BigQuery. Type: string (or Expression with
     resultType string).
    :type dataset:
     ~data_factory_management_client.models.GoogleBigQueryDatasetTypePropertiesDataset
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'GoogleBigQueryDatasetTypePropertiesTableName'},
        'table': {'key': 'table', 'type': 'GoogleBigQueryDatasetTypePropertiesTable'},
        'dataset': {'key': 'dataset', 'type': 'GoogleBigQueryDatasetTypePropertiesDataset'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["GoogleBigQueryDatasetTypePropertiesTableName"] = None,
        table: Optional["GoogleBigQueryDatasetTypePropertiesTable"] = None,
        dataset: Optional["GoogleBigQueryDatasetTypePropertiesDataset"] = None,
        **kwargs
    ):
        super(GoogleBigQueryDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.table = table
        self.dataset = dataset


class GoogleBigQueryDatasetTypePropertiesDataset(msrest.serialization.Model):
    """The database name of the Google BigQuery. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleBigQueryDatasetTypePropertiesDataset, self).__init__(**kwargs)


class GoogleBigQueryDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the Google BigQuery. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleBigQueryDatasetTypePropertiesTable, self).__init__(**kwargs)


class GoogleBigQueryDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using database + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleBigQueryDatasetTypePropertiesTableName, self).__init__(**kwargs)


class GoogleBigQueryLinkedService(LinkedService):
    """Google BigQuery service linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param project: Required. The default BigQuery project to query against.
    :type project:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesProject
    :param additional_projects: A comma-separated list of public BigQuery projects to access.
    :type additional_projects:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesAdditionalProjects
    :param request_google_drive_scope: Whether to request access to Google Drive. Allowing Google
     Drive access enables support for federated tables that combine BigQuery data with data from
     Google Drive. The default value is false.
    :type request_google_drive_scope:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesRequestGoogleDriveScope
    :param authentication_type: Required. The OAuth 2.0 authentication mechanism used for
     authentication. ServiceAuthentication can only be used on self-hosted IR. Possible values
     include: 'ServiceAuthentication', 'UserAuthentication'.
    :type authentication_type: str or
     ~data_factory_management_client.models.GoogleBigQueryAuthenticationType
    :param refresh_token: The base definition of a secret type.
    :type refresh_token: ~data_factory_management_client.models.SecretBase
    :param client_id: The client id of the google application used to acquire the refresh token.
     Type: string (or Expression with resultType string).
    :type client_id:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param email: The service account email ID that is used for ServiceAuthentication and can only
     be used on self-hosted IR.
    :type email:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesEmail
    :param key_file_path: The full path to the .p12 key file that is used to authenticate the
     service account email address and can only be used on self-hosted IR.
    :type key_file_path:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesKeyFilePath
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesTrustedCertPath
    :param use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :type use_system_trust_store:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesUseSystemTrustStore
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'project': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'project': {'key': 'typeProperties.project', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesProject'},
        'additional_projects': {'key': 'typeProperties.additionalProjects', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesAdditionalProjects'},
        'request_google_drive_scope': {'key': 'typeProperties.requestGoogleDriveScope', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesRequestGoogleDriveScope'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'refresh_token': {'key': 'typeProperties.refreshToken', 'type': 'SecretBase'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'email': {'key': 'typeProperties.email', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesEmail'},
        'key_file_path': {'key': 'typeProperties.keyFilePath', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesKeyFilePath'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesTrustedCertPath'},
        'use_system_trust_store': {'key': 'typeProperties.useSystemTrustStore', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesUseSystemTrustStore'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        project: "GoogleBigQueryLinkedServiceTypePropertiesProject",
        authentication_type: Union[str, "GoogleBigQueryAuthenticationType"],
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        additional_projects: Optional["GoogleBigQueryLinkedServiceTypePropertiesAdditionalProjects"] = None,
        request_google_drive_scope: Optional["GoogleBigQueryLinkedServiceTypePropertiesRequestGoogleDriveScope"] = None,
        refresh_token: Optional["SecretBase"] = None,
        client_id: Optional["GoogleBigQueryLinkedServiceTypePropertiesClientId"] = None,
        client_secret: Optional["SecretBase"] = None,
        email: Optional["GoogleBigQueryLinkedServiceTypePropertiesEmail"] = None,
        key_file_path: Optional["GoogleBigQueryLinkedServiceTypePropertiesKeyFilePath"] = None,
        trusted_cert_path: Optional["GoogleBigQueryLinkedServiceTypePropertiesTrustedCertPath"] = None,
        use_system_trust_store: Optional["GoogleBigQueryLinkedServiceTypePropertiesUseSystemTrustStore"] = None,
        encrypted_credential: Optional["GoogleBigQueryLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(GoogleBigQueryLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'GoogleBigQuery'
        self.project = project
        self.additional_projects = additional_projects
        self.request_google_drive_scope = request_google_drive_scope
        self.authentication_type = authentication_type
        self.refresh_token = refresh_token
        self.client_id = client_id
        self.client_secret = client_secret
        self.email = email
        self.key_file_path = key_file_path
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.encrypted_credential = encrypted_credential


class GoogleBigQueryLinkedServiceTypeProperties(msrest.serialization.Model):
    """Google BigQuery service linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param project: Required. The default BigQuery project to query against.
    :type project:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesProject
    :param additional_projects: A comma-separated list of public BigQuery projects to access.
    :type additional_projects:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesAdditionalProjects
    :param request_google_drive_scope: Whether to request access to Google Drive. Allowing Google
     Drive access enables support for federated tables that combine BigQuery data with data from
     Google Drive. The default value is false.
    :type request_google_drive_scope:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesRequestGoogleDriveScope
    :param authentication_type: Required. The OAuth 2.0 authentication mechanism used for
     authentication. ServiceAuthentication can only be used on self-hosted IR. Possible values
     include: 'ServiceAuthentication', 'UserAuthentication'.
    :type authentication_type: str or
     ~data_factory_management_client.models.GoogleBigQueryAuthenticationType
    :param refresh_token: The base definition of a secret type.
    :type refresh_token: ~data_factory_management_client.models.SecretBase
    :param client_id: The client id of the google application used to acquire the refresh token.
     Type: string (or Expression with resultType string).
    :type client_id:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param email: The service account email ID that is used for ServiceAuthentication and can only
     be used on self-hosted IR.
    :type email:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesEmail
    :param key_file_path: The full path to the .p12 key file that is used to authenticate the
     service account email address and can only be used on self-hosted IR.
    :type key_file_path:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesKeyFilePath
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesTrustedCertPath
    :param use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :type use_system_trust_store:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesUseSystemTrustStore
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.GoogleBigQueryLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'project': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'project': {'key': 'project', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesProject'},
        'additional_projects': {'key': 'additionalProjects', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesAdditionalProjects'},
        'request_google_drive_scope': {'key': 'requestGoogleDriveScope', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesRequestGoogleDriveScope'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'refresh_token': {'key': 'refreshToken', 'type': 'SecretBase'},
        'client_id': {'key': 'clientId', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'clientSecret', 'type': 'SecretBase'},
        'email': {'key': 'email', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesEmail'},
        'key_file_path': {'key': 'keyFilePath', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesKeyFilePath'},
        'trusted_cert_path': {'key': 'trustedCertPath', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesTrustedCertPath'},
        'use_system_trust_store': {'key': 'useSystemTrustStore', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesUseSystemTrustStore'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'GoogleBigQueryLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        project: "GoogleBigQueryLinkedServiceTypePropertiesProject",
        authentication_type: Union[str, "GoogleBigQueryAuthenticationType"],
        additional_projects: Optional["GoogleBigQueryLinkedServiceTypePropertiesAdditionalProjects"] = None,
        request_google_drive_scope: Optional["GoogleBigQueryLinkedServiceTypePropertiesRequestGoogleDriveScope"] = None,
        refresh_token: Optional["SecretBase"] = None,
        client_id: Optional["GoogleBigQueryLinkedServiceTypePropertiesClientId"] = None,
        client_secret: Optional["SecretBase"] = None,
        email: Optional["GoogleBigQueryLinkedServiceTypePropertiesEmail"] = None,
        key_file_path: Optional["GoogleBigQueryLinkedServiceTypePropertiesKeyFilePath"] = None,
        trusted_cert_path: Optional["GoogleBigQueryLinkedServiceTypePropertiesTrustedCertPath"] = None,
        use_system_trust_store: Optional["GoogleBigQueryLinkedServiceTypePropertiesUseSystemTrustStore"] = None,
        encrypted_credential: Optional["GoogleBigQueryLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(GoogleBigQueryLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.project = project
        self.additional_projects = additional_projects
        self.request_google_drive_scope = request_google_drive_scope
        self.authentication_type = authentication_type
        self.refresh_token = refresh_token
        self.client_id = client_id
        self.client_secret = client_secret
        self.email = email
        self.key_file_path = key_file_path
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.encrypted_credential = encrypted_credential


class GoogleBigQueryLinkedServiceTypePropertiesAdditionalProjects(msrest.serialization.Model):
    """A comma-separated list of public BigQuery projects to access.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleBigQueryLinkedServiceTypePropertiesAdditionalProjects, self).__init__(**kwargs)


class GoogleBigQueryLinkedServiceTypePropertiesClientId(msrest.serialization.Model):
    """The client id of the google application used to acquire the refresh token. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleBigQueryLinkedServiceTypePropertiesClientId, self).__init__(**kwargs)


class GoogleBigQueryLinkedServiceTypePropertiesEmail(msrest.serialization.Model):
    """The service account email ID that is used for ServiceAuthentication and can only be used on self-hosted IR.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleBigQueryLinkedServiceTypePropertiesEmail, self).__init__(**kwargs)


class GoogleBigQueryLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleBigQueryLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class GoogleBigQueryLinkedServiceTypePropertiesKeyFilePath(msrest.serialization.Model):
    """The full path to the .p12 key file that is used to authenticate the service account email address and can only be used on self-hosted IR.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleBigQueryLinkedServiceTypePropertiesKeyFilePath, self).__init__(**kwargs)


class GoogleBigQueryLinkedServiceTypePropertiesProject(msrest.serialization.Model):
    """The default BigQuery project to query against.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleBigQueryLinkedServiceTypePropertiesProject, self).__init__(**kwargs)


class GoogleBigQueryLinkedServiceTypePropertiesRequestGoogleDriveScope(msrest.serialization.Model):
    """Whether to request access to Google Drive. Allowing Google Drive access enables support for federated tables that combine BigQuery data with data from Google Drive. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleBigQueryLinkedServiceTypePropertiesRequestGoogleDriveScope, self).__init__(**kwargs)


class GoogleBigQueryLinkedServiceTypePropertiesTrustedCertPath(msrest.serialization.Model):
    """The full path of the .pem file containing trusted CA certificates for verifying the server when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The default value is the cacerts.pem file installed with the IR.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleBigQueryLinkedServiceTypePropertiesTrustedCertPath, self).__init__(**kwargs)


class GoogleBigQueryLinkedServiceTypePropertiesUseSystemTrustStore(msrest.serialization.Model):
    """Specifies whether to use a CA certificate from the system trust store or from a specified PEM file. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleBigQueryLinkedServiceTypePropertiesUseSystemTrustStore, self).__init__(**kwargs)


class GoogleBigQueryObjectDataset(Dataset):
    """Google BigQuery service dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using database + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.GoogleBigQueryDatasetTypePropertiesTableName
    :param table: The table name of the Google BigQuery. Type: string (or Expression with
     resultType string).
    :type table: ~data_factory_management_client.models.GoogleBigQueryDatasetTypePropertiesTable
    :param dataset: The database name of the Google BigQuery. Type: string (or Expression with
     resultType string).
    :type dataset:
     ~data_factory_management_client.models.GoogleBigQueryDatasetTypePropertiesDataset
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GoogleBigQueryDatasetTypePropertiesTableName'},
        'table': {'key': 'typeProperties.table', 'type': 'GoogleBigQueryDatasetTypePropertiesTable'},
        'dataset': {'key': 'typeProperties.dataset', 'type': 'GoogleBigQueryDatasetTypePropertiesDataset'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GoogleBigQueryDatasetTypePropertiesTableName"] = None,
        table: Optional["GoogleBigQueryDatasetTypePropertiesTable"] = None,
        dataset: Optional["GoogleBigQueryDatasetTypePropertiesDataset"] = None,
        **kwargs
    ):
        super(GoogleBigQueryObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'GoogleBigQueryObject'
        self.table_name = table_name
        self.table = table
        self.dataset = dataset


class GoogleBigQuerySource(TabularSource):
    """A copy activity Google BigQuery service source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.GoogleBigQuerySourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'GoogleBigQuerySourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["GoogleBigQuerySourceQuery"] = None,
        **kwargs
    ):
        super(GoogleBigQuerySource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'GoogleBigQuerySource'
        self.query = query


class GoogleBigQuerySourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleBigQuerySourceQuery, self).__init__(**kwargs)


class GoogleCloudStorageLinkedService(LinkedService):
    """Linked service for Google Cloud Storage.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param access_key_id: The access key identifier of the Google Cloud Storage Identity and Access
     Management (IAM) user. Type: string (or Expression with resultType string).
    :type access_key_id:
     ~data_factory_management_client.models.GoogleCloudStorageLinkedServiceTypePropertiesAccessKeyId
    :param secret_access_key: The base definition of a secret type.
    :type secret_access_key: ~data_factory_management_client.models.SecretBase
    :param service_url: This value specifies the endpoint to access with the Google Cloud Storage
     Connector. This is an optional property; change it only if you want to try a different service
     endpoint or want to switch between https and http. Type: string (or Expression with resultType
     string).
    :type service_url:
     ~data_factory_management_client.models.GoogleCloudStorageLinkedServiceTypePropertiesServiceUrl
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.GoogleCloudStorageLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'access_key_id': {'key': 'typeProperties.accessKeyId', 'type': 'GoogleCloudStorageLinkedServiceTypePropertiesAccessKeyId'},
        'secret_access_key': {'key': 'typeProperties.secretAccessKey', 'type': 'SecretBase'},
        'service_url': {'key': 'typeProperties.serviceUrl', 'type': 'GoogleCloudStorageLinkedServiceTypePropertiesServiceUrl'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'GoogleCloudStorageLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        access_key_id: Optional["GoogleCloudStorageLinkedServiceTypePropertiesAccessKeyId"] = None,
        secret_access_key: Optional["SecretBase"] = None,
        service_url: Optional["GoogleCloudStorageLinkedServiceTypePropertiesServiceUrl"] = None,
        encrypted_credential: Optional["GoogleCloudStorageLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(GoogleCloudStorageLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'GoogleCloudStorage'
        self.access_key_id = access_key_id
        self.secret_access_key = secret_access_key
        self.service_url = service_url
        self.encrypted_credential = encrypted_credential


class GoogleCloudStorageLinkedServiceTypeProperties(msrest.serialization.Model):
    """Google Cloud Storage linked service properties.

    :param access_key_id: The access key identifier of the Google Cloud Storage Identity and Access
     Management (IAM) user. Type: string (or Expression with resultType string).
    :type access_key_id:
     ~data_factory_management_client.models.GoogleCloudStorageLinkedServiceTypePropertiesAccessKeyId
    :param secret_access_key: The base definition of a secret type.
    :type secret_access_key: ~data_factory_management_client.models.SecretBase
    :param service_url: This value specifies the endpoint to access with the Google Cloud Storage
     Connector. This is an optional property; change it only if you want to try a different service
     endpoint or want to switch between https and http. Type: string (or Expression with resultType
     string).
    :type service_url:
     ~data_factory_management_client.models.GoogleCloudStorageLinkedServiceTypePropertiesServiceUrl
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.GoogleCloudStorageLinkedServiceTypePropertiesEncryptedCredential
    """

    _attribute_map = {
        'access_key_id': {'key': 'accessKeyId', 'type': 'GoogleCloudStorageLinkedServiceTypePropertiesAccessKeyId'},
        'secret_access_key': {'key': 'secretAccessKey', 'type': 'SecretBase'},
        'service_url': {'key': 'serviceUrl', 'type': 'GoogleCloudStorageLinkedServiceTypePropertiesServiceUrl'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'GoogleCloudStorageLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        access_key_id: Optional["GoogleCloudStorageLinkedServiceTypePropertiesAccessKeyId"] = None,
        secret_access_key: Optional["SecretBase"] = None,
        service_url: Optional["GoogleCloudStorageLinkedServiceTypePropertiesServiceUrl"] = None,
        encrypted_credential: Optional["GoogleCloudStorageLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(GoogleCloudStorageLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.access_key_id = access_key_id
        self.secret_access_key = secret_access_key
        self.service_url = service_url
        self.encrypted_credential = encrypted_credential


class GoogleCloudStorageLinkedServiceTypePropertiesAccessKeyId(msrest.serialization.Model):
    """The access key identifier of the Google Cloud Storage Identity and Access Management (IAM) user. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleCloudStorageLinkedServiceTypePropertiesAccessKeyId, self).__init__(**kwargs)


class GoogleCloudStorageLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleCloudStorageLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class GoogleCloudStorageLinkedServiceTypePropertiesServiceUrl(msrest.serialization.Model):
    """This value specifies the endpoint to access with the Google Cloud Storage Connector. This is an optional property; change it only if you want to try a different service endpoint or want to switch between https and http. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleCloudStorageLinkedServiceTypePropertiesServiceUrl, self).__init__(**kwargs)


class GoogleCloudStorageLocation(DatasetLocation):
    """The location of Google Cloud Storage dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage location.Constant filled by server.
    :type type: str
    :param folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :type folder_path: ~data_factory_management_client.models.DatasetLocationFolderPath
    :param file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :type file_name: ~data_factory_management_client.models.DatasetLocationFileName
    :param bucket_name: Specify the bucketName of Google Cloud Storage. Type: string (or Expression
     with resultType string).
    :type bucket_name: ~data_factory_management_client.models.GoogleCloudStorageLocationBucketName
    :param version: Specify the version of Google Cloud Storage. Type: string (or Expression with
     resultType string).
    :type version: ~data_factory_management_client.models.GoogleCloudStorageLocationVersion
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'DatasetLocationFolderPath'},
        'file_name': {'key': 'fileName', 'type': 'DatasetLocationFileName'},
        'bucket_name': {'key': 'bucketName', 'type': 'GoogleCloudStorageLocationBucketName'},
        'version': {'key': 'version', 'type': 'GoogleCloudStorageLocationVersion'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        folder_path: Optional["DatasetLocationFolderPath"] = None,
        file_name: Optional["DatasetLocationFileName"] = None,
        bucket_name: Optional["GoogleCloudStorageLocationBucketName"] = None,
        version: Optional["GoogleCloudStorageLocationVersion"] = None,
        **kwargs
    ):
        super(GoogleCloudStorageLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'GoogleCloudStorageLocation'
        self.bucket_name = bucket_name
        self.version = version


class GoogleCloudStorageLocationBucketName(msrest.serialization.Model):
    """Specify the bucketName of Google Cloud Storage. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleCloudStorageLocationBucketName, self).__init__(**kwargs)


class GoogleCloudStorageLocationVersion(msrest.serialization.Model):
    """Specify the version of Google Cloud Storage. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleCloudStorageLocationVersion, self).__init__(**kwargs)


class GoogleCloudStorageReadSettings(StoreReadSettings):
    """Google Cloud Storage read settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The read setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreReadSettingsMaxConcurrentConnections
    :param recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.GoogleCloudStorageReadSettingsRecursive
    :param wildcard_folder_path: Google Cloud Storage wildcardFolderPath. Type: string (or
     Expression with resultType string).
    :type wildcard_folder_path:
     ~data_factory_management_client.models.GoogleCloudStorageReadSettingsWildcardFolderPath
    :param wildcard_file_name: Google Cloud Storage wildcardFileName. Type: string (or Expression
     with resultType string).
    :type wildcard_file_name:
     ~data_factory_management_client.models.GoogleCloudStorageReadSettingsWildcardFileName
    :param prefix: The prefix filter for the Google Cloud Storage object name. Type: string (or
     Expression with resultType string).
    :type prefix: ~data_factory_management_client.models.GoogleCloudStorageReadSettingsPrefix
    :param file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :type file_list_path:
     ~data_factory_management_client.models.GoogleCloudStorageReadSettingsFileListPath
    :param enable_partition_discovery: Indicates whether to enable partition discovery.
    :type enable_partition_discovery: bool
    :param modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_start:
     ~data_factory_management_client.models.GoogleCloudStorageReadSettingsModifiedDatetimeStart
    :param modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :type modified_datetime_end:
     ~data_factory_management_client.models.GoogleCloudStorageReadSettingsModifiedDatetimeEnd
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreReadSettingsMaxConcurrentConnections'},
        'recursive': {'key': 'recursive', 'type': 'GoogleCloudStorageReadSettingsRecursive'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'GoogleCloudStorageReadSettingsWildcardFolderPath'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'GoogleCloudStorageReadSettingsWildcardFileName'},
        'prefix': {'key': 'prefix', 'type': 'GoogleCloudStorageReadSettingsPrefix'},
        'file_list_path': {'key': 'fileListPath', 'type': 'GoogleCloudStorageReadSettingsFileListPath'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'GoogleCloudStorageReadSettingsModifiedDatetimeStart'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'GoogleCloudStorageReadSettingsModifiedDatetimeEnd'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreReadSettingsMaxConcurrentConnections"] = None,
        recursive: Optional["GoogleCloudStorageReadSettingsRecursive"] = None,
        wildcard_folder_path: Optional["GoogleCloudStorageReadSettingsWildcardFolderPath"] = None,
        wildcard_file_name: Optional["GoogleCloudStorageReadSettingsWildcardFileName"] = None,
        prefix: Optional["GoogleCloudStorageReadSettingsPrefix"] = None,
        file_list_path: Optional["GoogleCloudStorageReadSettingsFileListPath"] = None,
        enable_partition_discovery: Optional[bool] = None,
        modified_datetime_start: Optional["GoogleCloudStorageReadSettingsModifiedDatetimeStart"] = None,
        modified_datetime_end: Optional["GoogleCloudStorageReadSettingsModifiedDatetimeEnd"] = None,
        **kwargs
    ):
        super(GoogleCloudStorageReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'GoogleCloudStorageReadSettings'
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.prefix = prefix
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class GoogleCloudStorageReadSettingsFileListPath(msrest.serialization.Model):
    """Point to a text file that lists each file (relative path to the path configured in the dataset) that you want to copy. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleCloudStorageReadSettingsFileListPath, self).__init__(**kwargs)


class GoogleCloudStorageReadSettingsModifiedDatetimeEnd(msrest.serialization.Model):
    """The end of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleCloudStorageReadSettingsModifiedDatetimeEnd, self).__init__(**kwargs)


class GoogleCloudStorageReadSettingsModifiedDatetimeStart(msrest.serialization.Model):
    """The start of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleCloudStorageReadSettingsModifiedDatetimeStart, self).__init__(**kwargs)


class GoogleCloudStorageReadSettingsPrefix(msrest.serialization.Model):
    """The prefix filter for the Google Cloud Storage object name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleCloudStorageReadSettingsPrefix, self).__init__(**kwargs)


class GoogleCloudStorageReadSettingsRecursive(msrest.serialization.Model):
    """If true, files under the folder path will be read recursively. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleCloudStorageReadSettingsRecursive, self).__init__(**kwargs)


class GoogleCloudStorageReadSettingsWildcardFileName(msrest.serialization.Model):
    """Google Cloud Storage wildcardFileName. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleCloudStorageReadSettingsWildcardFileName, self).__init__(**kwargs)


class GoogleCloudStorageReadSettingsWildcardFolderPath(msrest.serialization.Model):
    """Google Cloud Storage wildcardFolderPath. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GoogleCloudStorageReadSettingsWildcardFolderPath, self).__init__(**kwargs)


class GreenplumDatasetTypeProperties(msrest.serialization.Model):
    """Greenplum Dataset Properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.GreenplumDatasetTypePropertiesTableName
    :param table: The table name of Greenplum. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.GreenplumDatasetTypePropertiesTable
    :param schema: The schema name of Greenplum. Type: string (or Expression with resultType
     string).
    :type schema: ~data_factory_management_client.models.GreenplumDatasetTypePropertiesSchema
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'GreenplumDatasetTypePropertiesTableName'},
        'table': {'key': 'table', 'type': 'GreenplumDatasetTypePropertiesTable'},
        'schema': {'key': 'schema', 'type': 'GreenplumDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["GreenplumDatasetTypePropertiesTableName"] = None,
        table: Optional["GreenplumDatasetTypePropertiesTable"] = None,
        schema: Optional["GreenplumDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(GreenplumDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.table = table
        self.schema = schema


class GreenplumDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of Greenplum. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GreenplumDatasetTypePropertiesSchema, self).__init__(**kwargs)


class GreenplumDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of Greenplum. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GreenplumDatasetTypePropertiesTable, self).__init__(**kwargs)


class GreenplumDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GreenplumDatasetTypePropertiesTableName, self).__init__(**kwargs)


class GreenplumLinkedService(LinkedService):
    """Greenplum Database linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.GreenplumLinkedServiceTypePropertiesConnectionString
    :param pwd: Azure Key Vault secret reference.
    :type pwd: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.GreenplumLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'GreenplumLinkedServiceTypePropertiesConnectionString'},
        'pwd': {'key': 'typeProperties.pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'GreenplumLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        connection_string: Optional["GreenplumLinkedServiceTypePropertiesConnectionString"] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["GreenplumLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(GreenplumLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Greenplum'
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class GreenplumLinkedServiceTypeProperties(msrest.serialization.Model):
    """Greenplum Database linked service properties.

    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.GreenplumLinkedServiceTypePropertiesConnectionString
    :param pwd: Azure Key Vault secret reference.
    :type pwd: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.GreenplumLinkedServiceTypePropertiesEncryptedCredential
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'GreenplumLinkedServiceTypePropertiesConnectionString'},
        'pwd': {'key': 'pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'GreenplumLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional["GreenplumLinkedServiceTypePropertiesConnectionString"] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["GreenplumLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(GreenplumLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class GreenplumLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """An ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GreenplumLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class GreenplumLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GreenplumLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class GreenplumSource(TabularSource):
    """A copy activity Greenplum Database source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.GreenplumSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'GreenplumSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["GreenplumSourceQuery"] = None,
        **kwargs
    ):
        super(GreenplumSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'GreenplumSource'
        self.query = query


class GreenplumSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(GreenplumSourceQuery, self).__init__(**kwargs)


class GreenplumTableDataset(Dataset):
    """Greenplum Database dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.GreenplumDatasetTypePropertiesTableName
    :param table: The table name of Greenplum. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.GreenplumDatasetTypePropertiesTable
    :param schema_type_properties_schema: The schema name of Greenplum. Type: string (or Expression
     with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.GreenplumDatasetTypePropertiesSchema
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GreenplumDatasetTypePropertiesTableName'},
        'table': {'key': 'typeProperties.table', 'type': 'GreenplumDatasetTypePropertiesTable'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'GreenplumDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GreenplumDatasetTypePropertiesTableName"] = None,
        table: Optional["GreenplumDatasetTypePropertiesTable"] = None,
        schema_type_properties_schema: Optional["GreenplumDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(GreenplumTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'GreenplumTable'
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class HBaseLinkedService(LinkedService):
    """HBase server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. The IP address or host name of the HBase server. (i.e. 192.168.222.160).
    :type host: ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesHost
    :param port: The TCP port that the HBase instance uses to listen for client connections. The
     default value is 9090.
    :type port: ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesPort
    :param http_path: The partial URL corresponding to the HBase server. (i.e.
     /gateway/sandbox/hbase/version).
    :type http_path:
     ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesHttpPath
    :param authentication_type: Required. The authentication mechanism to use to connect to the
     HBase server. Possible values include: 'Anonymous', 'Basic'.
    :type authentication_type: str or
     ~data_factory_management_client.models.HBaseAuthenticationType
    :param username: The user name used to connect to the HBase instance.
    :type username: ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :type enable_ssl:
     ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesEnableSsl
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesTrustedCertPath
    :param allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :type allow_host_name_cn_mismatch:
     ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesAllowHostNameCNMismatch
    :param allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :type allow_self_signed_server_cert:
     ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesAllowSelfSignedServerCert
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'HBaseLinkedServiceTypePropertiesHost'},
        'port': {'key': 'typeProperties.port', 'type': 'HBaseLinkedServiceTypePropertiesPort'},
        'http_path': {'key': 'typeProperties.httpPath', 'type': 'HBaseLinkedServiceTypePropertiesHttpPath'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'HBaseLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'HBaseLinkedServiceTypePropertiesEnableSsl'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'HBaseLinkedServiceTypePropertiesTrustedCertPath'},
        'allow_host_name_cn_mismatch': {'key': 'typeProperties.allowHostNameCNMismatch', 'type': 'HBaseLinkedServiceTypePropertiesAllowHostNameCNMismatch'},
        'allow_self_signed_server_cert': {'key': 'typeProperties.allowSelfSignedServerCert', 'type': 'HBaseLinkedServiceTypePropertiesAllowSelfSignedServerCert'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'HBaseLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "HBaseLinkedServiceTypePropertiesHost",
        authentication_type: Union[str, "HBaseAuthenticationType"],
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        port: Optional["HBaseLinkedServiceTypePropertiesPort"] = None,
        http_path: Optional["HBaseLinkedServiceTypePropertiesHttpPath"] = None,
        username: Optional["HBaseLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        enable_ssl: Optional["HBaseLinkedServiceTypePropertiesEnableSsl"] = None,
        trusted_cert_path: Optional["HBaseLinkedServiceTypePropertiesTrustedCertPath"] = None,
        allow_host_name_cn_mismatch: Optional["HBaseLinkedServiceTypePropertiesAllowHostNameCNMismatch"] = None,
        allow_self_signed_server_cert: Optional["HBaseLinkedServiceTypePropertiesAllowSelfSignedServerCert"] = None,
        encrypted_credential: Optional["HBaseLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(HBaseLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'HBase'
        self.host = host
        self.port = port
        self.http_path = http_path
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class HBaseLinkedServiceTypeProperties(msrest.serialization.Model):
    """HBase server linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. The IP address or host name of the HBase server. (i.e. 192.168.222.160).
    :type host: ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesHost
    :param port: The TCP port that the HBase instance uses to listen for client connections. The
     default value is 9090.
    :type port: ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesPort
    :param http_path: The partial URL corresponding to the HBase server. (i.e.
     /gateway/sandbox/hbase/version).
    :type http_path:
     ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesHttpPath
    :param authentication_type: Required. The authentication mechanism to use to connect to the
     HBase server. Possible values include: 'Anonymous', 'Basic'.
    :type authentication_type: str or
     ~data_factory_management_client.models.HBaseAuthenticationType
    :param username: The user name used to connect to the HBase instance.
    :type username: ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :type enable_ssl:
     ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesEnableSsl
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesTrustedCertPath
    :param allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :type allow_host_name_cn_mismatch:
     ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesAllowHostNameCNMismatch
    :param allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :type allow_self_signed_server_cert:
     ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesAllowSelfSignedServerCert
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.HBaseLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'HBaseLinkedServiceTypePropertiesHost'},
        'port': {'key': 'port', 'type': 'HBaseLinkedServiceTypePropertiesPort'},
        'http_path': {'key': 'httpPath', 'type': 'HBaseLinkedServiceTypePropertiesHttpPath'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'username': {'key': 'username', 'type': 'HBaseLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'enable_ssl': {'key': 'enableSsl', 'type': 'HBaseLinkedServiceTypePropertiesEnableSsl'},
        'trusted_cert_path': {'key': 'trustedCertPath', 'type': 'HBaseLinkedServiceTypePropertiesTrustedCertPath'},
        'allow_host_name_cn_mismatch': {'key': 'allowHostNameCNMismatch', 'type': 'HBaseLinkedServiceTypePropertiesAllowHostNameCNMismatch'},
        'allow_self_signed_server_cert': {'key': 'allowSelfSignedServerCert', 'type': 'HBaseLinkedServiceTypePropertiesAllowSelfSignedServerCert'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'HBaseLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "HBaseLinkedServiceTypePropertiesHost",
        authentication_type: Union[str, "HBaseAuthenticationType"],
        port: Optional["HBaseLinkedServiceTypePropertiesPort"] = None,
        http_path: Optional["HBaseLinkedServiceTypePropertiesHttpPath"] = None,
        username: Optional["HBaseLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        enable_ssl: Optional["HBaseLinkedServiceTypePropertiesEnableSsl"] = None,
        trusted_cert_path: Optional["HBaseLinkedServiceTypePropertiesTrustedCertPath"] = None,
        allow_host_name_cn_mismatch: Optional["HBaseLinkedServiceTypePropertiesAllowHostNameCNMismatch"] = None,
        allow_self_signed_server_cert: Optional["HBaseLinkedServiceTypePropertiesAllowSelfSignedServerCert"] = None,
        encrypted_credential: Optional["HBaseLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(HBaseLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.port = port
        self.http_path = http_path
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class HBaseLinkedServiceTypePropertiesAllowHostNameCNMismatch(msrest.serialization.Model):
    """Specifies whether to require a CA-issued SSL certificate name to match the host name of the server when connecting over SSL. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HBaseLinkedServiceTypePropertiesAllowHostNameCNMismatch, self).__init__(**kwargs)


class HBaseLinkedServiceTypePropertiesAllowSelfSignedServerCert(msrest.serialization.Model):
    """Specifies whether to allow self-signed certificates from the server. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HBaseLinkedServiceTypePropertiesAllowSelfSignedServerCert, self).__init__(**kwargs)


class HBaseLinkedServiceTypePropertiesEnableSsl(msrest.serialization.Model):
    """Specifies whether the connections to the server are encrypted using SSL. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HBaseLinkedServiceTypePropertiesEnableSsl, self).__init__(**kwargs)


class HBaseLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HBaseLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class HBaseLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """The IP address or host name of the HBase server. (i.e. 192.168.222.160).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HBaseLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class HBaseLinkedServiceTypePropertiesHttpPath(msrest.serialization.Model):
    """The partial URL corresponding to the HBase server. (i.e. /gateway/sandbox/hbase/version).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HBaseLinkedServiceTypePropertiesHttpPath, self).__init__(**kwargs)


class HBaseLinkedServiceTypePropertiesPort(msrest.serialization.Model):
    """The TCP port that the HBase instance uses to listen for client connections. The default value is 9090.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HBaseLinkedServiceTypePropertiesPort, self).__init__(**kwargs)


class HBaseLinkedServiceTypePropertiesTrustedCertPath(msrest.serialization.Model):
    """The full path of the .pem file containing trusted CA certificates for verifying the server when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The default value is the cacerts.pem file installed with the IR.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HBaseLinkedServiceTypePropertiesTrustedCertPath, self).__init__(**kwargs)


class HBaseLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """The user name used to connect to the HBase instance.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HBaseLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class HBaseObjectDataset(Dataset):
    """HBase server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(HBaseObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'HBaseObject'
        self.table_name = table_name


class HBaseSource(TabularSource):
    """A copy activity HBase server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.HBaseSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'HBaseSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["HBaseSourceQuery"] = None,
        **kwargs
    ):
        super(HBaseSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'HBaseSource'
        self.query = query


class HBaseSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HBaseSourceQuery, self).__init__(**kwargs)


class HdfsLinkedService(LinkedService):
    """Hadoop Distributed File System (HDFS) linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param url: Required. The URL of the HDFS service endpoint, e.g.
     http://myhostname:50070/webhdfs/v1 . Type: string (or Expression with resultType string).
    :type url: ~data_factory_management_client.models.HdfsLinkedServiceTypePropertiesUrl
    :param authentication_type: Type of authentication used to connect to the HDFS. Possible values
     are: Anonymous and Windows. Type: string (or Expression with resultType string).
    :type authentication_type:
     ~data_factory_management_client.models.HdfsLinkedServiceTypePropertiesAuthenticationType
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.HdfsLinkedServiceTypePropertiesEncryptedCredential
    :param user_name: User name for Windows authentication. Type: string (or Expression with
     resultType string).
    :type user_name: ~data_factory_management_client.models.HdfsLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'url': {'key': 'typeProperties.url', 'type': 'HdfsLinkedServiceTypePropertiesUrl'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'HdfsLinkedServiceTypePropertiesAuthenticationType'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'HdfsLinkedServiceTypePropertiesEncryptedCredential'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'HdfsLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        url: "HdfsLinkedServiceTypePropertiesUrl",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        authentication_type: Optional["HdfsLinkedServiceTypePropertiesAuthenticationType"] = None,
        encrypted_credential: Optional["HdfsLinkedServiceTypePropertiesEncryptedCredential"] = None,
        user_name: Optional["HdfsLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        **kwargs
    ):
        super(HdfsLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Hdfs'
        self.url = url
        self.authentication_type = authentication_type
        self.encrypted_credential = encrypted_credential
        self.user_name = user_name
        self.password = password


class HdfsLinkedServiceTypeProperties(msrest.serialization.Model):
    """HDFS linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param url: Required. The URL of the HDFS service endpoint, e.g.
     http://myhostname:50070/webhdfs/v1 . Type: string (or Expression with resultType string).
    :type url: ~data_factory_management_client.models.HdfsLinkedServiceTypePropertiesUrl
    :param authentication_type: Type of authentication used to connect to the HDFS. Possible values
     are: Anonymous and Windows. Type: string (or Expression with resultType string).
    :type authentication_type:
     ~data_factory_management_client.models.HdfsLinkedServiceTypePropertiesAuthenticationType
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.HdfsLinkedServiceTypePropertiesEncryptedCredential
    :param user_name: User name for Windows authentication. Type: string (or Expression with
     resultType string).
    :type user_name: ~data_factory_management_client.models.HdfsLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    """

    _validation = {
        'url': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'HdfsLinkedServiceTypePropertiesUrl'},
        'authentication_type': {'key': 'authenticationType', 'type': 'HdfsLinkedServiceTypePropertiesAuthenticationType'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'HdfsLinkedServiceTypePropertiesEncryptedCredential'},
        'user_name': {'key': 'userName', 'type': 'HdfsLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        url: "HdfsLinkedServiceTypePropertiesUrl",
        authentication_type: Optional["HdfsLinkedServiceTypePropertiesAuthenticationType"] = None,
        encrypted_credential: Optional["HdfsLinkedServiceTypePropertiesEncryptedCredential"] = None,
        user_name: Optional["HdfsLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        **kwargs
    ):
        super(HdfsLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.url = url
        self.authentication_type = authentication_type
        self.encrypted_credential = encrypted_credential
        self.user_name = user_name
        self.password = password


class HdfsLinkedServiceTypePropertiesAuthenticationType(msrest.serialization.Model):
    """Type of authentication used to connect to the HDFS. Possible values are: Anonymous and Windows. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HdfsLinkedServiceTypePropertiesAuthenticationType, self).__init__(**kwargs)


class HdfsLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HdfsLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class HdfsLinkedServiceTypePropertiesUrl(msrest.serialization.Model):
    """The URL of the HDFS service endpoint, e.g. http://myhostname:50070/webhdfs/v1 . Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HdfsLinkedServiceTypePropertiesUrl, self).__init__(**kwargs)


class HdfsLinkedServiceTypePropertiesUserName(msrest.serialization.Model):
    """User name for Windows authentication. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HdfsLinkedServiceTypePropertiesUserName, self).__init__(**kwargs)


class HdfsLocation(DatasetLocation):
    """The location of HDFS.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage location.Constant filled by server.
    :type type: str
    :param folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :type folder_path: ~data_factory_management_client.models.DatasetLocationFolderPath
    :param file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :type file_name: ~data_factory_management_client.models.DatasetLocationFileName
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'DatasetLocationFolderPath'},
        'file_name': {'key': 'fileName', 'type': 'DatasetLocationFileName'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        folder_path: Optional["DatasetLocationFolderPath"] = None,
        file_name: Optional["DatasetLocationFileName"] = None,
        **kwargs
    ):
        super(HdfsLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'HdfsLocation'


class HdfsReadSettings(StoreReadSettings):
    """HDFS read settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The read setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreReadSettingsMaxConcurrentConnections
    :param recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.HdfsReadSettingsRecursive
    :param wildcard_folder_path: HDFS wildcardFolderPath. Type: string (or Expression with
     resultType string).
    :type wildcard_folder_path:
     ~data_factory_management_client.models.HdfsReadSettingsWildcardFolderPath
    :param wildcard_file_name: HDFS wildcardFileName. Type: string (or Expression with resultType
     string).
    :type wildcard_file_name:
     ~data_factory_management_client.models.HdfsReadSettingsWildcardFileName
    :param file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :type file_list_path: ~data_factory_management_client.models.HdfsReadSettingsFileListPath
    :param enable_partition_discovery: Indicates whether to enable partition discovery.
    :type enable_partition_discovery: bool
    :param modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_start:
     ~data_factory_management_client.models.HdfsReadSettingsModifiedDatetimeStart
    :param modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :type modified_datetime_end:
     ~data_factory_management_client.models.HdfsReadSettingsModifiedDatetimeEnd
    :param distcp_settings: Distcp settings.
    :type distcp_settings: ~data_factory_management_client.models.DistcpSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreReadSettingsMaxConcurrentConnections'},
        'recursive': {'key': 'recursive', 'type': 'HdfsReadSettingsRecursive'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'HdfsReadSettingsWildcardFolderPath'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'HdfsReadSettingsWildcardFileName'},
        'file_list_path': {'key': 'fileListPath', 'type': 'HdfsReadSettingsFileListPath'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'HdfsReadSettingsModifiedDatetimeStart'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'HdfsReadSettingsModifiedDatetimeEnd'},
        'distcp_settings': {'key': 'distcpSettings', 'type': 'DistcpSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreReadSettingsMaxConcurrentConnections"] = None,
        recursive: Optional["HdfsReadSettingsRecursive"] = None,
        wildcard_folder_path: Optional["HdfsReadSettingsWildcardFolderPath"] = None,
        wildcard_file_name: Optional["HdfsReadSettingsWildcardFileName"] = None,
        file_list_path: Optional["HdfsReadSettingsFileListPath"] = None,
        enable_partition_discovery: Optional[bool] = None,
        modified_datetime_start: Optional["HdfsReadSettingsModifiedDatetimeStart"] = None,
        modified_datetime_end: Optional["HdfsReadSettingsModifiedDatetimeEnd"] = None,
        distcp_settings: Optional["DistcpSettings"] = None,
        **kwargs
    ):
        super(HdfsReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'HdfsReadSettings'
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end
        self.distcp_settings = distcp_settings


class HdfsReadSettingsFileListPath(msrest.serialization.Model):
    """Point to a text file that lists each file (relative path to the path configured in the dataset) that you want to copy. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HdfsReadSettingsFileListPath, self).__init__(**kwargs)


class HdfsReadSettingsModifiedDatetimeEnd(msrest.serialization.Model):
    """The end of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HdfsReadSettingsModifiedDatetimeEnd, self).__init__(**kwargs)


class HdfsReadSettingsModifiedDatetimeStart(msrest.serialization.Model):
    """The start of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HdfsReadSettingsModifiedDatetimeStart, self).__init__(**kwargs)


class HdfsReadSettingsRecursive(msrest.serialization.Model):
    """If true, files under the folder path will be read recursively. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HdfsReadSettingsRecursive, self).__init__(**kwargs)


class HdfsReadSettingsWildcardFileName(msrest.serialization.Model):
    """HDFS wildcardFileName. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HdfsReadSettingsWildcardFileName, self).__init__(**kwargs)


class HdfsReadSettingsWildcardFolderPath(msrest.serialization.Model):
    """HDFS wildcardFolderPath. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HdfsReadSettingsWildcardFolderPath, self).__init__(**kwargs)


class HdfsSource(CopySource):
    """A copy activity HDFS source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.HdfsSourceRecursive
    :param distcp_settings: Distcp settings.
    :type distcp_settings: ~data_factory_management_client.models.DistcpSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'recursive': {'key': 'recursive', 'type': 'HdfsSourceRecursive'},
        'distcp_settings': {'key': 'distcpSettings', 'type': 'DistcpSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        recursive: Optional["HdfsSourceRecursive"] = None,
        distcp_settings: Optional["DistcpSettings"] = None,
        **kwargs
    ):
        super(HdfsSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'HdfsSource'
        self.recursive = recursive
        self.distcp_settings = distcp_settings


class HdfsSourceRecursive(msrest.serialization.Model):
    """If true, files under the folder path will be read recursively. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HdfsSourceRecursive, self).__init__(**kwargs)


class HDInsightHiveActivity(ExecutionActivity):
    """HDInsight Hive activity type.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param storage_linked_services: Storage linked service references.
    :type storage_linked_services:
     list[~data_factory_management_client.models.LinkedServiceReference]
    :param arguments: User specified arguments to HDInsightActivity.
    :type arguments:
     list[~data_factory_management_client.models.HDInsightHiveActivityTypePropertiesArgumentsItem]
    :param get_debug_info: The HDInsightActivityDebugInfoOption settings to use. Possible values
     include: 'None', 'Always', 'Failure'.
    :type get_debug_info: str or
     ~data_factory_management_client.models.HDInsightActivityDebugInfoOption
    :param script_path: Script path. Type: string (or Expression with resultType string).
    :type script_path:
     ~data_factory_management_client.models.HDInsightHiveActivityTypePropertiesScriptPath
    :param script_linked_service: Linked service reference type.
    :type script_linked_service: ~data_factory_management_client.models.LinkedServiceReference
    :param defines: Allows user to specify defines for Hive job request.
    :type defines: dict[str, object]
    :param variables: User specified arguments under hivevar namespace.
    :type variables:
     list[~data_factory_management_client.models.HDInsightHiveActivityTypePropertiesVariablesItem]
    :param query_timeout: Query timeout value (in minutes).  Effective when the HDInsight cluster
     is with ESP (Enterprise Security Package).
    :type query_timeout: int
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'storage_linked_services': {'key': 'typeProperties.storageLinkedServices', 'type': '[LinkedServiceReference]'},
        'arguments': {'key': 'typeProperties.arguments', 'type': '[HDInsightHiveActivityTypePropertiesArgumentsItem]'},
        'get_debug_info': {'key': 'typeProperties.getDebugInfo', 'type': 'str'},
        'script_path': {'key': 'typeProperties.scriptPath', 'type': 'HDInsightHiveActivityTypePropertiesScriptPath'},
        'script_linked_service': {'key': 'typeProperties.scriptLinkedService', 'type': 'LinkedServiceReference'},
        'defines': {'key': 'typeProperties.defines', 'type': '{object}'},
        'variables': {'key': 'typeProperties.variables', 'type': '[HDInsightHiveActivityTypePropertiesVariablesItem]'},
        'query_timeout': {'key': 'typeProperties.queryTimeout', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        storage_linked_services: Optional[List["LinkedServiceReference"]] = None,
        arguments: Optional[List["HDInsightHiveActivityTypePropertiesArgumentsItem"]] = None,
        get_debug_info: Optional[Union[str, "HDInsightActivityDebugInfoOption"]] = None,
        script_path: Optional["HDInsightHiveActivityTypePropertiesScriptPath"] = None,
        script_linked_service: Optional["LinkedServiceReference"] = None,
        defines: Optional[Dict[str, object]] = None,
        variables: Optional[List["HDInsightHiveActivityTypePropertiesVariablesItem"]] = None,
        query_timeout: Optional[int] = None,
        **kwargs
    ):
        super(HDInsightHiveActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'HDInsightHive'
        self.storage_linked_services = storage_linked_services
        self.arguments = arguments
        self.get_debug_info = get_debug_info
        self.script_path = script_path
        self.script_linked_service = script_linked_service
        self.defines = defines
        self.variables = variables
        self.query_timeout = query_timeout


class HDInsightHiveActivityTypeProperties(msrest.serialization.Model):
    """HDInsight Hive activity properties.

    :param storage_linked_services: Storage linked service references.
    :type storage_linked_services:
     list[~data_factory_management_client.models.LinkedServiceReference]
    :param arguments: User specified arguments to HDInsightActivity.
    :type arguments:
     list[~data_factory_management_client.models.HDInsightHiveActivityTypePropertiesArgumentsItem]
    :param get_debug_info: The HDInsightActivityDebugInfoOption settings to use. Possible values
     include: 'None', 'Always', 'Failure'.
    :type get_debug_info: str or
     ~data_factory_management_client.models.HDInsightActivityDebugInfoOption
    :param script_path: Script path. Type: string (or Expression with resultType string).
    :type script_path:
     ~data_factory_management_client.models.HDInsightHiveActivityTypePropertiesScriptPath
    :param script_linked_service: Linked service reference type.
    :type script_linked_service: ~data_factory_management_client.models.LinkedServiceReference
    :param defines: Allows user to specify defines for Hive job request.
    :type defines: dict[str, object]
    :param variables: User specified arguments under hivevar namespace.
    :type variables:
     list[~data_factory_management_client.models.HDInsightHiveActivityTypePropertiesVariablesItem]
    :param query_timeout: Query timeout value (in minutes).  Effective when the HDInsight cluster
     is with ESP (Enterprise Security Package).
    :type query_timeout: int
    """

    _attribute_map = {
        'storage_linked_services': {'key': 'storageLinkedServices', 'type': '[LinkedServiceReference]'},
        'arguments': {'key': 'arguments', 'type': '[HDInsightHiveActivityTypePropertiesArgumentsItem]'},
        'get_debug_info': {'key': 'getDebugInfo', 'type': 'str'},
        'script_path': {'key': 'scriptPath', 'type': 'HDInsightHiveActivityTypePropertiesScriptPath'},
        'script_linked_service': {'key': 'scriptLinkedService', 'type': 'LinkedServiceReference'},
        'defines': {'key': 'defines', 'type': '{object}'},
        'variables': {'key': 'variables', 'type': '[HDInsightHiveActivityTypePropertiesVariablesItem]'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        storage_linked_services: Optional[List["LinkedServiceReference"]] = None,
        arguments: Optional[List["HDInsightHiveActivityTypePropertiesArgumentsItem"]] = None,
        get_debug_info: Optional[Union[str, "HDInsightActivityDebugInfoOption"]] = None,
        script_path: Optional["HDInsightHiveActivityTypePropertiesScriptPath"] = None,
        script_linked_service: Optional["LinkedServiceReference"] = None,
        defines: Optional[Dict[str, object]] = None,
        variables: Optional[List["HDInsightHiveActivityTypePropertiesVariablesItem"]] = None,
        query_timeout: Optional[int] = None,
        **kwargs
    ):
        super(HDInsightHiveActivityTypeProperties, self).__init__(**kwargs)
        self.storage_linked_services = storage_linked_services
        self.arguments = arguments
        self.get_debug_info = get_debug_info
        self.script_path = script_path
        self.script_linked_service = script_linked_service
        self.defines = defines
        self.variables = variables
        self.query_timeout = query_timeout


class HDInsightHiveActivityTypePropertiesArgumentsItem(msrest.serialization.Model):
    """Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightHiveActivityTypePropertiesArgumentsItem, self).__init__(**kwargs)


class HDInsightHiveActivityTypePropertiesScriptPath(msrest.serialization.Model):
    """Script path. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightHiveActivityTypePropertiesScriptPath, self).__init__(**kwargs)


class HDInsightHiveActivityTypePropertiesVariablesItem(msrest.serialization.Model):
    """Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightHiveActivityTypePropertiesVariablesItem, self).__init__(**kwargs)


class HDInsightLinkedService(LinkedService):
    """HDInsight linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param cluster_uri: Required. HDInsight cluster URI. Type: string (or Expression with
     resultType string).
    :type cluster_uri:
     ~data_factory_management_client.models.HDInsightLinkedServiceTypePropertiesClusterUri
    :param user_name: HDInsight cluster user name. Type: string (or Expression with resultType
     string).
    :type user_name:
     ~data_factory_management_client.models.HDInsightLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param hcatalog_linked_service_name: Linked service reference type.
    :type hcatalog_linked_service_name:
     ~data_factory_management_client.models.LinkedServiceReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.HDInsightLinkedServiceTypePropertiesEncryptedCredential
    :param is_esp_enabled: Specify if the HDInsight is created with ESP (Enterprise Security
     Package). Type: Boolean.
    :type is_esp_enabled:
     ~data_factory_management_client.models.HDInsightLinkedServiceTypePropertiesIsEspEnabled
    :param file_system: Specify the FileSystem if the main storage for the HDInsight is ADLS Gen2.
     Type: string (or Expression with resultType string).
    :type file_system:
     ~data_factory_management_client.models.HDInsightLinkedServiceTypePropertiesFileSystem
    """

    _validation = {
        'type': {'required': True},
        'cluster_uri': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'cluster_uri': {'key': 'typeProperties.clusterUri', 'type': 'HDInsightLinkedServiceTypePropertiesClusterUri'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'HDInsightLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'linked_service_name': {'key': 'typeProperties.linkedServiceName', 'type': 'LinkedServiceReference'},
        'hcatalog_linked_service_name': {'key': 'typeProperties.hcatalogLinkedServiceName', 'type': 'LinkedServiceReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'HDInsightLinkedServiceTypePropertiesEncryptedCredential'},
        'is_esp_enabled': {'key': 'typeProperties.isEspEnabled', 'type': 'HDInsightLinkedServiceTypePropertiesIsEspEnabled'},
        'file_system': {'key': 'typeProperties.fileSystem', 'type': 'HDInsightLinkedServiceTypePropertiesFileSystem'},
    }

    def __init__(
        self,
        *,
        cluster_uri: "HDInsightLinkedServiceTypePropertiesClusterUri",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        user_name: Optional["HDInsightLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        hcatalog_linked_service_name: Optional["LinkedServiceReference"] = None,
        encrypted_credential: Optional["HDInsightLinkedServiceTypePropertiesEncryptedCredential"] = None,
        is_esp_enabled: Optional["HDInsightLinkedServiceTypePropertiesIsEspEnabled"] = None,
        file_system: Optional["HDInsightLinkedServiceTypePropertiesFileSystem"] = None,
        **kwargs
    ):
        super(HDInsightLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'HDInsight'
        self.cluster_uri = cluster_uri
        self.user_name = user_name
        self.password = password
        self.linked_service_name = linked_service_name
        self.hcatalog_linked_service_name = hcatalog_linked_service_name
        self.encrypted_credential = encrypted_credential
        self.is_esp_enabled = is_esp_enabled
        self.file_system = file_system


class HDInsightLinkedServiceTypeProperties(msrest.serialization.Model):
    """HDInsight linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param cluster_uri: Required. HDInsight cluster URI. Type: string (or Expression with
     resultType string).
    :type cluster_uri:
     ~data_factory_management_client.models.HDInsightLinkedServiceTypePropertiesClusterUri
    :param user_name: HDInsight cluster user name. Type: string (or Expression with resultType
     string).
    :type user_name:
     ~data_factory_management_client.models.HDInsightLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param hcatalog_linked_service_name: Linked service reference type.
    :type hcatalog_linked_service_name:
     ~data_factory_management_client.models.LinkedServiceReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.HDInsightLinkedServiceTypePropertiesEncryptedCredential
    :param is_esp_enabled: Specify if the HDInsight is created with ESP (Enterprise Security
     Package). Type: Boolean.
    :type is_esp_enabled:
     ~data_factory_management_client.models.HDInsightLinkedServiceTypePropertiesIsEspEnabled
    :param file_system: Specify the FileSystem if the main storage for the HDInsight is ADLS Gen2.
     Type: string (or Expression with resultType string).
    :type file_system:
     ~data_factory_management_client.models.HDInsightLinkedServiceTypePropertiesFileSystem
    """

    _validation = {
        'cluster_uri': {'required': True},
    }

    _attribute_map = {
        'cluster_uri': {'key': 'clusterUri', 'type': 'HDInsightLinkedServiceTypePropertiesClusterUri'},
        'user_name': {'key': 'userName', 'type': 'HDInsightLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'hcatalog_linked_service_name': {'key': 'hcatalogLinkedServiceName', 'type': 'LinkedServiceReference'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'HDInsightLinkedServiceTypePropertiesEncryptedCredential'},
        'is_esp_enabled': {'key': 'isEspEnabled', 'type': 'HDInsightLinkedServiceTypePropertiesIsEspEnabled'},
        'file_system': {'key': 'fileSystem', 'type': 'HDInsightLinkedServiceTypePropertiesFileSystem'},
    }

    def __init__(
        self,
        *,
        cluster_uri: "HDInsightLinkedServiceTypePropertiesClusterUri",
        user_name: Optional["HDInsightLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        hcatalog_linked_service_name: Optional["LinkedServiceReference"] = None,
        encrypted_credential: Optional["HDInsightLinkedServiceTypePropertiesEncryptedCredential"] = None,
        is_esp_enabled: Optional["HDInsightLinkedServiceTypePropertiesIsEspEnabled"] = None,
        file_system: Optional["HDInsightLinkedServiceTypePropertiesFileSystem"] = None,
        **kwargs
    ):
        super(HDInsightLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.cluster_uri = cluster_uri
        self.user_name = user_name
        self.password = password
        self.linked_service_name = linked_service_name
        self.hcatalog_linked_service_name = hcatalog_linked_service_name
        self.encrypted_credential = encrypted_credential
        self.is_esp_enabled = is_esp_enabled
        self.file_system = file_system


class HDInsightLinkedServiceTypePropertiesClusterUri(msrest.serialization.Model):
    """HDInsight cluster URI. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightLinkedServiceTypePropertiesClusterUri, self).__init__(**kwargs)


class HDInsightLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class HDInsightLinkedServiceTypePropertiesFileSystem(msrest.serialization.Model):
    """Specify the FileSystem if the main storage for the HDInsight is ADLS Gen2. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightLinkedServiceTypePropertiesFileSystem, self).__init__(**kwargs)


class HDInsightLinkedServiceTypePropertiesIsEspEnabled(msrest.serialization.Model):
    """Specify if the HDInsight is created with ESP (Enterprise Security Package). Type: Boolean.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightLinkedServiceTypePropertiesIsEspEnabled, self).__init__(**kwargs)


class HDInsightLinkedServiceTypePropertiesUserName(msrest.serialization.Model):
    """HDInsight cluster user name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightLinkedServiceTypePropertiesUserName, self).__init__(**kwargs)


class HDInsightMapReduceActivity(ExecutionActivity):
    """HDInsight MapReduce activity type.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param storage_linked_services: Storage linked service references.
    :type storage_linked_services:
     list[~data_factory_management_client.models.LinkedServiceReference]
    :param arguments: User specified arguments to HDInsightActivity.
    :type arguments:
     list[~data_factory_management_client.models.HDInsightMapReduceActivityTypePropertiesArgumentsItem]
    :param get_debug_info: The HDInsightActivityDebugInfoOption settings to use. Possible values
     include: 'None', 'Always', 'Failure'.
    :type get_debug_info: str or
     ~data_factory_management_client.models.HDInsightActivityDebugInfoOption
    :param class_name: Required. Class name. Type: string (or Expression with resultType string).
    :type class_name:
     ~data_factory_management_client.models.HDInsightMapReduceActivityTypePropertiesClassName
    :param jar_file_path: Required. Jar path. Type: string (or Expression with resultType string).
    :type jar_file_path:
     ~data_factory_management_client.models.HDInsightMapReduceActivityTypePropertiesJarFilePath
    :param jar_linked_service: Linked service reference type.
    :type jar_linked_service: ~data_factory_management_client.models.LinkedServiceReference
    :param jar_libs: Jar libs.
    :type jar_libs:
     list[~data_factory_management_client.models.HDInsightMapReduceActivityTypePropertiesJarLibsItem]
    :param defines: Allows user to specify defines for the MapReduce job request.
    :type defines: dict[str, object]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'class_name': {'required': True},
        'jar_file_path': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'storage_linked_services': {'key': 'typeProperties.storageLinkedServices', 'type': '[LinkedServiceReference]'},
        'arguments': {'key': 'typeProperties.arguments', 'type': '[HDInsightMapReduceActivityTypePropertiesArgumentsItem]'},
        'get_debug_info': {'key': 'typeProperties.getDebugInfo', 'type': 'str'},
        'class_name': {'key': 'typeProperties.className', 'type': 'HDInsightMapReduceActivityTypePropertiesClassName'},
        'jar_file_path': {'key': 'typeProperties.jarFilePath', 'type': 'HDInsightMapReduceActivityTypePropertiesJarFilePath'},
        'jar_linked_service': {'key': 'typeProperties.jarLinkedService', 'type': 'LinkedServiceReference'},
        'jar_libs': {'key': 'typeProperties.jarLibs', 'type': '[HDInsightMapReduceActivityTypePropertiesJarLibsItem]'},
        'defines': {'key': 'typeProperties.defines', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        name: str,
        class_name: "HDInsightMapReduceActivityTypePropertiesClassName",
        jar_file_path: "HDInsightMapReduceActivityTypePropertiesJarFilePath",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        storage_linked_services: Optional[List["LinkedServiceReference"]] = None,
        arguments: Optional[List["HDInsightMapReduceActivityTypePropertiesArgumentsItem"]] = None,
        get_debug_info: Optional[Union[str, "HDInsightActivityDebugInfoOption"]] = None,
        jar_linked_service: Optional["LinkedServiceReference"] = None,
        jar_libs: Optional[List["HDInsightMapReduceActivityTypePropertiesJarLibsItem"]] = None,
        defines: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(HDInsightMapReduceActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'HDInsightMapReduce'
        self.storage_linked_services = storage_linked_services
        self.arguments = arguments
        self.get_debug_info = get_debug_info
        self.class_name = class_name
        self.jar_file_path = jar_file_path
        self.jar_linked_service = jar_linked_service
        self.jar_libs = jar_libs
        self.defines = defines


class HDInsightMapReduceActivityTypeProperties(msrest.serialization.Model):
    """HDInsight MapReduce activity properties.

    All required parameters must be populated in order to send to Azure.

    :param storage_linked_services: Storage linked service references.
    :type storage_linked_services:
     list[~data_factory_management_client.models.LinkedServiceReference]
    :param arguments: User specified arguments to HDInsightActivity.
    :type arguments:
     list[~data_factory_management_client.models.HDInsightMapReduceActivityTypePropertiesArgumentsItem]
    :param get_debug_info: The HDInsightActivityDebugInfoOption settings to use. Possible values
     include: 'None', 'Always', 'Failure'.
    :type get_debug_info: str or
     ~data_factory_management_client.models.HDInsightActivityDebugInfoOption
    :param class_name: Required. Class name. Type: string (or Expression with resultType string).
    :type class_name:
     ~data_factory_management_client.models.HDInsightMapReduceActivityTypePropertiesClassName
    :param jar_file_path: Required. Jar path. Type: string (or Expression with resultType string).
    :type jar_file_path:
     ~data_factory_management_client.models.HDInsightMapReduceActivityTypePropertiesJarFilePath
    :param jar_linked_service: Linked service reference type.
    :type jar_linked_service: ~data_factory_management_client.models.LinkedServiceReference
    :param jar_libs: Jar libs.
    :type jar_libs:
     list[~data_factory_management_client.models.HDInsightMapReduceActivityTypePropertiesJarLibsItem]
    :param defines: Allows user to specify defines for the MapReduce job request.
    :type defines: dict[str, object]
    """

    _validation = {
        'class_name': {'required': True},
        'jar_file_path': {'required': True},
    }

    _attribute_map = {
        'storage_linked_services': {'key': 'storageLinkedServices', 'type': '[LinkedServiceReference]'},
        'arguments': {'key': 'arguments', 'type': '[HDInsightMapReduceActivityTypePropertiesArgumentsItem]'},
        'get_debug_info': {'key': 'getDebugInfo', 'type': 'str'},
        'class_name': {'key': 'className', 'type': 'HDInsightMapReduceActivityTypePropertiesClassName'},
        'jar_file_path': {'key': 'jarFilePath', 'type': 'HDInsightMapReduceActivityTypePropertiesJarFilePath'},
        'jar_linked_service': {'key': 'jarLinkedService', 'type': 'LinkedServiceReference'},
        'jar_libs': {'key': 'jarLibs', 'type': '[HDInsightMapReduceActivityTypePropertiesJarLibsItem]'},
        'defines': {'key': 'defines', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        class_name: "HDInsightMapReduceActivityTypePropertiesClassName",
        jar_file_path: "HDInsightMapReduceActivityTypePropertiesJarFilePath",
        storage_linked_services: Optional[List["LinkedServiceReference"]] = None,
        arguments: Optional[List["HDInsightMapReduceActivityTypePropertiesArgumentsItem"]] = None,
        get_debug_info: Optional[Union[str, "HDInsightActivityDebugInfoOption"]] = None,
        jar_linked_service: Optional["LinkedServiceReference"] = None,
        jar_libs: Optional[List["HDInsightMapReduceActivityTypePropertiesJarLibsItem"]] = None,
        defines: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(HDInsightMapReduceActivityTypeProperties, self).__init__(**kwargs)
        self.storage_linked_services = storage_linked_services
        self.arguments = arguments
        self.get_debug_info = get_debug_info
        self.class_name = class_name
        self.jar_file_path = jar_file_path
        self.jar_linked_service = jar_linked_service
        self.jar_libs = jar_libs
        self.defines = defines


class HDInsightMapReduceActivityTypePropertiesArgumentsItem(msrest.serialization.Model):
    """Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightMapReduceActivityTypePropertiesArgumentsItem, self).__init__(**kwargs)


class HDInsightMapReduceActivityTypePropertiesClassName(msrest.serialization.Model):
    """Class name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightMapReduceActivityTypePropertiesClassName, self).__init__(**kwargs)


class HDInsightMapReduceActivityTypePropertiesJarFilePath(msrest.serialization.Model):
    """Jar path. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightMapReduceActivityTypePropertiesJarFilePath, self).__init__(**kwargs)


class HDInsightMapReduceActivityTypePropertiesJarLibsItem(msrest.serialization.Model):
    """Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightMapReduceActivityTypePropertiesJarLibsItem, self).__init__(**kwargs)


class HDInsightOnDemandLinkedService(LinkedService):
    """HDInsight ondemand linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param cluster_size: Required. Number of worker/data nodes in the cluster. Suggestion value: 4.
     Type: string (or Expression with resultType string).
    :type cluster_size:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesClusterSize
    :param time_to_live: Required. The allowed idle time for the on-demand HDInsight cluster.
     Specifies how long the on-demand HDInsight cluster stays alive after completion of an activity
     run if there are no other active jobs in the cluster. The minimum value is 5 mins. Type: string
     (or Expression with resultType string).
    :type time_to_live:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesTimeToLive
    :param version: Required. Version of the HDInsight cluster.  Type: string (or Expression with
     resultType string).
    :type version:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesVersion
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param host_subscription_id: Required. The customer’s subscription to host the cluster. Type:
     string (or Expression with resultType string).
    :type host_subscription_id:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesHostSubscriptionId
    :param service_principal_id: The service principal id for the hostSubscriptionId. Type: string
     (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: Required. The Tenant id/name to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesTenant
    :param cluster_resource_group: Required. The resource group where the cluster belongs. Type:
     string (or Expression with resultType string).
    :type cluster_resource_group:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesClusterResourceGroup
    :param cluster_name_prefix: The prefix of cluster name, postfix will be distinct with
     timestamp. Type: string (or Expression with resultType string).
    :type cluster_name_prefix:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesClusterNamePrefix
    :param cluster_user_name: The username to access the cluster. Type: string (or Expression with
     resultType string).
    :type cluster_user_name:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesClusterUserName
    :param cluster_password: The base definition of a secret type.
    :type cluster_password: ~data_factory_management_client.models.SecretBase
    :param cluster_ssh_user_name: The username to SSH remotely connect to cluster’s node (for
     Linux). Type: string (or Expression with resultType string).
    :type cluster_ssh_user_name:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesClusterSshUserName
    :param cluster_ssh_password: The base definition of a secret type.
    :type cluster_ssh_password: ~data_factory_management_client.models.SecretBase
    :param additional_linked_service_names: Specifies additional storage accounts for the HDInsight
     linked service so that the Data Factory service can register them on your behalf.
    :type additional_linked_service_names:
     list[~data_factory_management_client.models.LinkedServiceReference]
    :param hcatalog_linked_service_name: Linked service reference type.
    :type hcatalog_linked_service_name:
     ~data_factory_management_client.models.LinkedServiceReference
    :param cluster_type: The cluster type. Type: string (or Expression with resultType string).
    :type cluster_type:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesClusterType
    :param spark_version: The version of spark if the cluster type is 'spark'. Type: string (or
     Expression with resultType string).
    :type spark_version:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesSparkVersion
    :param core_configuration: Specifies the core configuration parameters (as in core-site.xml)
     for the HDInsight cluster to be created.
    :type core_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesCoreConfiguration
    :param h_base_configuration: Specifies the HBase configuration parameters (hbase-site.xml) for
     the HDInsight cluster.
    :type h_base_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesHBaseConfiguration
    :param hdfs_configuration: Specifies the HDFS configuration parameters (hdfs-site.xml) for the
     HDInsight cluster.
    :type hdfs_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesHdfsConfiguration
    :param hive_configuration: Specifies the hive configuration parameters (hive-site.xml) for the
     HDInsight cluster.
    :type hive_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesHiveConfiguration
    :param map_reduce_configuration: Specifies the MapReduce configuration parameters (mapred-
     site.xml) for the HDInsight cluster.
    :type map_reduce_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesMapReduceConfiguration
    :param oozie_configuration: Specifies the Oozie configuration parameters (oozie-site.xml) for
     the HDInsight cluster.
    :type oozie_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesOozieConfiguration
    :param storm_configuration: Specifies the Storm configuration parameters (storm-site.xml) for
     the HDInsight cluster.
    :type storm_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesStormConfiguration
    :param yarn_configuration: Specifies the Yarn configuration parameters (yarn-site.xml) for the
     HDInsight cluster.
    :type yarn_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesYarnConfiguration
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesEncryptedCredential
    :param head_node_size: Specifies the size of the head node for the HDInsight cluster.
    :type head_node_size:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesHeadNodeSize
    :param data_node_size: Specifies the size of the data node for the HDInsight cluster.
    :type data_node_size:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesDataNodeSize
    :param zookeeper_node_size: Specifies the size of the Zoo Keeper node for the HDInsight
     cluster.
    :type zookeeper_node_size:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesZookeeperNodeSize
    :param script_actions: Custom script actions to run on HDI ondemand cluster once it's up.
     Please refer to https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-customize-
     cluster-linux?toc=%2Fen-us%2Fazure%2Fhdinsight%2Fr-server%2FTOC.json&bc=%2Fen-
     us%2Fazure%2Fbread%2Ftoc.json#understanding-script-actions.
    :type script_actions: list[~data_factory_management_client.models.ScriptAction]
    :param virtual_network_id: The ARM resource ID for the vNet to which the cluster should be
     joined after creation. Type: string (or Expression with resultType string).
    :type virtual_network_id:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesVirtualNetworkId
    :param subnet_name: The ARM resource ID for the subnet in the vNet. If virtualNetworkId was
     specified, then this property is required. Type: string (or Expression with resultType string).
    :type subnet_name:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesSubnetName
    """

    _validation = {
        'type': {'required': True},
        'cluster_size': {'required': True},
        'time_to_live': {'required': True},
        'version': {'required': True},
        'linked_service_name': {'required': True},
        'host_subscription_id': {'required': True},
        'tenant': {'required': True},
        'cluster_resource_group': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'cluster_size': {'key': 'typeProperties.clusterSize', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesClusterSize'},
        'time_to_live': {'key': 'typeProperties.timeToLive', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesTimeToLive'},
        'version': {'key': 'typeProperties.version', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesVersion'},
        'linked_service_name': {'key': 'typeProperties.linkedServiceName', 'type': 'LinkedServiceReference'},
        'host_subscription_id': {'key': 'typeProperties.hostSubscriptionId', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesHostSubscriptionId'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesTenant'},
        'cluster_resource_group': {'key': 'typeProperties.clusterResourceGroup', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesClusterResourceGroup'},
        'cluster_name_prefix': {'key': 'typeProperties.clusterNamePrefix', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesClusterNamePrefix'},
        'cluster_user_name': {'key': 'typeProperties.clusterUserName', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesClusterUserName'},
        'cluster_password': {'key': 'typeProperties.clusterPassword', 'type': 'SecretBase'},
        'cluster_ssh_user_name': {'key': 'typeProperties.clusterSshUserName', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesClusterSshUserName'},
        'cluster_ssh_password': {'key': 'typeProperties.clusterSshPassword', 'type': 'SecretBase'},
        'additional_linked_service_names': {'key': 'typeProperties.additionalLinkedServiceNames', 'type': '[LinkedServiceReference]'},
        'hcatalog_linked_service_name': {'key': 'typeProperties.hcatalogLinkedServiceName', 'type': 'LinkedServiceReference'},
        'cluster_type': {'key': 'typeProperties.clusterType', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesClusterType'},
        'spark_version': {'key': 'typeProperties.sparkVersion', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesSparkVersion'},
        'core_configuration': {'key': 'typeProperties.coreConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesCoreConfiguration'},
        'h_base_configuration': {'key': 'typeProperties.hBaseConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesHBaseConfiguration'},
        'hdfs_configuration': {'key': 'typeProperties.hdfsConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesHdfsConfiguration'},
        'hive_configuration': {'key': 'typeProperties.hiveConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesHiveConfiguration'},
        'map_reduce_configuration': {'key': 'typeProperties.mapReduceConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesMapReduceConfiguration'},
        'oozie_configuration': {'key': 'typeProperties.oozieConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesOozieConfiguration'},
        'storm_configuration': {'key': 'typeProperties.stormConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesStormConfiguration'},
        'yarn_configuration': {'key': 'typeProperties.yarnConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesYarnConfiguration'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesEncryptedCredential'},
        'head_node_size': {'key': 'typeProperties.headNodeSize', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesHeadNodeSize'},
        'data_node_size': {'key': 'typeProperties.dataNodeSize', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesDataNodeSize'},
        'zookeeper_node_size': {'key': 'typeProperties.zookeeperNodeSize', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesZookeeperNodeSize'},
        'script_actions': {'key': 'typeProperties.scriptActions', 'type': '[ScriptAction]'},
        'virtual_network_id': {'key': 'typeProperties.virtualNetworkId', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesVirtualNetworkId'},
        'subnet_name': {'key': 'typeProperties.subnetName', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesSubnetName'},
    }

    def __init__(
        self,
        *,
        cluster_size: "HDInsightOnDemandLinkedServiceTypePropertiesClusterSize",
        time_to_live: "HDInsightOnDemandLinkedServiceTypePropertiesTimeToLive",
        version: "HDInsightOnDemandLinkedServiceTypePropertiesVersion",
        linked_service_name: "LinkedServiceReference",
        host_subscription_id: "HDInsightOnDemandLinkedServiceTypePropertiesHostSubscriptionId",
        tenant: "HDInsightOnDemandLinkedServiceTypePropertiesTenant",
        cluster_resource_group: "HDInsightOnDemandLinkedServiceTypePropertiesClusterResourceGroup",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        service_principal_id: Optional["HDInsightOnDemandLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        cluster_name_prefix: Optional["HDInsightOnDemandLinkedServiceTypePropertiesClusterNamePrefix"] = None,
        cluster_user_name: Optional["HDInsightOnDemandLinkedServiceTypePropertiesClusterUserName"] = None,
        cluster_password: Optional["SecretBase"] = None,
        cluster_ssh_user_name: Optional["HDInsightOnDemandLinkedServiceTypePropertiesClusterSshUserName"] = None,
        cluster_ssh_password: Optional["SecretBase"] = None,
        additional_linked_service_names: Optional[List["LinkedServiceReference"]] = None,
        hcatalog_linked_service_name: Optional["LinkedServiceReference"] = None,
        cluster_type: Optional["HDInsightOnDemandLinkedServiceTypePropertiesClusterType"] = None,
        spark_version: Optional["HDInsightOnDemandLinkedServiceTypePropertiesSparkVersion"] = None,
        core_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesCoreConfiguration"] = None,
        h_base_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesHBaseConfiguration"] = None,
        hdfs_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesHdfsConfiguration"] = None,
        hive_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesHiveConfiguration"] = None,
        map_reduce_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesMapReduceConfiguration"] = None,
        oozie_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesOozieConfiguration"] = None,
        storm_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesStormConfiguration"] = None,
        yarn_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesYarnConfiguration"] = None,
        encrypted_credential: Optional["HDInsightOnDemandLinkedServiceTypePropertiesEncryptedCredential"] = None,
        head_node_size: Optional["HDInsightOnDemandLinkedServiceTypePropertiesHeadNodeSize"] = None,
        data_node_size: Optional["HDInsightOnDemandLinkedServiceTypePropertiesDataNodeSize"] = None,
        zookeeper_node_size: Optional["HDInsightOnDemandLinkedServiceTypePropertiesZookeeperNodeSize"] = None,
        script_actions: Optional[List["ScriptAction"]] = None,
        virtual_network_id: Optional["HDInsightOnDemandLinkedServiceTypePropertiesVirtualNetworkId"] = None,
        subnet_name: Optional["HDInsightOnDemandLinkedServiceTypePropertiesSubnetName"] = None,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'HDInsightOnDemand'
        self.cluster_size = cluster_size
        self.time_to_live = time_to_live
        self.version = version
        self.linked_service_name = linked_service_name
        self.host_subscription_id = host_subscription_id
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.cluster_resource_group = cluster_resource_group
        self.cluster_name_prefix = cluster_name_prefix
        self.cluster_user_name = cluster_user_name
        self.cluster_password = cluster_password
        self.cluster_ssh_user_name = cluster_ssh_user_name
        self.cluster_ssh_password = cluster_ssh_password
        self.additional_linked_service_names = additional_linked_service_names
        self.hcatalog_linked_service_name = hcatalog_linked_service_name
        self.cluster_type = cluster_type
        self.spark_version = spark_version
        self.core_configuration = core_configuration
        self.h_base_configuration = h_base_configuration
        self.hdfs_configuration = hdfs_configuration
        self.hive_configuration = hive_configuration
        self.map_reduce_configuration = map_reduce_configuration
        self.oozie_configuration = oozie_configuration
        self.storm_configuration = storm_configuration
        self.yarn_configuration = yarn_configuration
        self.encrypted_credential = encrypted_credential
        self.head_node_size = head_node_size
        self.data_node_size = data_node_size
        self.zookeeper_node_size = zookeeper_node_size
        self.script_actions = script_actions
        self.virtual_network_id = virtual_network_id
        self.subnet_name = subnet_name


class HDInsightOnDemandLinkedServiceTypeProperties(msrest.serialization.Model):
    """HDInsight ondemand linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param cluster_size: Required. Number of worker/data nodes in the cluster. Suggestion value: 4.
     Type: string (or Expression with resultType string).
    :type cluster_size:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesClusterSize
    :param time_to_live: Required. The allowed idle time for the on-demand HDInsight cluster.
     Specifies how long the on-demand HDInsight cluster stays alive after completion of an activity
     run if there are no other active jobs in the cluster. The minimum value is 5 mins. Type: string
     (or Expression with resultType string).
    :type time_to_live:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesTimeToLive
    :param version: Required. Version of the HDInsight cluster.  Type: string (or Expression with
     resultType string).
    :type version:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesVersion
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param host_subscription_id: Required. The customer’s subscription to host the cluster. Type:
     string (or Expression with resultType string).
    :type host_subscription_id:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesHostSubscriptionId
    :param service_principal_id: The service principal id for the hostSubscriptionId. Type: string
     (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: Required. The Tenant id/name to which the service principal belongs. Type:
     string (or Expression with resultType string).
    :type tenant:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesTenant
    :param cluster_resource_group: Required. The resource group where the cluster belongs. Type:
     string (or Expression with resultType string).
    :type cluster_resource_group:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesClusterResourceGroup
    :param cluster_name_prefix: The prefix of cluster name, postfix will be distinct with
     timestamp. Type: string (or Expression with resultType string).
    :type cluster_name_prefix:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesClusterNamePrefix
    :param cluster_user_name: The username to access the cluster. Type: string (or Expression with
     resultType string).
    :type cluster_user_name:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesClusterUserName
    :param cluster_password: The base definition of a secret type.
    :type cluster_password: ~data_factory_management_client.models.SecretBase
    :param cluster_ssh_user_name: The username to SSH remotely connect to cluster’s node (for
     Linux). Type: string (or Expression with resultType string).
    :type cluster_ssh_user_name:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesClusterSshUserName
    :param cluster_ssh_password: The base definition of a secret type.
    :type cluster_ssh_password: ~data_factory_management_client.models.SecretBase
    :param additional_linked_service_names: Specifies additional storage accounts for the HDInsight
     linked service so that the Data Factory service can register them on your behalf.
    :type additional_linked_service_names:
     list[~data_factory_management_client.models.LinkedServiceReference]
    :param hcatalog_linked_service_name: Linked service reference type.
    :type hcatalog_linked_service_name:
     ~data_factory_management_client.models.LinkedServiceReference
    :param cluster_type: The cluster type. Type: string (or Expression with resultType string).
    :type cluster_type:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesClusterType
    :param spark_version: The version of spark if the cluster type is 'spark'. Type: string (or
     Expression with resultType string).
    :type spark_version:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesSparkVersion
    :param core_configuration: Specifies the core configuration parameters (as in core-site.xml)
     for the HDInsight cluster to be created.
    :type core_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesCoreConfiguration
    :param h_base_configuration: Specifies the HBase configuration parameters (hbase-site.xml) for
     the HDInsight cluster.
    :type h_base_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesHBaseConfiguration
    :param hdfs_configuration: Specifies the HDFS configuration parameters (hdfs-site.xml) for the
     HDInsight cluster.
    :type hdfs_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesHdfsConfiguration
    :param hive_configuration: Specifies the hive configuration parameters (hive-site.xml) for the
     HDInsight cluster.
    :type hive_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesHiveConfiguration
    :param map_reduce_configuration: Specifies the MapReduce configuration parameters (mapred-
     site.xml) for the HDInsight cluster.
    :type map_reduce_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesMapReduceConfiguration
    :param oozie_configuration: Specifies the Oozie configuration parameters (oozie-site.xml) for
     the HDInsight cluster.
    :type oozie_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesOozieConfiguration
    :param storm_configuration: Specifies the Storm configuration parameters (storm-site.xml) for
     the HDInsight cluster.
    :type storm_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesStormConfiguration
    :param yarn_configuration: Specifies the Yarn configuration parameters (yarn-site.xml) for the
     HDInsight cluster.
    :type yarn_configuration:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesYarnConfiguration
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesEncryptedCredential
    :param head_node_size: Specifies the size of the head node for the HDInsight cluster.
    :type head_node_size:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesHeadNodeSize
    :param data_node_size: Specifies the size of the data node for the HDInsight cluster.
    :type data_node_size:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesDataNodeSize
    :param zookeeper_node_size: Specifies the size of the Zoo Keeper node for the HDInsight
     cluster.
    :type zookeeper_node_size:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesZookeeperNodeSize
    :param script_actions: Custom script actions to run on HDI ondemand cluster once it's up.
     Please refer to https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-customize-
     cluster-linux?toc=%2Fen-us%2Fazure%2Fhdinsight%2Fr-server%2FTOC.json&bc=%2Fen-
     us%2Fazure%2Fbread%2Ftoc.json#understanding-script-actions.
    :type script_actions: list[~data_factory_management_client.models.ScriptAction]
    :param virtual_network_id: The ARM resource ID for the vNet to which the cluster should be
     joined after creation. Type: string (or Expression with resultType string).
    :type virtual_network_id:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesVirtualNetworkId
    :param subnet_name: The ARM resource ID for the subnet in the vNet. If virtualNetworkId was
     specified, then this property is required. Type: string (or Expression with resultType string).
    :type subnet_name:
     ~data_factory_management_client.models.HDInsightOnDemandLinkedServiceTypePropertiesSubnetName
    """

    _validation = {
        'cluster_size': {'required': True},
        'time_to_live': {'required': True},
        'version': {'required': True},
        'linked_service_name': {'required': True},
        'host_subscription_id': {'required': True},
        'tenant': {'required': True},
        'cluster_resource_group': {'required': True},
    }

    _attribute_map = {
        'cluster_size': {'key': 'clusterSize', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesClusterSize'},
        'time_to_live': {'key': 'timeToLive', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesTimeToLive'},
        'version': {'key': 'version', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesVersion'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'host_subscription_id': {'key': 'hostSubscriptionId', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesHostSubscriptionId'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'tenant', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesTenant'},
        'cluster_resource_group': {'key': 'clusterResourceGroup', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesClusterResourceGroup'},
        'cluster_name_prefix': {'key': 'clusterNamePrefix', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesClusterNamePrefix'},
        'cluster_user_name': {'key': 'clusterUserName', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesClusterUserName'},
        'cluster_password': {'key': 'clusterPassword', 'type': 'SecretBase'},
        'cluster_ssh_user_name': {'key': 'clusterSshUserName', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesClusterSshUserName'},
        'cluster_ssh_password': {'key': 'clusterSshPassword', 'type': 'SecretBase'},
        'additional_linked_service_names': {'key': 'additionalLinkedServiceNames', 'type': '[LinkedServiceReference]'},
        'hcatalog_linked_service_name': {'key': 'hcatalogLinkedServiceName', 'type': 'LinkedServiceReference'},
        'cluster_type': {'key': 'clusterType', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesClusterType'},
        'spark_version': {'key': 'sparkVersion', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesSparkVersion'},
        'core_configuration': {'key': 'coreConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesCoreConfiguration'},
        'h_base_configuration': {'key': 'hBaseConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesHBaseConfiguration'},
        'hdfs_configuration': {'key': 'hdfsConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesHdfsConfiguration'},
        'hive_configuration': {'key': 'hiveConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesHiveConfiguration'},
        'map_reduce_configuration': {'key': 'mapReduceConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesMapReduceConfiguration'},
        'oozie_configuration': {'key': 'oozieConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesOozieConfiguration'},
        'storm_configuration': {'key': 'stormConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesStormConfiguration'},
        'yarn_configuration': {'key': 'yarnConfiguration', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesYarnConfiguration'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesEncryptedCredential'},
        'head_node_size': {'key': 'headNodeSize', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesHeadNodeSize'},
        'data_node_size': {'key': 'dataNodeSize', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesDataNodeSize'},
        'zookeeper_node_size': {'key': 'zookeeperNodeSize', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesZookeeperNodeSize'},
        'script_actions': {'key': 'scriptActions', 'type': '[ScriptAction]'},
        'virtual_network_id': {'key': 'virtualNetworkId', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesVirtualNetworkId'},
        'subnet_name': {'key': 'subnetName', 'type': 'HDInsightOnDemandLinkedServiceTypePropertiesSubnetName'},
    }

    def __init__(
        self,
        *,
        cluster_size: "HDInsightOnDemandLinkedServiceTypePropertiesClusterSize",
        time_to_live: "HDInsightOnDemandLinkedServiceTypePropertiesTimeToLive",
        version: "HDInsightOnDemandLinkedServiceTypePropertiesVersion",
        linked_service_name: "LinkedServiceReference",
        host_subscription_id: "HDInsightOnDemandLinkedServiceTypePropertiesHostSubscriptionId",
        tenant: "HDInsightOnDemandLinkedServiceTypePropertiesTenant",
        cluster_resource_group: "HDInsightOnDemandLinkedServiceTypePropertiesClusterResourceGroup",
        service_principal_id: Optional["HDInsightOnDemandLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        cluster_name_prefix: Optional["HDInsightOnDemandLinkedServiceTypePropertiesClusterNamePrefix"] = None,
        cluster_user_name: Optional["HDInsightOnDemandLinkedServiceTypePropertiesClusterUserName"] = None,
        cluster_password: Optional["SecretBase"] = None,
        cluster_ssh_user_name: Optional["HDInsightOnDemandLinkedServiceTypePropertiesClusterSshUserName"] = None,
        cluster_ssh_password: Optional["SecretBase"] = None,
        additional_linked_service_names: Optional[List["LinkedServiceReference"]] = None,
        hcatalog_linked_service_name: Optional["LinkedServiceReference"] = None,
        cluster_type: Optional["HDInsightOnDemandLinkedServiceTypePropertiesClusterType"] = None,
        spark_version: Optional["HDInsightOnDemandLinkedServiceTypePropertiesSparkVersion"] = None,
        core_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesCoreConfiguration"] = None,
        h_base_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesHBaseConfiguration"] = None,
        hdfs_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesHdfsConfiguration"] = None,
        hive_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesHiveConfiguration"] = None,
        map_reduce_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesMapReduceConfiguration"] = None,
        oozie_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesOozieConfiguration"] = None,
        storm_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesStormConfiguration"] = None,
        yarn_configuration: Optional["HDInsightOnDemandLinkedServiceTypePropertiesYarnConfiguration"] = None,
        encrypted_credential: Optional["HDInsightOnDemandLinkedServiceTypePropertiesEncryptedCredential"] = None,
        head_node_size: Optional["HDInsightOnDemandLinkedServiceTypePropertiesHeadNodeSize"] = None,
        data_node_size: Optional["HDInsightOnDemandLinkedServiceTypePropertiesDataNodeSize"] = None,
        zookeeper_node_size: Optional["HDInsightOnDemandLinkedServiceTypePropertiesZookeeperNodeSize"] = None,
        script_actions: Optional[List["ScriptAction"]] = None,
        virtual_network_id: Optional["HDInsightOnDemandLinkedServiceTypePropertiesVirtualNetworkId"] = None,
        subnet_name: Optional["HDInsightOnDemandLinkedServiceTypePropertiesSubnetName"] = None,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.cluster_size = cluster_size
        self.time_to_live = time_to_live
        self.version = version
        self.linked_service_name = linked_service_name
        self.host_subscription_id = host_subscription_id
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.cluster_resource_group = cluster_resource_group
        self.cluster_name_prefix = cluster_name_prefix
        self.cluster_user_name = cluster_user_name
        self.cluster_password = cluster_password
        self.cluster_ssh_user_name = cluster_ssh_user_name
        self.cluster_ssh_password = cluster_ssh_password
        self.additional_linked_service_names = additional_linked_service_names
        self.hcatalog_linked_service_name = hcatalog_linked_service_name
        self.cluster_type = cluster_type
        self.spark_version = spark_version
        self.core_configuration = core_configuration
        self.h_base_configuration = h_base_configuration
        self.hdfs_configuration = hdfs_configuration
        self.hive_configuration = hive_configuration
        self.map_reduce_configuration = map_reduce_configuration
        self.oozie_configuration = oozie_configuration
        self.storm_configuration = storm_configuration
        self.yarn_configuration = yarn_configuration
        self.encrypted_credential = encrypted_credential
        self.head_node_size = head_node_size
        self.data_node_size = data_node_size
        self.zookeeper_node_size = zookeeper_node_size
        self.script_actions = script_actions
        self.virtual_network_id = virtual_network_id
        self.subnet_name = subnet_name


class HDInsightOnDemandLinkedServiceTypePropertiesClusterNamePrefix(msrest.serialization.Model):
    """The prefix of cluster name, postfix will be distinct with timestamp. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesClusterNamePrefix, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesClusterResourceGroup(msrest.serialization.Model):
    """The resource group where the cluster belongs. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesClusterResourceGroup, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesClusterSize(msrest.serialization.Model):
    """Number of worker/data nodes in the cluster. Suggestion value: 4. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesClusterSize, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesClusterSshUserName(msrest.serialization.Model):
    """The username to SSH remotely connect to cluster’s node (for Linux). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesClusterSshUserName, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesClusterType(msrest.serialization.Model):
    """The cluster type. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesClusterType, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesClusterUserName(msrest.serialization.Model):
    """The username to access the cluster. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesClusterUserName, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesCoreConfiguration(msrest.serialization.Model):
    """Specifies the core configuration parameters (as in core-site.xml) for the HDInsight cluster to be created.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesCoreConfiguration, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesDataNodeSize(msrest.serialization.Model):
    """Specifies the size of the data node for the HDInsight cluster.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesDataNodeSize, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesHBaseConfiguration(msrest.serialization.Model):
    """Specifies the HBase configuration parameters (hbase-site.xml) for the HDInsight cluster.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesHBaseConfiguration, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesHdfsConfiguration(msrest.serialization.Model):
    """Specifies the HDFS configuration parameters (hdfs-site.xml) for the HDInsight cluster.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesHdfsConfiguration, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesHeadNodeSize(msrest.serialization.Model):
    """Specifies the size of the head node for the HDInsight cluster.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesHeadNodeSize, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesHiveConfiguration(msrest.serialization.Model):
    """Specifies the hive configuration parameters (hive-site.xml) for the HDInsight cluster.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesHiveConfiguration, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesHostSubscriptionId(msrest.serialization.Model):
    """The customer’s subscription to host the cluster. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesHostSubscriptionId, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesMapReduceConfiguration(msrest.serialization.Model):
    """Specifies the MapReduce configuration parameters (mapred-site.xml) for the HDInsight cluster.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesMapReduceConfiguration, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesOozieConfiguration(msrest.serialization.Model):
    """Specifies the Oozie configuration parameters (oozie-site.xml) for the HDInsight cluster.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesOozieConfiguration, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """The service principal id for the hostSubscriptionId. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesSparkVersion(msrest.serialization.Model):
    """The version of spark if the cluster type is 'spark'. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesSparkVersion, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesStormConfiguration(msrest.serialization.Model):
    """Specifies the Storm configuration parameters (storm-site.xml) for the HDInsight cluster.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesStormConfiguration, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesSubnetName(msrest.serialization.Model):
    """The ARM resource ID for the subnet in the vNet. If virtualNetworkId was specified, then this property is required. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesSubnetName, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesTenant(msrest.serialization.Model):
    """The Tenant id/name to which the service principal belongs. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesTenant, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesTimeToLive(msrest.serialization.Model):
    """The allowed idle time for the on-demand HDInsight cluster. Specifies how long the on-demand HDInsight cluster stays alive after completion of an activity run if there are no other active jobs in the cluster. The minimum value is 5 mins. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesTimeToLive, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesVersion(msrest.serialization.Model):
    """Version of the HDInsight cluster.  Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesVersion, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesVirtualNetworkId(msrest.serialization.Model):
    """The ARM resource ID for the vNet to which the cluster should be joined after creation. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesVirtualNetworkId, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesYarnConfiguration(msrest.serialization.Model):
    """Specifies the Yarn configuration parameters (yarn-site.xml) for the HDInsight cluster.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesYarnConfiguration, self).__init__(**kwargs)


class HDInsightOnDemandLinkedServiceTypePropertiesZookeeperNodeSize(msrest.serialization.Model):
    """Specifies the size of the Zoo Keeper node for the HDInsight cluster.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightOnDemandLinkedServiceTypePropertiesZookeeperNodeSize, self).__init__(**kwargs)


class HDInsightPigActivity(ExecutionActivity):
    """HDInsight Pig activity type.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param storage_linked_services: Storage linked service references.
    :type storage_linked_services:
     list[~data_factory_management_client.models.LinkedServiceReference]
    :param arguments: User specified arguments to HDInsightActivity. Type: array (or Expression
     with resultType array).
    :type arguments:
     ~data_factory_management_client.models.HDInsightPigActivityTypePropertiesArguments
    :param get_debug_info: The HDInsightActivityDebugInfoOption settings to use. Possible values
     include: 'None', 'Always', 'Failure'.
    :type get_debug_info: str or
     ~data_factory_management_client.models.HDInsightActivityDebugInfoOption
    :param script_path: Script path. Type: string (or Expression with resultType string).
    :type script_path:
     ~data_factory_management_client.models.HDInsightPigActivityTypePropertiesScriptPath
    :param script_linked_service: Linked service reference type.
    :type script_linked_service: ~data_factory_management_client.models.LinkedServiceReference
    :param defines: Allows user to specify defines for Pig job request.
    :type defines: dict[str, object]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'storage_linked_services': {'key': 'typeProperties.storageLinkedServices', 'type': '[LinkedServiceReference]'},
        'arguments': {'key': 'typeProperties.arguments', 'type': 'HDInsightPigActivityTypePropertiesArguments'},
        'get_debug_info': {'key': 'typeProperties.getDebugInfo', 'type': 'str'},
        'script_path': {'key': 'typeProperties.scriptPath', 'type': 'HDInsightPigActivityTypePropertiesScriptPath'},
        'script_linked_service': {'key': 'typeProperties.scriptLinkedService', 'type': 'LinkedServiceReference'},
        'defines': {'key': 'typeProperties.defines', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        storage_linked_services: Optional[List["LinkedServiceReference"]] = None,
        arguments: Optional["HDInsightPigActivityTypePropertiesArguments"] = None,
        get_debug_info: Optional[Union[str, "HDInsightActivityDebugInfoOption"]] = None,
        script_path: Optional["HDInsightPigActivityTypePropertiesScriptPath"] = None,
        script_linked_service: Optional["LinkedServiceReference"] = None,
        defines: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(HDInsightPigActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'HDInsightPig'
        self.storage_linked_services = storage_linked_services
        self.arguments = arguments
        self.get_debug_info = get_debug_info
        self.script_path = script_path
        self.script_linked_service = script_linked_service
        self.defines = defines


class HDInsightPigActivityTypeProperties(msrest.serialization.Model):
    """HDInsight Pig activity properties.

    :param storage_linked_services: Storage linked service references.
    :type storage_linked_services:
     list[~data_factory_management_client.models.LinkedServiceReference]
    :param arguments: User specified arguments to HDInsightActivity. Type: array (or Expression
     with resultType array).
    :type arguments:
     ~data_factory_management_client.models.HDInsightPigActivityTypePropertiesArguments
    :param get_debug_info: The HDInsightActivityDebugInfoOption settings to use. Possible values
     include: 'None', 'Always', 'Failure'.
    :type get_debug_info: str or
     ~data_factory_management_client.models.HDInsightActivityDebugInfoOption
    :param script_path: Script path. Type: string (or Expression with resultType string).
    :type script_path:
     ~data_factory_management_client.models.HDInsightPigActivityTypePropertiesScriptPath
    :param script_linked_service: Linked service reference type.
    :type script_linked_service: ~data_factory_management_client.models.LinkedServiceReference
    :param defines: Allows user to specify defines for Pig job request.
    :type defines: dict[str, object]
    """

    _attribute_map = {
        'storage_linked_services': {'key': 'storageLinkedServices', 'type': '[LinkedServiceReference]'},
        'arguments': {'key': 'arguments', 'type': 'HDInsightPigActivityTypePropertiesArguments'},
        'get_debug_info': {'key': 'getDebugInfo', 'type': 'str'},
        'script_path': {'key': 'scriptPath', 'type': 'HDInsightPigActivityTypePropertiesScriptPath'},
        'script_linked_service': {'key': 'scriptLinkedService', 'type': 'LinkedServiceReference'},
        'defines': {'key': 'defines', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        storage_linked_services: Optional[List["LinkedServiceReference"]] = None,
        arguments: Optional["HDInsightPigActivityTypePropertiesArguments"] = None,
        get_debug_info: Optional[Union[str, "HDInsightActivityDebugInfoOption"]] = None,
        script_path: Optional["HDInsightPigActivityTypePropertiesScriptPath"] = None,
        script_linked_service: Optional["LinkedServiceReference"] = None,
        defines: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(HDInsightPigActivityTypeProperties, self).__init__(**kwargs)
        self.storage_linked_services = storage_linked_services
        self.arguments = arguments
        self.get_debug_info = get_debug_info
        self.script_path = script_path
        self.script_linked_service = script_linked_service
        self.defines = defines


class HDInsightPigActivityTypePropertiesArguments(msrest.serialization.Model):
    """User specified arguments to HDInsightActivity. Type: array (or Expression with resultType array).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightPigActivityTypePropertiesArguments, self).__init__(**kwargs)


class HDInsightPigActivityTypePropertiesScriptPath(msrest.serialization.Model):
    """Script path. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightPigActivityTypePropertiesScriptPath, self).__init__(**kwargs)


class HDInsightSparkActivity(ExecutionActivity):
    """HDInsight Spark activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param root_path: Required. The root path in 'sparkJobLinkedService' for all the job’s files.
     Type: string (or Expression with resultType string).
    :type root_path:
     ~data_factory_management_client.models.HDInsightSparkActivityTypePropertiesRootPath
    :param entry_file_path: Required. The relative path to the root folder of the code/package to
     be executed. Type: string (or Expression with resultType string).
    :type entry_file_path:
     ~data_factory_management_client.models.HDInsightSparkActivityTypePropertiesEntryFilePath
    :param arguments: The user-specified arguments to HDInsightSparkActivity.
    :type arguments:
     list[~data_factory_management_client.models.HDInsightSparkActivityTypePropertiesArgumentsItem]
    :param get_debug_info: The HDInsightActivityDebugInfoOption settings to use. Possible values
     include: 'None', 'Always', 'Failure'.
    :type get_debug_info: str or
     ~data_factory_management_client.models.HDInsightActivityDebugInfoOption
    :param spark_job_linked_service: Linked service reference type.
    :type spark_job_linked_service: ~data_factory_management_client.models.LinkedServiceReference
    :param class_name: The application's Java/Spark main class.
    :type class_name: str
    :param proxy_user: The user to impersonate that will execute the job. Type: string (or
     Expression with resultType string).
    :type proxy_user:
     ~data_factory_management_client.models.HDInsightSparkActivityTypePropertiesProxyUser
    :param spark_config: Spark configuration property.
    :type spark_config: dict[str, object]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'root_path': {'required': True},
        'entry_file_path': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'root_path': {'key': 'typeProperties.rootPath', 'type': 'HDInsightSparkActivityTypePropertiesRootPath'},
        'entry_file_path': {'key': 'typeProperties.entryFilePath', 'type': 'HDInsightSparkActivityTypePropertiesEntryFilePath'},
        'arguments': {'key': 'typeProperties.arguments', 'type': '[HDInsightSparkActivityTypePropertiesArgumentsItem]'},
        'get_debug_info': {'key': 'typeProperties.getDebugInfo', 'type': 'str'},
        'spark_job_linked_service': {'key': 'typeProperties.sparkJobLinkedService', 'type': 'LinkedServiceReference'},
        'class_name': {'key': 'typeProperties.className', 'type': 'str'},
        'proxy_user': {'key': 'typeProperties.proxyUser', 'type': 'HDInsightSparkActivityTypePropertiesProxyUser'},
        'spark_config': {'key': 'typeProperties.sparkConfig', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        name: str,
        root_path: "HDInsightSparkActivityTypePropertiesRootPath",
        entry_file_path: "HDInsightSparkActivityTypePropertiesEntryFilePath",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        arguments: Optional[List["HDInsightSparkActivityTypePropertiesArgumentsItem"]] = None,
        get_debug_info: Optional[Union[str, "HDInsightActivityDebugInfoOption"]] = None,
        spark_job_linked_service: Optional["LinkedServiceReference"] = None,
        class_name: Optional[str] = None,
        proxy_user: Optional["HDInsightSparkActivityTypePropertiesProxyUser"] = None,
        spark_config: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(HDInsightSparkActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'HDInsightSpark'
        self.root_path = root_path
        self.entry_file_path = entry_file_path
        self.arguments = arguments
        self.get_debug_info = get_debug_info
        self.spark_job_linked_service = spark_job_linked_service
        self.class_name = class_name
        self.proxy_user = proxy_user
        self.spark_config = spark_config


class HDInsightSparkActivityTypeProperties(msrest.serialization.Model):
    """HDInsight spark activity properties.

    All required parameters must be populated in order to send to Azure.

    :param root_path: Required. The root path in 'sparkJobLinkedService' for all the job’s files.
     Type: string (or Expression with resultType string).
    :type root_path:
     ~data_factory_management_client.models.HDInsightSparkActivityTypePropertiesRootPath
    :param entry_file_path: Required. The relative path to the root folder of the code/package to
     be executed. Type: string (or Expression with resultType string).
    :type entry_file_path:
     ~data_factory_management_client.models.HDInsightSparkActivityTypePropertiesEntryFilePath
    :param arguments: The user-specified arguments to HDInsightSparkActivity.
    :type arguments:
     list[~data_factory_management_client.models.HDInsightSparkActivityTypePropertiesArgumentsItem]
    :param get_debug_info: The HDInsightActivityDebugInfoOption settings to use. Possible values
     include: 'None', 'Always', 'Failure'.
    :type get_debug_info: str or
     ~data_factory_management_client.models.HDInsightActivityDebugInfoOption
    :param spark_job_linked_service: Linked service reference type.
    :type spark_job_linked_service: ~data_factory_management_client.models.LinkedServiceReference
    :param class_name: The application's Java/Spark main class.
    :type class_name: str
    :param proxy_user: The user to impersonate that will execute the job. Type: string (or
     Expression with resultType string).
    :type proxy_user:
     ~data_factory_management_client.models.HDInsightSparkActivityTypePropertiesProxyUser
    :param spark_config: Spark configuration property.
    :type spark_config: dict[str, object]
    """

    _validation = {
        'root_path': {'required': True},
        'entry_file_path': {'required': True},
    }

    _attribute_map = {
        'root_path': {'key': 'rootPath', 'type': 'HDInsightSparkActivityTypePropertiesRootPath'},
        'entry_file_path': {'key': 'entryFilePath', 'type': 'HDInsightSparkActivityTypePropertiesEntryFilePath'},
        'arguments': {'key': 'arguments', 'type': '[HDInsightSparkActivityTypePropertiesArgumentsItem]'},
        'get_debug_info': {'key': 'getDebugInfo', 'type': 'str'},
        'spark_job_linked_service': {'key': 'sparkJobLinkedService', 'type': 'LinkedServiceReference'},
        'class_name': {'key': 'className', 'type': 'str'},
        'proxy_user': {'key': 'proxyUser', 'type': 'HDInsightSparkActivityTypePropertiesProxyUser'},
        'spark_config': {'key': 'sparkConfig', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        root_path: "HDInsightSparkActivityTypePropertiesRootPath",
        entry_file_path: "HDInsightSparkActivityTypePropertiesEntryFilePath",
        arguments: Optional[List["HDInsightSparkActivityTypePropertiesArgumentsItem"]] = None,
        get_debug_info: Optional[Union[str, "HDInsightActivityDebugInfoOption"]] = None,
        spark_job_linked_service: Optional["LinkedServiceReference"] = None,
        class_name: Optional[str] = None,
        proxy_user: Optional["HDInsightSparkActivityTypePropertiesProxyUser"] = None,
        spark_config: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(HDInsightSparkActivityTypeProperties, self).__init__(**kwargs)
        self.root_path = root_path
        self.entry_file_path = entry_file_path
        self.arguments = arguments
        self.get_debug_info = get_debug_info
        self.spark_job_linked_service = spark_job_linked_service
        self.class_name = class_name
        self.proxy_user = proxy_user
        self.spark_config = spark_config


class HDInsightSparkActivityTypePropertiesArgumentsItem(msrest.serialization.Model):
    """Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightSparkActivityTypePropertiesArgumentsItem, self).__init__(**kwargs)


class HDInsightSparkActivityTypePropertiesEntryFilePath(msrest.serialization.Model):
    """The relative path to the root folder of the code/package to be executed. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightSparkActivityTypePropertiesEntryFilePath, self).__init__(**kwargs)


class HDInsightSparkActivityTypePropertiesProxyUser(msrest.serialization.Model):
    """The user to impersonate that will execute the job. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightSparkActivityTypePropertiesProxyUser, self).__init__(**kwargs)


class HDInsightSparkActivityTypePropertiesRootPath(msrest.serialization.Model):
    """The root path in 'sparkJobLinkedService' for all the job’s files. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightSparkActivityTypePropertiesRootPath, self).__init__(**kwargs)


class HDInsightStreamingActivity(ExecutionActivity):
    """HDInsight streaming activity type.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param storage_linked_services: Storage linked service references.
    :type storage_linked_services:
     list[~data_factory_management_client.models.LinkedServiceReference]
    :param arguments: User specified arguments to HDInsightActivity.
    :type arguments:
     list[~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesArgumentsItem]
    :param get_debug_info: The HDInsightActivityDebugInfoOption settings to use. Possible values
     include: 'None', 'Always', 'Failure'.
    :type get_debug_info: str or
     ~data_factory_management_client.models.HDInsightActivityDebugInfoOption
    :param mapper: Required. Mapper executable name. Type: string (or Expression with resultType
     string).
    :type mapper:
     ~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesMapper
    :param reducer: Required. Reducer executable name. Type: string (or Expression with resultType
     string).
    :type reducer:
     ~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesReducer
    :param input: Required. Input blob path. Type: string (or Expression with resultType string).
    :type input:
     ~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesInput
    :param output: Required. Output blob path. Type: string (or Expression with resultType string).
    :type output:
     ~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesOutput
    :param file_paths: Required. Paths to streaming job files. Can be directories.
    :type file_paths:
     list[~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesFilePathsItem]
    :param file_linked_service: Linked service reference type.
    :type file_linked_service: ~data_factory_management_client.models.LinkedServiceReference
    :param combiner: Combiner executable name. Type: string (or Expression with resultType string).
    :type combiner:
     ~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesCombiner
    :param command_environment: Command line environment values.
    :type command_environment:
     list[~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesCommandEnvironmentItem]
    :param defines: Allows user to specify defines for streaming job request.
    :type defines: dict[str, object]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'mapper': {'required': True},
        'reducer': {'required': True},
        'input': {'required': True},
        'output': {'required': True},
        'file_paths': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'storage_linked_services': {'key': 'typeProperties.storageLinkedServices', 'type': '[LinkedServiceReference]'},
        'arguments': {'key': 'typeProperties.arguments', 'type': '[HDInsightStreamingActivityTypePropertiesArgumentsItem]'},
        'get_debug_info': {'key': 'typeProperties.getDebugInfo', 'type': 'str'},
        'mapper': {'key': 'typeProperties.mapper', 'type': 'HDInsightStreamingActivityTypePropertiesMapper'},
        'reducer': {'key': 'typeProperties.reducer', 'type': 'HDInsightStreamingActivityTypePropertiesReducer'},
        'input': {'key': 'typeProperties.input', 'type': 'HDInsightStreamingActivityTypePropertiesInput'},
        'output': {'key': 'typeProperties.output', 'type': 'HDInsightStreamingActivityTypePropertiesOutput'},
        'file_paths': {'key': 'typeProperties.filePaths', 'type': '[HDInsightStreamingActivityTypePropertiesFilePathsItem]'},
        'file_linked_service': {'key': 'typeProperties.fileLinkedService', 'type': 'LinkedServiceReference'},
        'combiner': {'key': 'typeProperties.combiner', 'type': 'HDInsightStreamingActivityTypePropertiesCombiner'},
        'command_environment': {'key': 'typeProperties.commandEnvironment', 'type': '[HDInsightStreamingActivityTypePropertiesCommandEnvironmentItem]'},
        'defines': {'key': 'typeProperties.defines', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        name: str,
        mapper: "HDInsightStreamingActivityTypePropertiesMapper",
        reducer: "HDInsightStreamingActivityTypePropertiesReducer",
        input: "HDInsightStreamingActivityTypePropertiesInput",
        output: "HDInsightStreamingActivityTypePropertiesOutput",
        file_paths: List["HDInsightStreamingActivityTypePropertiesFilePathsItem"],
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        storage_linked_services: Optional[List["LinkedServiceReference"]] = None,
        arguments: Optional[List["HDInsightStreamingActivityTypePropertiesArgumentsItem"]] = None,
        get_debug_info: Optional[Union[str, "HDInsightActivityDebugInfoOption"]] = None,
        file_linked_service: Optional["LinkedServiceReference"] = None,
        combiner: Optional["HDInsightStreamingActivityTypePropertiesCombiner"] = None,
        command_environment: Optional[List["HDInsightStreamingActivityTypePropertiesCommandEnvironmentItem"]] = None,
        defines: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(HDInsightStreamingActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'HDInsightStreaming'
        self.storage_linked_services = storage_linked_services
        self.arguments = arguments
        self.get_debug_info = get_debug_info
        self.mapper = mapper
        self.reducer = reducer
        self.input = input
        self.output = output
        self.file_paths = file_paths
        self.file_linked_service = file_linked_service
        self.combiner = combiner
        self.command_environment = command_environment
        self.defines = defines


class HDInsightStreamingActivityTypeProperties(msrest.serialization.Model):
    """HDInsight streaming activity properties.

    All required parameters must be populated in order to send to Azure.

    :param storage_linked_services: Storage linked service references.
    :type storage_linked_services:
     list[~data_factory_management_client.models.LinkedServiceReference]
    :param arguments: User specified arguments to HDInsightActivity.
    :type arguments:
     list[~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesArgumentsItem]
    :param get_debug_info: The HDInsightActivityDebugInfoOption settings to use. Possible values
     include: 'None', 'Always', 'Failure'.
    :type get_debug_info: str or
     ~data_factory_management_client.models.HDInsightActivityDebugInfoOption
    :param mapper: Required. Mapper executable name. Type: string (or Expression with resultType
     string).
    :type mapper:
     ~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesMapper
    :param reducer: Required. Reducer executable name. Type: string (or Expression with resultType
     string).
    :type reducer:
     ~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesReducer
    :param input: Required. Input blob path. Type: string (or Expression with resultType string).
    :type input:
     ~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesInput
    :param output: Required. Output blob path. Type: string (or Expression with resultType string).
    :type output:
     ~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesOutput
    :param file_paths: Required. Paths to streaming job files. Can be directories.
    :type file_paths:
     list[~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesFilePathsItem]
    :param file_linked_service: Linked service reference type.
    :type file_linked_service: ~data_factory_management_client.models.LinkedServiceReference
    :param combiner: Combiner executable name. Type: string (or Expression with resultType string).
    :type combiner:
     ~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesCombiner
    :param command_environment: Command line environment values.
    :type command_environment:
     list[~data_factory_management_client.models.HDInsightStreamingActivityTypePropertiesCommandEnvironmentItem]
    :param defines: Allows user to specify defines for streaming job request.
    :type defines: dict[str, object]
    """

    _validation = {
        'mapper': {'required': True},
        'reducer': {'required': True},
        'input': {'required': True},
        'output': {'required': True},
        'file_paths': {'required': True},
    }

    _attribute_map = {
        'storage_linked_services': {'key': 'storageLinkedServices', 'type': '[LinkedServiceReference]'},
        'arguments': {'key': 'arguments', 'type': '[HDInsightStreamingActivityTypePropertiesArgumentsItem]'},
        'get_debug_info': {'key': 'getDebugInfo', 'type': 'str'},
        'mapper': {'key': 'mapper', 'type': 'HDInsightStreamingActivityTypePropertiesMapper'},
        'reducer': {'key': 'reducer', 'type': 'HDInsightStreamingActivityTypePropertiesReducer'},
        'input': {'key': 'input', 'type': 'HDInsightStreamingActivityTypePropertiesInput'},
        'output': {'key': 'output', 'type': 'HDInsightStreamingActivityTypePropertiesOutput'},
        'file_paths': {'key': 'filePaths', 'type': '[HDInsightStreamingActivityTypePropertiesFilePathsItem]'},
        'file_linked_service': {'key': 'fileLinkedService', 'type': 'LinkedServiceReference'},
        'combiner': {'key': 'combiner', 'type': 'HDInsightStreamingActivityTypePropertiesCombiner'},
        'command_environment': {'key': 'commandEnvironment', 'type': '[HDInsightStreamingActivityTypePropertiesCommandEnvironmentItem]'},
        'defines': {'key': 'defines', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        mapper: "HDInsightStreamingActivityTypePropertiesMapper",
        reducer: "HDInsightStreamingActivityTypePropertiesReducer",
        input: "HDInsightStreamingActivityTypePropertiesInput",
        output: "HDInsightStreamingActivityTypePropertiesOutput",
        file_paths: List["HDInsightStreamingActivityTypePropertiesFilePathsItem"],
        storage_linked_services: Optional[List["LinkedServiceReference"]] = None,
        arguments: Optional[List["HDInsightStreamingActivityTypePropertiesArgumentsItem"]] = None,
        get_debug_info: Optional[Union[str, "HDInsightActivityDebugInfoOption"]] = None,
        file_linked_service: Optional["LinkedServiceReference"] = None,
        combiner: Optional["HDInsightStreamingActivityTypePropertiesCombiner"] = None,
        command_environment: Optional[List["HDInsightStreamingActivityTypePropertiesCommandEnvironmentItem"]] = None,
        defines: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(HDInsightStreamingActivityTypeProperties, self).__init__(**kwargs)
        self.storage_linked_services = storage_linked_services
        self.arguments = arguments
        self.get_debug_info = get_debug_info
        self.mapper = mapper
        self.reducer = reducer
        self.input = input
        self.output = output
        self.file_paths = file_paths
        self.file_linked_service = file_linked_service
        self.combiner = combiner
        self.command_environment = command_environment
        self.defines = defines


class HDInsightStreamingActivityTypePropertiesArgumentsItem(msrest.serialization.Model):
    """Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightStreamingActivityTypePropertiesArgumentsItem, self).__init__(**kwargs)


class HDInsightStreamingActivityTypePropertiesCombiner(msrest.serialization.Model):
    """Combiner executable name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightStreamingActivityTypePropertiesCombiner, self).__init__(**kwargs)


class HDInsightStreamingActivityTypePropertiesCommandEnvironmentItem(msrest.serialization.Model):
    """Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightStreamingActivityTypePropertiesCommandEnvironmentItem, self).__init__(**kwargs)


class HDInsightStreamingActivityTypePropertiesFilePathsItem(msrest.serialization.Model):
    """Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightStreamingActivityTypePropertiesFilePathsItem, self).__init__(**kwargs)


class HDInsightStreamingActivityTypePropertiesInput(msrest.serialization.Model):
    """Input blob path. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightStreamingActivityTypePropertiesInput, self).__init__(**kwargs)


class HDInsightStreamingActivityTypePropertiesMapper(msrest.serialization.Model):
    """Mapper executable name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightStreamingActivityTypePropertiesMapper, self).__init__(**kwargs)


class HDInsightStreamingActivityTypePropertiesOutput(msrest.serialization.Model):
    """Output blob path. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightStreamingActivityTypePropertiesOutput, self).__init__(**kwargs)


class HDInsightStreamingActivityTypePropertiesReducer(msrest.serialization.Model):
    """Reducer executable name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HDInsightStreamingActivityTypePropertiesReducer, self).__init__(**kwargs)


class HiveDatasetTypeProperties(msrest.serialization.Model):
    """Hive Properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.HiveDatasetTypePropertiesTableName
    :param table: The table name of the Hive. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.HiveDatasetTypePropertiesTable
    :param schema: The schema name of the Hive. Type: string (or Expression with resultType
     string).
    :type schema: ~data_factory_management_client.models.HiveDatasetTypePropertiesSchema
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'HiveDatasetTypePropertiesTableName'},
        'table': {'key': 'table', 'type': 'HiveDatasetTypePropertiesTable'},
        'schema': {'key': 'schema', 'type': 'HiveDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["HiveDatasetTypePropertiesTableName"] = None,
        table: Optional["HiveDatasetTypePropertiesTable"] = None,
        schema: Optional["HiveDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(HiveDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.table = table
        self.schema = schema


class HiveDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of the Hive. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveDatasetTypePropertiesSchema, self).__init__(**kwargs)


class HiveDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the Hive. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveDatasetTypePropertiesTable, self).__init__(**kwargs)


class HiveDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveDatasetTypePropertiesTableName, self).__init__(**kwargs)


class HiveLinkedService(LinkedService):
    """Hive Server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. IP address or host name of the Hive server, separated by ';' for
     multiple hosts (only when serviceDiscoveryMode is enable).
    :type host: ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesHost
    :param port: The TCP port that the Hive server uses to listen for client connections.
    :type port: ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesPort
    :param server_type: The type of Hive server. Possible values include: 'HiveServer1',
     'HiveServer2', 'HiveThriftServer'.
    :type server_type: str or ~data_factory_management_client.models.HiveServerType
    :param thrift_transport_protocol: The transport protocol to use in the Thrift layer. Possible
     values include: 'Binary', 'SASL', 'HTTP '.
    :type thrift_transport_protocol: str or
     ~data_factory_management_client.models.HiveThriftTransportProtocol
    :param authentication_type: Required. The authentication method used to access the Hive server.
     Possible values include: 'Anonymous', 'Username', 'UsernameAndPassword',
     'WindowsAzureHDInsightService'.
    :type authentication_type: str or ~data_factory_management_client.models.HiveAuthenticationType
    :param service_discovery_mode: true to indicate using the ZooKeeper service, false not.
    :type service_discovery_mode:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesServiceDiscoveryMode
    :param zoo_keeper_name_space: The namespace on ZooKeeper under which Hive Server 2 nodes are
     added.
    :type zoo_keeper_name_space:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesZooKeeperNameSpace
    :param use_native_query: Specifies whether the driver uses native HiveQL queries,or converts
     them into an equivalent form in HiveQL.
    :type use_native_query:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesUseNativeQuery
    :param username: The user name that you use to access Hive Server.
    :type username: ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param http_path: The partial URL corresponding to the Hive server.
    :type http_path: ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesHttpPath
    :param enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :type enable_ssl:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesEnableSsl
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesTrustedCertPath
    :param use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :type use_system_trust_store:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesUseSystemTrustStore
    :param allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :type allow_host_name_cn_mismatch:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesAllowHostNameCNMismatch
    :param allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :type allow_self_signed_server_cert:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesAllowSelfSignedServerCert
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'HiveLinkedServiceTypePropertiesHost'},
        'port': {'key': 'typeProperties.port', 'type': 'HiveLinkedServiceTypePropertiesPort'},
        'server_type': {'key': 'typeProperties.serverType', 'type': 'str'},
        'thrift_transport_protocol': {'key': 'typeProperties.thriftTransportProtocol', 'type': 'str'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'service_discovery_mode': {'key': 'typeProperties.serviceDiscoveryMode', 'type': 'HiveLinkedServiceTypePropertiesServiceDiscoveryMode'},
        'zoo_keeper_name_space': {'key': 'typeProperties.zooKeeperNameSpace', 'type': 'HiveLinkedServiceTypePropertiesZooKeeperNameSpace'},
        'use_native_query': {'key': 'typeProperties.useNativeQuery', 'type': 'HiveLinkedServiceTypePropertiesUseNativeQuery'},
        'username': {'key': 'typeProperties.username', 'type': 'HiveLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'http_path': {'key': 'typeProperties.httpPath', 'type': 'HiveLinkedServiceTypePropertiesHttpPath'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'HiveLinkedServiceTypePropertiesEnableSsl'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'HiveLinkedServiceTypePropertiesTrustedCertPath'},
        'use_system_trust_store': {'key': 'typeProperties.useSystemTrustStore', 'type': 'HiveLinkedServiceTypePropertiesUseSystemTrustStore'},
        'allow_host_name_cn_mismatch': {'key': 'typeProperties.allowHostNameCNMismatch', 'type': 'HiveLinkedServiceTypePropertiesAllowHostNameCNMismatch'},
        'allow_self_signed_server_cert': {'key': 'typeProperties.allowSelfSignedServerCert', 'type': 'HiveLinkedServiceTypePropertiesAllowSelfSignedServerCert'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'HiveLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "HiveLinkedServiceTypePropertiesHost",
        authentication_type: Union[str, "HiveAuthenticationType"],
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        port: Optional["HiveLinkedServiceTypePropertiesPort"] = None,
        server_type: Optional[Union[str, "HiveServerType"]] = None,
        thrift_transport_protocol: Optional[Union[str, "HiveThriftTransportProtocol"]] = None,
        service_discovery_mode: Optional["HiveLinkedServiceTypePropertiesServiceDiscoveryMode"] = None,
        zoo_keeper_name_space: Optional["HiveLinkedServiceTypePropertiesZooKeeperNameSpace"] = None,
        use_native_query: Optional["HiveLinkedServiceTypePropertiesUseNativeQuery"] = None,
        username: Optional["HiveLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        http_path: Optional["HiveLinkedServiceTypePropertiesHttpPath"] = None,
        enable_ssl: Optional["HiveLinkedServiceTypePropertiesEnableSsl"] = None,
        trusted_cert_path: Optional["HiveLinkedServiceTypePropertiesTrustedCertPath"] = None,
        use_system_trust_store: Optional["HiveLinkedServiceTypePropertiesUseSystemTrustStore"] = None,
        allow_host_name_cn_mismatch: Optional["HiveLinkedServiceTypePropertiesAllowHostNameCNMismatch"] = None,
        allow_self_signed_server_cert: Optional["HiveLinkedServiceTypePropertiesAllowSelfSignedServerCert"] = None,
        encrypted_credential: Optional["HiveLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(HiveLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Hive'
        self.host = host
        self.port = port
        self.server_type = server_type
        self.thrift_transport_protocol = thrift_transport_protocol
        self.authentication_type = authentication_type
        self.service_discovery_mode = service_discovery_mode
        self.zoo_keeper_name_space = zoo_keeper_name_space
        self.use_native_query = use_native_query
        self.username = username
        self.password = password
        self.http_path = http_path
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class HiveLinkedServiceTypeProperties(msrest.serialization.Model):
    """Hive Server linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. IP address or host name of the Hive server, separated by ';' for
     multiple hosts (only when serviceDiscoveryMode is enable).
    :type host: ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesHost
    :param port: The TCP port that the Hive server uses to listen for client connections.
    :type port: ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesPort
    :param server_type: The type of Hive server. Possible values include: 'HiveServer1',
     'HiveServer2', 'HiveThriftServer'.
    :type server_type: str or ~data_factory_management_client.models.HiveServerType
    :param thrift_transport_protocol: The transport protocol to use in the Thrift layer. Possible
     values include: 'Binary', 'SASL', 'HTTP '.
    :type thrift_transport_protocol: str or
     ~data_factory_management_client.models.HiveThriftTransportProtocol
    :param authentication_type: Required. The authentication method used to access the Hive server.
     Possible values include: 'Anonymous', 'Username', 'UsernameAndPassword',
     'WindowsAzureHDInsightService'.
    :type authentication_type: str or ~data_factory_management_client.models.HiveAuthenticationType
    :param service_discovery_mode: true to indicate using the ZooKeeper service, false not.
    :type service_discovery_mode:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesServiceDiscoveryMode
    :param zoo_keeper_name_space: The namespace on ZooKeeper under which Hive Server 2 nodes are
     added.
    :type zoo_keeper_name_space:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesZooKeeperNameSpace
    :param use_native_query: Specifies whether the driver uses native HiveQL queries,or converts
     them into an equivalent form in HiveQL.
    :type use_native_query:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesUseNativeQuery
    :param username: The user name that you use to access Hive Server.
    :type username: ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param http_path: The partial URL corresponding to the Hive server.
    :type http_path: ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesHttpPath
    :param enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :type enable_ssl:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesEnableSsl
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesTrustedCertPath
    :param use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :type use_system_trust_store:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesUseSystemTrustStore
    :param allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :type allow_host_name_cn_mismatch:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesAllowHostNameCNMismatch
    :param allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :type allow_self_signed_server_cert:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesAllowSelfSignedServerCert
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.HiveLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'HiveLinkedServiceTypePropertiesHost'},
        'port': {'key': 'port', 'type': 'HiveLinkedServiceTypePropertiesPort'},
        'server_type': {'key': 'serverType', 'type': 'str'},
        'thrift_transport_protocol': {'key': 'thriftTransportProtocol', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'service_discovery_mode': {'key': 'serviceDiscoveryMode', 'type': 'HiveLinkedServiceTypePropertiesServiceDiscoveryMode'},
        'zoo_keeper_name_space': {'key': 'zooKeeperNameSpace', 'type': 'HiveLinkedServiceTypePropertiesZooKeeperNameSpace'},
        'use_native_query': {'key': 'useNativeQuery', 'type': 'HiveLinkedServiceTypePropertiesUseNativeQuery'},
        'username': {'key': 'username', 'type': 'HiveLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'http_path': {'key': 'httpPath', 'type': 'HiveLinkedServiceTypePropertiesHttpPath'},
        'enable_ssl': {'key': 'enableSsl', 'type': 'HiveLinkedServiceTypePropertiesEnableSsl'},
        'trusted_cert_path': {'key': 'trustedCertPath', 'type': 'HiveLinkedServiceTypePropertiesTrustedCertPath'},
        'use_system_trust_store': {'key': 'useSystemTrustStore', 'type': 'HiveLinkedServiceTypePropertiesUseSystemTrustStore'},
        'allow_host_name_cn_mismatch': {'key': 'allowHostNameCNMismatch', 'type': 'HiveLinkedServiceTypePropertiesAllowHostNameCNMismatch'},
        'allow_self_signed_server_cert': {'key': 'allowSelfSignedServerCert', 'type': 'HiveLinkedServiceTypePropertiesAllowSelfSignedServerCert'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'HiveLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "HiveLinkedServiceTypePropertiesHost",
        authentication_type: Union[str, "HiveAuthenticationType"],
        port: Optional["HiveLinkedServiceTypePropertiesPort"] = None,
        server_type: Optional[Union[str, "HiveServerType"]] = None,
        thrift_transport_protocol: Optional[Union[str, "HiveThriftTransportProtocol"]] = None,
        service_discovery_mode: Optional["HiveLinkedServiceTypePropertiesServiceDiscoveryMode"] = None,
        zoo_keeper_name_space: Optional["HiveLinkedServiceTypePropertiesZooKeeperNameSpace"] = None,
        use_native_query: Optional["HiveLinkedServiceTypePropertiesUseNativeQuery"] = None,
        username: Optional["HiveLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        http_path: Optional["HiveLinkedServiceTypePropertiesHttpPath"] = None,
        enable_ssl: Optional["HiveLinkedServiceTypePropertiesEnableSsl"] = None,
        trusted_cert_path: Optional["HiveLinkedServiceTypePropertiesTrustedCertPath"] = None,
        use_system_trust_store: Optional["HiveLinkedServiceTypePropertiesUseSystemTrustStore"] = None,
        allow_host_name_cn_mismatch: Optional["HiveLinkedServiceTypePropertiesAllowHostNameCNMismatch"] = None,
        allow_self_signed_server_cert: Optional["HiveLinkedServiceTypePropertiesAllowSelfSignedServerCert"] = None,
        encrypted_credential: Optional["HiveLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(HiveLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.port = port
        self.server_type = server_type
        self.thrift_transport_protocol = thrift_transport_protocol
        self.authentication_type = authentication_type
        self.service_discovery_mode = service_discovery_mode
        self.zoo_keeper_name_space = zoo_keeper_name_space
        self.use_native_query = use_native_query
        self.username = username
        self.password = password
        self.http_path = http_path
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class HiveLinkedServiceTypePropertiesAllowHostNameCNMismatch(msrest.serialization.Model):
    """Specifies whether to require a CA-issued SSL certificate name to match the host name of the server when connecting over SSL. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveLinkedServiceTypePropertiesAllowHostNameCNMismatch, self).__init__(**kwargs)


class HiveLinkedServiceTypePropertiesAllowSelfSignedServerCert(msrest.serialization.Model):
    """Specifies whether to allow self-signed certificates from the server. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveLinkedServiceTypePropertiesAllowSelfSignedServerCert, self).__init__(**kwargs)


class HiveLinkedServiceTypePropertiesEnableSsl(msrest.serialization.Model):
    """Specifies whether the connections to the server are encrypted using SSL. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveLinkedServiceTypePropertiesEnableSsl, self).__init__(**kwargs)


class HiveLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class HiveLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """IP address or host name of the Hive server, separated by ';' for multiple hosts (only when serviceDiscoveryMode is enable).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class HiveLinkedServiceTypePropertiesHttpPath(msrest.serialization.Model):
    """The partial URL corresponding to the Hive server.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveLinkedServiceTypePropertiesHttpPath, self).__init__(**kwargs)


class HiveLinkedServiceTypePropertiesPort(msrest.serialization.Model):
    """The TCP port that the Hive server uses to listen for client connections.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveLinkedServiceTypePropertiesPort, self).__init__(**kwargs)


class HiveLinkedServiceTypePropertiesServiceDiscoveryMode(msrest.serialization.Model):
    """true to indicate using the ZooKeeper service, false not.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveLinkedServiceTypePropertiesServiceDiscoveryMode, self).__init__(**kwargs)


class HiveLinkedServiceTypePropertiesTrustedCertPath(msrest.serialization.Model):
    """The full path of the .pem file containing trusted CA certificates for verifying the server when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The default value is the cacerts.pem file installed with the IR.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveLinkedServiceTypePropertiesTrustedCertPath, self).__init__(**kwargs)


class HiveLinkedServiceTypePropertiesUseNativeQuery(msrest.serialization.Model):
    """Specifies whether the driver uses native HiveQL queries,or converts them into an equivalent form in HiveQL.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveLinkedServiceTypePropertiesUseNativeQuery, self).__init__(**kwargs)


class HiveLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """The user name that you use to access Hive Server.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class HiveLinkedServiceTypePropertiesUseSystemTrustStore(msrest.serialization.Model):
    """Specifies whether to use a CA certificate from the system trust store or from a specified PEM file. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveLinkedServiceTypePropertiesUseSystemTrustStore, self).__init__(**kwargs)


class HiveLinkedServiceTypePropertiesZooKeeperNameSpace(msrest.serialization.Model):
    """The namespace on ZooKeeper under which Hive Server 2 nodes are added.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveLinkedServiceTypePropertiesZooKeeperNameSpace, self).__init__(**kwargs)


class HiveObjectDataset(Dataset):
    """Hive Server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.HiveDatasetTypePropertiesTableName
    :param table: The table name of the Hive. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.HiveDatasetTypePropertiesTable
    :param schema_type_properties_schema: The schema name of the Hive. Type: string (or Expression
     with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.HiveDatasetTypePropertiesSchema
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'HiveDatasetTypePropertiesTableName'},
        'table': {'key': 'typeProperties.table', 'type': 'HiveDatasetTypePropertiesTable'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'HiveDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["HiveDatasetTypePropertiesTableName"] = None,
        table: Optional["HiveDatasetTypePropertiesTable"] = None,
        schema_type_properties_schema: Optional["HiveDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(HiveObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'HiveObject'
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class HiveSource(TabularSource):
    """A copy activity Hive Server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.HiveSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'HiveSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["HiveSourceQuery"] = None,
        **kwargs
    ):
        super(HiveSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'HiveSource'
        self.query = query


class HiveSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HiveSourceQuery, self).__init__(**kwargs)


class HttpDataset(Dataset):
    """A file in an HTTP web server.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param relative_url: The relative URL based on the URL in the HttpLinkedService refers to an
     HTTP file Type: string (or Expression with resultType string).
    :type relative_url: ~data_factory_management_client.models.HttpDatasetTypePropertiesRelativeUrl
    :param request_method: The HTTP method for the HTTP request. Type: string (or Expression with
     resultType string).
    :type request_method:
     ~data_factory_management_client.models.HttpDatasetTypePropertiesRequestMethod
    :param request_body: The body for the HTTP request. Type: string (or Expression with resultType
     string).
    :type request_body: ~data_factory_management_client.models.HttpDatasetTypePropertiesRequestBody
    :param additional_headers: The headers for the HTTP Request. e.g. request-header-
     name-1:request-header-value-1
     ...
     request-header-name-n:request-header-value-n Type: string (or Expression with resultType
     string).
    :type additional_headers:
     ~data_factory_management_client.models.HttpDatasetTypePropertiesAdditionalHeaders
    :param format: The format definition of a storage.
    :type format: ~data_factory_management_client.models.DatasetStorageFormat
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'relative_url': {'key': 'typeProperties.relativeUrl', 'type': 'HttpDatasetTypePropertiesRelativeUrl'},
        'request_method': {'key': 'typeProperties.requestMethod', 'type': 'HttpDatasetTypePropertiesRequestMethod'},
        'request_body': {'key': 'typeProperties.requestBody', 'type': 'HttpDatasetTypePropertiesRequestBody'},
        'additional_headers': {'key': 'typeProperties.additionalHeaders', 'type': 'HttpDatasetTypePropertiesAdditionalHeaders'},
        'format': {'key': 'typeProperties.format', 'type': 'DatasetStorageFormat'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        relative_url: Optional["HttpDatasetTypePropertiesRelativeUrl"] = None,
        request_method: Optional["HttpDatasetTypePropertiesRequestMethod"] = None,
        request_body: Optional["HttpDatasetTypePropertiesRequestBody"] = None,
        additional_headers: Optional["HttpDatasetTypePropertiesAdditionalHeaders"] = None,
        format: Optional["DatasetStorageFormat"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(HttpDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'HttpFile'
        self.relative_url = relative_url
        self.request_method = request_method
        self.request_body = request_body
        self.additional_headers = additional_headers
        self.format = format
        self.compression = compression


class HttpDatasetTypeProperties(msrest.serialization.Model):
    """Properties specific to this dataset type.

    :param relative_url: The relative URL based on the URL in the HttpLinkedService refers to an
     HTTP file Type: string (or Expression with resultType string).
    :type relative_url: ~data_factory_management_client.models.HttpDatasetTypePropertiesRelativeUrl
    :param request_method: The HTTP method for the HTTP request. Type: string (or Expression with
     resultType string).
    :type request_method:
     ~data_factory_management_client.models.HttpDatasetTypePropertiesRequestMethod
    :param request_body: The body for the HTTP request. Type: string (or Expression with resultType
     string).
    :type request_body: ~data_factory_management_client.models.HttpDatasetTypePropertiesRequestBody
    :param additional_headers: The headers for the HTTP Request. e.g. request-header-
     name-1:request-header-value-1
     ...
     request-header-name-n:request-header-value-n Type: string (or Expression with resultType
     string).
    :type additional_headers:
     ~data_factory_management_client.models.HttpDatasetTypePropertiesAdditionalHeaders
    :param format: The format definition of a storage.
    :type format: ~data_factory_management_client.models.DatasetStorageFormat
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _attribute_map = {
        'relative_url': {'key': 'relativeUrl', 'type': 'HttpDatasetTypePropertiesRelativeUrl'},
        'request_method': {'key': 'requestMethod', 'type': 'HttpDatasetTypePropertiesRequestMethod'},
        'request_body': {'key': 'requestBody', 'type': 'HttpDatasetTypePropertiesRequestBody'},
        'additional_headers': {'key': 'additionalHeaders', 'type': 'HttpDatasetTypePropertiesAdditionalHeaders'},
        'format': {'key': 'format', 'type': 'DatasetStorageFormat'},
        'compression': {'key': 'compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        relative_url: Optional["HttpDatasetTypePropertiesRelativeUrl"] = None,
        request_method: Optional["HttpDatasetTypePropertiesRequestMethod"] = None,
        request_body: Optional["HttpDatasetTypePropertiesRequestBody"] = None,
        additional_headers: Optional["HttpDatasetTypePropertiesAdditionalHeaders"] = None,
        format: Optional["DatasetStorageFormat"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(HttpDatasetTypeProperties, self).__init__(**kwargs)
        self.relative_url = relative_url
        self.request_method = request_method
        self.request_body = request_body
        self.additional_headers = additional_headers
        self.format = format
        self.compression = compression


class HttpDatasetTypePropertiesAdditionalHeaders(msrest.serialization.Model):
    """The headers for the HTTP Request. e.g. request-header-name-1:request-header-value-1
...
request-header-name-n:request-header-value-n Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpDatasetTypePropertiesAdditionalHeaders, self).__init__(**kwargs)


class HttpDatasetTypePropertiesRelativeUrl(msrest.serialization.Model):
    """The relative URL based on the URL in the HttpLinkedService refers to an HTTP file Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpDatasetTypePropertiesRelativeUrl, self).__init__(**kwargs)


class HttpDatasetTypePropertiesRequestBody(msrest.serialization.Model):
    """The body for the HTTP request. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpDatasetTypePropertiesRequestBody, self).__init__(**kwargs)


class HttpDatasetTypePropertiesRequestMethod(msrest.serialization.Model):
    """The HTTP method for the HTTP request. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpDatasetTypePropertiesRequestMethod, self).__init__(**kwargs)


class HttpLinkedService(LinkedService):
    """Linked service for an HTTP source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param url: Required. The base URL of the HTTP endpoint, e.g. http://www.microsoft.com. Type:
     string (or Expression with resultType string).
    :type url: ~data_factory_management_client.models.HttpLinkedServiceTypePropertiesUrl
    :param authentication_type: The authentication type to be used to connect to the HTTP server.
     Possible values include: 'Basic', 'Anonymous', 'Digest', 'Windows', 'ClientCertificate'.
    :type authentication_type: str or ~data_factory_management_client.models.HttpAuthenticationType
    :param user_name: User name for Basic, Digest, or Windows authentication. Type: string (or
     Expression with resultType string).
    :type user_name: ~data_factory_management_client.models.HttpLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param embedded_cert_data: Base64 encoded certificate data for ClientCertificate
     authentication. For on-premises copy with ClientCertificate authentication, either
     CertThumbprint or EmbeddedCertData/Password should be specified. Type: string (or Expression
     with resultType string).
    :type embedded_cert_data:
     ~data_factory_management_client.models.HttpLinkedServiceTypePropertiesEmbeddedCertData
    :param cert_thumbprint: Thumbprint of certificate for ClientCertificate authentication. Only
     valid for on-premises copy. For on-premises copy with ClientCertificate authentication, either
     CertThumbprint or EmbeddedCertData/Password should be specified. Type: string (or Expression
     with resultType string).
    :type cert_thumbprint:
     ~data_factory_management_client.models.HttpLinkedServiceTypePropertiesCertThumbprint
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.HttpLinkedServiceTypePropertiesEncryptedCredential
    :param enable_server_certificate_validation: If true, validate the HTTPS server SSL
     certificate. Default value is true. Type: boolean (or Expression with resultType boolean).
    :type enable_server_certificate_validation:
     ~data_factory_management_client.models.HttpLinkedServiceTypePropertiesEnableServerCertificateValidation
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'url': {'key': 'typeProperties.url', 'type': 'HttpLinkedServiceTypePropertiesUrl'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'HttpLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'embedded_cert_data': {'key': 'typeProperties.embeddedCertData', 'type': 'HttpLinkedServiceTypePropertiesEmbeddedCertData'},
        'cert_thumbprint': {'key': 'typeProperties.certThumbprint', 'type': 'HttpLinkedServiceTypePropertiesCertThumbprint'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'HttpLinkedServiceTypePropertiesEncryptedCredential'},
        'enable_server_certificate_validation': {'key': 'typeProperties.enableServerCertificateValidation', 'type': 'HttpLinkedServiceTypePropertiesEnableServerCertificateValidation'},
    }

    def __init__(
        self,
        *,
        url: "HttpLinkedServiceTypePropertiesUrl",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        authentication_type: Optional[Union[str, "HttpAuthenticationType"]] = None,
        user_name: Optional["HttpLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        embedded_cert_data: Optional["HttpLinkedServiceTypePropertiesEmbeddedCertData"] = None,
        cert_thumbprint: Optional["HttpLinkedServiceTypePropertiesCertThumbprint"] = None,
        encrypted_credential: Optional["HttpLinkedServiceTypePropertiesEncryptedCredential"] = None,
        enable_server_certificate_validation: Optional["HttpLinkedServiceTypePropertiesEnableServerCertificateValidation"] = None,
        **kwargs
    ):
        super(HttpLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'HttpServer'
        self.url = url
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.embedded_cert_data = embedded_cert_data
        self.cert_thumbprint = cert_thumbprint
        self.encrypted_credential = encrypted_credential
        self.enable_server_certificate_validation = enable_server_certificate_validation


class HttpLinkedServiceTypeProperties(msrest.serialization.Model):
    """Properties specific to this linked service type.

    All required parameters must be populated in order to send to Azure.

    :param url: Required. The base URL of the HTTP endpoint, e.g. http://www.microsoft.com. Type:
     string (or Expression with resultType string).
    :type url: ~data_factory_management_client.models.HttpLinkedServiceTypePropertiesUrl
    :param authentication_type: The authentication type to be used to connect to the HTTP server.
     Possible values include: 'Basic', 'Anonymous', 'Digest', 'Windows', 'ClientCertificate'.
    :type authentication_type: str or ~data_factory_management_client.models.HttpAuthenticationType
    :param user_name: User name for Basic, Digest, or Windows authentication. Type: string (or
     Expression with resultType string).
    :type user_name: ~data_factory_management_client.models.HttpLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param embedded_cert_data: Base64 encoded certificate data for ClientCertificate
     authentication. For on-premises copy with ClientCertificate authentication, either
     CertThumbprint or EmbeddedCertData/Password should be specified. Type: string (or Expression
     with resultType string).
    :type embedded_cert_data:
     ~data_factory_management_client.models.HttpLinkedServiceTypePropertiesEmbeddedCertData
    :param cert_thumbprint: Thumbprint of certificate for ClientCertificate authentication. Only
     valid for on-premises copy. For on-premises copy with ClientCertificate authentication, either
     CertThumbprint or EmbeddedCertData/Password should be specified. Type: string (or Expression
     with resultType string).
    :type cert_thumbprint:
     ~data_factory_management_client.models.HttpLinkedServiceTypePropertiesCertThumbprint
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.HttpLinkedServiceTypePropertiesEncryptedCredential
    :param enable_server_certificate_validation: If true, validate the HTTPS server SSL
     certificate. Default value is true. Type: boolean (or Expression with resultType boolean).
    :type enable_server_certificate_validation:
     ~data_factory_management_client.models.HttpLinkedServiceTypePropertiesEnableServerCertificateValidation
    """

    _validation = {
        'url': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'HttpLinkedServiceTypePropertiesUrl'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'user_name': {'key': 'userName', 'type': 'HttpLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'embedded_cert_data': {'key': 'embeddedCertData', 'type': 'HttpLinkedServiceTypePropertiesEmbeddedCertData'},
        'cert_thumbprint': {'key': 'certThumbprint', 'type': 'HttpLinkedServiceTypePropertiesCertThumbprint'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'HttpLinkedServiceTypePropertiesEncryptedCredential'},
        'enable_server_certificate_validation': {'key': 'enableServerCertificateValidation', 'type': 'HttpLinkedServiceTypePropertiesEnableServerCertificateValidation'},
    }

    def __init__(
        self,
        *,
        url: "HttpLinkedServiceTypePropertiesUrl",
        authentication_type: Optional[Union[str, "HttpAuthenticationType"]] = None,
        user_name: Optional["HttpLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        embedded_cert_data: Optional["HttpLinkedServiceTypePropertiesEmbeddedCertData"] = None,
        cert_thumbprint: Optional["HttpLinkedServiceTypePropertiesCertThumbprint"] = None,
        encrypted_credential: Optional["HttpLinkedServiceTypePropertiesEncryptedCredential"] = None,
        enable_server_certificate_validation: Optional["HttpLinkedServiceTypePropertiesEnableServerCertificateValidation"] = None,
        **kwargs
    ):
        super(HttpLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.url = url
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.embedded_cert_data = embedded_cert_data
        self.cert_thumbprint = cert_thumbprint
        self.encrypted_credential = encrypted_credential
        self.enable_server_certificate_validation = enable_server_certificate_validation


class HttpLinkedServiceTypePropertiesCertThumbprint(msrest.serialization.Model):
    """Thumbprint of certificate for ClientCertificate authentication. Only valid for on-premises copy. For on-premises copy with ClientCertificate authentication, either CertThumbprint or EmbeddedCertData/Password should be specified. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpLinkedServiceTypePropertiesCertThumbprint, self).__init__(**kwargs)


class HttpLinkedServiceTypePropertiesEmbeddedCertData(msrest.serialization.Model):
    """Base64 encoded certificate data for ClientCertificate authentication. For on-premises copy with ClientCertificate authentication, either CertThumbprint or EmbeddedCertData/Password should be specified. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpLinkedServiceTypePropertiesEmbeddedCertData, self).__init__(**kwargs)


class HttpLinkedServiceTypePropertiesEnableServerCertificateValidation(msrest.serialization.Model):
    """If true, validate the HTTPS server SSL certificate. Default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpLinkedServiceTypePropertiesEnableServerCertificateValidation, self).__init__(**kwargs)


class HttpLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class HttpLinkedServiceTypePropertiesUrl(msrest.serialization.Model):
    """The base URL of the HTTP endpoint, e.g. http://www.microsoft.com. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpLinkedServiceTypePropertiesUrl, self).__init__(**kwargs)


class HttpLinkedServiceTypePropertiesUserName(msrest.serialization.Model):
    """User name for Basic, Digest, or Windows authentication. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpLinkedServiceTypePropertiesUserName, self).__init__(**kwargs)


class HttpReadSettings(StoreReadSettings):
    """Sftp read settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The read setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreReadSettingsMaxConcurrentConnections
    :param request_method: The HTTP method used to call the RESTful API. The default is GET. Type:
     string (or Expression with resultType string).
    :type request_method: ~data_factory_management_client.models.HttpReadSettingsRequestMethod
    :param request_body: The HTTP request body to the RESTful API if requestMethod is POST. Type:
     string (or Expression with resultType string).
    :type request_body: ~data_factory_management_client.models.HttpReadSettingsRequestBody
    :param additional_headers: The additional HTTP headers in the request to the RESTful API. Type:
     string (or Expression with resultType string).
    :type additional_headers:
     ~data_factory_management_client.models.HttpReadSettingsAdditionalHeaders
    :param request_timeout: Specifies the timeout for a HTTP client to get HTTP response from HTTP
     server.
    :type request_timeout: ~data_factory_management_client.models.HttpReadSettingsRequestTimeout
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreReadSettingsMaxConcurrentConnections'},
        'request_method': {'key': 'requestMethod', 'type': 'HttpReadSettingsRequestMethod'},
        'request_body': {'key': 'requestBody', 'type': 'HttpReadSettingsRequestBody'},
        'additional_headers': {'key': 'additionalHeaders', 'type': 'HttpReadSettingsAdditionalHeaders'},
        'request_timeout': {'key': 'requestTimeout', 'type': 'HttpReadSettingsRequestTimeout'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreReadSettingsMaxConcurrentConnections"] = None,
        request_method: Optional["HttpReadSettingsRequestMethod"] = None,
        request_body: Optional["HttpReadSettingsRequestBody"] = None,
        additional_headers: Optional["HttpReadSettingsAdditionalHeaders"] = None,
        request_timeout: Optional["HttpReadSettingsRequestTimeout"] = None,
        **kwargs
    ):
        super(HttpReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'HttpReadSettings'
        self.request_method = request_method
        self.request_body = request_body
        self.additional_headers = additional_headers
        self.request_timeout = request_timeout


class HttpReadSettingsAdditionalHeaders(msrest.serialization.Model):
    """The additional HTTP headers in the request to the RESTful API. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpReadSettingsAdditionalHeaders, self).__init__(**kwargs)


class HttpReadSettingsRequestBody(msrest.serialization.Model):
    """The HTTP request body to the RESTful API if requestMethod is POST. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpReadSettingsRequestBody, self).__init__(**kwargs)


class HttpReadSettingsRequestMethod(msrest.serialization.Model):
    """The HTTP method used to call the RESTful API. The default is GET. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpReadSettingsRequestMethod, self).__init__(**kwargs)


class HttpReadSettingsRequestTimeout(msrest.serialization.Model):
    """Specifies the timeout for a HTTP client to get HTTP response from HTTP server.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpReadSettingsRequestTimeout, self).__init__(**kwargs)


class HttpServerLocation(DatasetLocation):
    """The location of http server.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage location.Constant filled by server.
    :type type: str
    :param folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :type folder_path: ~data_factory_management_client.models.DatasetLocationFolderPath
    :param file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :type file_name: ~data_factory_management_client.models.DatasetLocationFileName
    :param relative_url: Specify the relativeUrl of http server. Type: string (or Expression with
     resultType string).
    :type relative_url: ~data_factory_management_client.models.HttpServerLocationRelativeUrl
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'DatasetLocationFolderPath'},
        'file_name': {'key': 'fileName', 'type': 'DatasetLocationFileName'},
        'relative_url': {'key': 'relativeUrl', 'type': 'HttpServerLocationRelativeUrl'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        folder_path: Optional["DatasetLocationFolderPath"] = None,
        file_name: Optional["DatasetLocationFileName"] = None,
        relative_url: Optional["HttpServerLocationRelativeUrl"] = None,
        **kwargs
    ):
        super(HttpServerLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'HttpServerLocation'
        self.relative_url = relative_url


class HttpServerLocationRelativeUrl(msrest.serialization.Model):
    """Specify the relativeUrl of http server. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpServerLocationRelativeUrl, self).__init__(**kwargs)


class HttpSource(CopySource):
    """A copy activity source for an HTTP file.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param http_request_timeout: Specifies the timeout for a HTTP client to get HTTP response from
     HTTP server. The default value is equivalent to System.Net.HttpWebRequest.Timeout. Type: string
     (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type http_request_timeout: ~data_factory_management_client.models.HttpSourceHttpRequestTimeout
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'http_request_timeout': {'key': 'httpRequestTimeout', 'type': 'HttpSourceHttpRequestTimeout'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        http_request_timeout: Optional["HttpSourceHttpRequestTimeout"] = None,
        **kwargs
    ):
        super(HttpSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'HttpSource'
        self.http_request_timeout = http_request_timeout


class HttpSourceHttpRequestTimeout(msrest.serialization.Model):
    """Specifies the timeout for a HTTP client to get HTTP response from HTTP server. The default value is equivalent to System.Net.HttpWebRequest.Timeout. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HttpSourceHttpRequestTimeout, self).__init__(**kwargs)


class HubspotLinkedService(LinkedService):
    """Hubspot Service linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param client_id: Required. The client ID associated with your Hubspot application.
    :type client_id:
     ~data_factory_management_client.models.HubspotLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param access_token: The base definition of a secret type.
    :type access_token: ~data_factory_management_client.models.SecretBase
    :param refresh_token: The base definition of a secret type.
    :type refresh_token: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.HubspotLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.HubspotLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.HubspotLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.HubspotLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'HubspotLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'access_token': {'key': 'typeProperties.accessToken', 'type': 'SecretBase'},
        'refresh_token': {'key': 'typeProperties.refreshToken', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'HubspotLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'HubspotLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'HubspotLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'HubspotLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        client_id: "HubspotLinkedServiceTypePropertiesClientId",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        client_secret: Optional["SecretBase"] = None,
        access_token: Optional["SecretBase"] = None,
        refresh_token: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["HubspotLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["HubspotLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["HubspotLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["HubspotLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(HubspotLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Hubspot'
        self.client_id = client_id
        self.client_secret = client_secret
        self.access_token = access_token
        self.refresh_token = refresh_token
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class HubspotLinkedServiceTypeProperties(msrest.serialization.Model):
    """Hubspot Service linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param client_id: Required. The client ID associated with your Hubspot application.
    :type client_id:
     ~data_factory_management_client.models.HubspotLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param access_token: The base definition of a secret type.
    :type access_token: ~data_factory_management_client.models.SecretBase
    :param refresh_token: The base definition of a secret type.
    :type refresh_token: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.HubspotLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.HubspotLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.HubspotLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.HubspotLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'client_id': {'required': True},
    }

    _attribute_map = {
        'client_id': {'key': 'clientId', 'type': 'HubspotLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'clientSecret', 'type': 'SecretBase'},
        'access_token': {'key': 'accessToken', 'type': 'SecretBase'},
        'refresh_token': {'key': 'refreshToken', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'HubspotLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'HubspotLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'HubspotLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'HubspotLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        client_id: "HubspotLinkedServiceTypePropertiesClientId",
        client_secret: Optional["SecretBase"] = None,
        access_token: Optional["SecretBase"] = None,
        refresh_token: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["HubspotLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["HubspotLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["HubspotLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["HubspotLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(HubspotLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.client_id = client_id
        self.client_secret = client_secret
        self.access_token = access_token
        self.refresh_token = refresh_token
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class HubspotLinkedServiceTypePropertiesClientId(msrest.serialization.Model):
    """The client ID associated with your Hubspot application.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HubspotLinkedServiceTypePropertiesClientId, self).__init__(**kwargs)


class HubspotLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HubspotLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class HubspotLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HubspotLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class HubspotLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HubspotLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class HubspotLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HubspotLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class HubspotObjectDataset(Dataset):
    """Hubspot Service dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(HubspotObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'HubspotObject'
        self.table_name = table_name


class HubspotSource(TabularSource):
    """A copy activity Hubspot Service source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.HubspotSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'HubspotSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["HubspotSourceQuery"] = None,
        **kwargs
    ):
        super(HubspotSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'HubspotSource'
        self.query = query


class HubspotSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(HubspotSourceQuery, self).__init__(**kwargs)


class IfConditionActivity(ControlActivity):
    """This activity evaluates a boolean expression and executes either the activities under the ifTrueActivities property or the ifFalseActivities property depending on the result of the expression.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param expression: Required. Azure Data Factory expression definition.
    :type expression: ~data_factory_management_client.models.Expression
    :param if_true_activities: List of activities to execute if expression is evaluated to true.
     This is an optional property and if not provided, the activity will exit without any action.
    :type if_true_activities: list[~data_factory_management_client.models.Activity]
    :param if_false_activities: List of activities to execute if expression is evaluated to false.
     This is an optional property and if not provided, the activity will exit without any action.
    :type if_false_activities: list[~data_factory_management_client.models.Activity]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'expression': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'expression': {'key': 'typeProperties.expression', 'type': 'Expression'},
        'if_true_activities': {'key': 'typeProperties.ifTrueActivities', 'type': '[Activity]'},
        'if_false_activities': {'key': 'typeProperties.ifFalseActivities', 'type': '[Activity]'},
    }

    def __init__(
        self,
        *,
        name: str,
        expression: "Expression",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        if_true_activities: Optional[List["Activity"]] = None,
        if_false_activities: Optional[List["Activity"]] = None,
        **kwargs
    ):
        super(IfConditionActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'IfCondition'
        self.expression = expression
        self.if_true_activities = if_true_activities
        self.if_false_activities = if_false_activities


class IfConditionActivityTypeProperties(msrest.serialization.Model):
    """IfCondition activity properties.

    All required parameters must be populated in order to send to Azure.

    :param expression: Required. Azure Data Factory expression definition.
    :type expression: ~data_factory_management_client.models.Expression
    :param if_true_activities: List of activities to execute if expression is evaluated to true.
     This is an optional property and if not provided, the activity will exit without any action.
    :type if_true_activities: list[~data_factory_management_client.models.Activity]
    :param if_false_activities: List of activities to execute if expression is evaluated to false.
     This is an optional property and if not provided, the activity will exit without any action.
    :type if_false_activities: list[~data_factory_management_client.models.Activity]
    """

    _validation = {
        'expression': {'required': True},
    }

    _attribute_map = {
        'expression': {'key': 'expression', 'type': 'Expression'},
        'if_true_activities': {'key': 'ifTrueActivities', 'type': '[Activity]'},
        'if_false_activities': {'key': 'ifFalseActivities', 'type': '[Activity]'},
    }

    def __init__(
        self,
        *,
        expression: "Expression",
        if_true_activities: Optional[List["Activity"]] = None,
        if_false_activities: Optional[List["Activity"]] = None,
        **kwargs
    ):
        super(IfConditionActivityTypeProperties, self).__init__(**kwargs)
        self.expression = expression
        self.if_true_activities = if_true_activities
        self.if_false_activities = if_false_activities


class ImpalaDatasetTypeProperties(msrest.serialization.Model):
    """Impala Dataset Properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.ImpalaDatasetTypePropertiesTableName
    :param table: The table name of the Impala. Type: string (or Expression with resultType
     string).
    :type table: ~data_factory_management_client.models.ImpalaDatasetTypePropertiesTable
    :param schema: The schema name of the Impala. Type: string (or Expression with resultType
     string).
    :type schema: ~data_factory_management_client.models.ImpalaDatasetTypePropertiesSchema
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'ImpalaDatasetTypePropertiesTableName'},
        'table': {'key': 'table', 'type': 'ImpalaDatasetTypePropertiesTable'},
        'schema': {'key': 'schema', 'type': 'ImpalaDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["ImpalaDatasetTypePropertiesTableName"] = None,
        table: Optional["ImpalaDatasetTypePropertiesTable"] = None,
        schema: Optional["ImpalaDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(ImpalaDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.table = table
        self.schema = schema


class ImpalaDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of the Impala. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ImpalaDatasetTypePropertiesSchema, self).__init__(**kwargs)


class ImpalaDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the Impala. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ImpalaDatasetTypePropertiesTable, self).__init__(**kwargs)


class ImpalaDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ImpalaDatasetTypePropertiesTableName, self).__init__(**kwargs)


class ImpalaLinkedService(LinkedService):
    """Impala server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. The IP address or host name of the Impala server. (i.e.
     192.168.222.160).
    :type host: ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesHost
    :param port: The TCP port that the Impala server uses to listen for client connections. The
     default value is 21050.
    :type port: ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesPort
    :param authentication_type: Required. The authentication type to use. Possible values include:
     'Anonymous', 'SASLUsername', 'UsernameAndPassword'.
    :type authentication_type: str or
     ~data_factory_management_client.models.ImpalaAuthenticationType
    :param username: The user name used to access the Impala server. The default value is anonymous
     when using SASLUsername.
    :type username:
     ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :type enable_ssl:
     ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesEnableSsl
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesTrustedCertPath
    :param use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :type use_system_trust_store:
     ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesUseSystemTrustStore
    :param allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :type allow_host_name_cn_mismatch:
     ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesAllowHostNameCNMismatch
    :param allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :type allow_self_signed_server_cert:
     ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesAllowSelfSignedServerCert
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'ImpalaLinkedServiceTypePropertiesHost'},
        'port': {'key': 'typeProperties.port', 'type': 'ImpalaLinkedServiceTypePropertiesPort'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'ImpalaLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'ImpalaLinkedServiceTypePropertiesEnableSsl'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'ImpalaLinkedServiceTypePropertiesTrustedCertPath'},
        'use_system_trust_store': {'key': 'typeProperties.useSystemTrustStore', 'type': 'ImpalaLinkedServiceTypePropertiesUseSystemTrustStore'},
        'allow_host_name_cn_mismatch': {'key': 'typeProperties.allowHostNameCNMismatch', 'type': 'ImpalaLinkedServiceTypePropertiesAllowHostNameCNMismatch'},
        'allow_self_signed_server_cert': {'key': 'typeProperties.allowSelfSignedServerCert', 'type': 'ImpalaLinkedServiceTypePropertiesAllowSelfSignedServerCert'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'ImpalaLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "ImpalaLinkedServiceTypePropertiesHost",
        authentication_type: Union[str, "ImpalaAuthenticationType"],
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        port: Optional["ImpalaLinkedServiceTypePropertiesPort"] = None,
        username: Optional["ImpalaLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        enable_ssl: Optional["ImpalaLinkedServiceTypePropertiesEnableSsl"] = None,
        trusted_cert_path: Optional["ImpalaLinkedServiceTypePropertiesTrustedCertPath"] = None,
        use_system_trust_store: Optional["ImpalaLinkedServiceTypePropertiesUseSystemTrustStore"] = None,
        allow_host_name_cn_mismatch: Optional["ImpalaLinkedServiceTypePropertiesAllowHostNameCNMismatch"] = None,
        allow_self_signed_server_cert: Optional["ImpalaLinkedServiceTypePropertiesAllowSelfSignedServerCert"] = None,
        encrypted_credential: Optional["ImpalaLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(ImpalaLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Impala'
        self.host = host
        self.port = port
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class ImpalaLinkedServiceTypeProperties(msrest.serialization.Model):
    """Impala server linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. The IP address or host name of the Impala server. (i.e.
     192.168.222.160).
    :type host: ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesHost
    :param port: The TCP port that the Impala server uses to listen for client connections. The
     default value is 21050.
    :type port: ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesPort
    :param authentication_type: Required. The authentication type to use. Possible values include:
     'Anonymous', 'SASLUsername', 'UsernameAndPassword'.
    :type authentication_type: str or
     ~data_factory_management_client.models.ImpalaAuthenticationType
    :param username: The user name used to access the Impala server. The default value is anonymous
     when using SASLUsername.
    :type username:
     ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :type enable_ssl:
     ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesEnableSsl
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesTrustedCertPath
    :param use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :type use_system_trust_store:
     ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesUseSystemTrustStore
    :param allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :type allow_host_name_cn_mismatch:
     ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesAllowHostNameCNMismatch
    :param allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :type allow_self_signed_server_cert:
     ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesAllowSelfSignedServerCert
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.ImpalaLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'ImpalaLinkedServiceTypePropertiesHost'},
        'port': {'key': 'port', 'type': 'ImpalaLinkedServiceTypePropertiesPort'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'username': {'key': 'username', 'type': 'ImpalaLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'enable_ssl': {'key': 'enableSsl', 'type': 'ImpalaLinkedServiceTypePropertiesEnableSsl'},
        'trusted_cert_path': {'key': 'trustedCertPath', 'type': 'ImpalaLinkedServiceTypePropertiesTrustedCertPath'},
        'use_system_trust_store': {'key': 'useSystemTrustStore', 'type': 'ImpalaLinkedServiceTypePropertiesUseSystemTrustStore'},
        'allow_host_name_cn_mismatch': {'key': 'allowHostNameCNMismatch', 'type': 'ImpalaLinkedServiceTypePropertiesAllowHostNameCNMismatch'},
        'allow_self_signed_server_cert': {'key': 'allowSelfSignedServerCert', 'type': 'ImpalaLinkedServiceTypePropertiesAllowSelfSignedServerCert'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'ImpalaLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "ImpalaLinkedServiceTypePropertiesHost",
        authentication_type: Union[str, "ImpalaAuthenticationType"],
        port: Optional["ImpalaLinkedServiceTypePropertiesPort"] = None,
        username: Optional["ImpalaLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        enable_ssl: Optional["ImpalaLinkedServiceTypePropertiesEnableSsl"] = None,
        trusted_cert_path: Optional["ImpalaLinkedServiceTypePropertiesTrustedCertPath"] = None,
        use_system_trust_store: Optional["ImpalaLinkedServiceTypePropertiesUseSystemTrustStore"] = None,
        allow_host_name_cn_mismatch: Optional["ImpalaLinkedServiceTypePropertiesAllowHostNameCNMismatch"] = None,
        allow_self_signed_server_cert: Optional["ImpalaLinkedServiceTypePropertiesAllowSelfSignedServerCert"] = None,
        encrypted_credential: Optional["ImpalaLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(ImpalaLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.port = port
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class ImpalaLinkedServiceTypePropertiesAllowHostNameCNMismatch(msrest.serialization.Model):
    """Specifies whether to require a CA-issued SSL certificate name to match the host name of the server when connecting over SSL. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ImpalaLinkedServiceTypePropertiesAllowHostNameCNMismatch, self).__init__(**kwargs)


class ImpalaLinkedServiceTypePropertiesAllowSelfSignedServerCert(msrest.serialization.Model):
    """Specifies whether to allow self-signed certificates from the server. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ImpalaLinkedServiceTypePropertiesAllowSelfSignedServerCert, self).__init__(**kwargs)


class ImpalaLinkedServiceTypePropertiesEnableSsl(msrest.serialization.Model):
    """Specifies whether the connections to the server are encrypted using SSL. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ImpalaLinkedServiceTypePropertiesEnableSsl, self).__init__(**kwargs)


class ImpalaLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ImpalaLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class ImpalaLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """The IP address or host name of the Impala server. (i.e. 192.168.222.160).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ImpalaLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class ImpalaLinkedServiceTypePropertiesPort(msrest.serialization.Model):
    """The TCP port that the Impala server uses to listen for client connections. The default value is 21050.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ImpalaLinkedServiceTypePropertiesPort, self).__init__(**kwargs)


class ImpalaLinkedServiceTypePropertiesTrustedCertPath(msrest.serialization.Model):
    """The full path of the .pem file containing trusted CA certificates for verifying the server when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The default value is the cacerts.pem file installed with the IR.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ImpalaLinkedServiceTypePropertiesTrustedCertPath, self).__init__(**kwargs)


class ImpalaLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """The user name used to access the Impala server. The default value is anonymous when using SASLUsername.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ImpalaLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class ImpalaLinkedServiceTypePropertiesUseSystemTrustStore(msrest.serialization.Model):
    """Specifies whether to use a CA certificate from the system trust store or from a specified PEM file. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ImpalaLinkedServiceTypePropertiesUseSystemTrustStore, self).__init__(**kwargs)


class ImpalaObjectDataset(Dataset):
    """Impala server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.ImpalaDatasetTypePropertiesTableName
    :param table: The table name of the Impala. Type: string (or Expression with resultType
     string).
    :type table: ~data_factory_management_client.models.ImpalaDatasetTypePropertiesTable
    :param schema_type_properties_schema: The schema name of the Impala. Type: string (or
     Expression with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.ImpalaDatasetTypePropertiesSchema
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'ImpalaDatasetTypePropertiesTableName'},
        'table': {'key': 'typeProperties.table', 'type': 'ImpalaDatasetTypePropertiesTable'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'ImpalaDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["ImpalaDatasetTypePropertiesTableName"] = None,
        table: Optional["ImpalaDatasetTypePropertiesTable"] = None,
        schema_type_properties_schema: Optional["ImpalaDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(ImpalaObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'ImpalaObject'
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class ImpalaSource(TabularSource):
    """A copy activity Impala server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.ImpalaSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'ImpalaSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["ImpalaSourceQuery"] = None,
        **kwargs
    ):
        super(ImpalaSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'ImpalaSource'
        self.query = query


class ImpalaSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ImpalaSourceQuery, self).__init__(**kwargs)


class InformixLinkedService(LinkedService):
    """Informix linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: Required. The non-access credential portion of the connection string
     as well as an optional encrypted credential. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.InformixLinkedServiceTypePropertiesConnectionString
    :param authentication_type: Type of authentication used to connect to the Informix as ODBC data
     store. Possible values are: Anonymous and Basic. Type: string (or Expression with resultType
     string).
    :type authentication_type:
     ~data_factory_management_client.models.InformixLinkedServiceTypePropertiesAuthenticationType
    :param credential: The base definition of a secret type.
    :type credential: ~data_factory_management_client.models.SecretBase
    :param user_name: User name for Basic authentication. Type: string (or Expression with
     resultType string).
    :type user_name:
     ~data_factory_management_client.models.InformixLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.InformixLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'InformixLinkedServiceTypePropertiesConnectionString'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'InformixLinkedServiceTypePropertiesAuthenticationType'},
        'credential': {'key': 'typeProperties.credential', 'type': 'SecretBase'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'InformixLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'InformixLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "InformixLinkedServiceTypePropertiesConnectionString",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        authentication_type: Optional["InformixLinkedServiceTypePropertiesAuthenticationType"] = None,
        credential: Optional["SecretBase"] = None,
        user_name: Optional["InformixLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["InformixLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(InformixLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Informix'
        self.connection_string = connection_string
        self.authentication_type = authentication_type
        self.credential = credential
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class InformixLinkedServiceTypeProperties(msrest.serialization.Model):
    """Informix linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param connection_string: Required. The non-access credential portion of the connection string
     as well as an optional encrypted credential. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.InformixLinkedServiceTypePropertiesConnectionString
    :param authentication_type: Type of authentication used to connect to the Informix as ODBC data
     store. Possible values are: Anonymous and Basic. Type: string (or Expression with resultType
     string).
    :type authentication_type:
     ~data_factory_management_client.models.InformixLinkedServiceTypePropertiesAuthenticationType
    :param credential: The base definition of a secret type.
    :type credential: ~data_factory_management_client.models.SecretBase
    :param user_name: User name for Basic authentication. Type: string (or Expression with
     resultType string).
    :type user_name:
     ~data_factory_management_client.models.InformixLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.InformixLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'InformixLinkedServiceTypePropertiesConnectionString'},
        'authentication_type': {'key': 'authenticationType', 'type': 'InformixLinkedServiceTypePropertiesAuthenticationType'},
        'credential': {'key': 'credential', 'type': 'SecretBase'},
        'user_name': {'key': 'userName', 'type': 'InformixLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'InformixLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "InformixLinkedServiceTypePropertiesConnectionString",
        authentication_type: Optional["InformixLinkedServiceTypePropertiesAuthenticationType"] = None,
        credential: Optional["SecretBase"] = None,
        user_name: Optional["InformixLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["InformixLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(InformixLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.authentication_type = authentication_type
        self.credential = credential
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class InformixLinkedServiceTypePropertiesAuthenticationType(msrest.serialization.Model):
    """Type of authentication used to connect to the Informix as ODBC data store. Possible values are: Anonymous and Basic. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(InformixLinkedServiceTypePropertiesAuthenticationType, self).__init__(**kwargs)


class InformixLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The non-access credential portion of the connection string as well as an optional encrypted credential. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(InformixLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class InformixLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(InformixLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class InformixLinkedServiceTypePropertiesUserName(msrest.serialization.Model):
    """User name for Basic authentication. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(InformixLinkedServiceTypePropertiesUserName, self).__init__(**kwargs)


class InformixSink(CopySink):
    """A copy activity Informix sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param pre_copy_script: A query to execute before starting the copy. Type: string (or
     Expression with resultType string).
    :type pre_copy_script: ~data_factory_management_client.models.InformixSinkPreCopyScript
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'InformixSinkPreCopyScript'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        pre_copy_script: Optional["InformixSinkPreCopyScript"] = None,
        **kwargs
    ):
        super(InformixSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'InformixSink'
        self.pre_copy_script = pre_copy_script


class InformixSinkPreCopyScript(msrest.serialization.Model):
    """A query to execute before starting the copy. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(InformixSinkPreCopyScript, self).__init__(**kwargs)


class InformixSource(TabularSource):
    """A copy activity source for Informix.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: Database query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.InformixSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'InformixSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["InformixSourceQuery"] = None,
        **kwargs
    ):
        super(InformixSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'InformixSource'
        self.query = query


class InformixSourceQuery(msrest.serialization.Model):
    """Database query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(InformixSourceQuery, self).__init__(**kwargs)


class InformixTableDataset(Dataset):
    """The Informix table dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The Informix table name. Type: string (or Expression with resultType
     string).
    :type table_name:
     ~data_factory_management_client.models.InformixTableDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'InformixTableDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["InformixTableDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(InformixTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'InformixTable'
        self.table_name = table_name


class InformixTableDatasetTypeProperties(msrest.serialization.Model):
    """Informix table dataset properties.

    :param table_name: The Informix table name. Type: string (or Expression with resultType
     string).
    :type table_name:
     ~data_factory_management_client.models.InformixTableDatasetTypePropertiesTableName
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'InformixTableDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["InformixTableDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(InformixTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name


class InformixTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """The Informix table name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(InformixTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class IntegrationRuntime(msrest.serialization.Model):
    """Azure Data Factory nested object which serves as a compute resource for activities.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: ManagedIntegrationRuntime, SelfHostedIntegrationRuntime.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The type of integration runtime.Constant filled by server.  Possible
     values include: 'Managed', 'SelfHosted'.
    :type type: str or ~data_factory_management_client.models.IntegrationRuntimeType
    :param description: Integration runtime description.
    :type description: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'Managed': 'ManagedIntegrationRuntime', 'SelfHosted': 'SelfHostedIntegrationRuntime'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        **kwargs
    ):
        super(IntegrationRuntime, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'IntegrationRuntime'
        self.description = description


class IntegrationRuntimeAuthKeys(msrest.serialization.Model):
    """The integration runtime authentication keys.

    :param auth_key1: The primary integration runtime authentication key.
    :type auth_key1: str
    :param auth_key2: The primary integration runtime authentication key.
    :type auth_key2: str
    """

    _attribute_map = {
        'auth_key1': {'key': 'authKey1', 'type': 'str'},
        'auth_key2': {'key': 'authKey2', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        auth_key1: Optional[str] = None,
        auth_key2: Optional[str] = None,
        **kwargs
    ):
        super(IntegrationRuntimeAuthKeys, self).__init__(**kwargs)
        self.auth_key1 = auth_key1
        self.auth_key2 = auth_key2


class IntegrationRuntimeComputeProperties(msrest.serialization.Model):
    """The compute resource properties for managed integration runtime.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param location: The location for managed integration runtime. The supported regions could be
     found on https://docs.microsoft.com/en-us/azure/data-factory/data-factory-data-movement-
     activities.
    :type location: str
    :param node_size: The node size requirement to managed integration runtime.
    :type node_size: str
    :param number_of_nodes: The required number of nodes for managed integration runtime.
    :type number_of_nodes: int
    :param max_parallel_executions_per_node: Maximum parallel executions count per node for managed
     integration runtime.
    :type max_parallel_executions_per_node: int
    :param data_flow_properties: Data flow properties for managed integration runtime.
    :type data_flow_properties:
     ~data_factory_management_client.models.IntegrationRuntimeDataFlowProperties
    :param v_net_properties: VNet properties for managed integration runtime.
    :type v_net_properties: ~data_factory_management_client.models.IntegrationRuntimeVNetProperties
    """

    _validation = {
        'number_of_nodes': {'minimum': 1},
        'max_parallel_executions_per_node': {'minimum': 1},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'location': {'key': 'location', 'type': 'str'},
        'node_size': {'key': 'nodeSize', 'type': 'str'},
        'number_of_nodes': {'key': 'numberOfNodes', 'type': 'int'},
        'max_parallel_executions_per_node': {'key': 'maxParallelExecutionsPerNode', 'type': 'int'},
        'data_flow_properties': {'key': 'dataFlowProperties', 'type': 'IntegrationRuntimeDataFlowProperties'},
        'v_net_properties': {'key': 'vNetProperties', 'type': 'IntegrationRuntimeVNetProperties'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        location: Optional[str] = None,
        node_size: Optional[str] = None,
        number_of_nodes: Optional[int] = None,
        max_parallel_executions_per_node: Optional[int] = None,
        data_flow_properties: Optional["IntegrationRuntimeDataFlowProperties"] = None,
        v_net_properties: Optional["IntegrationRuntimeVNetProperties"] = None,
        **kwargs
    ):
        super(IntegrationRuntimeComputeProperties, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.location = location
        self.node_size = node_size
        self.number_of_nodes = number_of_nodes
        self.max_parallel_executions_per_node = max_parallel_executions_per_node
        self.data_flow_properties = data_flow_properties
        self.v_net_properties = v_net_properties


class IntegrationRuntimeConnectionInfo(msrest.serialization.Model):
    """Connection information for encrypting the on-premises data source credentials.

    Variables are only populated by the server, and will be ignored when sending a request.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :ivar service_token: The token generated in service. Callers use this token to authenticate to
     integration runtime.
    :vartype service_token: str
    :ivar identity_cert_thumbprint: The integration runtime SSL certificate thumbprint. Click-Once
     application uses it to do server validation.
    :vartype identity_cert_thumbprint: str
    :ivar host_service_uri: The on-premises integration runtime host URL.
    :vartype host_service_uri: str
    :ivar version: The integration runtime version.
    :vartype version: str
    :ivar public_key: The public key for encrypting a credential when transferring the credential
     to the integration runtime.
    :vartype public_key: str
    :ivar is_identity_cert_exprired: Whether the identity certificate is expired.
    :vartype is_identity_cert_exprired: bool
    """

    _validation = {
        'service_token': {'readonly': True},
        'identity_cert_thumbprint': {'readonly': True},
        'host_service_uri': {'readonly': True},
        'version': {'readonly': True},
        'public_key': {'readonly': True},
        'is_identity_cert_exprired': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'service_token': {'key': 'serviceToken', 'type': 'str'},
        'identity_cert_thumbprint': {'key': 'identityCertThumbprint', 'type': 'str'},
        'host_service_uri': {'key': 'hostServiceUri', 'type': 'str'},
        'version': {'key': 'version', 'type': 'str'},
        'public_key': {'key': 'publicKey', 'type': 'str'},
        'is_identity_cert_exprired': {'key': 'isIdentityCertExprired', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(IntegrationRuntimeConnectionInfo, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.service_token = None
        self.identity_cert_thumbprint = None
        self.host_service_uri = None
        self.version = None
        self.public_key = None
        self.is_identity_cert_exprired = None


class IntegrationRuntimeCustomSetupScriptProperties(msrest.serialization.Model):
    """Custom setup script properties for a managed dedicated integration runtime.

    :param blob_container_uri: The URI of the Azure blob container that contains the custom setup
     script.
    :type blob_container_uri: str
    :param sas_token: Azure Data Factory secure string definition. The string value will be masked
     with asterisks '*' during Get or List API calls.
    :type sas_token: ~data_factory_management_client.models.SecureString
    """

    _attribute_map = {
        'blob_container_uri': {'key': 'blobContainerUri', 'type': 'str'},
        'sas_token': {'key': 'sasToken', 'type': 'SecureString'},
    }

    def __init__(
        self,
        *,
        blob_container_uri: Optional[str] = None,
        sas_token: Optional["SecureString"] = None,
        **kwargs
    ):
        super(IntegrationRuntimeCustomSetupScriptProperties, self).__init__(**kwargs)
        self.blob_container_uri = blob_container_uri
        self.sas_token = sas_token


class IntegrationRuntimeDataFlowProperties(msrest.serialization.Model):
    """Data flow properties for managed integration runtime.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param compute_type: Compute type of the cluster which will execute data flow job. Possible
     values include: 'General', 'MemoryOptimized', 'ComputeOptimized'.
    :type compute_type: str or ~data_factory_management_client.models.DataFlowComputeType
    :param core_count: Core count of the cluster which will execute data flow job. Supported values
     are: 8, 16, 32, 48, 80, 144 and 272.
    :type core_count: int
    :param time_to_live: Time to live (in minutes) setting of the cluster which will execute data
     flow job.
    :type time_to_live: int
    """

    _validation = {
        'time_to_live': {'minimum': 0},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'compute_type': {'key': 'computeType', 'type': 'str'},
        'core_count': {'key': 'coreCount', 'type': 'int'},
        'time_to_live': {'key': 'timeToLive', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        compute_type: Optional[Union[str, "DataFlowComputeType"]] = None,
        core_count: Optional[int] = None,
        time_to_live: Optional[int] = None,
        **kwargs
    ):
        super(IntegrationRuntimeDataFlowProperties, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.compute_type = compute_type
        self.core_count = core_count
        self.time_to_live = time_to_live


class IntegrationRuntimeDataProxyProperties(msrest.serialization.Model):
    """Data proxy properties for a managed dedicated integration runtime.

    :param connect_via: The entity reference.
    :type connect_via: ~data_factory_management_client.models.EntityReference
    :param staging_linked_service: The entity reference.
    :type staging_linked_service: ~data_factory_management_client.models.EntityReference
    :param path: The path to contain the staged data in the Blob storage.
    :type path: str
    """

    _attribute_map = {
        'connect_via': {'key': 'connectVia', 'type': 'EntityReference'},
        'staging_linked_service': {'key': 'stagingLinkedService', 'type': 'EntityReference'},
        'path': {'key': 'path', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        connect_via: Optional["EntityReference"] = None,
        staging_linked_service: Optional["EntityReference"] = None,
        path: Optional[str] = None,
        **kwargs
    ):
        super(IntegrationRuntimeDataProxyProperties, self).__init__(**kwargs)
        self.connect_via = connect_via
        self.staging_linked_service = staging_linked_service
        self.path = path


class IntegrationRuntimeDebugResource(SubResourceDebugResource):
    """Integration runtime debug resource.

    All required parameters must be populated in order to send to Azure.

    :param name: The resource name.
    :type name: str
    :param properties: Required. Azure Data Factory nested object which serves as a compute
     resource for activities.
    :type properties: ~data_factory_management_client.models.IntegrationRuntime
    """

    _validation = {
        'properties': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'IntegrationRuntime'},
    }

    def __init__(
        self,
        *,
        properties: "IntegrationRuntime",
        name: Optional[str] = None,
        **kwargs
    ):
        super(IntegrationRuntimeDebugResource, self).__init__(name=name, **kwargs)
        self.properties = properties


class IntegrationRuntimeListResponse(msrest.serialization.Model):
    """A list of integration runtime resources.

    All required parameters must be populated in order to send to Azure.

    :param value: Required. List of integration runtimes.
    :type value: list[~data_factory_management_client.models.IntegrationRuntimeResource]
    :param next_link: The link to the next page of results, if any remaining results exist.
    :type next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[IntegrationRuntimeResource]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["IntegrationRuntimeResource"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        super(IntegrationRuntimeListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class IntegrationRuntimeMonitoringData(msrest.serialization.Model):
    """Get monitoring data response.

    :param name: Integration runtime name.
    :type name: str
    :param nodes: Integration runtime node monitoring data.
    :type nodes: list[~data_factory_management_client.models.IntegrationRuntimeNodeMonitoringData]
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'nodes': {'key': 'nodes', 'type': '[IntegrationRuntimeNodeMonitoringData]'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        nodes: Optional[List["IntegrationRuntimeNodeMonitoringData"]] = None,
        **kwargs
    ):
        super(IntegrationRuntimeMonitoringData, self).__init__(**kwargs)
        self.name = name
        self.nodes = nodes


class IntegrationRuntimeNodeIpAddress(msrest.serialization.Model):
    """The IP address of self-hosted integration runtime node.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar ip_address: The IP address of self-hosted integration runtime node.
    :vartype ip_address: str
    """

    _validation = {
        'ip_address': {'readonly': True},
    }

    _attribute_map = {
        'ip_address': {'key': 'ipAddress', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        super(IntegrationRuntimeNodeIpAddress, self).__init__(**kwargs)
        self.ip_address = None


class IntegrationRuntimeNodeMonitoringData(msrest.serialization.Model):
    """Monitoring data for integration runtime node.

    Variables are only populated by the server, and will be ignored when sending a request.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :ivar node_name: Name of the integration runtime node.
    :vartype node_name: str
    :ivar available_memory_in_mb: Available memory (MB) on the integration runtime node.
    :vartype available_memory_in_mb: int
    :ivar cpu_utilization: CPU percentage on the integration runtime node.
    :vartype cpu_utilization: int
    :ivar concurrent_jobs_limit: Maximum concurrent jobs on the integration runtime node.
    :vartype concurrent_jobs_limit: int
    :ivar concurrent_jobs_running: The number of jobs currently running on the integration runtime
     node.
    :vartype concurrent_jobs_running: int
    :ivar max_concurrent_jobs: The maximum concurrent jobs in this integration runtime.
    :vartype max_concurrent_jobs: int
    :ivar sent_bytes: Sent bytes on the integration runtime node.
    :vartype sent_bytes: float
    :ivar received_bytes: Received bytes on the integration runtime node.
    :vartype received_bytes: float
    """

    _validation = {
        'node_name': {'readonly': True},
        'available_memory_in_mb': {'readonly': True},
        'cpu_utilization': {'readonly': True},
        'concurrent_jobs_limit': {'readonly': True},
        'concurrent_jobs_running': {'readonly': True},
        'max_concurrent_jobs': {'readonly': True},
        'sent_bytes': {'readonly': True},
        'received_bytes': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'node_name': {'key': 'nodeName', 'type': 'str'},
        'available_memory_in_mb': {'key': 'availableMemoryInMB', 'type': 'int'},
        'cpu_utilization': {'key': 'cpuUtilization', 'type': 'int'},
        'concurrent_jobs_limit': {'key': 'concurrentJobsLimit', 'type': 'int'},
        'concurrent_jobs_running': {'key': 'concurrentJobsRunning', 'type': 'int'},
        'max_concurrent_jobs': {'key': 'maxConcurrentJobs', 'type': 'int'},
        'sent_bytes': {'key': 'sentBytes', 'type': 'float'},
        'received_bytes': {'key': 'receivedBytes', 'type': 'float'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(IntegrationRuntimeNodeMonitoringData, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.node_name = None
        self.available_memory_in_mb = None
        self.cpu_utilization = None
        self.concurrent_jobs_limit = None
        self.concurrent_jobs_running = None
        self.max_concurrent_jobs = None
        self.sent_bytes = None
        self.received_bytes = None


class IntegrationRuntimeReference(msrest.serialization.Model):
    """Integration runtime reference type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of integration runtime. Default value:
     "IntegrationRuntimeReference".
    :vartype type: str
    :param reference_name: Required. Reference integration runtime name.
    :type reference_name: str
    :param parameters: An object mapping parameter names to argument values.
    :type parameters: dict[str, object]
    """

    _validation = {
        'type': {'required': True, 'constant': True},
        'reference_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{object}'},
    }

    type = "IntegrationRuntimeReference"

    def __init__(
        self,
        *,
        reference_name: str,
        parameters: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(IntegrationRuntimeReference, self).__init__(**kwargs)
        self.reference_name = reference_name
        self.parameters = parameters


class IntegrationRuntimeRegenerateKeyParameters(msrest.serialization.Model):
    """Parameters to regenerate the authentication key.

    :param key_name: The name of the authentication key to regenerate. Possible values include:
     'authKey1', 'authKey2'.
    :type key_name: str or ~data_factory_management_client.models.IntegrationRuntimeAuthKeyName
    """

    _attribute_map = {
        'key_name': {'key': 'keyName', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        key_name: Optional[Union[str, "IntegrationRuntimeAuthKeyName"]] = None,
        **kwargs
    ):
        super(IntegrationRuntimeRegenerateKeyParameters, self).__init__(**kwargs)
        self.key_name = key_name


class IntegrationRuntimeResource(SubResource):
    """Integration runtime resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :param properties: Required. Azure Data Factory nested object which serves as a compute
     resource for activities.
    :type properties: ~data_factory_management_client.models.IntegrationRuntime
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
        'properties': {'required': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'IntegrationRuntime'},
    }

    def __init__(
        self,
        *,
        properties: "IntegrationRuntime",
        **kwargs
    ):
        super(IntegrationRuntimeResource, self).__init__(**kwargs)
        self.properties = properties


class IntegrationRuntimeSsisCatalogInfo(msrest.serialization.Model):
    """Catalog information for managed dedicated integration runtime.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param catalog_server_endpoint: The catalog database server URL.
    :type catalog_server_endpoint: str
    :param catalog_admin_user_name: The administrator user name of catalog database.
    :type catalog_admin_user_name: str
    :param catalog_admin_password: Azure Data Factory secure string definition. The string value
     will be masked with asterisks '*' during Get or List API calls.
    :type catalog_admin_password: ~data_factory_management_client.models.SecureString
    :param catalog_pricing_tier: The pricing tier for the catalog database. The valid values could
     be found in https://azure.microsoft.com/en-us/pricing/details/sql-database/. Possible values
     include: 'Basic', 'Standard', 'Premium', 'PremiumRS'.
    :type catalog_pricing_tier: str or
     ~data_factory_management_client.models.IntegrationRuntimeSsisCatalogPricingTier
    """

    _validation = {
        'catalog_admin_user_name': {'max_length': 128, 'min_length': 1},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'catalog_server_endpoint': {'key': 'catalogServerEndpoint', 'type': 'str'},
        'catalog_admin_user_name': {'key': 'catalogAdminUserName', 'type': 'str'},
        'catalog_admin_password': {'key': 'catalogAdminPassword', 'type': 'SecureString'},
        'catalog_pricing_tier': {'key': 'catalogPricingTier', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        catalog_server_endpoint: Optional[str] = None,
        catalog_admin_user_name: Optional[str] = None,
        catalog_admin_password: Optional["SecureString"] = None,
        catalog_pricing_tier: Optional[Union[str, "IntegrationRuntimeSsisCatalogPricingTier"]] = None,
        **kwargs
    ):
        super(IntegrationRuntimeSsisCatalogInfo, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.catalog_server_endpoint = catalog_server_endpoint
        self.catalog_admin_user_name = catalog_admin_user_name
        self.catalog_admin_password = catalog_admin_password
        self.catalog_pricing_tier = catalog_pricing_tier


class IntegrationRuntimeSsisProperties(msrest.serialization.Model):
    """SSIS properties for managed integration runtime.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param catalog_info: Catalog information for managed dedicated integration runtime.
    :type catalog_info: ~data_factory_management_client.models.IntegrationRuntimeSsisCatalogInfo
    :param license_type: License type for bringing your own license scenario. Possible values
     include: 'BasePrice', 'LicenseIncluded'.
    :type license_type: str or ~data_factory_management_client.models.IntegrationRuntimeLicenseType
    :param custom_setup_script_properties: Custom setup script properties for a managed dedicated
     integration runtime.
    :type custom_setup_script_properties:
     ~data_factory_management_client.models.IntegrationRuntimeCustomSetupScriptProperties
    :param data_proxy_properties: Data proxy properties for a managed dedicated integration
     runtime.
    :type data_proxy_properties:
     ~data_factory_management_client.models.IntegrationRuntimeDataProxyProperties
    :param edition: The edition for the SSIS Integration Runtime. Possible values include:
     'Standard', 'Enterprise'.
    :type edition: str or ~data_factory_management_client.models.IntegrationRuntimeEdition
    :param express_custom_setup_properties: Custom setup without script properties for a SSIS
     integration runtime.
    :type express_custom_setup_properties:
     list[~data_factory_management_client.models.CustomSetupBase]
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'catalog_info': {'key': 'catalogInfo', 'type': 'IntegrationRuntimeSsisCatalogInfo'},
        'license_type': {'key': 'licenseType', 'type': 'str'},
        'custom_setup_script_properties': {'key': 'customSetupScriptProperties', 'type': 'IntegrationRuntimeCustomSetupScriptProperties'},
        'data_proxy_properties': {'key': 'dataProxyProperties', 'type': 'IntegrationRuntimeDataProxyProperties'},
        'edition': {'key': 'edition', 'type': 'str'},
        'express_custom_setup_properties': {'key': 'expressCustomSetupProperties', 'type': '[CustomSetupBase]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        catalog_info: Optional["IntegrationRuntimeSsisCatalogInfo"] = None,
        license_type: Optional[Union[str, "IntegrationRuntimeLicenseType"]] = None,
        custom_setup_script_properties: Optional["IntegrationRuntimeCustomSetupScriptProperties"] = None,
        data_proxy_properties: Optional["IntegrationRuntimeDataProxyProperties"] = None,
        edition: Optional[Union[str, "IntegrationRuntimeEdition"]] = None,
        express_custom_setup_properties: Optional[List["CustomSetupBase"]] = None,
        **kwargs
    ):
        super(IntegrationRuntimeSsisProperties, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.catalog_info = catalog_info
        self.license_type = license_type
        self.custom_setup_script_properties = custom_setup_script_properties
        self.data_proxy_properties = data_proxy_properties
        self.edition = edition
        self.express_custom_setup_properties = express_custom_setup_properties


class IntegrationRuntimeStatus(msrest.serialization.Model):
    """Integration runtime status.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: ManagedIntegrationRuntimeStatus, SelfHostedIntegrationRuntimeStatus.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The type of integration runtime.Constant filled by server.  Possible
     values include: 'Managed', 'SelfHosted'.
    :type type: str or ~data_factory_management_client.models.IntegrationRuntimeType
    :ivar data_factory_name: The data factory name which the integration runtime belong to.
    :vartype data_factory_name: str
    :ivar state: The state of integration runtime. Possible values include: 'Initial', 'Stopped',
     'Started', 'Starting', 'Stopping', 'NeedRegistration', 'Online', 'Limited', 'Offline',
     'AccessDenied'.
    :vartype state: str or ~data_factory_management_client.models.IntegrationRuntimeState
    """

    _validation = {
        'type': {'required': True},
        'data_factory_name': {'readonly': True},
        'state': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'data_factory_name': {'key': 'dataFactoryName', 'type': 'str'},
        'state': {'key': 'state', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'Managed': 'ManagedIntegrationRuntimeStatus', 'SelfHosted': 'SelfHostedIntegrationRuntimeStatus'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(IntegrationRuntimeStatus, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'IntegrationRuntimeStatus'
        self.data_factory_name = None
        self.state = None


class IntegrationRuntimeStatusListResponse(msrest.serialization.Model):
    """A list of integration runtime status.

    All required parameters must be populated in order to send to Azure.

    :param value: Required. List of integration runtime status.
    :type value: list[~data_factory_management_client.models.IntegrationRuntimeStatusResponse]
    :param next_link: The link to the next page of results, if any remaining results exist.
    :type next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[IntegrationRuntimeStatusResponse]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["IntegrationRuntimeStatusResponse"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        super(IntegrationRuntimeStatusListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class IntegrationRuntimeStatusResponse(msrest.serialization.Model):
    """Integration runtime status response.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar name: The integration runtime name.
    :vartype name: str
    :param properties: Required. Integration runtime status.
    :type properties: ~data_factory_management_client.models.IntegrationRuntimeStatus
    """

    _validation = {
        'name': {'readonly': True},
        'properties': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'IntegrationRuntimeStatus'},
    }

    def __init__(
        self,
        *,
        properties: "IntegrationRuntimeStatus",
        **kwargs
    ):
        super(IntegrationRuntimeStatusResponse, self).__init__(**kwargs)
        self.name = None
        self.properties = properties


class IntegrationRuntimeVNetProperties(msrest.serialization.Model):
    """VNet properties for managed integration runtime.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param v_net_id: The ID of the VNet that this integration runtime will join.
    :type v_net_id: str
    :param subnet: The name of the subnet this integration runtime will join.
    :type subnet: str
    :param public_ips: Resource IDs of the public IP addresses that this integration runtime will
     use.
    :type public_ips: list[str]
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'v_net_id': {'key': 'vNetId', 'type': 'str'},
        'subnet': {'key': 'subnet', 'type': 'str'},
        'public_ips': {'key': 'publicIPs', 'type': '[str]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        v_net_id: Optional[str] = None,
        subnet: Optional[str] = None,
        public_ips: Optional[List[str]] = None,
        **kwargs
    ):
        super(IntegrationRuntimeVNetProperties, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.v_net_id = v_net_id
        self.subnet = subnet
        self.public_ips = public_ips


class JiraLinkedService(LinkedService):
    """Jira Service linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. The IP address or host name of the Jira service. (e.g.
     jira.example.com).
    :type host: ~data_factory_management_client.models.JiraLinkedServiceTypePropertiesHost
    :param port: The TCP port that the Jira server uses to listen for client connections. The
     default value is 443 if connecting through HTTPS, or 8080 if connecting through HTTP.
    :type port: ~data_factory_management_client.models.JiraLinkedServiceTypePropertiesPort
    :param username: Required. The user name that you use to access Jira Service.
    :type username: ~data_factory_management_client.models.JiraLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.JiraLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.JiraLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.JiraLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.JiraLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'username': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'JiraLinkedServiceTypePropertiesHost'},
        'port': {'key': 'typeProperties.port', 'type': 'JiraLinkedServiceTypePropertiesPort'},
        'username': {'key': 'typeProperties.username', 'type': 'JiraLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'JiraLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'JiraLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'JiraLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'JiraLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "JiraLinkedServiceTypePropertiesHost",
        username: "JiraLinkedServiceTypePropertiesUsername",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        port: Optional["JiraLinkedServiceTypePropertiesPort"] = None,
        password: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["JiraLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["JiraLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["JiraLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["JiraLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(JiraLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Jira'
        self.host = host
        self.port = port
        self.username = username
        self.password = password
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class JiraLinkedServiceTypeProperties(msrest.serialization.Model):
    """Jira Service linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. The IP address or host name of the Jira service. (e.g.
     jira.example.com).
    :type host: ~data_factory_management_client.models.JiraLinkedServiceTypePropertiesHost
    :param port: The TCP port that the Jira server uses to listen for client connections. The
     default value is 443 if connecting through HTTPS, or 8080 if connecting through HTTP.
    :type port: ~data_factory_management_client.models.JiraLinkedServiceTypePropertiesPort
    :param username: Required. The user name that you use to access Jira Service.
    :type username: ~data_factory_management_client.models.JiraLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.JiraLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.JiraLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.JiraLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.JiraLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
        'username': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'JiraLinkedServiceTypePropertiesHost'},
        'port': {'key': 'port', 'type': 'JiraLinkedServiceTypePropertiesPort'},
        'username': {'key': 'username', 'type': 'JiraLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'JiraLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'JiraLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'JiraLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'JiraLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "JiraLinkedServiceTypePropertiesHost",
        username: "JiraLinkedServiceTypePropertiesUsername",
        port: Optional["JiraLinkedServiceTypePropertiesPort"] = None,
        password: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["JiraLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["JiraLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["JiraLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["JiraLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(JiraLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.port = port
        self.username = username
        self.password = password
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class JiraLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(JiraLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class JiraLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """The IP address or host name of the Jira service. (e.g. jira.example.com).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(JiraLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class JiraLinkedServiceTypePropertiesPort(msrest.serialization.Model):
    """The TCP port that the Jira server uses to listen for client connections. The default value is 443 if connecting through HTTPS, or 8080 if connecting through HTTP.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(JiraLinkedServiceTypePropertiesPort, self).__init__(**kwargs)


class JiraLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(JiraLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class JiraLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(JiraLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class JiraLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(JiraLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class JiraLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """The user name that you use to access Jira Service.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(JiraLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class JiraObjectDataset(Dataset):
    """Jira Service dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(JiraObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'JiraObject'
        self.table_name = table_name


class JiraSource(TabularSource):
    """A copy activity Jira Service source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.JiraSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'JiraSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["JiraSourceQuery"] = None,
        **kwargs
    ):
        super(JiraSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'JiraSource'
        self.query = query


class JiraSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(JiraSourceQuery, self).__init__(**kwargs)


class JsonDataset(Dataset):
    """Json dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param location: Dataset location.
    :type location: ~data_factory_management_client.models.DatasetLocation
    :param encoding_name: The code page name of the preferred encoding. If not specified, the
     default value is UTF-8, unless BOM denotes another Unicode encoding. Refer to the name column
     of the table in the following link to set supported values:
     https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with
     resultType string).
    :type encoding_name:
     ~data_factory_management_client.models.JsonDatasetTypePropertiesEncodingName
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'location': {'key': 'typeProperties.location', 'type': 'DatasetLocation'},
        'encoding_name': {'key': 'typeProperties.encodingName', 'type': 'JsonDatasetTypePropertiesEncodingName'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        location: Optional["DatasetLocation"] = None,
        encoding_name: Optional["JsonDatasetTypePropertiesEncodingName"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(JsonDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Json'
        self.location = location
        self.encoding_name = encoding_name
        self.compression = compression


class JsonDatasetTypeProperties(msrest.serialization.Model):
    """Json dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param location: Required. Dataset location.
    :type location: ~data_factory_management_client.models.DatasetLocation
    :param encoding_name: The code page name of the preferred encoding. If not specified, the
     default value is UTF-8, unless BOM denotes another Unicode encoding. Refer to the name column
     of the table in the following link to set supported values:
     https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with
     resultType string).
    :type encoding_name:
     ~data_factory_management_client.models.JsonDatasetTypePropertiesEncodingName
    :param compression: The compression method used on a dataset.
    :type compression: ~data_factory_management_client.models.DatasetCompression
    """

    _validation = {
        'location': {'required': True},
    }

    _attribute_map = {
        'location': {'key': 'location', 'type': 'DatasetLocation'},
        'encoding_name': {'key': 'encodingName', 'type': 'JsonDatasetTypePropertiesEncodingName'},
        'compression': {'key': 'compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        location: "DatasetLocation",
        encoding_name: Optional["JsonDatasetTypePropertiesEncodingName"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        super(JsonDatasetTypeProperties, self).__init__(**kwargs)
        self.location = location
        self.encoding_name = encoding_name
        self.compression = compression


class JsonDatasetTypePropertiesEncodingName(msrest.serialization.Model):
    """The code page name of the preferred encoding. If not specified, the default value is UTF-8, unless BOM denotes another Unicode encoding. Refer to the name column of the table in the following link to set supported values: https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(JsonDatasetTypePropertiesEncodingName, self).__init__(**kwargs)


class JsonFormat(DatasetStorageFormat):
    """The data stored in JSON format.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage format.Constant filled by server.
    :type type: str
    :param serializer: Serializer. Type: string (or Expression with resultType string).
    :type serializer: ~data_factory_management_client.models.DatasetStorageFormatSerializer
    :param deserializer: Deserializer. Type: string (or Expression with resultType string).
    :type deserializer: ~data_factory_management_client.models.DatasetStorageFormatDeserializer
    :param file_pattern: JSON format file pattern. A property of JsonFormat. Possible values
     include: 'setOfObjects', 'arrayOfObjects'.
    :type file_pattern: str or ~data_factory_management_client.models.JsonFormatFilePattern
    :param nesting_separator: The character used to separate nesting levels. Default value is '.'
     (dot). Type: string (or Expression with resultType string).
    :type nesting_separator: ~data_factory_management_client.models.JsonFormatNestingSeparator
    :param encoding_name: The code page name of the preferred encoding. If not provided, the
     default value is 'utf-8', unless the byte order mark (BOM) denotes another Unicode encoding.
     The full list of supported values can be found in the 'Name' column of the table of encodings
     in the following reference: https://go.microsoft.com/fwlink/?linkid=861078. Type: string (or
     Expression with resultType string).
    :type encoding_name: ~data_factory_management_client.models.JsonFormatEncodingName
    :param json_node_reference: The JSONPath of the JSON array element to be flattened. Example:
     "$.ArrayPath". Type: string (or Expression with resultType string).
    :type json_node_reference: ~data_factory_management_client.models.JsonFormatJsonNodeReference
    :param json_path_definition: The JSONPath definition for each column mapping with a customized
     column name to extract data from JSON file. For fields under root object, start with "$"; for
     fields inside the array chosen by jsonNodeReference property, start from the array element.
     Example: {"Column1": "$.Column1Path", "Column2": "Column2PathInArray"}. Type: object (or
     Expression with resultType object).
    :type json_path_definition: ~data_factory_management_client.models.JsonFormatJsonPathDefinition
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'serializer': {'key': 'serializer', 'type': 'DatasetStorageFormatSerializer'},
        'deserializer': {'key': 'deserializer', 'type': 'DatasetStorageFormatDeserializer'},
        'file_pattern': {'key': 'filePattern', 'type': 'str'},
        'nesting_separator': {'key': 'nestingSeparator', 'type': 'JsonFormatNestingSeparator'},
        'encoding_name': {'key': 'encodingName', 'type': 'JsonFormatEncodingName'},
        'json_node_reference': {'key': 'jsonNodeReference', 'type': 'JsonFormatJsonNodeReference'},
        'json_path_definition': {'key': 'jsonPathDefinition', 'type': 'JsonFormatJsonPathDefinition'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        serializer: Optional["DatasetStorageFormatSerializer"] = None,
        deserializer: Optional["DatasetStorageFormatDeserializer"] = None,
        file_pattern: Optional[Union[str, "JsonFormatFilePattern"]] = None,
        nesting_separator: Optional["JsonFormatNestingSeparator"] = None,
        encoding_name: Optional["JsonFormatEncodingName"] = None,
        json_node_reference: Optional["JsonFormatJsonNodeReference"] = None,
        json_path_definition: Optional["JsonFormatJsonPathDefinition"] = None,
        **kwargs
    ):
        super(JsonFormat, self).__init__(additional_properties=additional_properties, serializer=serializer, deserializer=deserializer, **kwargs)
        self.type = 'JsonFormat'
        self.file_pattern = file_pattern
        self.nesting_separator = nesting_separator
        self.encoding_name = encoding_name
        self.json_node_reference = json_node_reference
        self.json_path_definition = json_path_definition


class JsonFormatEncodingName(msrest.serialization.Model):
    """The code page name of the preferred encoding. If not provided, the default value is 'utf-8', unless the byte order mark (BOM) denotes another Unicode encoding. The full list of supported values can be found in the 'Name' column of the table of encodings in the following reference: https://go.microsoft.com/fwlink/?linkid=861078. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(JsonFormatEncodingName, self).__init__(**kwargs)


class JsonFormatJsonNodeReference(msrest.serialization.Model):
    """The JSONPath of the JSON array element to be flattened. Example: "$.ArrayPath". Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(JsonFormatJsonNodeReference, self).__init__(**kwargs)


class JsonFormatJsonPathDefinition(msrest.serialization.Model):
    """The JSONPath definition for each column mapping with a customized column name to extract data from JSON file. For fields under root object, start with "$"; for fields inside the array chosen by jsonNodeReference property, start from the array element. Example: {"Column1": "$.Column1Path", "Column2": "Column2PathInArray"}. Type: object (or Expression with resultType object).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(JsonFormatJsonPathDefinition, self).__init__(**kwargs)


class JsonFormatNestingSeparator(msrest.serialization.Model):
    """The character used to separate nesting levels. Default value is '.' (dot). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(JsonFormatNestingSeparator, self).__init__(**kwargs)


class JsonSink(CopySink):
    """A copy activity Json sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param store_settings: Connector write settings.
    :type store_settings: ~data_factory_management_client.models.StoreWriteSettings
    :param format_settings: Json write settings.
    :type format_settings: ~data_factory_management_client.models.JsonWriteSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreWriteSettings'},
        'format_settings': {'key': 'formatSettings', 'type': 'JsonWriteSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        store_settings: Optional["StoreWriteSettings"] = None,
        format_settings: Optional["JsonWriteSettings"] = None,
        **kwargs
    ):
        super(JsonSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'JsonSink'
        self.store_settings = store_settings
        self.format_settings = format_settings


class JsonSource(CopySource):
    """A copy activity Json source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param store_settings: Connector read setting.
    :type store_settings: ~data_factory_management_client.models.StoreReadSettings
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreReadSettings'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(JsonSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'JsonSource'
        self.store_settings = store_settings
        self.additional_columns = additional_columns


class JsonWriteSettings(FormatWriteSettings):
    """Json write settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The write setting type.Constant filled by server.
    :type type: str
    :param file_pattern: File pattern of JSON. This setting controls the way a collection of JSON
     objects will be treated. The default value is 'setOfObjects'. It is case-sensitive. Possible
     values include: 'setOfObjects', 'arrayOfObjects'.
    :type file_pattern: str or ~data_factory_management_client.models.JsonWriteFilePattern
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'file_pattern': {'key': 'filePattern', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        file_pattern: Optional[Union[str, "JsonWriteFilePattern"]] = None,
        **kwargs
    ):
        super(JsonWriteSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'JsonWriteSettings'
        self.file_pattern = file_pattern


class LicensedComponentSetupTypeProperties(msrest.serialization.Model):
    """Installation of licensed component setup type properties.

    All required parameters must be populated in order to send to Azure.

    :param component_name: Required. The name of the 3rd party component.
    :type component_name: str
    :param license_key: The base definition of a secret type.
    :type license_key: ~data_factory_management_client.models.SecretBase
    """

    _validation = {
        'component_name': {'required': True},
    }

    _attribute_map = {
        'component_name': {'key': 'componentName', 'type': 'str'},
        'license_key': {'key': 'licenseKey', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        component_name: str,
        license_key: Optional["SecretBase"] = None,
        **kwargs
    ):
        super(LicensedComponentSetupTypeProperties, self).__init__(**kwargs)
        self.component_name = component_name
        self.license_key = license_key


class LinkedIntegrationRuntime(msrest.serialization.Model):
    """The linked integration runtime information.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar name: The name of the linked integration runtime.
    :vartype name: str
    :ivar subscription_id: The subscription ID for which the linked integration runtime belong to.
    :vartype subscription_id: str
    :ivar data_factory_name: The name of the data factory for which the linked integration runtime
     belong to.
    :vartype data_factory_name: str
    :ivar data_factory_location: The location of the data factory for which the linked integration
     runtime belong to.
    :vartype data_factory_location: str
    :ivar create_time: The creating time of the linked integration runtime.
    :vartype create_time: ~datetime.datetime
    """

    _validation = {
        'name': {'readonly': True},
        'subscription_id': {'readonly': True},
        'data_factory_name': {'readonly': True},
        'data_factory_location': {'readonly': True},
        'create_time': {'readonly': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'subscription_id': {'key': 'subscriptionId', 'type': 'str'},
        'data_factory_name': {'key': 'dataFactoryName', 'type': 'str'},
        'data_factory_location': {'key': 'dataFactoryLocation', 'type': 'str'},
        'create_time': {'key': 'createTime', 'type': 'iso-8601'},
    }

    def __init__(
        self,
        **kwargs
    ):
        super(LinkedIntegrationRuntime, self).__init__(**kwargs)
        self.name = None
        self.subscription_id = None
        self.data_factory_name = None
        self.data_factory_location = None
        self.create_time = None


class LinkedIntegrationRuntimeType(msrest.serialization.Model):
    """The base definition of a linked integration runtime.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: LinkedIntegrationRuntimeKeyAuthorization, LinkedIntegrationRuntimeRbacAuthorization.

    All required parameters must be populated in order to send to Azure.

    :param authorization_type: Required. The authorization type for integration runtime
     sharing.Constant filled by server.
    :type authorization_type: str
    """

    _validation = {
        'authorization_type': {'required': True},
    }

    _attribute_map = {
        'authorization_type': {'key': 'authorizationType', 'type': 'str'},
    }

    _subtype_map = {
        'authorization_type': {'Key': 'LinkedIntegrationRuntimeKeyAuthorization', 'RBAC': 'LinkedIntegrationRuntimeRbacAuthorization'}
    }

    def __init__(
        self,
        **kwargs
    ):
        super(LinkedIntegrationRuntimeType, self).__init__(**kwargs)
        self.authorization_type = None


class LinkedIntegrationRuntimeKeyAuthorization(LinkedIntegrationRuntimeType):
    """The key authorization type integration runtime.

    All required parameters must be populated in order to send to Azure.

    :param authorization_type: Required. The authorization type for integration runtime
     sharing.Constant filled by server.
    :type authorization_type: str
    :param key: Required. Azure Data Factory secure string definition. The string value will be
     masked with asterisks '*' during Get or List API calls.
    :type key: ~data_factory_management_client.models.SecureString
    """

    _validation = {
        'authorization_type': {'required': True},
        'key': {'required': True},
    }

    _attribute_map = {
        'authorization_type': {'key': 'authorizationType', 'type': 'str'},
        'key': {'key': 'key', 'type': 'SecureString'},
    }

    def __init__(
        self,
        *,
        key: "SecureString",
        **kwargs
    ):
        super(LinkedIntegrationRuntimeKeyAuthorization, self).__init__(**kwargs)
        self.authorization_type = 'Key'
        self.key = key


class LinkedIntegrationRuntimeRbacAuthorization(LinkedIntegrationRuntimeType):
    """The role based access control (RBAC) authorization type integration runtime.

    All required parameters must be populated in order to send to Azure.

    :param authorization_type: Required. The authorization type for integration runtime
     sharing.Constant filled by server.
    :type authorization_type: str
    :param resource_id: Required. The resource identifier of the integration runtime to be shared.
    :type resource_id: str
    """

    _validation = {
        'authorization_type': {'required': True},
        'resource_id': {'required': True},
    }

    _attribute_map = {
        'authorization_type': {'key': 'authorizationType', 'type': 'str'},
        'resource_id': {'key': 'resourceId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        resource_id: str,
        **kwargs
    ):
        super(LinkedIntegrationRuntimeRbacAuthorization, self).__init__(**kwargs)
        self.authorization_type = 'RBAC'
        self.resource_id = resource_id


class LinkedIntegrationRuntimeRequest(msrest.serialization.Model):
    """Data factory name for linked integration runtime request.

    All required parameters must be populated in order to send to Azure.

    :param linked_factory_name: Required. The data factory name for linked integration runtime.
    :type linked_factory_name: str
    """

    _validation = {
        'linked_factory_name': {'required': True},
    }

    _attribute_map = {
        'linked_factory_name': {'key': 'factoryName', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        linked_factory_name: str,
        **kwargs
    ):
        super(LinkedIntegrationRuntimeRequest, self).__init__(**kwargs)
        self.linked_factory_name = linked_factory_name


class LinkedServiceAnnotationsItem(msrest.serialization.Model):
    """LinkedServiceAnnotationsItem.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(LinkedServiceAnnotationsItem, self).__init__(**kwargs)


class LinkedServiceDebugResource(SubResourceDebugResource):
    """Linked service debug resource.

    All required parameters must be populated in order to send to Azure.

    :param name: The resource name.
    :type name: str
    :param properties: Required. The Azure Data Factory nested object which contains the
     information and credential which can be used to connect with related store or compute resource.
    :type properties: ~data_factory_management_client.models.LinkedService
    """

    _validation = {
        'properties': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'LinkedService'},
    }

    def __init__(
        self,
        *,
        properties: "LinkedService",
        name: Optional[str] = None,
        **kwargs
    ):
        super(LinkedServiceDebugResource, self).__init__(name=name, **kwargs)
        self.properties = properties


class LinkedServiceListResponse(msrest.serialization.Model):
    """A list of linked service resources.

    All required parameters must be populated in order to send to Azure.

    :param value: Required. List of linked services.
    :type value: list[~data_factory_management_client.models.LinkedServiceResource]
    :param next_link: The link to the next page of results, if any remaining results exist.
    :type next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[LinkedServiceResource]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["LinkedServiceResource"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        super(LinkedServiceListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class LinkedServiceReference(msrest.serialization.Model):
    """Linked service reference type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Linked service reference type. Default value: "LinkedServiceReference".
    :vartype type: str
    :param reference_name: Required. Reference LinkedService name.
    :type reference_name: str
    :param parameters: An object mapping parameter names to argument values.
    :type parameters: dict[str, object]
    """

    _validation = {
        'type': {'required': True, 'constant': True},
        'reference_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{object}'},
    }

    type = "LinkedServiceReference"

    def __init__(
        self,
        *,
        reference_name: str,
        parameters: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(LinkedServiceReference, self).__init__(**kwargs)
        self.reference_name = reference_name
        self.parameters = parameters


class LinkedServiceResource(SubResource):
    """Linked service resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :param properties: Required. The Azure Data Factory nested object which contains the
     information and credential which can be used to connect with related store or compute resource.
    :type properties: ~data_factory_management_client.models.LinkedService
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
        'properties': {'required': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'LinkedService'},
    }

    def __init__(
        self,
        *,
        properties: "LinkedService",
        **kwargs
    ):
        super(LinkedServiceResource, self).__init__(**kwargs)
        self.properties = properties


class LogStorageSettings(msrest.serialization.Model):
    """Log storage settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param path: The path to storage for storing detailed logs of activity execution. Type: string
     (or Expression with resultType string).
    :type path: ~data_factory_management_client.models.LogStorageSettingsPath
    """

    _validation = {
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'path': {'key': 'path', 'type': 'LogStorageSettingsPath'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        path: Optional["LogStorageSettingsPath"] = None,
        **kwargs
    ):
        super(LogStorageSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.linked_service_name = linked_service_name
        self.path = path


class LogStorageSettingsPath(msrest.serialization.Model):
    """The path to storage for storing detailed logs of activity execution. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(LogStorageSettingsPath, self).__init__(**kwargs)


class LookupActivity(ExecutionActivity):
    """Lookup activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param source: Required. A copy activity source.
    :type source: ~data_factory_management_client.models.CopySource
    :param dataset: Required. Dataset reference type.
    :type dataset: ~data_factory_management_client.models.DatasetReference
    :param first_row_only: Whether to return first row or all rows. Default value is true. Type:
     boolean (or Expression with resultType boolean).
    :type first_row_only:
     ~data_factory_management_client.models.LookupActivityTypePropertiesFirstRowOnly
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'source': {'required': True},
        'dataset': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'source': {'key': 'typeProperties.source', 'type': 'CopySource'},
        'dataset': {'key': 'typeProperties.dataset', 'type': 'DatasetReference'},
        'first_row_only': {'key': 'typeProperties.firstRowOnly', 'type': 'LookupActivityTypePropertiesFirstRowOnly'},
    }

    def __init__(
        self,
        *,
        name: str,
        source: "CopySource",
        dataset: "DatasetReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        first_row_only: Optional["LookupActivityTypePropertiesFirstRowOnly"] = None,
        **kwargs
    ):
        super(LookupActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'Lookup'
        self.source = source
        self.dataset = dataset
        self.first_row_only = first_row_only


class LookupActivityTypeProperties(msrest.serialization.Model):
    """Lookup activity properties.

    All required parameters must be populated in order to send to Azure.

    :param source: Required. A copy activity source.
    :type source: ~data_factory_management_client.models.CopySource
    :param dataset: Required. Dataset reference type.
    :type dataset: ~data_factory_management_client.models.DatasetReference
    :param first_row_only: Whether to return first row or all rows. Default value is true. Type:
     boolean (or Expression with resultType boolean).
    :type first_row_only:
     ~data_factory_management_client.models.LookupActivityTypePropertiesFirstRowOnly
    """

    _validation = {
        'source': {'required': True},
        'dataset': {'required': True},
    }

    _attribute_map = {
        'source': {'key': 'source', 'type': 'CopySource'},
        'dataset': {'key': 'dataset', 'type': 'DatasetReference'},
        'first_row_only': {'key': 'firstRowOnly', 'type': 'LookupActivityTypePropertiesFirstRowOnly'},
    }

    def __init__(
        self,
        *,
        source: "CopySource",
        dataset: "DatasetReference",
        first_row_only: Optional["LookupActivityTypePropertiesFirstRowOnly"] = None,
        **kwargs
    ):
        super(LookupActivityTypeProperties, self).__init__(**kwargs)
        self.source = source
        self.dataset = dataset
        self.first_row_only = first_row_only


class LookupActivityTypePropertiesFirstRowOnly(msrest.serialization.Model):
    """Whether to return first row or all rows. Default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(LookupActivityTypePropertiesFirstRowOnly, self).__init__(**kwargs)


class MagentoLinkedService(LinkedService):
    """Magento server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. The URL of the Magento instance. (i.e. 192.168.222.110/magento3).
    :type host: ~data_factory_management_client.models.MagentoLinkedServiceTypePropertiesHost
    :param access_token: The base definition of a secret type.
    :type access_token: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.MagentoLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.MagentoLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.MagentoLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.MagentoLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'MagentoLinkedServiceTypePropertiesHost'},
        'access_token': {'key': 'typeProperties.accessToken', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'MagentoLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'MagentoLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'MagentoLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'MagentoLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "MagentoLinkedServiceTypePropertiesHost",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        access_token: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["MagentoLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["MagentoLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["MagentoLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["MagentoLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(MagentoLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Magento'
        self.host = host
        self.access_token = access_token
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class MagentoLinkedServiceTypeProperties(msrest.serialization.Model):
    """Magento server linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. The URL of the Magento instance. (i.e. 192.168.222.110/magento3).
    :type host: ~data_factory_management_client.models.MagentoLinkedServiceTypePropertiesHost
    :param access_token: The base definition of a secret type.
    :type access_token: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.MagentoLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.MagentoLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.MagentoLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.MagentoLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'MagentoLinkedServiceTypePropertiesHost'},
        'access_token': {'key': 'accessToken', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'MagentoLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'MagentoLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'MagentoLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'MagentoLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "MagentoLinkedServiceTypePropertiesHost",
        access_token: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["MagentoLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["MagentoLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["MagentoLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["MagentoLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(MagentoLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.access_token = access_token
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class MagentoLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MagentoLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class MagentoLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """The URL of the Magento instance. (i.e. 192.168.222.110/magento3).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MagentoLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class MagentoLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MagentoLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class MagentoLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MagentoLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class MagentoLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MagentoLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class MagentoObjectDataset(Dataset):
    """Magento server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(MagentoObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MagentoObject'
        self.table_name = table_name


class MagentoSource(TabularSource):
    """A copy activity Magento server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.MagentoSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'MagentoSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["MagentoSourceQuery"] = None,
        **kwargs
    ):
        super(MagentoSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'MagentoSource'
        self.query = query


class MagentoSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MagentoSourceQuery, self).__init__(**kwargs)


class ManagedIntegrationRuntime(IntegrationRuntime):
    """Managed integration runtime, including managed elastic and managed dedicated integration runtimes.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The type of integration runtime.Constant filled by server.  Possible
     values include: 'Managed', 'SelfHosted'.
    :type type: str or ~data_factory_management_client.models.IntegrationRuntimeType
    :param description: Integration runtime description.
    :type description: str
    :ivar state: The state of integration runtime. Possible values include: 'Initial', 'Stopped',
     'Started', 'Starting', 'Stopping', 'NeedRegistration', 'Online', 'Limited', 'Offline',
     'AccessDenied'.
    :vartype state: str or ~data_factory_management_client.models.IntegrationRuntimeState
    :param compute_properties: The compute resource properties for managed integration runtime.
    :type compute_properties:
     ~data_factory_management_client.models.IntegrationRuntimeComputeProperties
    :param ssis_properties: SSIS properties for managed integration runtime.
    :type ssis_properties: ~data_factory_management_client.models.IntegrationRuntimeSsisProperties
    """

    _validation = {
        'type': {'required': True},
        'state': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'state': {'key': 'state', 'type': 'str'},
        'compute_properties': {'key': 'typeProperties.computeProperties', 'type': 'IntegrationRuntimeComputeProperties'},
        'ssis_properties': {'key': 'typeProperties.ssisProperties', 'type': 'IntegrationRuntimeSsisProperties'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        compute_properties: Optional["IntegrationRuntimeComputeProperties"] = None,
        ssis_properties: Optional["IntegrationRuntimeSsisProperties"] = None,
        **kwargs
    ):
        super(ManagedIntegrationRuntime, self).__init__(additional_properties=additional_properties, description=description, **kwargs)
        self.type = 'Managed'
        self.state = None
        self.compute_properties = compute_properties
        self.ssis_properties = ssis_properties


class ManagedIntegrationRuntimeError(msrest.serialization.Model):
    """Error definition for managed integration runtime.

    Variables are only populated by the server, and will be ignored when sending a request.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :ivar time: The time when the error occurred.
    :vartype time: ~datetime.datetime
    :ivar code: Error code.
    :vartype code: str
    :ivar parameters: Managed integration runtime error parameters.
    :vartype parameters: list[str]
    :ivar message: Error message.
    :vartype message: str
    """

    _validation = {
        'time': {'readonly': True},
        'code': {'readonly': True},
        'parameters': {'readonly': True},
        'message': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'time': {'key': 'time', 'type': 'iso-8601'},
        'code': {'key': 'code', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '[str]'},
        'message': {'key': 'message', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(ManagedIntegrationRuntimeError, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.time = None
        self.code = None
        self.parameters = None
        self.message = None


class ManagedIntegrationRuntimeNode(msrest.serialization.Model):
    """Properties of integration runtime node.

    Variables are only populated by the server, and will be ignored when sending a request.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :ivar node_id: The managed integration runtime node id.
    :vartype node_id: str
    :ivar status: The managed integration runtime node status. Possible values include: 'Starting',
     'Available', 'Recycling', 'Unavailable'.
    :vartype status: str or
     ~data_factory_management_client.models.ManagedIntegrationRuntimeNodeStatus
    :param errors: The errors that occurred on this integration runtime node.
    :type errors: list[~data_factory_management_client.models.ManagedIntegrationRuntimeError]
    """

    _validation = {
        'node_id': {'readonly': True},
        'status': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'node_id': {'key': 'nodeId', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'errors': {'key': 'errors', 'type': '[ManagedIntegrationRuntimeError]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        errors: Optional[List["ManagedIntegrationRuntimeError"]] = None,
        **kwargs
    ):
        super(ManagedIntegrationRuntimeNode, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.node_id = None
        self.status = None
        self.errors = errors


class ManagedIntegrationRuntimeOperationResult(msrest.serialization.Model):
    """Properties of managed integration runtime operation result.

    Variables are only populated by the server, and will be ignored when sending a request.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :ivar type: The operation type. Could be start or stop.
    :vartype type: str
    :ivar start_time: The start time of the operation.
    :vartype start_time: ~datetime.datetime
    :ivar result: The operation result.
    :vartype result: str
    :ivar error_code: The error code.
    :vartype error_code: str
    :ivar parameters: Managed integration runtime error parameters.
    :vartype parameters: list[str]
    :ivar activity_id: The activity id for the operation request.
    :vartype activity_id: str
    """

    _validation = {
        'type': {'readonly': True},
        'start_time': {'readonly': True},
        'result': {'readonly': True},
        'error_code': {'readonly': True},
        'parameters': {'readonly': True},
        'activity_id': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'result': {'key': 'result', 'type': 'str'},
        'error_code': {'key': 'errorCode', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '[str]'},
        'activity_id': {'key': 'activityId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(ManagedIntegrationRuntimeOperationResult, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = None
        self.start_time = None
        self.result = None
        self.error_code = None
        self.parameters = None
        self.activity_id = None


class ManagedIntegrationRuntimeStatus(IntegrationRuntimeStatus):
    """Managed integration runtime status.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The type of integration runtime.Constant filled by server.  Possible
     values include: 'Managed', 'SelfHosted'.
    :type type: str or ~data_factory_management_client.models.IntegrationRuntimeType
    :ivar data_factory_name: The data factory name which the integration runtime belong to.
    :vartype data_factory_name: str
    :ivar state: The state of integration runtime. Possible values include: 'Initial', 'Stopped',
     'Started', 'Starting', 'Stopping', 'NeedRegistration', 'Online', 'Limited', 'Offline',
     'AccessDenied'.
    :vartype state: str or ~data_factory_management_client.models.IntegrationRuntimeState
    :ivar create_time: The time at which the integration runtime was created, in ISO8601 format.
    :vartype create_time: ~datetime.datetime
    :ivar nodes: The list of nodes for managed integration runtime.
    :vartype nodes: list[~data_factory_management_client.models.ManagedIntegrationRuntimeNode]
    :ivar other_errors: The errors that occurred on this integration runtime.
    :vartype other_errors:
     list[~data_factory_management_client.models.ManagedIntegrationRuntimeError]
    :ivar last_operation: Properties of managed integration runtime operation result.
    :vartype last_operation:
     ~data_factory_management_client.models.ManagedIntegrationRuntimeOperationResult
    """

    _validation = {
        'type': {'required': True},
        'data_factory_name': {'readonly': True},
        'state': {'readonly': True},
        'create_time': {'readonly': True},
        'nodes': {'readonly': True},
        'other_errors': {'readonly': True},
        'last_operation': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'data_factory_name': {'key': 'dataFactoryName', 'type': 'str'},
        'state': {'key': 'state', 'type': 'str'},
        'create_time': {'key': 'typeProperties.createTime', 'type': 'iso-8601'},
        'nodes': {'key': 'typeProperties.nodes', 'type': '[ManagedIntegrationRuntimeNode]'},
        'other_errors': {'key': 'typeProperties.otherErrors', 'type': '[ManagedIntegrationRuntimeError]'},
        'last_operation': {'key': 'typeProperties.lastOperation', 'type': 'ManagedIntegrationRuntimeOperationResult'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(ManagedIntegrationRuntimeStatus, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'Managed'
        self.create_time = None
        self.nodes = None
        self.other_errors = None
        self.last_operation = None


class ManagedIntegrationRuntimeStatusTypeProperties(msrest.serialization.Model):
    """Managed integration runtime status type properties.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar create_time: The time at which the integration runtime was created, in ISO8601 format.
    :vartype create_time: ~datetime.datetime
    :ivar nodes: The list of nodes for managed integration runtime.
    :vartype nodes: list[~data_factory_management_client.models.ManagedIntegrationRuntimeNode]
    :ivar other_errors: The errors that occurred on this integration runtime.
    :vartype other_errors:
     list[~data_factory_management_client.models.ManagedIntegrationRuntimeError]
    :ivar last_operation: Properties of managed integration runtime operation result.
    :vartype last_operation:
     ~data_factory_management_client.models.ManagedIntegrationRuntimeOperationResult
    """

    _validation = {
        'create_time': {'readonly': True},
        'nodes': {'readonly': True},
        'other_errors': {'readonly': True},
        'last_operation': {'readonly': True},
    }

    _attribute_map = {
        'create_time': {'key': 'createTime', 'type': 'iso-8601'},
        'nodes': {'key': 'nodes', 'type': '[ManagedIntegrationRuntimeNode]'},
        'other_errors': {'key': 'otherErrors', 'type': '[ManagedIntegrationRuntimeError]'},
        'last_operation': {'key': 'lastOperation', 'type': 'ManagedIntegrationRuntimeOperationResult'},
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ManagedIntegrationRuntimeStatusTypeProperties, self).__init__(**kwargs)
        self.create_time = None
        self.nodes = None
        self.other_errors = None
        self.last_operation = None


class ManagedIntegrationRuntimeTypeProperties(msrest.serialization.Model):
    """Managed integration runtime type properties.

    :param compute_properties: The compute resource properties for managed integration runtime.
    :type compute_properties:
     ~data_factory_management_client.models.IntegrationRuntimeComputeProperties
    :param ssis_properties: SSIS properties for managed integration runtime.
    :type ssis_properties: ~data_factory_management_client.models.IntegrationRuntimeSsisProperties
    """

    _attribute_map = {
        'compute_properties': {'key': 'computeProperties', 'type': 'IntegrationRuntimeComputeProperties'},
        'ssis_properties': {'key': 'ssisProperties', 'type': 'IntegrationRuntimeSsisProperties'},
    }

    def __init__(
        self,
        *,
        compute_properties: Optional["IntegrationRuntimeComputeProperties"] = None,
        ssis_properties: Optional["IntegrationRuntimeSsisProperties"] = None,
        **kwargs
    ):
        super(ManagedIntegrationRuntimeTypeProperties, self).__init__(**kwargs)
        self.compute_properties = compute_properties
        self.ssis_properties = ssis_properties


class MappingDataFlow(DataFlow):
    """Mapping data flow.

    :param type: Type of data flow.Constant filled by server.
    :type type: str
    :param description: The description of the data flow.
    :type description: str
    :param annotations: List of tags that can be used for describing the data flow.
    :type annotations: list[~data_factory_management_client.models.DataFlowAnnotationsItem]
    :param folder: The folder that this data flow is in. If not specified, Data flow will appear at
     the root level.
    :type folder: ~data_factory_management_client.models.DataFlowFolder
    :param sources: List of sources in data flow.
    :type sources: list[~data_factory_management_client.models.DataFlowSource]
    :param sinks: List of sinks in data flow.
    :type sinks: list[~data_factory_management_client.models.DataFlowSink]
    :param transformations: List of transformations in data flow.
    :type transformations: list[~data_factory_management_client.models.Transformation]
    :param script: DataFlow script.
    :type script: str
    """

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[DataFlowAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DataFlowFolder'},
        'sources': {'key': 'typeProperties.sources', 'type': '[DataFlowSource]'},
        'sinks': {'key': 'typeProperties.sinks', 'type': '[DataFlowSink]'},
        'transformations': {'key': 'typeProperties.transformations', 'type': '[Transformation]'},
        'script': {'key': 'typeProperties.script', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        description: Optional[str] = None,
        annotations: Optional[List["DataFlowAnnotationsItem"]] = None,
        folder: Optional["DataFlowFolder"] = None,
        sources: Optional[List["DataFlowSource"]] = None,
        sinks: Optional[List["DataFlowSink"]] = None,
        transformations: Optional[List["Transformation"]] = None,
        script: Optional[str] = None,
        **kwargs
    ):
        super(MappingDataFlow, self).__init__(description=description, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MappingDataFlow'
        self.sources = sources
        self.sinks = sinks
        self.transformations = transformations
        self.script = script


class MappingDataFlowTypeProperties(msrest.serialization.Model):
    """Mapping data flow type properties.

    :param sources: List of sources in data flow.
    :type sources: list[~data_factory_management_client.models.DataFlowSource]
    :param sinks: List of sinks in data flow.
    :type sinks: list[~data_factory_management_client.models.DataFlowSink]
    :param transformations: List of transformations in data flow.
    :type transformations: list[~data_factory_management_client.models.Transformation]
    :param script: DataFlow script.
    :type script: str
    """

    _attribute_map = {
        'sources': {'key': 'sources', 'type': '[DataFlowSource]'},
        'sinks': {'key': 'sinks', 'type': '[DataFlowSink]'},
        'transformations': {'key': 'transformations', 'type': '[Transformation]'},
        'script': {'key': 'script', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        sources: Optional[List["DataFlowSource"]] = None,
        sinks: Optional[List["DataFlowSink"]] = None,
        transformations: Optional[List["Transformation"]] = None,
        script: Optional[str] = None,
        **kwargs
    ):
        super(MappingDataFlowTypeProperties, self).__init__(**kwargs)
        self.sources = sources
        self.sinks = sinks
        self.transformations = transformations
        self.script = script


class MariaDBLinkedService(LinkedService):
    """MariaDB server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.MariaDBLinkedServiceTypePropertiesConnectionString
    :param pwd: Azure Key Vault secret reference.
    :type pwd: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.MariaDBLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'MariaDBLinkedServiceTypePropertiesConnectionString'},
        'pwd': {'key': 'typeProperties.pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'MariaDBLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        connection_string: Optional["MariaDBLinkedServiceTypePropertiesConnectionString"] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["MariaDBLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(MariaDBLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'MariaDB'
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class MariaDBLinkedServiceTypeProperties(msrest.serialization.Model):
    """MariaDB server linked service properties.

    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.MariaDBLinkedServiceTypePropertiesConnectionString
    :param pwd: Azure Key Vault secret reference.
    :type pwd: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.MariaDBLinkedServiceTypePropertiesEncryptedCredential
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'MariaDBLinkedServiceTypePropertiesConnectionString'},
        'pwd': {'key': 'pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'MariaDBLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional["MariaDBLinkedServiceTypePropertiesConnectionString"] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["MariaDBLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(MariaDBLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class MariaDBLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """An ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MariaDBLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class MariaDBLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MariaDBLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class MariaDBSource(TabularSource):
    """A copy activity MariaDB server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.MariaDBSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'MariaDBSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["MariaDBSourceQuery"] = None,
        **kwargs
    ):
        super(MariaDBSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'MariaDBSource'
        self.query = query


class MariaDBSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MariaDBSourceQuery, self).__init__(**kwargs)


class MariaDBTableDataset(Dataset):
    """MariaDB server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(MariaDBTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MariaDBTable'
        self.table_name = table_name


class MarketoLinkedService(LinkedService):
    """Marketo server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param endpoint: Required. The endpoint of the Marketo server. (i.e. 123-ABC-321.mktorest.com).
    :type endpoint:
     ~data_factory_management_client.models.MarketoLinkedServiceTypePropertiesEndpoint
    :param client_id: Required. The client Id of your Marketo service.
    :type client_id:
     ~data_factory_management_client.models.MarketoLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.MarketoLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.MarketoLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.MarketoLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.MarketoLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'endpoint': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'MarketoLinkedServiceTypePropertiesEndpoint'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'MarketoLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'MarketoLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'MarketoLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'MarketoLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'MarketoLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        endpoint: "MarketoLinkedServiceTypePropertiesEndpoint",
        client_id: "MarketoLinkedServiceTypePropertiesClientId",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["MarketoLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["MarketoLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["MarketoLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["MarketoLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(MarketoLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Marketo'
        self.endpoint = endpoint
        self.client_id = client_id
        self.client_secret = client_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class MarketoLinkedServiceTypeProperties(msrest.serialization.Model):
    """Marketo server linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param endpoint: Required. The endpoint of the Marketo server. (i.e. 123-ABC-321.mktorest.com).
    :type endpoint:
     ~data_factory_management_client.models.MarketoLinkedServiceTypePropertiesEndpoint
    :param client_id: Required. The client Id of your Marketo service.
    :type client_id:
     ~data_factory_management_client.models.MarketoLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.MarketoLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.MarketoLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.MarketoLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.MarketoLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'endpoint': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'endpoint': {'key': 'endpoint', 'type': 'MarketoLinkedServiceTypePropertiesEndpoint'},
        'client_id': {'key': 'clientId', 'type': 'MarketoLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'clientSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'MarketoLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'MarketoLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'MarketoLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'MarketoLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        endpoint: "MarketoLinkedServiceTypePropertiesEndpoint",
        client_id: "MarketoLinkedServiceTypePropertiesClientId",
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["MarketoLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["MarketoLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["MarketoLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["MarketoLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(MarketoLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.endpoint = endpoint
        self.client_id = client_id
        self.client_secret = client_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class MarketoLinkedServiceTypePropertiesClientId(msrest.serialization.Model):
    """The client Id of your Marketo service.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MarketoLinkedServiceTypePropertiesClientId, self).__init__(**kwargs)


class MarketoLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MarketoLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class MarketoLinkedServiceTypePropertiesEndpoint(msrest.serialization.Model):
    """The endpoint of the Marketo server. (i.e. 123-ABC-321.mktorest.com).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MarketoLinkedServiceTypePropertiesEndpoint, self).__init__(**kwargs)


class MarketoLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MarketoLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class MarketoLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MarketoLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class MarketoLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MarketoLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class MarketoObjectDataset(Dataset):
    """Marketo server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(MarketoObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MarketoObject'
        self.table_name = table_name


class MarketoSource(TabularSource):
    """A copy activity Marketo server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.MarketoSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'MarketoSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["MarketoSourceQuery"] = None,
        **kwargs
    ):
        super(MarketoSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'MarketoSource'
        self.query = query


class MarketoSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MarketoSourceQuery, self).__init__(**kwargs)


class MicrosoftAccessLinkedService(LinkedService):
    """Microsoft Access linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: Required. The non-access credential portion of the connection string
     as well as an optional encrypted credential. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.MicrosoftAccessLinkedServiceTypePropertiesConnectionString
    :param authentication_type: Type of authentication used to connect to the Microsoft Access as
     ODBC data store. Possible values are: Anonymous and Basic. Type: string (or Expression with
     resultType string).
    :type authentication_type:
     ~data_factory_management_client.models.MicrosoftAccessLinkedServiceTypePropertiesAuthenticationType
    :param credential: The base definition of a secret type.
    :type credential: ~data_factory_management_client.models.SecretBase
    :param user_name: User name for Basic authentication. Type: string (or Expression with
     resultType string).
    :type user_name:
     ~data_factory_management_client.models.MicrosoftAccessLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.MicrosoftAccessLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'MicrosoftAccessLinkedServiceTypePropertiesConnectionString'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'MicrosoftAccessLinkedServiceTypePropertiesAuthenticationType'},
        'credential': {'key': 'typeProperties.credential', 'type': 'SecretBase'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'MicrosoftAccessLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'MicrosoftAccessLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "MicrosoftAccessLinkedServiceTypePropertiesConnectionString",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        authentication_type: Optional["MicrosoftAccessLinkedServiceTypePropertiesAuthenticationType"] = None,
        credential: Optional["SecretBase"] = None,
        user_name: Optional["MicrosoftAccessLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["MicrosoftAccessLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(MicrosoftAccessLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'MicrosoftAccess'
        self.connection_string = connection_string
        self.authentication_type = authentication_type
        self.credential = credential
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class MicrosoftAccessLinkedServiceTypeProperties(msrest.serialization.Model):
    """Microsoft Access linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param connection_string: Required. The non-access credential portion of the connection string
     as well as an optional encrypted credential. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.MicrosoftAccessLinkedServiceTypePropertiesConnectionString
    :param authentication_type: Type of authentication used to connect to the Microsoft Access as
     ODBC data store. Possible values are: Anonymous and Basic. Type: string (or Expression with
     resultType string).
    :type authentication_type:
     ~data_factory_management_client.models.MicrosoftAccessLinkedServiceTypePropertiesAuthenticationType
    :param credential: The base definition of a secret type.
    :type credential: ~data_factory_management_client.models.SecretBase
    :param user_name: User name for Basic authentication. Type: string (or Expression with
     resultType string).
    :type user_name:
     ~data_factory_management_client.models.MicrosoftAccessLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.MicrosoftAccessLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'MicrosoftAccessLinkedServiceTypePropertiesConnectionString'},
        'authentication_type': {'key': 'authenticationType', 'type': 'MicrosoftAccessLinkedServiceTypePropertiesAuthenticationType'},
        'credential': {'key': 'credential', 'type': 'SecretBase'},
        'user_name': {'key': 'userName', 'type': 'MicrosoftAccessLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'MicrosoftAccessLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "MicrosoftAccessLinkedServiceTypePropertiesConnectionString",
        authentication_type: Optional["MicrosoftAccessLinkedServiceTypePropertiesAuthenticationType"] = None,
        credential: Optional["SecretBase"] = None,
        user_name: Optional["MicrosoftAccessLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["MicrosoftAccessLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(MicrosoftAccessLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.authentication_type = authentication_type
        self.credential = credential
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class MicrosoftAccessLinkedServiceTypePropertiesAuthenticationType(msrest.serialization.Model):
    """Type of authentication used to connect to the Microsoft Access as ODBC data store. Possible values are: Anonymous and Basic. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MicrosoftAccessLinkedServiceTypePropertiesAuthenticationType, self).__init__(**kwargs)


class MicrosoftAccessLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The non-access credential portion of the connection string as well as an optional encrypted credential. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MicrosoftAccessLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class MicrosoftAccessLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MicrosoftAccessLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class MicrosoftAccessLinkedServiceTypePropertiesUserName(msrest.serialization.Model):
    """User name for Basic authentication. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MicrosoftAccessLinkedServiceTypePropertiesUserName, self).__init__(**kwargs)


class MicrosoftAccessSink(CopySink):
    """A copy activity Microsoft Access sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param pre_copy_script: A query to execute before starting the copy. Type: string (or
     Expression with resultType string).
    :type pre_copy_script: ~data_factory_management_client.models.MicrosoftAccessSinkPreCopyScript
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'MicrosoftAccessSinkPreCopyScript'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        pre_copy_script: Optional["MicrosoftAccessSinkPreCopyScript"] = None,
        **kwargs
    ):
        super(MicrosoftAccessSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'MicrosoftAccessSink'
        self.pre_copy_script = pre_copy_script


class MicrosoftAccessSinkPreCopyScript(msrest.serialization.Model):
    """A query to execute before starting the copy. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MicrosoftAccessSinkPreCopyScript, self).__init__(**kwargs)


class MicrosoftAccessSource(CopySource):
    """A copy activity source for Microsoft Access.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query: Database query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.MicrosoftAccessSourceQuery
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query': {'key': 'query', 'type': 'MicrosoftAccessSourceQuery'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query: Optional["MicrosoftAccessSourceQuery"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(MicrosoftAccessSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'MicrosoftAccessSource'
        self.query = query
        self.additional_columns = additional_columns


class MicrosoftAccessSourceQuery(msrest.serialization.Model):
    """Database query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MicrosoftAccessSourceQuery, self).__init__(**kwargs)


class MicrosoftAccessTableDataset(Dataset):
    """The Microsoft Access table dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The Microsoft Access table name. Type: string (or Expression with resultType
     string).
    :type table_name:
     ~data_factory_management_client.models.MicrosoftAccessTableDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'MicrosoftAccessTableDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["MicrosoftAccessTableDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(MicrosoftAccessTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MicrosoftAccessTable'
        self.table_name = table_name


class MicrosoftAccessTableDatasetTypeProperties(msrest.serialization.Model):
    """Microsoft Access table dataset properties.

    :param table_name: The Microsoft Access table name. Type: string (or Expression with resultType
     string).
    :type table_name:
     ~data_factory_management_client.models.MicrosoftAccessTableDatasetTypePropertiesTableName
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'MicrosoftAccessTableDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["MicrosoftAccessTableDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(MicrosoftAccessTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name


class MicrosoftAccessTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """The Microsoft Access table name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MicrosoftAccessTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class MongoDbCollectionDataset(Dataset):
    """The MongoDB database dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param collection_name: Required. The table name of the MongoDB database. Type: string (or
     Expression with resultType string).
    :type collection_name:
     ~data_factory_management_client.models.MongoDbCollectionDatasetTypePropertiesCollectionName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'collection_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'collection_name': {'key': 'typeProperties.collectionName', 'type': 'MongoDbCollectionDatasetTypePropertiesCollectionName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        collection_name: "MongoDbCollectionDatasetTypePropertiesCollectionName",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        super(MongoDbCollectionDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MongoDbCollection'
        self.collection_name = collection_name


class MongoDbCollectionDatasetTypeProperties(msrest.serialization.Model):
    """MongoDB database dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param collection_name: Required. The table name of the MongoDB database. Type: string (or
     Expression with resultType string).
    :type collection_name:
     ~data_factory_management_client.models.MongoDbCollectionDatasetTypePropertiesCollectionName
    """

    _validation = {
        'collection_name': {'required': True},
    }

    _attribute_map = {
        'collection_name': {'key': 'collectionName', 'type': 'MongoDbCollectionDatasetTypePropertiesCollectionName'},
    }

    def __init__(
        self,
        *,
        collection_name: "MongoDbCollectionDatasetTypePropertiesCollectionName",
        **kwargs
    ):
        super(MongoDbCollectionDatasetTypeProperties, self).__init__(**kwargs)
        self.collection_name = collection_name


class MongoDbCollectionDatasetTypePropertiesCollectionName(msrest.serialization.Model):
    """The table name of the MongoDB database. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbCollectionDatasetTypePropertiesCollectionName, self).__init__(**kwargs)


class MongoDbCursorMethodsProperties(msrest.serialization.Model):
    """Cursor methods for Mongodb query.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param project: Specifies the fields to return in the documents that match the query filter. To
     return all fields in the matching documents, omit this parameter. Type: string (or Expression
     with resultType string).
    :type project: ~data_factory_management_client.models.MongoDbCursorMethodsPropertiesProject
    :param sort: Specifies the order in which the query returns matching documents. Type: string
     (or Expression with resultType string). Type: string (or Expression with resultType string).
    :type sort: ~data_factory_management_client.models.MongoDbCursorMethodsPropertiesSort
    :param skip: Specifies the how many documents skipped and where MongoDB begins returning
     results. This approach may be useful in implementing paginated results. Type: integer (or
     Expression with resultType integer).
    :type skip: ~data_factory_management_client.models.MongoDbCursorMethodsPropertiesSkip
    :param limit: Specifies the maximum number of documents the server returns. limit() is
     analogous to the LIMIT statement in a SQL database. Type: integer (or Expression with
     resultType integer).
    :type limit: ~data_factory_management_client.models.MongoDbCursorMethodsPropertiesLimit
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'project': {'key': 'project', 'type': 'MongoDbCursorMethodsPropertiesProject'},
        'sort': {'key': 'sort', 'type': 'MongoDbCursorMethodsPropertiesSort'},
        'skip': {'key': 'skip', 'type': 'MongoDbCursorMethodsPropertiesSkip'},
        'limit': {'key': 'limit', 'type': 'MongoDbCursorMethodsPropertiesLimit'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        project: Optional["MongoDbCursorMethodsPropertiesProject"] = None,
        sort: Optional["MongoDbCursorMethodsPropertiesSort"] = None,
        skip: Optional["MongoDbCursorMethodsPropertiesSkip"] = None,
        limit: Optional["MongoDbCursorMethodsPropertiesLimit"] = None,
        **kwargs
    ):
        super(MongoDbCursorMethodsProperties, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.project = project
        self.sort = sort
        self.skip = skip
        self.limit = limit


class MongoDbCursorMethodsPropertiesLimit(msrest.serialization.Model):
    """Specifies the maximum number of documents the server returns. limit() is analogous to the LIMIT statement in a SQL database. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbCursorMethodsPropertiesLimit, self).__init__(**kwargs)


class MongoDbCursorMethodsPropertiesProject(msrest.serialization.Model):
    """Specifies the fields to return in the documents that match the query filter. To return all fields in the matching documents, omit this parameter. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbCursorMethodsPropertiesProject, self).__init__(**kwargs)


class MongoDbCursorMethodsPropertiesSkip(msrest.serialization.Model):
    """Specifies the how many documents skipped and where MongoDB begins returning results. This approach may be useful in implementing paginated results. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbCursorMethodsPropertiesSkip, self).__init__(**kwargs)


class MongoDbCursorMethodsPropertiesSort(msrest.serialization.Model):
    """Specifies the order in which the query returns matching documents. Type: string (or Expression with resultType string). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbCursorMethodsPropertiesSort, self).__init__(**kwargs)


class MongoDbLinkedService(LinkedService):
    """Linked service for MongoDb data source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param server: Required. The IP address or server name of the MongoDB server. Type: string (or
     Expression with resultType string).
    :type server: ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesServer
    :param authentication_type: The authentication type to be used to connect to the MongoDB
     database. Possible values include: 'Basic', 'Anonymous'.
    :type authentication_type: str or
     ~data_factory_management_client.models.MongoDbAuthenticationType
    :param database_name: Required. The name of the MongoDB database that you want to access. Type:
     string (or Expression with resultType string).
    :type database_name:
     ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesDatabaseName
    :param username: Username for authentication. Type: string (or Expression with resultType
     string).
    :type username:
     ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param auth_source: Database to verify the username and password. Type: string (or Expression
     with resultType string).
    :type auth_source:
     ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesAuthSource
    :param port: The TCP port number that the MongoDB server uses to listen for client connections.
     The default value is 27017. Type: integer (or Expression with resultType integer), minimum: 0.
    :type port: ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesPort
    :param enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false. Type: boolean (or Expression with resultType boolean).
    :type enable_ssl:
     ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesEnableSsl
    :param allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false. Type: boolean (or Expression with resultType boolean).
    :type allow_self_signed_server_cert:
     ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesAllowSelfSignedServerCert
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'server': {'required': True},
        'database_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'server': {'key': 'typeProperties.server', 'type': 'MongoDbLinkedServiceTypePropertiesServer'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'database_name': {'key': 'typeProperties.databaseName', 'type': 'MongoDbLinkedServiceTypePropertiesDatabaseName'},
        'username': {'key': 'typeProperties.username', 'type': 'MongoDbLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'auth_source': {'key': 'typeProperties.authSource', 'type': 'MongoDbLinkedServiceTypePropertiesAuthSource'},
        'port': {'key': 'typeProperties.port', 'type': 'MongoDbLinkedServiceTypePropertiesPort'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'MongoDbLinkedServiceTypePropertiesEnableSsl'},
        'allow_self_signed_server_cert': {'key': 'typeProperties.allowSelfSignedServerCert', 'type': 'MongoDbLinkedServiceTypePropertiesAllowSelfSignedServerCert'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'MongoDbLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        server: "MongoDbLinkedServiceTypePropertiesServer",
        database_name: "MongoDbLinkedServiceTypePropertiesDatabaseName",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        authentication_type: Optional[Union[str, "MongoDbAuthenticationType"]] = None,
        username: Optional["MongoDbLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        auth_source: Optional["MongoDbLinkedServiceTypePropertiesAuthSource"] = None,
        port: Optional["MongoDbLinkedServiceTypePropertiesPort"] = None,
        enable_ssl: Optional["MongoDbLinkedServiceTypePropertiesEnableSsl"] = None,
        allow_self_signed_server_cert: Optional["MongoDbLinkedServiceTypePropertiesAllowSelfSignedServerCert"] = None,
        encrypted_credential: Optional["MongoDbLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(MongoDbLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'MongoDb'
        self.server = server
        self.authentication_type = authentication_type
        self.database_name = database_name
        self.username = username
        self.password = password
        self.auth_source = auth_source
        self.port = port
        self.enable_ssl = enable_ssl
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class MongoDbLinkedServiceTypeProperties(msrest.serialization.Model):
    """MongoDB linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param server: Required. The IP address or server name of the MongoDB server. Type: string (or
     Expression with resultType string).
    :type server: ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesServer
    :param authentication_type: The authentication type to be used to connect to the MongoDB
     database. Possible values include: 'Basic', 'Anonymous'.
    :type authentication_type: str or
     ~data_factory_management_client.models.MongoDbAuthenticationType
    :param database_name: Required. The name of the MongoDB database that you want to access. Type:
     string (or Expression with resultType string).
    :type database_name:
     ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesDatabaseName
    :param username: Username for authentication. Type: string (or Expression with resultType
     string).
    :type username:
     ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param auth_source: Database to verify the username and password. Type: string (or Expression
     with resultType string).
    :type auth_source:
     ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesAuthSource
    :param port: The TCP port number that the MongoDB server uses to listen for client connections.
     The default value is 27017. Type: integer (or Expression with resultType integer), minimum: 0.
    :type port: ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesPort
    :param enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false. Type: boolean (or Expression with resultType boolean).
    :type enable_ssl:
     ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesEnableSsl
    :param allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false. Type: boolean (or Expression with resultType boolean).
    :type allow_self_signed_server_cert:
     ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesAllowSelfSignedServerCert
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.MongoDbLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'server': {'required': True},
        'database_name': {'required': True},
    }

    _attribute_map = {
        'server': {'key': 'server', 'type': 'MongoDbLinkedServiceTypePropertiesServer'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'database_name': {'key': 'databaseName', 'type': 'MongoDbLinkedServiceTypePropertiesDatabaseName'},
        'username': {'key': 'username', 'type': 'MongoDbLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'auth_source': {'key': 'authSource', 'type': 'MongoDbLinkedServiceTypePropertiesAuthSource'},
        'port': {'key': 'port', 'type': 'MongoDbLinkedServiceTypePropertiesPort'},
        'enable_ssl': {'key': 'enableSsl', 'type': 'MongoDbLinkedServiceTypePropertiesEnableSsl'},
        'allow_self_signed_server_cert': {'key': 'allowSelfSignedServerCert', 'type': 'MongoDbLinkedServiceTypePropertiesAllowSelfSignedServerCert'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'MongoDbLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        server: "MongoDbLinkedServiceTypePropertiesServer",
        database_name: "MongoDbLinkedServiceTypePropertiesDatabaseName",
        authentication_type: Optional[Union[str, "MongoDbAuthenticationType"]] = None,
        username: Optional["MongoDbLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        auth_source: Optional["MongoDbLinkedServiceTypePropertiesAuthSource"] = None,
        port: Optional["MongoDbLinkedServiceTypePropertiesPort"] = None,
        enable_ssl: Optional["MongoDbLinkedServiceTypePropertiesEnableSsl"] = None,
        allow_self_signed_server_cert: Optional["MongoDbLinkedServiceTypePropertiesAllowSelfSignedServerCert"] = None,
        encrypted_credential: Optional["MongoDbLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(MongoDbLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.server = server
        self.authentication_type = authentication_type
        self.database_name = database_name
        self.username = username
        self.password = password
        self.auth_source = auth_source
        self.port = port
        self.enable_ssl = enable_ssl
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class MongoDbLinkedServiceTypePropertiesAllowSelfSignedServerCert(msrest.serialization.Model):
    """Specifies whether to allow self-signed certificates from the server. The default value is false. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbLinkedServiceTypePropertiesAllowSelfSignedServerCert, self).__init__(**kwargs)


class MongoDbLinkedServiceTypePropertiesAuthSource(msrest.serialization.Model):
    """Database to verify the username and password. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbLinkedServiceTypePropertiesAuthSource, self).__init__(**kwargs)


class MongoDbLinkedServiceTypePropertiesDatabaseName(msrest.serialization.Model):
    """The name of the MongoDB database that you want to access. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbLinkedServiceTypePropertiesDatabaseName, self).__init__(**kwargs)


class MongoDbLinkedServiceTypePropertiesEnableSsl(msrest.serialization.Model):
    """Specifies whether the connections to the server are encrypted using SSL. The default value is false. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbLinkedServiceTypePropertiesEnableSsl, self).__init__(**kwargs)


class MongoDbLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class MongoDbLinkedServiceTypePropertiesPort(msrest.serialization.Model):
    """The TCP port number that the MongoDB server uses to listen for client connections. The default value is 27017. Type: integer (or Expression with resultType integer), minimum: 0.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbLinkedServiceTypePropertiesPort, self).__init__(**kwargs)


class MongoDbLinkedServiceTypePropertiesServer(msrest.serialization.Model):
    """The IP address or server name of the MongoDB server. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbLinkedServiceTypePropertiesServer, self).__init__(**kwargs)


class MongoDbLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """Username for authentication. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class MongoDbSource(CopySource):
    """A copy activity source for a MongoDB database.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query: Database query. Should be a SQL-92 query expression. Type: string (or Expression
     with resultType string).
    :type query: ~data_factory_management_client.models.MongoDbSourceQuery
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query': {'key': 'query', 'type': 'MongoDbSourceQuery'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query: Optional["MongoDbSourceQuery"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(MongoDbSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'MongoDbSource'
        self.query = query
        self.additional_columns = additional_columns


class MongoDbSourceQuery(msrest.serialization.Model):
    """Database query. Should be a SQL-92 query expression. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbSourceQuery, self).__init__(**kwargs)


class MongoDbV2CollectionDataset(Dataset):
    """The MongoDB database dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param collection: Required. The collection name of the MongoDB database. Type: string (or
     Expression with resultType string).
    :type collection:
     ~data_factory_management_client.models.MongoDbV2CollectionDatasetTypePropertiesCollection
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'collection': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'collection': {'key': 'typeProperties.collection', 'type': 'MongoDbV2CollectionDatasetTypePropertiesCollection'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        collection: "MongoDbV2CollectionDatasetTypePropertiesCollection",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        super(MongoDbV2CollectionDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MongoDbV2Collection'
        self.collection = collection


class MongoDbV2CollectionDatasetTypeProperties(msrest.serialization.Model):
    """MongoDB database dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param collection: Required. The collection name of the MongoDB database. Type: string (or
     Expression with resultType string).
    :type collection:
     ~data_factory_management_client.models.MongoDbV2CollectionDatasetTypePropertiesCollection
    """

    _validation = {
        'collection': {'required': True},
    }

    _attribute_map = {
        'collection': {'key': 'collection', 'type': 'MongoDbV2CollectionDatasetTypePropertiesCollection'},
    }

    def __init__(
        self,
        *,
        collection: "MongoDbV2CollectionDatasetTypePropertiesCollection",
        **kwargs
    ):
        super(MongoDbV2CollectionDatasetTypeProperties, self).__init__(**kwargs)
        self.collection = collection


class MongoDbV2CollectionDatasetTypePropertiesCollection(msrest.serialization.Model):
    """The collection name of the MongoDB database. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbV2CollectionDatasetTypePropertiesCollection, self).__init__(**kwargs)


class MongoDbV2LinkedService(LinkedService):
    """Linked service for MongoDB data source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: Required. The MongoDB connection string. Type: string, SecureString
     or AzureKeyVaultSecretReference. Type: string, SecureString or AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.MongoDbV2LinkedServiceTypePropertiesConnectionString
    :param database: Required. The name of the MongoDB database that you want to access. Type:
     string (or Expression with resultType string).
    :type database:
     ~data_factory_management_client.models.MongoDbV2LinkedServiceTypePropertiesDatabase
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
        'database': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'MongoDbV2LinkedServiceTypePropertiesConnectionString'},
        'database': {'key': 'typeProperties.database', 'type': 'MongoDbV2LinkedServiceTypePropertiesDatabase'},
    }

    def __init__(
        self,
        *,
        connection_string: "MongoDbV2LinkedServiceTypePropertiesConnectionString",
        database: "MongoDbV2LinkedServiceTypePropertiesDatabase",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        **kwargs
    ):
        super(MongoDbV2LinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'MongoDbV2'
        self.connection_string = connection_string
        self.database = database


class MongoDbV2LinkedServiceTypeProperties(msrest.serialization.Model):
    """MongoDB linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param connection_string: Required. The MongoDB connection string. Type: string, SecureString
     or AzureKeyVaultSecretReference. Type: string, SecureString or AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.MongoDbV2LinkedServiceTypePropertiesConnectionString
    :param database: Required. The name of the MongoDB database that you want to access. Type:
     string (or Expression with resultType string).
    :type database:
     ~data_factory_management_client.models.MongoDbV2LinkedServiceTypePropertiesDatabase
    """

    _validation = {
        'connection_string': {'required': True},
        'database': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'MongoDbV2LinkedServiceTypePropertiesConnectionString'},
        'database': {'key': 'database', 'type': 'MongoDbV2LinkedServiceTypePropertiesDatabase'},
    }

    def __init__(
        self,
        *,
        connection_string: "MongoDbV2LinkedServiceTypePropertiesConnectionString",
        database: "MongoDbV2LinkedServiceTypePropertiesDatabase",
        **kwargs
    ):
        super(MongoDbV2LinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.database = database


class MongoDbV2LinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The MongoDB connection string. Type: string, SecureString or AzureKeyVaultSecretReference. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbV2LinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class MongoDbV2LinkedServiceTypePropertiesDatabase(msrest.serialization.Model):
    """The name of the MongoDB database that you want to access. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbV2LinkedServiceTypePropertiesDatabase, self).__init__(**kwargs)


class MongoDbV2Source(CopySource):
    """A copy activity source for a MongoDB database.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param filter: Specifies selection filter using query operators. To return all documents in a
     collection, omit this parameter or pass an empty document ({}). Type: string (or Expression
     with resultType string).
    :type filter: ~data_factory_management_client.models.MongoDbV2SourceFilter
    :param cursor_methods: Cursor methods for Mongodb query.
    :type cursor_methods: ~data_factory_management_client.models.MongoDbCursorMethodsProperties
    :param batch_size: Specifies the number of documents to return in each batch of the response
     from MongoDB instance. In most cases, modifying the batch size will not affect the user or the
     application. This property's main purpose is to avoid hit the limitation of response size.
     Type: integer (or Expression with resultType integer).
    :type batch_size: ~data_factory_management_client.models.MongoDbV2SourceBatchSize
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.MongoDbV2SourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'filter': {'key': 'filter', 'type': 'MongoDbV2SourceFilter'},
        'cursor_methods': {'key': 'cursorMethods', 'type': 'MongoDbCursorMethodsProperties'},
        'batch_size': {'key': 'batchSize', 'type': 'MongoDbV2SourceBatchSize'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'MongoDbV2SourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        filter: Optional["MongoDbV2SourceFilter"] = None,
        cursor_methods: Optional["MongoDbCursorMethodsProperties"] = None,
        batch_size: Optional["MongoDbV2SourceBatchSize"] = None,
        query_timeout: Optional["MongoDbV2SourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(MongoDbV2Source, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'MongoDbV2Source'
        self.filter = filter
        self.cursor_methods = cursor_methods
        self.batch_size = batch_size
        self.query_timeout = query_timeout
        self.additional_columns = additional_columns


class MongoDbV2SourceBatchSize(msrest.serialization.Model):
    """Specifies the number of documents to return in each batch of the response from MongoDB instance. In most cases, modifying the batch size will not affect the user or the application. This property's main purpose is to avoid hit the limitation of response size. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbV2SourceBatchSize, self).__init__(**kwargs)


class MongoDbV2SourceFilter(msrest.serialization.Model):
    """Specifies selection filter using query operators. To return all documents in a collection, omit this parameter or pass an empty document ({}). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbV2SourceFilter, self).__init__(**kwargs)


class MongoDbV2SourceQueryTimeout(msrest.serialization.Model):
    """Query timeout. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MongoDbV2SourceQueryTimeout, self).__init__(**kwargs)


class MySqlLinkedService(LinkedService):
    """Linked service for MySQL data source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: Required. The connection string.
    :type connection_string:
     ~data_factory_management_client.models.MySqlLinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.MySqlLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'MySqlLinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'MySqlLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "MySqlLinkedServiceTypePropertiesConnectionString",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["MySqlLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(MySqlLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'MySql'
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class MySqlLinkedServiceTypeProperties(msrest.serialization.Model):
    """MySQL linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param connection_string: Required. The connection string.
    :type connection_string:
     ~data_factory_management_client.models.MySqlLinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.MySqlLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'MySqlLinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'MySqlLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "MySqlLinkedServiceTypePropertiesConnectionString",
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["MySqlLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(MySqlLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class MySqlLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The connection string.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MySqlLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class MySqlLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MySqlLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class MySqlSource(TabularSource):
    """A copy activity source for MySQL databases.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: Database query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.MySqlSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'MySqlSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["MySqlSourceQuery"] = None,
        **kwargs
    ):
        super(MySqlSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'MySqlSource'
        self.query = query


class MySqlSourceQuery(msrest.serialization.Model):
    """Database query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MySqlSourceQuery, self).__init__(**kwargs)


class MySqlTableDataset(Dataset):
    """The MySQL table dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The MySQL table name. Type: string (or Expression with resultType string).
    :type table_name:
     ~data_factory_management_client.models.MySqlTableDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'MySqlTableDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["MySqlTableDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(MySqlTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MySqlTable'
        self.table_name = table_name


class MySqlTableDatasetTypeProperties(msrest.serialization.Model):
    """MySql table dataset properties.

    :param table_name: The MySQL table name. Type: string (or Expression with resultType string).
    :type table_name:
     ~data_factory_management_client.models.MySqlTableDatasetTypePropertiesTableName
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'MySqlTableDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["MySqlTableDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(MySqlTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name


class MySqlTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """The MySQL table name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(MySqlTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class NetezzaLinkedService(LinkedService):
    """Netezza linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.NetezzaLinkedServiceTypePropertiesConnectionString
    :param pwd: Azure Key Vault secret reference.
    :type pwd: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.NetezzaLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'NetezzaLinkedServiceTypePropertiesConnectionString'},
        'pwd': {'key': 'typeProperties.pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'NetezzaLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        connection_string: Optional["NetezzaLinkedServiceTypePropertiesConnectionString"] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["NetezzaLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(NetezzaLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Netezza'
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class NetezzaLinkedServiceTypeProperties(msrest.serialization.Model):
    """Netezza linked service properties.

    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.NetezzaLinkedServiceTypePropertiesConnectionString
    :param pwd: Azure Key Vault secret reference.
    :type pwd: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.NetezzaLinkedServiceTypePropertiesEncryptedCredential
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'NetezzaLinkedServiceTypePropertiesConnectionString'},
        'pwd': {'key': 'pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'NetezzaLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional["NetezzaLinkedServiceTypePropertiesConnectionString"] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["NetezzaLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(NetezzaLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class NetezzaLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """An ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(NetezzaLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class NetezzaLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(NetezzaLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class NetezzaPartitionSettings(msrest.serialization.Model):
    """The settings that will be leveraged for Netezza source partitioning.

    :param partition_column_name: The name of the column in integer type that will be used for
     proceeding range partitioning. Type: string (or Expression with resultType string).
    :type partition_column_name:
     ~data_factory_management_client.models.NetezzaPartitionSettingsPartitionColumnName
    :param partition_upper_bound: The maximum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :type partition_upper_bound:
     ~data_factory_management_client.models.NetezzaPartitionSettingsPartitionUpperBound
    :param partition_lower_bound: The minimum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :type partition_lower_bound:
     ~data_factory_management_client.models.NetezzaPartitionSettingsPartitionLowerBound
    """

    _attribute_map = {
        'partition_column_name': {'key': 'partitionColumnName', 'type': 'NetezzaPartitionSettingsPartitionColumnName'},
        'partition_upper_bound': {'key': 'partitionUpperBound', 'type': 'NetezzaPartitionSettingsPartitionUpperBound'},
        'partition_lower_bound': {'key': 'partitionLowerBound', 'type': 'NetezzaPartitionSettingsPartitionLowerBound'},
    }

    def __init__(
        self,
        *,
        partition_column_name: Optional["NetezzaPartitionSettingsPartitionColumnName"] = None,
        partition_upper_bound: Optional["NetezzaPartitionSettingsPartitionUpperBound"] = None,
        partition_lower_bound: Optional["NetezzaPartitionSettingsPartitionLowerBound"] = None,
        **kwargs
    ):
        super(NetezzaPartitionSettings, self).__init__(**kwargs)
        self.partition_column_name = partition_column_name
        self.partition_upper_bound = partition_upper_bound
        self.partition_lower_bound = partition_lower_bound


class NetezzaPartitionSettingsPartitionColumnName(msrest.serialization.Model):
    """The name of the column in integer type that will be used for proceeding range partitioning. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(NetezzaPartitionSettingsPartitionColumnName, self).__init__(**kwargs)


class NetezzaPartitionSettingsPartitionLowerBound(msrest.serialization.Model):
    """The minimum value of column specified in partitionColumnName that will be used for proceeding range partitioning. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(NetezzaPartitionSettingsPartitionLowerBound, self).__init__(**kwargs)


class NetezzaPartitionSettingsPartitionUpperBound(msrest.serialization.Model):
    """The maximum value of column specified in partitionColumnName that will be used for proceeding range partitioning. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(NetezzaPartitionSettingsPartitionUpperBound, self).__init__(**kwargs)


class NetezzaSource(TabularSource):
    """A copy activity Netezza source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.NetezzaSourceQuery
    :param partition_option: The partition mechanism that will be used for Netezza read in
     parallel. Possible values include: 'None', 'DataSlice', 'DynamicRange'.
    :type partition_option: str or ~data_factory_management_client.models.NetezzaPartitionOption
    :param partition_settings: The settings that will be leveraged for Netezza source partitioning.
    :type partition_settings: ~data_factory_management_client.models.NetezzaPartitionSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'NetezzaSourceQuery'},
        'partition_option': {'key': 'partitionOption', 'type': 'str'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'NetezzaPartitionSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["NetezzaSourceQuery"] = None,
        partition_option: Optional[Union[str, "NetezzaPartitionOption"]] = None,
        partition_settings: Optional["NetezzaPartitionSettings"] = None,
        **kwargs
    ):
        super(NetezzaSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'NetezzaSource'
        self.query = query
        self.partition_option = partition_option
        self.partition_settings = partition_settings


class NetezzaSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(NetezzaSourceQuery, self).__init__(**kwargs)


class NetezzaTableDataset(Dataset):
    """Netezza dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.NetezzaTableDatasetTypePropertiesTableName
    :param table: The table name of the Netezza. Type: string (or Expression with resultType
     string).
    :type table: ~data_factory_management_client.models.NetezzaTableDatasetTypePropertiesTable
    :param schema_type_properties_schema: The schema name of the Netezza. Type: string (or
     Expression with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.NetezzaTableDatasetTypePropertiesSchema
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'NetezzaTableDatasetTypePropertiesTableName'},
        'table': {'key': 'typeProperties.table', 'type': 'NetezzaTableDatasetTypePropertiesTable'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'NetezzaTableDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["NetezzaTableDatasetTypePropertiesTableName"] = None,
        table: Optional["NetezzaTableDatasetTypePropertiesTable"] = None,
        schema_type_properties_schema: Optional["NetezzaTableDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(NetezzaTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'NetezzaTable'
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class NetezzaTableDatasetTypeProperties(msrest.serialization.Model):
    """Netezza dataset properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.NetezzaTableDatasetTypePropertiesTableName
    :param table: The table name of the Netezza. Type: string (or Expression with resultType
     string).
    :type table: ~data_factory_management_client.models.NetezzaTableDatasetTypePropertiesTable
    :param schema: The schema name of the Netezza. Type: string (or Expression with resultType
     string).
    :type schema: ~data_factory_management_client.models.NetezzaTableDatasetTypePropertiesSchema
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'NetezzaTableDatasetTypePropertiesTableName'},
        'table': {'key': 'table', 'type': 'NetezzaTableDatasetTypePropertiesTable'},
        'schema': {'key': 'schema', 'type': 'NetezzaTableDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["NetezzaTableDatasetTypePropertiesTableName"] = None,
        table: Optional["NetezzaTableDatasetTypePropertiesTable"] = None,
        schema: Optional["NetezzaTableDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(NetezzaTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.table = table
        self.schema = schema


class NetezzaTableDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of the Netezza. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(NetezzaTableDatasetTypePropertiesSchema, self).__init__(**kwargs)


class NetezzaTableDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the Netezza. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(NetezzaTableDatasetTypePropertiesTable, self).__init__(**kwargs)


class NetezzaTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(NetezzaTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class ODataLinkedService(LinkedService):
    """Open Data Protocol (OData) linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param url: Required. The URL of the OData service endpoint. Type: string (or Expression with
     resultType string).
    :type url: ~data_factory_management_client.models.ODataLinkedServiceTypePropertiesUrl
    :param authentication_type: Type of authentication used to connect to the OData service.
     Possible values include: 'Basic', 'Anonymous', 'Windows', 'AadServicePrincipal',
     'ManagedServiceIdentity'.
    :type authentication_type: str or
     ~data_factory_management_client.models.ODataAuthenticationType
    :param user_name: User name of the OData service. Type: string (or Expression with resultType
     string).
    :type user_name:
     ~data_factory_management_client.models.ODataLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param tenant: Specify the tenant information (domain name or tenant ID) under which your
     application resides. Type: string (or Expression with resultType string).
    :type tenant: ~data_factory_management_client.models.ODataLinkedServiceTypePropertiesTenant
    :param service_principal_id: Specify the application id of your application registered in Azure
     Active Directory. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.ODataLinkedServiceTypePropertiesServicePrincipalId
    :param aad_resource_id: Specify the resource you are requesting authorization to use Directory.
     Type: string (or Expression with resultType string).
    :type aad_resource_id:
     ~data_factory_management_client.models.ODataLinkedServiceTypePropertiesAadResourceId
    :param aad_service_principal_credential_type: Specify the credential type (key or cert) is used
     for service principal. Possible values include: 'ServicePrincipalKey', 'ServicePrincipalCert'.
    :type aad_service_principal_credential_type: str or
     ~data_factory_management_client.models.ODataAadServicePrincipalCredentialType
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param service_principal_embedded_cert: The base definition of a secret type.
    :type service_principal_embedded_cert: ~data_factory_management_client.models.SecretBase
    :param service_principal_embedded_cert_password: The base definition of a secret type.
    :type service_principal_embedded_cert_password:
     ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.ODataLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'url': {'key': 'typeProperties.url', 'type': 'ODataLinkedServiceTypePropertiesUrl'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'ODataLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'ODataLinkedServiceTypePropertiesTenant'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'ODataLinkedServiceTypePropertiesServicePrincipalId'},
        'aad_resource_id': {'key': 'typeProperties.aadResourceId', 'type': 'ODataLinkedServiceTypePropertiesAadResourceId'},
        'aad_service_principal_credential_type': {'key': 'typeProperties.aadServicePrincipalCredentialType', 'type': 'str'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'service_principal_embedded_cert': {'key': 'typeProperties.servicePrincipalEmbeddedCert', 'type': 'SecretBase'},
        'service_principal_embedded_cert_password': {'key': 'typeProperties.servicePrincipalEmbeddedCertPassword', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'ODataLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        url: "ODataLinkedServiceTypePropertiesUrl",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        authentication_type: Optional[Union[str, "ODataAuthenticationType"]] = None,
        user_name: Optional["ODataLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        tenant: Optional["ODataLinkedServiceTypePropertiesTenant"] = None,
        service_principal_id: Optional["ODataLinkedServiceTypePropertiesServicePrincipalId"] = None,
        aad_resource_id: Optional["ODataLinkedServiceTypePropertiesAadResourceId"] = None,
        aad_service_principal_credential_type: Optional[Union[str, "ODataAadServicePrincipalCredentialType"]] = None,
        service_principal_key: Optional["SecretBase"] = None,
        service_principal_embedded_cert: Optional["SecretBase"] = None,
        service_principal_embedded_cert_password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["ODataLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(ODataLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'OData'
        self.url = url
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.tenant = tenant
        self.service_principal_id = service_principal_id
        self.aad_resource_id = aad_resource_id
        self.aad_service_principal_credential_type = aad_service_principal_credential_type
        self.service_principal_key = service_principal_key
        self.service_principal_embedded_cert = service_principal_embedded_cert
        self.service_principal_embedded_cert_password = service_principal_embedded_cert_password
        self.encrypted_credential = encrypted_credential


class ODataLinkedServiceTypeProperties(msrest.serialization.Model):
    """OData linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param url: Required. The URL of the OData service endpoint. Type: string (or Expression with
     resultType string).
    :type url: ~data_factory_management_client.models.ODataLinkedServiceTypePropertiesUrl
    :param authentication_type: Type of authentication used to connect to the OData service.
     Possible values include: 'Basic', 'Anonymous', 'Windows', 'AadServicePrincipal',
     'ManagedServiceIdentity'.
    :type authentication_type: str or
     ~data_factory_management_client.models.ODataAuthenticationType
    :param user_name: User name of the OData service. Type: string (or Expression with resultType
     string).
    :type user_name:
     ~data_factory_management_client.models.ODataLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param tenant: Specify the tenant information (domain name or tenant ID) under which your
     application resides. Type: string (or Expression with resultType string).
    :type tenant: ~data_factory_management_client.models.ODataLinkedServiceTypePropertiesTenant
    :param service_principal_id: Specify the application id of your application registered in Azure
     Active Directory. Type: string (or Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.ODataLinkedServiceTypePropertiesServicePrincipalId
    :param aad_resource_id: Specify the resource you are requesting authorization to use Directory.
     Type: string (or Expression with resultType string).
    :type aad_resource_id:
     ~data_factory_management_client.models.ODataLinkedServiceTypePropertiesAadResourceId
    :param aad_service_principal_credential_type: Specify the credential type (key or cert) is used
     for service principal. Possible values include: 'ServicePrincipalKey', 'ServicePrincipalCert'.
    :type aad_service_principal_credential_type: str or
     ~data_factory_management_client.models.ODataAadServicePrincipalCredentialType
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param service_principal_embedded_cert: The base definition of a secret type.
    :type service_principal_embedded_cert: ~data_factory_management_client.models.SecretBase
    :param service_principal_embedded_cert_password: The base definition of a secret type.
    :type service_principal_embedded_cert_password:
     ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.ODataLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'url': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'ODataLinkedServiceTypePropertiesUrl'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'user_name': {'key': 'userName', 'type': 'ODataLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'tenant': {'key': 'tenant', 'type': 'ODataLinkedServiceTypePropertiesTenant'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'ODataLinkedServiceTypePropertiesServicePrincipalId'},
        'aad_resource_id': {'key': 'aadResourceId', 'type': 'ODataLinkedServiceTypePropertiesAadResourceId'},
        'aad_service_principal_credential_type': {'key': 'aadServicePrincipalCredentialType', 'type': 'str'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'service_principal_embedded_cert': {'key': 'servicePrincipalEmbeddedCert', 'type': 'SecretBase'},
        'service_principal_embedded_cert_password': {'key': 'servicePrincipalEmbeddedCertPassword', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'ODataLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        url: "ODataLinkedServiceTypePropertiesUrl",
        authentication_type: Optional[Union[str, "ODataAuthenticationType"]] = None,
        user_name: Optional["ODataLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        tenant: Optional["ODataLinkedServiceTypePropertiesTenant"] = None,
        service_principal_id: Optional["ODataLinkedServiceTypePropertiesServicePrincipalId"] = None,
        aad_resource_id: Optional["ODataLinkedServiceTypePropertiesAadResourceId"] = None,
        aad_service_principal_credential_type: Optional[Union[str, "ODataAadServicePrincipalCredentialType"]] = None,
        service_principal_key: Optional["SecretBase"] = None,
        service_principal_embedded_cert: Optional["SecretBase"] = None,
        service_principal_embedded_cert_password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["ODataLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(ODataLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.url = url
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.tenant = tenant
        self.service_principal_id = service_principal_id
        self.aad_resource_id = aad_resource_id
        self.aad_service_principal_credential_type = aad_service_principal_credential_type
        self.service_principal_key = service_principal_key
        self.service_principal_embedded_cert = service_principal_embedded_cert
        self.service_principal_embedded_cert_password = service_principal_embedded_cert_password
        self.encrypted_credential = encrypted_credential


class ODataLinkedServiceTypePropertiesAadResourceId(msrest.serialization.Model):
    """Specify the resource you are requesting authorization to use Directory. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ODataLinkedServiceTypePropertiesAadResourceId, self).__init__(**kwargs)


class ODataLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ODataLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class ODataLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """Specify the application id of your application registered in Azure Active Directory. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ODataLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class ODataLinkedServiceTypePropertiesTenant(msrest.serialization.Model):
    """Specify the tenant information (domain name or tenant ID) under which your application resides. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ODataLinkedServiceTypePropertiesTenant, self).__init__(**kwargs)


class ODataLinkedServiceTypePropertiesUrl(msrest.serialization.Model):
    """The URL of the OData service endpoint. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ODataLinkedServiceTypePropertiesUrl, self).__init__(**kwargs)


class ODataLinkedServiceTypePropertiesUserName(msrest.serialization.Model):
    """User name of the OData service. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ODataLinkedServiceTypePropertiesUserName, self).__init__(**kwargs)


class ODataResourceDataset(Dataset):
    """The Open Data Protocol (OData) resource dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param path: The OData resource path. Type: string (or Expression with resultType string).
    :type path: ~data_factory_management_client.models.ODataResourceDatasetTypePropertiesPath
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'path': {'key': 'typeProperties.path', 'type': 'ODataResourceDatasetTypePropertiesPath'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        path: Optional["ODataResourceDatasetTypePropertiesPath"] = None,
        **kwargs
    ):
        super(ODataResourceDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'ODataResource'
        self.path = path


class ODataResourceDatasetTypeProperties(msrest.serialization.Model):
    """OData dataset properties.

    :param path: The OData resource path. Type: string (or Expression with resultType string).
    :type path: ~data_factory_management_client.models.ODataResourceDatasetTypePropertiesPath
    """

    _attribute_map = {
        'path': {'key': 'path', 'type': 'ODataResourceDatasetTypePropertiesPath'},
    }

    def __init__(
        self,
        *,
        path: Optional["ODataResourceDatasetTypePropertiesPath"] = None,
        **kwargs
    ):
        super(ODataResourceDatasetTypeProperties, self).__init__(**kwargs)
        self.path = path


class ODataResourceDatasetTypePropertiesPath(msrest.serialization.Model):
    """The OData resource path. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ODataResourceDatasetTypePropertiesPath, self).__init__(**kwargs)


class ODataSource(CopySource):
    """A copy activity source for OData source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query: OData query. For example, "$top=1". Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.ODataSourceQuery
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query': {'key': 'query', 'type': 'ODataSourceQuery'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query: Optional["ODataSourceQuery"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(ODataSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'ODataSource'
        self.query = query
        self.additional_columns = additional_columns


class ODataSourceQuery(msrest.serialization.Model):
    """OData query. For example, "$top=1". Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ODataSourceQuery, self).__init__(**kwargs)


class OdbcLinkedService(LinkedService):
    """Open Database Connectivity (ODBC) linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: Required. The non-access credential portion of the connection string
     as well as an optional encrypted credential. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.OdbcLinkedServiceTypePropertiesConnectionString
    :param authentication_type: Type of authentication used to connect to the ODBC data store.
     Possible values are: Anonymous and Basic. Type: string (or Expression with resultType string).
    :type authentication_type:
     ~data_factory_management_client.models.OdbcLinkedServiceTypePropertiesAuthenticationType
    :param credential: The base definition of a secret type.
    :type credential: ~data_factory_management_client.models.SecretBase
    :param user_name: User name for Basic authentication. Type: string (or Expression with
     resultType string).
    :type user_name: ~data_factory_management_client.models.OdbcLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.OdbcLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'OdbcLinkedServiceTypePropertiesConnectionString'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'OdbcLinkedServiceTypePropertiesAuthenticationType'},
        'credential': {'key': 'typeProperties.credential', 'type': 'SecretBase'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'OdbcLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'OdbcLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "OdbcLinkedServiceTypePropertiesConnectionString",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        authentication_type: Optional["OdbcLinkedServiceTypePropertiesAuthenticationType"] = None,
        credential: Optional["SecretBase"] = None,
        user_name: Optional["OdbcLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["OdbcLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(OdbcLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Odbc'
        self.connection_string = connection_string
        self.authentication_type = authentication_type
        self.credential = credential
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class OdbcLinkedServiceTypeProperties(msrest.serialization.Model):
    """ODBC linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param connection_string: Required. The non-access credential portion of the connection string
     as well as an optional encrypted credential. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.OdbcLinkedServiceTypePropertiesConnectionString
    :param authentication_type: Type of authentication used to connect to the ODBC data store.
     Possible values are: Anonymous and Basic. Type: string (or Expression with resultType string).
    :type authentication_type:
     ~data_factory_management_client.models.OdbcLinkedServiceTypePropertiesAuthenticationType
    :param credential: The base definition of a secret type.
    :type credential: ~data_factory_management_client.models.SecretBase
    :param user_name: User name for Basic authentication. Type: string (or Expression with
     resultType string).
    :type user_name: ~data_factory_management_client.models.OdbcLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.OdbcLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'OdbcLinkedServiceTypePropertiesConnectionString'},
        'authentication_type': {'key': 'authenticationType', 'type': 'OdbcLinkedServiceTypePropertiesAuthenticationType'},
        'credential': {'key': 'credential', 'type': 'SecretBase'},
        'user_name': {'key': 'userName', 'type': 'OdbcLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'OdbcLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "OdbcLinkedServiceTypePropertiesConnectionString",
        authentication_type: Optional["OdbcLinkedServiceTypePropertiesAuthenticationType"] = None,
        credential: Optional["SecretBase"] = None,
        user_name: Optional["OdbcLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["OdbcLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(OdbcLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.authentication_type = authentication_type
        self.credential = credential
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class OdbcLinkedServiceTypePropertiesAuthenticationType(msrest.serialization.Model):
    """Type of authentication used to connect to the ODBC data store. Possible values are: Anonymous and Basic. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OdbcLinkedServiceTypePropertiesAuthenticationType, self).__init__(**kwargs)


class OdbcLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The non-access credential portion of the connection string as well as an optional encrypted credential. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OdbcLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class OdbcLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OdbcLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class OdbcLinkedServiceTypePropertiesUserName(msrest.serialization.Model):
    """User name for Basic authentication. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OdbcLinkedServiceTypePropertiesUserName, self).__init__(**kwargs)


class OdbcSink(CopySink):
    """A copy activity ODBC sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param pre_copy_script: A query to execute before starting the copy. Type: string (or
     Expression with resultType string).
    :type pre_copy_script: ~data_factory_management_client.models.OdbcSinkPreCopyScript
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'OdbcSinkPreCopyScript'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        pre_copy_script: Optional["OdbcSinkPreCopyScript"] = None,
        **kwargs
    ):
        super(OdbcSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'OdbcSink'
        self.pre_copy_script = pre_copy_script


class OdbcSinkPreCopyScript(msrest.serialization.Model):
    """A query to execute before starting the copy. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OdbcSinkPreCopyScript, self).__init__(**kwargs)


class OdbcSource(TabularSource):
    """A copy activity source for ODBC databases.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: Database query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.OdbcSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'OdbcSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["OdbcSourceQuery"] = None,
        **kwargs
    ):
        super(OdbcSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'OdbcSource'
        self.query = query


class OdbcSourceQuery(msrest.serialization.Model):
    """Database query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OdbcSourceQuery, self).__init__(**kwargs)


class OdbcTableDataset(Dataset):
    """The ODBC table dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The ODBC table name. Type: string (or Expression with resultType string).
    :type table_name:
     ~data_factory_management_client.models.OdbcTableDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'OdbcTableDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["OdbcTableDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(OdbcTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'OdbcTable'
        self.table_name = table_name


class OdbcTableDatasetTypeProperties(msrest.serialization.Model):
    """ODBC table dataset properties.

    :param table_name: The ODBC table name. Type: string (or Expression with resultType string).
    :type table_name:
     ~data_factory_management_client.models.OdbcTableDatasetTypePropertiesTableName
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'OdbcTableDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["OdbcTableDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(OdbcTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name


class OdbcTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """The ODBC table name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OdbcTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class Office365Dataset(Dataset):
    """The Office365 account.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: Required. Name of the dataset to extract from Office 365. Type: string (or
     Expression with resultType string).
    :type table_name:
     ~data_factory_management_client.models.Office365DatasetTypePropertiesTableName
    :param predicate: A predicate expression that can be used to filter the specific rows to
     extract from Office 365. Type: string (or Expression with resultType string).
    :type predicate: ~data_factory_management_client.models.Office365DatasetTypePropertiesPredicate
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'table_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'Office365DatasetTypePropertiesTableName'},
        'predicate': {'key': 'typeProperties.predicate', 'type': 'Office365DatasetTypePropertiesPredicate'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        table_name: "Office365DatasetTypePropertiesTableName",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        predicate: Optional["Office365DatasetTypePropertiesPredicate"] = None,
        **kwargs
    ):
        super(Office365Dataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Office365Table'
        self.table_name = table_name
        self.predicate = predicate


class Office365DatasetTypeProperties(msrest.serialization.Model):
    """Office365 dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param table_name: Required. Name of the dataset to extract from Office 365. Type: string (or
     Expression with resultType string).
    :type table_name:
     ~data_factory_management_client.models.Office365DatasetTypePropertiesTableName
    :param predicate: A predicate expression that can be used to filter the specific rows to
     extract from Office 365. Type: string (or Expression with resultType string).
    :type predicate: ~data_factory_management_client.models.Office365DatasetTypePropertiesPredicate
    """

    _validation = {
        'table_name': {'required': True},
    }

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'Office365DatasetTypePropertiesTableName'},
        'predicate': {'key': 'predicate', 'type': 'Office365DatasetTypePropertiesPredicate'},
    }

    def __init__(
        self,
        *,
        table_name: "Office365DatasetTypePropertiesTableName",
        predicate: Optional["Office365DatasetTypePropertiesPredicate"] = None,
        **kwargs
    ):
        super(Office365DatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.predicate = predicate


class Office365DatasetTypePropertiesPredicate(msrest.serialization.Model):
    """A predicate expression that can be used to filter the specific rows to extract from Office 365. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Office365DatasetTypePropertiesPredicate, self).__init__(**kwargs)


class Office365DatasetTypePropertiesTableName(msrest.serialization.Model):
    """Name of the dataset to extract from Office 365. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Office365DatasetTypePropertiesTableName, self).__init__(**kwargs)


class Office365LinkedService(LinkedService):
    """Office365 linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param office365_tenant_id: Required. Azure tenant ID to which the Office 365 account belongs.
     Type: string (or Expression with resultType string).
    :type office365_tenant_id:
     ~data_factory_management_client.models.Office365LinkedServiceTypePropertiesOffice365TenantId
    :param service_principal_tenant_id: Required. Specify the tenant information under which your
     Azure AD web application resides. Type: string (or Expression with resultType string).
    :type service_principal_tenant_id:
     ~data_factory_management_client.models.Office365LinkedServiceTypePropertiesServicePrincipalTenantId
    :param service_principal_id: Required. Specify the application's client ID. Type: string (or
     Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.Office365LinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: Required. The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.Office365LinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'office365_tenant_id': {'required': True},
        'service_principal_tenant_id': {'required': True},
        'service_principal_id': {'required': True},
        'service_principal_key': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'office365_tenant_id': {'key': 'typeProperties.office365TenantId', 'type': 'Office365LinkedServiceTypePropertiesOffice365TenantId'},
        'service_principal_tenant_id': {'key': 'typeProperties.servicePrincipalTenantId', 'type': 'Office365LinkedServiceTypePropertiesServicePrincipalTenantId'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'Office365LinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'Office365LinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        office365_tenant_id: "Office365LinkedServiceTypePropertiesOffice365TenantId",
        service_principal_tenant_id: "Office365LinkedServiceTypePropertiesServicePrincipalTenantId",
        service_principal_id: "Office365LinkedServiceTypePropertiesServicePrincipalId",
        service_principal_key: "SecretBase",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        encrypted_credential: Optional["Office365LinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(Office365LinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Office365'
        self.office365_tenant_id = office365_tenant_id
        self.service_principal_tenant_id = service_principal_tenant_id
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.encrypted_credential = encrypted_credential


class Office365LinkedServiceTypeProperties(msrest.serialization.Model):
    """Office365 linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param office365_tenant_id: Required. Azure tenant ID to which the Office 365 account belongs.
     Type: string (or Expression with resultType string).
    :type office365_tenant_id:
     ~data_factory_management_client.models.Office365LinkedServiceTypePropertiesOffice365TenantId
    :param service_principal_tenant_id: Required. Specify the tenant information under which your
     Azure AD web application resides. Type: string (or Expression with resultType string).
    :type service_principal_tenant_id:
     ~data_factory_management_client.models.Office365LinkedServiceTypePropertiesServicePrincipalTenantId
    :param service_principal_id: Required. Specify the application's client ID. Type: string (or
     Expression with resultType string).
    :type service_principal_id:
     ~data_factory_management_client.models.Office365LinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: Required. The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.Office365LinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'office365_tenant_id': {'required': True},
        'service_principal_tenant_id': {'required': True},
        'service_principal_id': {'required': True},
        'service_principal_key': {'required': True},
    }

    _attribute_map = {
        'office365_tenant_id': {'key': 'office365TenantId', 'type': 'Office365LinkedServiceTypePropertiesOffice365TenantId'},
        'service_principal_tenant_id': {'key': 'servicePrincipalTenantId', 'type': 'Office365LinkedServiceTypePropertiesServicePrincipalTenantId'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'Office365LinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'Office365LinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        office365_tenant_id: "Office365LinkedServiceTypePropertiesOffice365TenantId",
        service_principal_tenant_id: "Office365LinkedServiceTypePropertiesServicePrincipalTenantId",
        service_principal_id: "Office365LinkedServiceTypePropertiesServicePrincipalId",
        service_principal_key: "SecretBase",
        encrypted_credential: Optional["Office365LinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(Office365LinkedServiceTypeProperties, self).__init__(**kwargs)
        self.office365_tenant_id = office365_tenant_id
        self.service_principal_tenant_id = service_principal_tenant_id
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.encrypted_credential = encrypted_credential


class Office365LinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Office365LinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class Office365LinkedServiceTypePropertiesOffice365TenantId(msrest.serialization.Model):
    """Azure tenant ID to which the Office 365 account belongs. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Office365LinkedServiceTypePropertiesOffice365TenantId, self).__init__(**kwargs)


class Office365LinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """Specify the application's client ID. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Office365LinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class Office365LinkedServiceTypePropertiesServicePrincipalTenantId(msrest.serialization.Model):
    """Specify the tenant information under which your Azure AD web application resides. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Office365LinkedServiceTypePropertiesServicePrincipalTenantId, self).__init__(**kwargs)


class Office365Source(CopySource):
    """A copy activity source for an Office 365 service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param allowed_groups: The groups containing all the users. Type: array of strings (or
     Expression with resultType array of strings).
    :type allowed_groups: ~data_factory_management_client.models.Office365SourceAllowedGroups
    :param user_scope_filter_uri: The user scope uri. Type: string (or Expression with resultType
     string).
    :type user_scope_filter_uri:
     ~data_factory_management_client.models.Office365SourceUserScopeFilterUri
    :param date_filter_column: The Column to apply the :code:`<paramref name="StartTime"/>` and
     :code:`<paramref name="EndTime"/>`. Type: string (or Expression with resultType string).
    :type date_filter_column:
     ~data_factory_management_client.models.Office365SourceDateFilterColumn
    :param start_time: Start time of the requested range for this dataset. Type: string (or
     Expression with resultType string).
    :type start_time: ~data_factory_management_client.models.Office365SourceStartTime
    :param end_time: End time of the requested range for this dataset. Type: string (or Expression
     with resultType string).
    :type end_time: ~data_factory_management_client.models.Office365SourceEndTime
    :param output_columns: The columns to be read out from the Office 365 table. Type: array of
     objects (or Expression with resultType array of objects). Example: [ { "name": "Id" }, {
     "name": "CreatedDateTime" } ].
    :type output_columns: ~data_factory_management_client.models.Office365SourceOutputColumns
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'allowed_groups': {'key': 'allowedGroups', 'type': 'Office365SourceAllowedGroups'},
        'user_scope_filter_uri': {'key': 'userScopeFilterUri', 'type': 'Office365SourceUserScopeFilterUri'},
        'date_filter_column': {'key': 'dateFilterColumn', 'type': 'Office365SourceDateFilterColumn'},
        'start_time': {'key': 'startTime', 'type': 'Office365SourceStartTime'},
        'end_time': {'key': 'endTime', 'type': 'Office365SourceEndTime'},
        'output_columns': {'key': 'outputColumns', 'type': 'Office365SourceOutputColumns'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        allowed_groups: Optional["Office365SourceAllowedGroups"] = None,
        user_scope_filter_uri: Optional["Office365SourceUserScopeFilterUri"] = None,
        date_filter_column: Optional["Office365SourceDateFilterColumn"] = None,
        start_time: Optional["Office365SourceStartTime"] = None,
        end_time: Optional["Office365SourceEndTime"] = None,
        output_columns: Optional["Office365SourceOutputColumns"] = None,
        **kwargs
    ):
        super(Office365Source, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'Office365Source'
        self.allowed_groups = allowed_groups
        self.user_scope_filter_uri = user_scope_filter_uri
        self.date_filter_column = date_filter_column
        self.start_time = start_time
        self.end_time = end_time
        self.output_columns = output_columns


class Office365SourceAllowedGroups(msrest.serialization.Model):
    """The groups containing all the users. Type: array of strings (or Expression with resultType array of strings).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Office365SourceAllowedGroups, self).__init__(**kwargs)


class Office365SourceDateFilterColumn(msrest.serialization.Model):
    """The Column to apply the :code:`<paramref name="StartTime"/>` and :code:`<paramref name="EndTime"/>`. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Office365SourceDateFilterColumn, self).__init__(**kwargs)


class Office365SourceEndTime(msrest.serialization.Model):
    """End time of the requested range for this dataset. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Office365SourceEndTime, self).__init__(**kwargs)


class Office365SourceOutputColumns(msrest.serialization.Model):
    """The columns to be read out from the Office 365 table. Type: array of objects (or Expression with resultType array of objects). Example: [ { "name": "Id" }, { "name": "CreatedDateTime" } ].

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Office365SourceOutputColumns, self).__init__(**kwargs)


class Office365SourceStartTime(msrest.serialization.Model):
    """Start time of the requested range for this dataset. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Office365SourceStartTime, self).__init__(**kwargs)


class Office365SourceUserScopeFilterUri(msrest.serialization.Model):
    """The user scope uri. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(Office365SourceUserScopeFilterUri, self).__init__(**kwargs)


class Operation(msrest.serialization.Model):
    """Azure Data Factory API operation definition.

    :param name: Operation name: {provider}/{resource}/{operation}.
    :type name: str
    :param origin: The intended executor of the operation.
    :type origin: str
    :param display: Metadata associated with the operation.
    :type display: ~data_factory_management_client.models.OperationDisplay
    :param service_specification: Details about a service operation.
    :type service_specification:
     ~data_factory_management_client.models.OperationServiceSpecification
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'origin': {'key': 'origin', 'type': 'str'},
        'display': {'key': 'display', 'type': 'OperationDisplay'},
        'service_specification': {'key': 'properties.serviceSpecification', 'type': 'OperationServiceSpecification'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        origin: Optional[str] = None,
        display: Optional["OperationDisplay"] = None,
        service_specification: Optional["OperationServiceSpecification"] = None,
        **kwargs
    ):
        super(Operation, self).__init__(**kwargs)
        self.name = name
        self.origin = origin
        self.display = display
        self.service_specification = service_specification


class OperationDisplay(msrest.serialization.Model):
    """Metadata associated with the operation.

    :param description: The description of the operation.
    :type description: str
    :param provider: The name of the provider.
    :type provider: str
    :param resource: The name of the resource type on which the operation is performed.
    :type resource: str
    :param operation: The type of operation: get, read, delete, etc.
    :type operation: str
    """

    _attribute_map = {
        'description': {'key': 'description', 'type': 'str'},
        'provider': {'key': 'provider', 'type': 'str'},
        'resource': {'key': 'resource', 'type': 'str'},
        'operation': {'key': 'operation', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        description: Optional[str] = None,
        provider: Optional[str] = None,
        resource: Optional[str] = None,
        operation: Optional[str] = None,
        **kwargs
    ):
        super(OperationDisplay, self).__init__(**kwargs)
        self.description = description
        self.provider = provider
        self.resource = resource
        self.operation = operation


class OperationListResponse(msrest.serialization.Model):
    """A list of operations that can be performed by the Data Factory service.

    :param value: List of Data Factory operations supported by the Data Factory resource provider.
    :type value: list[~data_factory_management_client.models.Operation]
    :param next_link: The link to the next page of results, if any remaining results exist.
    :type next_link: str
    """

    _attribute_map = {
        'value': {'key': 'value', 'type': '[Operation]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: Optional[List["Operation"]] = None,
        next_link: Optional[str] = None,
        **kwargs
    ):
        super(OperationListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class OperationLogSpecification(msrest.serialization.Model):
    """Details about an operation related to logs.

    :param name: The name of the log category.
    :type name: str
    :param display_name: Localized display name.
    :type display_name: str
    :param blob_duration: Blobs created in the customer storage account, per hour.
    :type blob_duration: str
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'display_name': {'key': 'displayName', 'type': 'str'},
        'blob_duration': {'key': 'blobDuration', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        display_name: Optional[str] = None,
        blob_duration: Optional[str] = None,
        **kwargs
    ):
        super(OperationLogSpecification, self).__init__(**kwargs)
        self.name = name
        self.display_name = display_name
        self.blob_duration = blob_duration


class OperationMetricAvailability(msrest.serialization.Model):
    """Defines how often data for a metric becomes available.

    :param time_grain: The granularity for the metric.
    :type time_grain: str
    :param blob_duration: Blob created in the customer storage account, per hour.
    :type blob_duration: str
    """

    _attribute_map = {
        'time_grain': {'key': 'timeGrain', 'type': 'str'},
        'blob_duration': {'key': 'blobDuration', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        time_grain: Optional[str] = None,
        blob_duration: Optional[str] = None,
        **kwargs
    ):
        super(OperationMetricAvailability, self).__init__(**kwargs)
        self.time_grain = time_grain
        self.blob_duration = blob_duration


class OperationMetricDimension(msrest.serialization.Model):
    """Defines the metric dimension.

    :param name: The name of the dimension for the metric.
    :type name: str
    :param display_name: The display name of the metric dimension.
    :type display_name: str
    :param to_be_exported_for_shoebox: Whether the dimension should be exported to Azure Monitor.
    :type to_be_exported_for_shoebox: bool
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'display_name': {'key': 'displayName', 'type': 'str'},
        'to_be_exported_for_shoebox': {'key': 'toBeExportedForShoebox', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        display_name: Optional[str] = None,
        to_be_exported_for_shoebox: Optional[bool] = None,
        **kwargs
    ):
        super(OperationMetricDimension, self).__init__(**kwargs)
        self.name = name
        self.display_name = display_name
        self.to_be_exported_for_shoebox = to_be_exported_for_shoebox


class OperationMetricSpecification(msrest.serialization.Model):
    """Details about an operation related to metrics.

    :param name: The name of the metric.
    :type name: str
    :param display_name: Localized display name of the metric.
    :type display_name: str
    :param display_description: The description of the metric.
    :type display_description: str
    :param unit: The unit that the metric is measured in.
    :type unit: str
    :param aggregation_type: The type of metric aggregation.
    :type aggregation_type: str
    :param enable_regional_mdm_account: Whether or not the service is using regional MDM accounts.
    :type enable_regional_mdm_account: str
    :param source_mdm_account: The name of the MDM account.
    :type source_mdm_account: str
    :param source_mdm_namespace: The name of the MDM namespace.
    :type source_mdm_namespace: str
    :param availabilities: Defines how often data for metrics becomes available.
    :type availabilities: list[~data_factory_management_client.models.OperationMetricAvailability]
    :param dimensions: Defines the metric dimension.
    :type dimensions: list[~data_factory_management_client.models.OperationMetricDimension]
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'display_name': {'key': 'displayName', 'type': 'str'},
        'display_description': {'key': 'displayDescription', 'type': 'str'},
        'unit': {'key': 'unit', 'type': 'str'},
        'aggregation_type': {'key': 'aggregationType', 'type': 'str'},
        'enable_regional_mdm_account': {'key': 'enableRegionalMdmAccount', 'type': 'str'},
        'source_mdm_account': {'key': 'sourceMdmAccount', 'type': 'str'},
        'source_mdm_namespace': {'key': 'sourceMdmNamespace', 'type': 'str'},
        'availabilities': {'key': 'availabilities', 'type': '[OperationMetricAvailability]'},
        'dimensions': {'key': 'dimensions', 'type': '[OperationMetricDimension]'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        display_name: Optional[str] = None,
        display_description: Optional[str] = None,
        unit: Optional[str] = None,
        aggregation_type: Optional[str] = None,
        enable_regional_mdm_account: Optional[str] = None,
        source_mdm_account: Optional[str] = None,
        source_mdm_namespace: Optional[str] = None,
        availabilities: Optional[List["OperationMetricAvailability"]] = None,
        dimensions: Optional[List["OperationMetricDimension"]] = None,
        **kwargs
    ):
        super(OperationMetricSpecification, self).__init__(**kwargs)
        self.name = name
        self.display_name = display_name
        self.display_description = display_description
        self.unit = unit
        self.aggregation_type = aggregation_type
        self.enable_regional_mdm_account = enable_regional_mdm_account
        self.source_mdm_account = source_mdm_account
        self.source_mdm_namespace = source_mdm_namespace
        self.availabilities = availabilities
        self.dimensions = dimensions


class OperationProperties(msrest.serialization.Model):
    """Additional details about an operation.

    :param service_specification: Details about a service operation.
    :type service_specification:
     ~data_factory_management_client.models.OperationServiceSpecification
    """

    _attribute_map = {
        'service_specification': {'key': 'serviceSpecification', 'type': 'OperationServiceSpecification'},
    }

    def __init__(
        self,
        *,
        service_specification: Optional["OperationServiceSpecification"] = None,
        **kwargs
    ):
        super(OperationProperties, self).__init__(**kwargs)
        self.service_specification = service_specification


class OperationServiceSpecification(msrest.serialization.Model):
    """Details about a service operation.

    :param log_specifications: Details about operations related to logs.
    :type log_specifications:
     list[~data_factory_management_client.models.OperationLogSpecification]
    :param metric_specifications: Details about operations related to metrics.
    :type metric_specifications:
     list[~data_factory_management_client.models.OperationMetricSpecification]
    """

    _attribute_map = {
        'log_specifications': {'key': 'logSpecifications', 'type': '[OperationLogSpecification]'},
        'metric_specifications': {'key': 'metricSpecifications', 'type': '[OperationMetricSpecification]'},
    }

    def __init__(
        self,
        *,
        log_specifications: Optional[List["OperationLogSpecification"]] = None,
        metric_specifications: Optional[List["OperationMetricSpecification"]] = None,
        **kwargs
    ):
        super(OperationServiceSpecification, self).__init__(**kwargs)
        self.log_specifications = log_specifications
        self.metric_specifications = metric_specifications


class OracleLinkedService(LinkedService):
    """Oracle database.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.OracleLinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.OracleLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'OracleLinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'OracleLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "OracleLinkedServiceTypePropertiesConnectionString",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["OracleLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(OracleLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Oracle'
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class OracleLinkedServiceTypeProperties(msrest.serialization.Model):
    """Oracle database linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.OracleLinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.OracleLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'OracleLinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'OracleLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "OracleLinkedServiceTypePropertiesConnectionString",
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["OracleLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(OracleLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class OracleLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OracleLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class OracleLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OracleLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class OraclePartitionSettings(msrest.serialization.Model):
    """The settings that will be leveraged for Oracle source partitioning.

    :param partition_names: Names of the physical partitions of Oracle table.
    :type partition_names:
     ~data_factory_management_client.models.OraclePartitionSettingsPartitionNames
    :param partition_column_name: The name of the column in integer type that will be used for
     proceeding range partitioning. Type: string (or Expression with resultType string).
    :type partition_column_name:
     ~data_factory_management_client.models.OraclePartitionSettingsPartitionColumnName
    :param partition_upper_bound: The maximum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :type partition_upper_bound:
     ~data_factory_management_client.models.OraclePartitionSettingsPartitionUpperBound
    :param partition_lower_bound: The minimum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :type partition_lower_bound:
     ~data_factory_management_client.models.OraclePartitionSettingsPartitionLowerBound
    """

    _attribute_map = {
        'partition_names': {'key': 'partitionNames', 'type': 'OraclePartitionSettingsPartitionNames'},
        'partition_column_name': {'key': 'partitionColumnName', 'type': 'OraclePartitionSettingsPartitionColumnName'},
        'partition_upper_bound': {'key': 'partitionUpperBound', 'type': 'OraclePartitionSettingsPartitionUpperBound'},
        'partition_lower_bound': {'key': 'partitionLowerBound', 'type': 'OraclePartitionSettingsPartitionLowerBound'},
    }

    def __init__(
        self,
        *,
        partition_names: Optional["OraclePartitionSettingsPartitionNames"] = None,
        partition_column_name: Optional["OraclePartitionSettingsPartitionColumnName"] = None,
        partition_upper_bound: Optional["OraclePartitionSettingsPartitionUpperBound"] = None,
        partition_lower_bound: Optional["OraclePartitionSettingsPartitionLowerBound"] = None,
        **kwargs
    ):
        super(OraclePartitionSettings, self).__init__(**kwargs)
        self.partition_names = partition_names
        self.partition_column_name = partition_column_name
        self.partition_upper_bound = partition_upper_bound
        self.partition_lower_bound = partition_lower_bound


class OraclePartitionSettingsPartitionColumnName(msrest.serialization.Model):
    """The name of the column in integer type that will be used for proceeding range partitioning. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OraclePartitionSettingsPartitionColumnName, self).__init__(**kwargs)


class OraclePartitionSettingsPartitionLowerBound(msrest.serialization.Model):
    """The minimum value of column specified in partitionColumnName that will be used for proceeding range partitioning. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OraclePartitionSettingsPartitionLowerBound, self).__init__(**kwargs)


class OraclePartitionSettingsPartitionNames(msrest.serialization.Model):
    """Names of the physical partitions of Oracle table.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OraclePartitionSettingsPartitionNames, self).__init__(**kwargs)


class OraclePartitionSettingsPartitionUpperBound(msrest.serialization.Model):
    """The maximum value of column specified in partitionColumnName that will be used for proceeding range partitioning. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OraclePartitionSettingsPartitionUpperBound, self).__init__(**kwargs)


class OracleServiceCloudLinkedService(LinkedService):
    """Oracle Service Cloud linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. The URL of the Oracle Service Cloud instance.
    :type host:
     ~data_factory_management_client.models.OracleServiceCloudLinkedServiceTypePropertiesHost
    :param username: Required. The user name that you use to access Oracle Service Cloud server.
    :type username:
     ~data_factory_management_client.models.OracleServiceCloudLinkedServiceTypePropertiesUsername
    :param password: Required. The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true. Type: boolean (or Expression with resultType boolean).
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.OracleServiceCloudLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true. Type: boolean (or Expression with resultType boolean).
    :type use_host_verification:
     ~data_factory_management_client.models.OracleServiceCloudLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true. Type: boolean (or Expression with resultType
     boolean).
    :type use_peer_verification:
     ~data_factory_management_client.models.OracleServiceCloudLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.OracleServiceCloudLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'username': {'required': True},
        'password': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'OracleServiceCloudLinkedServiceTypePropertiesHost'},
        'username': {'key': 'typeProperties.username', 'type': 'OracleServiceCloudLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'OracleServiceCloudLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'OracleServiceCloudLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'OracleServiceCloudLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'OracleServiceCloudLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "OracleServiceCloudLinkedServiceTypePropertiesHost",
        username: "OracleServiceCloudLinkedServiceTypePropertiesUsername",
        password: "SecretBase",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        use_encrypted_endpoints: Optional["OracleServiceCloudLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["OracleServiceCloudLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["OracleServiceCloudLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["OracleServiceCloudLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(OracleServiceCloudLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'OracleServiceCloud'
        self.host = host
        self.username = username
        self.password = password
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class OracleServiceCloudLinkedServiceTypeProperties(msrest.serialization.Model):
    """Oracle Service Cloud linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. The URL of the Oracle Service Cloud instance.
    :type host:
     ~data_factory_management_client.models.OracleServiceCloudLinkedServiceTypePropertiesHost
    :param username: Required. The user name that you use to access Oracle Service Cloud server.
    :type username:
     ~data_factory_management_client.models.OracleServiceCloudLinkedServiceTypePropertiesUsername
    :param password: Required. The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true. Type: boolean (or Expression with resultType boolean).
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.OracleServiceCloudLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true. Type: boolean (or Expression with resultType boolean).
    :type use_host_verification:
     ~data_factory_management_client.models.OracleServiceCloudLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true. Type: boolean (or Expression with resultType
     boolean).
    :type use_peer_verification:
     ~data_factory_management_client.models.OracleServiceCloudLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.OracleServiceCloudLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
        'username': {'required': True},
        'password': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'OracleServiceCloudLinkedServiceTypePropertiesHost'},
        'username': {'key': 'username', 'type': 'OracleServiceCloudLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'OracleServiceCloudLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'OracleServiceCloudLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'OracleServiceCloudLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'OracleServiceCloudLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "OracleServiceCloudLinkedServiceTypePropertiesHost",
        username: "OracleServiceCloudLinkedServiceTypePropertiesUsername",
        password: "SecretBase",
        use_encrypted_endpoints: Optional["OracleServiceCloudLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["OracleServiceCloudLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["OracleServiceCloudLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["OracleServiceCloudLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(OracleServiceCloudLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.username = username
        self.password = password
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class OracleServiceCloudLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OracleServiceCloudLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class OracleServiceCloudLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """The URL of the Oracle Service Cloud instance.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OracleServiceCloudLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class OracleServiceCloudLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OracleServiceCloudLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class OracleServiceCloudLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OracleServiceCloudLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class OracleServiceCloudLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OracleServiceCloudLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class OracleServiceCloudLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """The user name that you use to access Oracle Service Cloud server.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OracleServiceCloudLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class OracleServiceCloudObjectDataset(Dataset):
    """Oracle Service Cloud dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(OracleServiceCloudObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'OracleServiceCloudObject'
        self.table_name = table_name


class OracleServiceCloudSource(TabularSource):
    """A copy activity Oracle Service Cloud source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.OracleServiceCloudSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'OracleServiceCloudSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["OracleServiceCloudSourceQuery"] = None,
        **kwargs
    ):
        super(OracleServiceCloudSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'OracleServiceCloudSource'
        self.query = query


class OracleServiceCloudSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OracleServiceCloudSourceQuery, self).__init__(**kwargs)


class OracleSink(CopySink):
    """A copy activity Oracle sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
     string).
    :type pre_copy_script: ~data_factory_management_client.models.OracleSinkPreCopyScript
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'OracleSinkPreCopyScript'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        pre_copy_script: Optional["OracleSinkPreCopyScript"] = None,
        **kwargs
    ):
        super(OracleSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'OracleSink'
        self.pre_copy_script = pre_copy_script


class OracleSinkPreCopyScript(msrest.serialization.Model):
    """SQL pre-copy script. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OracleSinkPreCopyScript, self).__init__(**kwargs)


class OracleSource(CopySource):
    """A copy activity Oracle source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param oracle_reader_query: Oracle reader query. Type: string (or Expression with resultType
     string).
    :type oracle_reader_query: ~data_factory_management_client.models.OracleSourceOracleReaderQuery
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.OracleSourceQueryTimeout
    :param partition_option: The partition mechanism that will be used for Oracle read in parallel.
     Possible values include: 'None', 'PhysicalPartitionsOfTable', 'DynamicRange'.
    :type partition_option: str or ~data_factory_management_client.models.OraclePartitionOption
    :param partition_settings: The settings that will be leveraged for Oracle source partitioning.
    :type partition_settings: ~data_factory_management_client.models.OraclePartitionSettings
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'oracle_reader_query': {'key': 'oracleReaderQuery', 'type': 'OracleSourceOracleReaderQuery'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'OracleSourceQueryTimeout'},
        'partition_option': {'key': 'partitionOption', 'type': 'str'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'OraclePartitionSettings'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        oracle_reader_query: Optional["OracleSourceOracleReaderQuery"] = None,
        query_timeout: Optional["OracleSourceQueryTimeout"] = None,
        partition_option: Optional[Union[str, "OraclePartitionOption"]] = None,
        partition_settings: Optional["OraclePartitionSettings"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(OracleSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'OracleSource'
        self.oracle_reader_query = oracle_reader_query
        self.query_timeout = query_timeout
        self.partition_option = partition_option
        self.partition_settings = partition_settings
        self.additional_columns = additional_columns


class OracleSourceOracleReaderQuery(msrest.serialization.Model):
    """Oracle reader query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OracleSourceOracleReaderQuery, self).__init__(**kwargs)


class OracleSourceQueryTimeout(msrest.serialization.Model):
    """Query timeout. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OracleSourceQueryTimeout, self).__init__(**kwargs)


class OracleTableDataset(Dataset):
    """The on-premises Oracle database dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.OracleTableDatasetTypePropertiesTableName
    :param schema_type_properties_schema: The schema name of the on-premises Oracle database. Type:
     string (or Expression with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.OracleTableDatasetTypePropertiesSchema
    :param table: The table name of the on-premises Oracle database. Type: string (or Expression
     with resultType string).
    :type table: ~data_factory_management_client.models.OracleTableDatasetTypePropertiesTable
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'OracleTableDatasetTypePropertiesTableName'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'OracleTableDatasetTypePropertiesSchema'},
        'table': {'key': 'typeProperties.table', 'type': 'OracleTableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["OracleTableDatasetTypePropertiesTableName"] = None,
        schema_type_properties_schema: Optional["OracleTableDatasetTypePropertiesSchema"] = None,
        table: Optional["OracleTableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(OracleTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'OracleTable'
        self.table_name = table_name
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class OracleTableDatasetTypeProperties(msrest.serialization.Model):
    """On-premises Oracle dataset properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.OracleTableDatasetTypePropertiesTableName
    :param schema: The schema name of the on-premises Oracle database. Type: string (or Expression
     with resultType string).
    :type schema: ~data_factory_management_client.models.OracleTableDatasetTypePropertiesSchema
    :param table: The table name of the on-premises Oracle database. Type: string (or Expression
     with resultType string).
    :type table: ~data_factory_management_client.models.OracleTableDatasetTypePropertiesTable
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'OracleTableDatasetTypePropertiesTableName'},
        'schema': {'key': 'schema', 'type': 'OracleTableDatasetTypePropertiesSchema'},
        'table': {'key': 'table', 'type': 'OracleTableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["OracleTableDatasetTypePropertiesTableName"] = None,
        schema: Optional["OracleTableDatasetTypePropertiesSchema"] = None,
        table: Optional["OracleTableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(OracleTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.schema = schema
        self.table = table


class OracleTableDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of the on-premises Oracle database. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OracleTableDatasetTypePropertiesSchema, self).__init__(**kwargs)


class OracleTableDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the on-premises Oracle database. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OracleTableDatasetTypePropertiesTable, self).__init__(**kwargs)


class OracleTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(OracleTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class OrcDataset(Dataset):
    """ORC dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param location: Dataset location.
    :type location: ~data_factory_management_client.models.DatasetLocation
    :param orc_compression_codec:  Possible values include: 'none', 'zlib', 'snappy'.
    :type orc_compression_codec: str or ~data_factory_management_client.models.OrcCompressionCodec
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'location': {'key': 'typeProperties.location', 'type': 'DatasetLocation'},
        'orc_compression_codec': {'key': 'typeProperties.orcCompressionCodec', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        location: Optional["DatasetLocation"] = None,
        orc_compression_codec: Optional[Union[str, "OrcCompressionCodec"]] = None,
        **kwargs
    ):
        super(OrcDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Orc'
        self.location = location
        self.orc_compression_codec = orc_compression_codec


class OrcDatasetTypeProperties(msrest.serialization.Model):
    """ORC dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param location: Required. Dataset location.
    :type location: ~data_factory_management_client.models.DatasetLocation
    :param orc_compression_codec:  Possible values include: 'none', 'zlib', 'snappy'.
    :type orc_compression_codec: str or ~data_factory_management_client.models.OrcCompressionCodec
    """

    _validation = {
        'location': {'required': True},
    }

    _attribute_map = {
        'location': {'key': 'location', 'type': 'DatasetLocation'},
        'orc_compression_codec': {'key': 'orcCompressionCodec', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        location: "DatasetLocation",
        orc_compression_codec: Optional[Union[str, "OrcCompressionCodec"]] = None,
        **kwargs
    ):
        super(OrcDatasetTypeProperties, self).__init__(**kwargs)
        self.location = location
        self.orc_compression_codec = orc_compression_codec


class OrcFormat(DatasetStorageFormat):
    """The data stored in Optimized Row Columnar (ORC) format.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage format.Constant filled by server.
    :type type: str
    :param serializer: Serializer. Type: string (or Expression with resultType string).
    :type serializer: ~data_factory_management_client.models.DatasetStorageFormatSerializer
    :param deserializer: Deserializer. Type: string (or Expression with resultType string).
    :type deserializer: ~data_factory_management_client.models.DatasetStorageFormatDeserializer
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'serializer': {'key': 'serializer', 'type': 'DatasetStorageFormatSerializer'},
        'deserializer': {'key': 'deserializer', 'type': 'DatasetStorageFormatDeserializer'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        serializer: Optional["DatasetStorageFormatSerializer"] = None,
        deserializer: Optional["DatasetStorageFormatDeserializer"] = None,
        **kwargs
    ):
        super(OrcFormat, self).__init__(additional_properties=additional_properties, serializer=serializer, deserializer=deserializer, **kwargs)
        self.type = 'OrcFormat'


class OrcSink(CopySink):
    """A copy activity ORC sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param store_settings: Connector write settings.
    :type store_settings: ~data_factory_management_client.models.StoreWriteSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreWriteSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        store_settings: Optional["StoreWriteSettings"] = None,
        **kwargs
    ):
        super(OrcSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'OrcSink'
        self.store_settings = store_settings


class OrcSource(CopySource):
    """A copy activity ORC source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param store_settings: Connector read setting.
    :type store_settings: ~data_factory_management_client.models.StoreReadSettings
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreReadSettings'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(OrcSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'OrcSource'
        self.store_settings = store_settings
        self.additional_columns = additional_columns


class ParameterSpecification(msrest.serialization.Model):
    """Definition of a single parameter for an entity.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. Parameter type. Possible values include: 'Object', 'String', 'Int',
     'Float', 'Bool', 'Array', 'SecureString'.
    :type type: str or ~data_factory_management_client.models.ParameterType
    :param default_value: Default value of parameter.
    :type default_value: ~data_factory_management_client.models.ParameterSpecificationDefaultValue
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'default_value': {'key': 'defaultValue', 'type': 'ParameterSpecificationDefaultValue'},
    }

    def __init__(
        self,
        *,
        type: Union[str, "ParameterType"],
        default_value: Optional["ParameterSpecificationDefaultValue"] = None,
        **kwargs
    ):
        super(ParameterSpecification, self).__init__(**kwargs)
        self.type = type
        self.default_value = default_value


class ParameterSpecificationDefaultValue(msrest.serialization.Model):
    """Default value of parameter.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ParameterSpecificationDefaultValue, self).__init__(**kwargs)


class ParquetDataset(Dataset):
    """Parquet dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param location: Dataset location.
    :type location: ~data_factory_management_client.models.DatasetLocation
    :param compression_codec:  Possible values include: 'none', 'gzip', 'snappy', 'lzo', 'bzip2',
     'deflate', 'zipDeflate', 'lz4'.
    :type compression_codec: str or ~data_factory_management_client.models.CompressionCodec
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'location': {'key': 'typeProperties.location', 'type': 'DatasetLocation'},
        'compression_codec': {'key': 'typeProperties.compressionCodec', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        location: Optional["DatasetLocation"] = None,
        compression_codec: Optional[Union[str, "CompressionCodec"]] = None,
        **kwargs
    ):
        super(ParquetDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Parquet'
        self.location = location
        self.compression_codec = compression_codec


class ParquetDatasetTypeProperties(msrest.serialization.Model):
    """Parquet dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param location: Required. Dataset location.
    :type location: ~data_factory_management_client.models.DatasetLocation
    :param compression_codec:  Possible values include: 'none', 'gzip', 'snappy', 'lzo', 'bzip2',
     'deflate', 'zipDeflate', 'lz4'.
    :type compression_codec: str or ~data_factory_management_client.models.CompressionCodec
    """

    _validation = {
        'location': {'required': True},
    }

    _attribute_map = {
        'location': {'key': 'location', 'type': 'DatasetLocation'},
        'compression_codec': {'key': 'compressionCodec', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        location: "DatasetLocation",
        compression_codec: Optional[Union[str, "CompressionCodec"]] = None,
        **kwargs
    ):
        super(ParquetDatasetTypeProperties, self).__init__(**kwargs)
        self.location = location
        self.compression_codec = compression_codec


class ParquetFormat(DatasetStorageFormat):
    """The data stored in Parquet format.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage format.Constant filled by server.
    :type type: str
    :param serializer: Serializer. Type: string (or Expression with resultType string).
    :type serializer: ~data_factory_management_client.models.DatasetStorageFormatSerializer
    :param deserializer: Deserializer. Type: string (or Expression with resultType string).
    :type deserializer: ~data_factory_management_client.models.DatasetStorageFormatDeserializer
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'serializer': {'key': 'serializer', 'type': 'DatasetStorageFormatSerializer'},
        'deserializer': {'key': 'deserializer', 'type': 'DatasetStorageFormatDeserializer'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        serializer: Optional["DatasetStorageFormatSerializer"] = None,
        deserializer: Optional["DatasetStorageFormatDeserializer"] = None,
        **kwargs
    ):
        super(ParquetFormat, self).__init__(additional_properties=additional_properties, serializer=serializer, deserializer=deserializer, **kwargs)
        self.type = 'ParquetFormat'


class ParquetSink(CopySink):
    """A copy activity Parquet sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param store_settings: Connector write settings.
    :type store_settings: ~data_factory_management_client.models.StoreWriteSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreWriteSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        store_settings: Optional["StoreWriteSettings"] = None,
        **kwargs
    ):
        super(ParquetSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'ParquetSink'
        self.store_settings = store_settings


class ParquetSource(CopySource):
    """A copy activity Parquet source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param store_settings: Connector read setting.
    :type store_settings: ~data_factory_management_client.models.StoreReadSettings
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreReadSettings'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(ParquetSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'ParquetSource'
        self.store_settings = store_settings
        self.additional_columns = additional_columns


class PaypalLinkedService(LinkedService):
    """Paypal Service linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. The URL of the PayPal instance. (i.e. api.sandbox.paypal.com).
    :type host: ~data_factory_management_client.models.PaypalLinkedServiceTypePropertiesHost
    :param client_id: Required. The client ID associated with your PayPal application.
    :type client_id:
     ~data_factory_management_client.models.PaypalLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.PaypalLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.PaypalLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.PaypalLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.PaypalLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'PaypalLinkedServiceTypePropertiesHost'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'PaypalLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'PaypalLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'PaypalLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'PaypalLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'PaypalLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "PaypalLinkedServiceTypePropertiesHost",
        client_id: "PaypalLinkedServiceTypePropertiesClientId",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["PaypalLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["PaypalLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["PaypalLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["PaypalLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(PaypalLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Paypal'
        self.host = host
        self.client_id = client_id
        self.client_secret = client_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class PaypalLinkedServiceTypeProperties(msrest.serialization.Model):
    """Paypal Service linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. The URL of the PayPal instance. (i.e. api.sandbox.paypal.com).
    :type host: ~data_factory_management_client.models.PaypalLinkedServiceTypePropertiesHost
    :param client_id: Required. The client ID associated with your PayPal application.
    :type client_id:
     ~data_factory_management_client.models.PaypalLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.PaypalLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.PaypalLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.PaypalLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.PaypalLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'PaypalLinkedServiceTypePropertiesHost'},
        'client_id': {'key': 'clientId', 'type': 'PaypalLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'clientSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'PaypalLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'PaypalLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'PaypalLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'PaypalLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "PaypalLinkedServiceTypePropertiesHost",
        client_id: "PaypalLinkedServiceTypePropertiesClientId",
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["PaypalLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["PaypalLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["PaypalLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["PaypalLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(PaypalLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.client_id = client_id
        self.client_secret = client_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class PaypalLinkedServiceTypePropertiesClientId(msrest.serialization.Model):
    """The client ID associated with your PayPal application.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PaypalLinkedServiceTypePropertiesClientId, self).__init__(**kwargs)


class PaypalLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PaypalLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class PaypalLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """The URL of the PayPal instance. (i.e. api.sandbox.paypal.com).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PaypalLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class PaypalLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PaypalLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class PaypalLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PaypalLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class PaypalLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PaypalLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class PaypalObjectDataset(Dataset):
    """Paypal Service dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(PaypalObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'PaypalObject'
        self.table_name = table_name


class PaypalSource(TabularSource):
    """A copy activity Paypal Service source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.PaypalSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'PaypalSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["PaypalSourceQuery"] = None,
        **kwargs
    ):
        super(PaypalSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'PaypalSource'
        self.query = query


class PaypalSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PaypalSourceQuery, self).__init__(**kwargs)


class PhoenixDatasetTypeProperties(msrest.serialization.Model):
    """Phoenix Dataset Properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.PhoenixDatasetTypePropertiesTableName
    :param table: The table name of the Phoenix. Type: string (or Expression with resultType
     string).
    :type table: ~data_factory_management_client.models.PhoenixDatasetTypePropertiesTable
    :param schema: The schema name of the Phoenix. Type: string (or Expression with resultType
     string).
    :type schema: ~data_factory_management_client.models.PhoenixDatasetTypePropertiesSchema
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'PhoenixDatasetTypePropertiesTableName'},
        'table': {'key': 'table', 'type': 'PhoenixDatasetTypePropertiesTable'},
        'schema': {'key': 'schema', 'type': 'PhoenixDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["PhoenixDatasetTypePropertiesTableName"] = None,
        table: Optional["PhoenixDatasetTypePropertiesTable"] = None,
        schema: Optional["PhoenixDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(PhoenixDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.table = table
        self.schema = schema


class PhoenixDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of the Phoenix. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PhoenixDatasetTypePropertiesSchema, self).__init__(**kwargs)


class PhoenixDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the Phoenix. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PhoenixDatasetTypePropertiesTable, self).__init__(**kwargs)


class PhoenixDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PhoenixDatasetTypePropertiesTableName, self).__init__(**kwargs)


class PhoenixLinkedService(LinkedService):
    """Phoenix server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. The IP address or host name of the Phoenix server. (i.e.
     192.168.222.160).
    :type host: ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesHost
    :param port: The TCP port that the Phoenix server uses to listen for client connections. The
     default value is 8765.
    :type port: ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesPort
    :param http_path: The partial URL corresponding to the Phoenix server. (i.e.
     /gateway/sandbox/phoenix/version). The default value is hbasephoenix if using
     WindowsAzureHDInsightService.
    :type http_path:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesHttpPath
    :param authentication_type: Required. The authentication mechanism used to connect to the
     Phoenix server. Possible values include: 'Anonymous', 'UsernameAndPassword',
     'WindowsAzureHDInsightService'.
    :type authentication_type: str or
     ~data_factory_management_client.models.PhoenixAuthenticationType
    :param username: The user name used to connect to the Phoenix server.
    :type username:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :type enable_ssl:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesEnableSsl
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesTrustedCertPath
    :param use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :type use_system_trust_store:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesUseSystemTrustStore
    :param allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :type allow_host_name_cn_mismatch:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesAllowHostNameCNMismatch
    :param allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :type allow_self_signed_server_cert:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesAllowSelfSignedServerCert
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'PhoenixLinkedServiceTypePropertiesHost'},
        'port': {'key': 'typeProperties.port', 'type': 'PhoenixLinkedServiceTypePropertiesPort'},
        'http_path': {'key': 'typeProperties.httpPath', 'type': 'PhoenixLinkedServiceTypePropertiesHttpPath'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'PhoenixLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'PhoenixLinkedServiceTypePropertiesEnableSsl'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'PhoenixLinkedServiceTypePropertiesTrustedCertPath'},
        'use_system_trust_store': {'key': 'typeProperties.useSystemTrustStore', 'type': 'PhoenixLinkedServiceTypePropertiesUseSystemTrustStore'},
        'allow_host_name_cn_mismatch': {'key': 'typeProperties.allowHostNameCNMismatch', 'type': 'PhoenixLinkedServiceTypePropertiesAllowHostNameCNMismatch'},
        'allow_self_signed_server_cert': {'key': 'typeProperties.allowSelfSignedServerCert', 'type': 'PhoenixLinkedServiceTypePropertiesAllowSelfSignedServerCert'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'PhoenixLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "PhoenixLinkedServiceTypePropertiesHost",
        authentication_type: Union[str, "PhoenixAuthenticationType"],
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        port: Optional["PhoenixLinkedServiceTypePropertiesPort"] = None,
        http_path: Optional["PhoenixLinkedServiceTypePropertiesHttpPath"] = None,
        username: Optional["PhoenixLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        enable_ssl: Optional["PhoenixLinkedServiceTypePropertiesEnableSsl"] = None,
        trusted_cert_path: Optional["PhoenixLinkedServiceTypePropertiesTrustedCertPath"] = None,
        use_system_trust_store: Optional["PhoenixLinkedServiceTypePropertiesUseSystemTrustStore"] = None,
        allow_host_name_cn_mismatch: Optional["PhoenixLinkedServiceTypePropertiesAllowHostNameCNMismatch"] = None,
        allow_self_signed_server_cert: Optional["PhoenixLinkedServiceTypePropertiesAllowSelfSignedServerCert"] = None,
        encrypted_credential: Optional["PhoenixLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(PhoenixLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Phoenix'
        self.host = host
        self.port = port
        self.http_path = http_path
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class PhoenixLinkedServiceTypeProperties(msrest.serialization.Model):
    """Phoenix server linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. The IP address or host name of the Phoenix server. (i.e.
     192.168.222.160).
    :type host: ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesHost
    :param port: The TCP port that the Phoenix server uses to listen for client connections. The
     default value is 8765.
    :type port: ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesPort
    :param http_path: The partial URL corresponding to the Phoenix server. (i.e.
     /gateway/sandbox/phoenix/version). The default value is hbasephoenix if using
     WindowsAzureHDInsightService.
    :type http_path:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesHttpPath
    :param authentication_type: Required. The authentication mechanism used to connect to the
     Phoenix server. Possible values include: 'Anonymous', 'UsernameAndPassword',
     'WindowsAzureHDInsightService'.
    :type authentication_type: str or
     ~data_factory_management_client.models.PhoenixAuthenticationType
    :param username: The user name used to connect to the Phoenix server.
    :type username:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :type enable_ssl:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesEnableSsl
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesTrustedCertPath
    :param use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :type use_system_trust_store:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesUseSystemTrustStore
    :param allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :type allow_host_name_cn_mismatch:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesAllowHostNameCNMismatch
    :param allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :type allow_self_signed_server_cert:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesAllowSelfSignedServerCert
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.PhoenixLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'PhoenixLinkedServiceTypePropertiesHost'},
        'port': {'key': 'port', 'type': 'PhoenixLinkedServiceTypePropertiesPort'},
        'http_path': {'key': 'httpPath', 'type': 'PhoenixLinkedServiceTypePropertiesHttpPath'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'username': {'key': 'username', 'type': 'PhoenixLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'enable_ssl': {'key': 'enableSsl', 'type': 'PhoenixLinkedServiceTypePropertiesEnableSsl'},
        'trusted_cert_path': {'key': 'trustedCertPath', 'type': 'PhoenixLinkedServiceTypePropertiesTrustedCertPath'},
        'use_system_trust_store': {'key': 'useSystemTrustStore', 'type': 'PhoenixLinkedServiceTypePropertiesUseSystemTrustStore'},
        'allow_host_name_cn_mismatch': {'key': 'allowHostNameCNMismatch', 'type': 'PhoenixLinkedServiceTypePropertiesAllowHostNameCNMismatch'},
        'allow_self_signed_server_cert': {'key': 'allowSelfSignedServerCert', 'type': 'PhoenixLinkedServiceTypePropertiesAllowSelfSignedServerCert'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'PhoenixLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "PhoenixLinkedServiceTypePropertiesHost",
        authentication_type: Union[str, "PhoenixAuthenticationType"],
        port: Optional["PhoenixLinkedServiceTypePropertiesPort"] = None,
        http_path: Optional["PhoenixLinkedServiceTypePropertiesHttpPath"] = None,
        username: Optional["PhoenixLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        enable_ssl: Optional["PhoenixLinkedServiceTypePropertiesEnableSsl"] = None,
        trusted_cert_path: Optional["PhoenixLinkedServiceTypePropertiesTrustedCertPath"] = None,
        use_system_trust_store: Optional["PhoenixLinkedServiceTypePropertiesUseSystemTrustStore"] = None,
        allow_host_name_cn_mismatch: Optional["PhoenixLinkedServiceTypePropertiesAllowHostNameCNMismatch"] = None,
        allow_self_signed_server_cert: Optional["PhoenixLinkedServiceTypePropertiesAllowSelfSignedServerCert"] = None,
        encrypted_credential: Optional["PhoenixLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(PhoenixLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.port = port
        self.http_path = http_path
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class PhoenixLinkedServiceTypePropertiesAllowHostNameCNMismatch(msrest.serialization.Model):
    """Specifies whether to require a CA-issued SSL certificate name to match the host name of the server when connecting over SSL. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PhoenixLinkedServiceTypePropertiesAllowHostNameCNMismatch, self).__init__(**kwargs)


class PhoenixLinkedServiceTypePropertiesAllowSelfSignedServerCert(msrest.serialization.Model):
    """Specifies whether to allow self-signed certificates from the server. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PhoenixLinkedServiceTypePropertiesAllowSelfSignedServerCert, self).__init__(**kwargs)


class PhoenixLinkedServiceTypePropertiesEnableSsl(msrest.serialization.Model):
    """Specifies whether the connections to the server are encrypted using SSL. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PhoenixLinkedServiceTypePropertiesEnableSsl, self).__init__(**kwargs)


class PhoenixLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PhoenixLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class PhoenixLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """The IP address or host name of the Phoenix server. (i.e. 192.168.222.160).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PhoenixLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class PhoenixLinkedServiceTypePropertiesHttpPath(msrest.serialization.Model):
    """The partial URL corresponding to the Phoenix server. (i.e. /gateway/sandbox/phoenix/version). The default value is hbasephoenix if using WindowsAzureHDInsightService.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PhoenixLinkedServiceTypePropertiesHttpPath, self).__init__(**kwargs)


class PhoenixLinkedServiceTypePropertiesPort(msrest.serialization.Model):
    """The TCP port that the Phoenix server uses to listen for client connections. The default value is 8765.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PhoenixLinkedServiceTypePropertiesPort, self).__init__(**kwargs)


class PhoenixLinkedServiceTypePropertiesTrustedCertPath(msrest.serialization.Model):
    """The full path of the .pem file containing trusted CA certificates for verifying the server when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The default value is the cacerts.pem file installed with the IR.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PhoenixLinkedServiceTypePropertiesTrustedCertPath, self).__init__(**kwargs)


class PhoenixLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """The user name used to connect to the Phoenix server.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PhoenixLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class PhoenixLinkedServiceTypePropertiesUseSystemTrustStore(msrest.serialization.Model):
    """Specifies whether to use a CA certificate from the system trust store or from a specified PEM file. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PhoenixLinkedServiceTypePropertiesUseSystemTrustStore, self).__init__(**kwargs)


class PhoenixObjectDataset(Dataset):
    """Phoenix server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.PhoenixDatasetTypePropertiesTableName
    :param table: The table name of the Phoenix. Type: string (or Expression with resultType
     string).
    :type table: ~data_factory_management_client.models.PhoenixDatasetTypePropertiesTable
    :param schema_type_properties_schema: The schema name of the Phoenix. Type: string (or
     Expression with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.PhoenixDatasetTypePropertiesSchema
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'PhoenixDatasetTypePropertiesTableName'},
        'table': {'key': 'typeProperties.table', 'type': 'PhoenixDatasetTypePropertiesTable'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'PhoenixDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["PhoenixDatasetTypePropertiesTableName"] = None,
        table: Optional["PhoenixDatasetTypePropertiesTable"] = None,
        schema_type_properties_schema: Optional["PhoenixDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(PhoenixObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'PhoenixObject'
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class PhoenixSource(TabularSource):
    """A copy activity Phoenix server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.PhoenixSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'PhoenixSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["PhoenixSourceQuery"] = None,
        **kwargs
    ):
        super(PhoenixSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'PhoenixSource'
        self.query = query


class PhoenixSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PhoenixSourceQuery, self).__init__(**kwargs)


class Pipeline(msrest.serialization.Model):
    """A data factory pipeline.

    :param description: The description of the pipeline.
    :type description: str
    :param activities: List of activities in pipeline.
    :type activities: list[~data_factory_management_client.models.Activity]
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param variables: Definition of variable for a Pipeline.
    :type variables: dict[str, ~data_factory_management_client.models.VariableSpecification]
    :param concurrency: The max number of concurrent runs for the pipeline.
    :type concurrency: int
    :param annotations: List of tags that can be used for describing the Pipeline.
    :type annotations: list[~data_factory_management_client.models.PipelineAnnotationsItem]
    :param run_dimensions: Dimensions emitted by Pipeline.
    :type run_dimensions: dict[str, object]
    :param folder: The folder that this Pipeline is in. If not specified, Pipeline will appear at
     the root level.
    :type folder: ~data_factory_management_client.models.PipelineFolder
    """

    _validation = {
        'concurrency': {'minimum': 1},
    }

    _attribute_map = {
        'description': {'key': 'description', 'type': 'str'},
        'activities': {'key': 'activities', 'type': '[Activity]'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'variables': {'key': 'variables', 'type': '{VariableSpecification}'},
        'concurrency': {'key': 'concurrency', 'type': 'int'},
        'annotations': {'key': 'annotations', 'type': '[PipelineAnnotationsItem]'},
        'run_dimensions': {'key': 'runDimensions', 'type': '{object}'},
        'folder': {'key': 'folder', 'type': 'PipelineFolder'},
    }

    def __init__(
        self,
        *,
        description: Optional[str] = None,
        activities: Optional[List["Activity"]] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        variables: Optional[Dict[str, "VariableSpecification"]] = None,
        concurrency: Optional[int] = None,
        annotations: Optional[List["PipelineAnnotationsItem"]] = None,
        run_dimensions: Optional[Dict[str, object]] = None,
        folder: Optional["PipelineFolder"] = None,
        **kwargs
    ):
        super(Pipeline, self).__init__(**kwargs)
        self.description = description
        self.activities = activities
        self.parameters = parameters
        self.variables = variables
        self.concurrency = concurrency
        self.annotations = annotations
        self.run_dimensions = run_dimensions
        self.folder = folder


class PipelineAnnotationsItem(msrest.serialization.Model):
    """PipelineAnnotationsItem.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PipelineAnnotationsItem, self).__init__(**kwargs)


class PipelineFolder(msrest.serialization.Model):
    """The folder that this Pipeline is in. If not specified, Pipeline will appear at the root level.

    :param name: The name of the folder that this Pipeline is in.
    :type name: str
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        **kwargs
    ):
        super(PipelineFolder, self).__init__(**kwargs)
        self.name = name


class PipelineListResponse(msrest.serialization.Model):
    """A list of pipeline resources.

    All required parameters must be populated in order to send to Azure.

    :param value: Required. List of pipelines.
    :type value: list[~data_factory_management_client.models.PipelineResource]
    :param next_link: The link to the next page of results, if any remaining results exist.
    :type next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[PipelineResource]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["PipelineResource"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        super(PipelineListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class PipelineReference(msrest.serialization.Model):
    """Pipeline reference type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Pipeline reference type. Default value: "PipelineReference".
    :vartype type: str
    :param reference_name: Required. Reference pipeline name.
    :type reference_name: str
    :param name: Reference name.
    :type name: str
    """

    _validation = {
        'type': {'required': True, 'constant': True},
        'reference_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
    }

    type = "PipelineReference"

    def __init__(
        self,
        *,
        reference_name: str,
        name: Optional[str] = None,
        **kwargs
    ):
        super(PipelineReference, self).__init__(**kwargs)
        self.reference_name = reference_name
        self.name = name


class PipelineResource(SubResource):
    """Pipeline resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param description: The description of the pipeline.
    :type description: str
    :param activities: List of activities in pipeline.
    :type activities: list[~data_factory_management_client.models.Activity]
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param variables: Definition of variable for a Pipeline.
    :type variables: dict[str, ~data_factory_management_client.models.VariableSpecification]
    :param concurrency: The max number of concurrent runs for the pipeline.
    :type concurrency: int
    :param annotations: List of tags that can be used for describing the Pipeline.
    :type annotations: list[~data_factory_management_client.models.PipelineAnnotationsItem]
    :param run_dimensions: Dimensions emitted by Pipeline.
    :type run_dimensions: dict[str, object]
    :param folder: The folder that this Pipeline is in. If not specified, Pipeline will appear at
     the root level.
    :type folder: ~data_factory_management_client.models.PipelineFolder
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
        'concurrency': {'minimum': 1},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'additional_properties': {'key': '', 'type': '{object}'},
        'description': {'key': 'properties.description', 'type': 'str'},
        'activities': {'key': 'properties.activities', 'type': '[Activity]'},
        'parameters': {'key': 'properties.parameters', 'type': '{ParameterSpecification}'},
        'variables': {'key': 'properties.variables', 'type': '{VariableSpecification}'},
        'concurrency': {'key': 'properties.concurrency', 'type': 'int'},
        'annotations': {'key': 'properties.annotations', 'type': '[PipelineAnnotationsItem]'},
        'run_dimensions': {'key': 'properties.runDimensions', 'type': '{object}'},
        'folder': {'key': 'properties.folder', 'type': 'PipelineFolder'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        activities: Optional[List["Activity"]] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        variables: Optional[Dict[str, "VariableSpecification"]] = None,
        concurrency: Optional[int] = None,
        annotations: Optional[List["PipelineAnnotationsItem"]] = None,
        run_dimensions: Optional[Dict[str, object]] = None,
        folder: Optional["PipelineFolder"] = None,
        **kwargs
    ):
        super(PipelineResource, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.description = description
        self.activities = activities
        self.parameters = parameters
        self.variables = variables
        self.concurrency = concurrency
        self.annotations = annotations
        self.run_dimensions = run_dimensions
        self.folder = folder


class PipelineRun(msrest.serialization.Model):
    """Information about a pipeline run.

    Variables are only populated by the server, and will be ignored when sending a request.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :ivar run_id: Identifier of a run.
    :vartype run_id: str
    :ivar run_group_id: Identifier that correlates all the recovery runs of a pipeline run.
    :vartype run_group_id: str
    :ivar is_latest: Indicates if the recovered pipeline run is the latest in its group.
    :vartype is_latest: bool
    :ivar pipeline_name: The pipeline name.
    :vartype pipeline_name: str
    :ivar parameters: The full or partial list of parameter name, value pair used in the pipeline
     run.
    :vartype parameters: dict[str, str]
    :ivar run_dimensions: Run dimensions emitted by Pipeline run.
    :vartype run_dimensions: dict[str, str]
    :ivar invoked_by: Provides entity name and id that started the pipeline run.
    :vartype invoked_by: ~data_factory_management_client.models.PipelineRunInvokedBy
    :ivar last_updated: The last updated timestamp for the pipeline run event in ISO8601 format.
    :vartype last_updated: ~datetime.datetime
    :ivar run_start: The start time of a pipeline run in ISO8601 format.
    :vartype run_start: ~datetime.datetime
    :ivar run_end: The end time of a pipeline run in ISO8601 format.
    :vartype run_end: ~datetime.datetime
    :ivar duration_in_ms: The duration of a pipeline run.
    :vartype duration_in_ms: int
    :ivar status: The status of a pipeline run.
    :vartype status: str
    :ivar message: The message from a pipeline run.
    :vartype message: str
    """

    _validation = {
        'run_id': {'readonly': True},
        'run_group_id': {'readonly': True},
        'is_latest': {'readonly': True},
        'pipeline_name': {'readonly': True},
        'parameters': {'readonly': True},
        'run_dimensions': {'readonly': True},
        'invoked_by': {'readonly': True},
        'last_updated': {'readonly': True},
        'run_start': {'readonly': True},
        'run_end': {'readonly': True},
        'duration_in_ms': {'readonly': True},
        'status': {'readonly': True},
        'message': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'run_id': {'key': 'runId', 'type': 'str'},
        'run_group_id': {'key': 'runGroupId', 'type': 'str'},
        'is_latest': {'key': 'isLatest', 'type': 'bool'},
        'pipeline_name': {'key': 'pipelineName', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{str}'},
        'run_dimensions': {'key': 'runDimensions', 'type': '{str}'},
        'invoked_by': {'key': 'invokedBy', 'type': 'PipelineRunInvokedBy'},
        'last_updated': {'key': 'lastUpdated', 'type': 'iso-8601'},
        'run_start': {'key': 'runStart', 'type': 'iso-8601'},
        'run_end': {'key': 'runEnd', 'type': 'iso-8601'},
        'duration_in_ms': {'key': 'durationInMs', 'type': 'int'},
        'status': {'key': 'status', 'type': 'str'},
        'message': {'key': 'message', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(PipelineRun, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.run_id = None
        self.run_group_id = None
        self.is_latest = None
        self.pipeline_name = None
        self.parameters = None
        self.run_dimensions = None
        self.invoked_by = None
        self.last_updated = None
        self.run_start = None
        self.run_end = None
        self.duration_in_ms = None
        self.status = None
        self.message = None


class PipelineRunInvokedBy(msrest.serialization.Model):
    """Provides entity name and id that started the pipeline run.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar name: Name of the entity that started the pipeline run.
    :vartype name: str
    :ivar id: The ID of the entity that started the run.
    :vartype id: str
    :ivar invoked_by_type: The type of the entity that started the run.
    :vartype invoked_by_type: str
    """

    _validation = {
        'name': {'readonly': True},
        'id': {'readonly': True},
        'invoked_by_type': {'readonly': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'id': {'key': 'id', 'type': 'str'},
        'invoked_by_type': {'key': 'invokedByType', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PipelineRunInvokedBy, self).__init__(**kwargs)
        self.name = None
        self.id = None
        self.invoked_by_type = None


class PipelineRunsQueryResponse(msrest.serialization.Model):
    """A list pipeline runs.

    All required parameters must be populated in order to send to Azure.

    :param value: Required. List of pipeline runs.
    :type value: list[~data_factory_management_client.models.PipelineRun]
    :param continuation_token: The continuation token for getting the next page of results, if any
     remaining results exist, null otherwise.
    :type continuation_token: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[PipelineRun]'},
        'continuation_token': {'key': 'continuationToken', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["PipelineRun"],
        continuation_token: Optional[str] = None,
        **kwargs
    ):
        super(PipelineRunsQueryResponse, self).__init__(**kwargs)
        self.value = value
        self.continuation_token = continuation_token


class PolybaseSettings(msrest.serialization.Model):
    """PolyBase settings.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param reject_type: Indicates whether the RejectValue property is specified as a literal value
     or a percentage. Possible values include: 'value', 'percentage'.
    :type reject_type: str or ~data_factory_management_client.models.PolybaseSettingsRejectType
    :param reject_value: Specifies the value or the percentage of rows that can be rejected before
     the query fails. Type: number (or Expression with resultType number), minimum: 0.
    :type reject_value: ~data_factory_management_client.models.PolybaseSettingsRejectValue
    :param reject_sample_value: Determines the number of rows to attempt to retrieve before the
     PolyBase recalculates the percentage of rejected rows. Type: integer (or Expression with
     resultType integer), minimum: 0.
    :type reject_sample_value:
     ~data_factory_management_client.models.PolybaseSettingsRejectSampleValue
    :param use_type_default: Specifies how to handle missing values in delimited text files when
     PolyBase retrieves data from the text file. Type: boolean (or Expression with resultType
     boolean).
    :type use_type_default: ~data_factory_management_client.models.PolybaseSettingsUseTypeDefault
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'reject_type': {'key': 'rejectType', 'type': 'str'},
        'reject_value': {'key': 'rejectValue', 'type': 'PolybaseSettingsRejectValue'},
        'reject_sample_value': {'key': 'rejectSampleValue', 'type': 'PolybaseSettingsRejectSampleValue'},
        'use_type_default': {'key': 'useTypeDefault', 'type': 'PolybaseSettingsUseTypeDefault'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        reject_type: Optional[Union[str, "PolybaseSettingsRejectType"]] = None,
        reject_value: Optional["PolybaseSettingsRejectValue"] = None,
        reject_sample_value: Optional["PolybaseSettingsRejectSampleValue"] = None,
        use_type_default: Optional["PolybaseSettingsUseTypeDefault"] = None,
        **kwargs
    ):
        super(PolybaseSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.reject_type = reject_type
        self.reject_value = reject_value
        self.reject_sample_value = reject_sample_value
        self.use_type_default = use_type_default


class PolybaseSettingsRejectSampleValue(msrest.serialization.Model):
    """Determines the number of rows to attempt to retrieve before the PolyBase recalculates the percentage of rejected rows. Type: integer (or Expression with resultType integer), minimum: 0.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PolybaseSettingsRejectSampleValue, self).__init__(**kwargs)


class PolybaseSettingsRejectValue(msrest.serialization.Model):
    """Specifies the value or the percentage of rows that can be rejected before the query fails. Type: number (or Expression with resultType number), minimum: 0.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PolybaseSettingsRejectValue, self).__init__(**kwargs)


class PolybaseSettingsUseTypeDefault(msrest.serialization.Model):
    """Specifies how to handle missing values in delimited text files when PolyBase retrieves data from the text file. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PolybaseSettingsUseTypeDefault, self).__init__(**kwargs)


class PostgreSqlLinkedService(LinkedService):
    """Linked service for PostgreSQL data source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: Required. The connection string.
    :type connection_string:
     ~data_factory_management_client.models.PostgreSqlLinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.PostgreSqlLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'PostgreSqlLinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'PostgreSqlLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "PostgreSqlLinkedServiceTypePropertiesConnectionString",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["PostgreSqlLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(PostgreSqlLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'PostgreSql'
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class PostgreSqlLinkedServiceTypeProperties(msrest.serialization.Model):
    """PostgreSQL linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param connection_string: Required. The connection string.
    :type connection_string:
     ~data_factory_management_client.models.PostgreSqlLinkedServiceTypePropertiesConnectionString
    :param password: Azure Key Vault secret reference.
    :type password: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.PostgreSqlLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'PostgreSqlLinkedServiceTypePropertiesConnectionString'},
        'password': {'key': 'password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'PostgreSqlLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "PostgreSqlLinkedServiceTypePropertiesConnectionString",
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["PostgreSqlLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(PostgreSqlLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class PostgreSqlLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The connection string.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PostgreSqlLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class PostgreSqlLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PostgreSqlLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class PostgreSqlSource(TabularSource):
    """A copy activity source for PostgreSQL databases.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: Database query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.PostgreSqlSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'PostgreSqlSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["PostgreSqlSourceQuery"] = None,
        **kwargs
    ):
        super(PostgreSqlSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'PostgreSqlSource'
        self.query = query


class PostgreSqlSourceQuery(msrest.serialization.Model):
    """Database query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PostgreSqlSourceQuery, self).__init__(**kwargs)


class PostgreSqlTableDataset(Dataset):
    """The PostgreSQL table dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.PostgreSqlTableDatasetTypePropertiesTableName
    :param table: The PostgreSQL table name. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.PostgreSqlTableDatasetTypePropertiesTable
    :param schema_type_properties_schema: The PostgreSQL schema name. Type: string (or Expression
     with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.PostgreSqlTableDatasetTypePropertiesSchema
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'PostgreSqlTableDatasetTypePropertiesTableName'},
        'table': {'key': 'typeProperties.table', 'type': 'PostgreSqlTableDatasetTypePropertiesTable'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'PostgreSqlTableDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["PostgreSqlTableDatasetTypePropertiesTableName"] = None,
        table: Optional["PostgreSqlTableDatasetTypePropertiesTable"] = None,
        schema_type_properties_schema: Optional["PostgreSqlTableDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(PostgreSqlTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'PostgreSqlTable'
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class PostgreSqlTableDatasetTypeProperties(msrest.serialization.Model):
    """PostgreSQL table dataset properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.PostgreSqlTableDatasetTypePropertiesTableName
    :param table: The PostgreSQL table name. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.PostgreSqlTableDatasetTypePropertiesTable
    :param schema: The PostgreSQL schema name. Type: string (or Expression with resultType string).
    :type schema: ~data_factory_management_client.models.PostgreSqlTableDatasetTypePropertiesSchema
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'PostgreSqlTableDatasetTypePropertiesTableName'},
        'table': {'key': 'table', 'type': 'PostgreSqlTableDatasetTypePropertiesTable'},
        'schema': {'key': 'schema', 'type': 'PostgreSqlTableDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["PostgreSqlTableDatasetTypePropertiesTableName"] = None,
        table: Optional["PostgreSqlTableDatasetTypePropertiesTable"] = None,
        schema: Optional["PostgreSqlTableDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(PostgreSqlTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.table = table
        self.schema = schema


class PostgreSqlTableDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The PostgreSQL schema name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PostgreSqlTableDatasetTypePropertiesSchema, self).__init__(**kwargs)


class PostgreSqlTableDatasetTypePropertiesTable(msrest.serialization.Model):
    """The PostgreSQL table name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PostgreSqlTableDatasetTypePropertiesTable, self).__init__(**kwargs)


class PostgreSqlTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PostgreSqlTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class PrestoDatasetTypeProperties(msrest.serialization.Model):
    """Presto Dataset Properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.PrestoDatasetTypePropertiesTableName
    :param table: The table name of the Presto. Type: string (or Expression with resultType
     string).
    :type table: ~data_factory_management_client.models.PrestoDatasetTypePropertiesTable
    :param schema: The schema name of the Presto. Type: string (or Expression with resultType
     string).
    :type schema: ~data_factory_management_client.models.PrestoDatasetTypePropertiesSchema
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'PrestoDatasetTypePropertiesTableName'},
        'table': {'key': 'table', 'type': 'PrestoDatasetTypePropertiesTable'},
        'schema': {'key': 'schema', 'type': 'PrestoDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["PrestoDatasetTypePropertiesTableName"] = None,
        table: Optional["PrestoDatasetTypePropertiesTable"] = None,
        schema: Optional["PrestoDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(PrestoDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.table = table
        self.schema = schema


class PrestoDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of the Presto. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoDatasetTypePropertiesSchema, self).__init__(**kwargs)


class PrestoDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the Presto. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoDatasetTypePropertiesTable, self).__init__(**kwargs)


class PrestoDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoDatasetTypePropertiesTableName, self).__init__(**kwargs)


class PrestoLinkedService(LinkedService):
    """Presto server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. The IP address or host name of the Presto server. (i.e.
     192.168.222.160).
    :type host: ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesHost
    :param server_version: Required. The version of the Presto server. (i.e. 0.148-t).
    :type server_version:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesServerVersion
    :param catalog: Required. The catalog context for all request against the server.
    :type catalog: ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesCatalog
    :param port: The TCP port that the Presto server uses to listen for client connections. The
     default value is 8080.
    :type port: ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesPort
    :param authentication_type: Required. The authentication mechanism used to connect to the
     Presto server. Possible values include: 'Anonymous', 'LDAP'.
    :type authentication_type: str or
     ~data_factory_management_client.models.PrestoAuthenticationType
    :param username: The user name used to connect to the Presto server.
    :type username:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :type enable_ssl:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesEnableSsl
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesTrustedCertPath
    :param use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :type use_system_trust_store:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesUseSystemTrustStore
    :param allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :type allow_host_name_cn_mismatch:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesAllowHostNameCNMismatch
    :param allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :type allow_self_signed_server_cert:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesAllowSelfSignedServerCert
    :param time_zone_id: The local time zone used by the connection. Valid values for this option
     are specified in the IANA Time Zone Database. The default value is the system time zone.
    :type time_zone_id:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesTimeZoneID
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'server_version': {'required': True},
        'catalog': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'PrestoLinkedServiceTypePropertiesHost'},
        'server_version': {'key': 'typeProperties.serverVersion', 'type': 'PrestoLinkedServiceTypePropertiesServerVersion'},
        'catalog': {'key': 'typeProperties.catalog', 'type': 'PrestoLinkedServiceTypePropertiesCatalog'},
        'port': {'key': 'typeProperties.port', 'type': 'PrestoLinkedServiceTypePropertiesPort'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'PrestoLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'PrestoLinkedServiceTypePropertiesEnableSsl'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'PrestoLinkedServiceTypePropertiesTrustedCertPath'},
        'use_system_trust_store': {'key': 'typeProperties.useSystemTrustStore', 'type': 'PrestoLinkedServiceTypePropertiesUseSystemTrustStore'},
        'allow_host_name_cn_mismatch': {'key': 'typeProperties.allowHostNameCNMismatch', 'type': 'PrestoLinkedServiceTypePropertiesAllowHostNameCNMismatch'},
        'allow_self_signed_server_cert': {'key': 'typeProperties.allowSelfSignedServerCert', 'type': 'PrestoLinkedServiceTypePropertiesAllowSelfSignedServerCert'},
        'time_zone_id': {'key': 'typeProperties.timeZoneID', 'type': 'PrestoLinkedServiceTypePropertiesTimeZoneID'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'PrestoLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "PrestoLinkedServiceTypePropertiesHost",
        server_version: "PrestoLinkedServiceTypePropertiesServerVersion",
        catalog: "PrestoLinkedServiceTypePropertiesCatalog",
        authentication_type: Union[str, "PrestoAuthenticationType"],
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        port: Optional["PrestoLinkedServiceTypePropertiesPort"] = None,
        username: Optional["PrestoLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        enable_ssl: Optional["PrestoLinkedServiceTypePropertiesEnableSsl"] = None,
        trusted_cert_path: Optional["PrestoLinkedServiceTypePropertiesTrustedCertPath"] = None,
        use_system_trust_store: Optional["PrestoLinkedServiceTypePropertiesUseSystemTrustStore"] = None,
        allow_host_name_cn_mismatch: Optional["PrestoLinkedServiceTypePropertiesAllowHostNameCNMismatch"] = None,
        allow_self_signed_server_cert: Optional["PrestoLinkedServiceTypePropertiesAllowSelfSignedServerCert"] = None,
        time_zone_id: Optional["PrestoLinkedServiceTypePropertiesTimeZoneID"] = None,
        encrypted_credential: Optional["PrestoLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(PrestoLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Presto'
        self.host = host
        self.server_version = server_version
        self.catalog = catalog
        self.port = port
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.time_zone_id = time_zone_id
        self.encrypted_credential = encrypted_credential


class PrestoLinkedServiceTypeProperties(msrest.serialization.Model):
    """Presto server linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. The IP address or host name of the Presto server. (i.e.
     192.168.222.160).
    :type host: ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesHost
    :param server_version: Required. The version of the Presto server. (i.e. 0.148-t).
    :type server_version:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesServerVersion
    :param catalog: Required. The catalog context for all request against the server.
    :type catalog: ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesCatalog
    :param port: The TCP port that the Presto server uses to listen for client connections. The
     default value is 8080.
    :type port: ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesPort
    :param authentication_type: Required. The authentication mechanism used to connect to the
     Presto server. Possible values include: 'Anonymous', 'LDAP'.
    :type authentication_type: str or
     ~data_factory_management_client.models.PrestoAuthenticationType
    :param username: The user name used to connect to the Presto server.
    :type username:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :type enable_ssl:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesEnableSsl
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesTrustedCertPath
    :param use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :type use_system_trust_store:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesUseSystemTrustStore
    :param allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :type allow_host_name_cn_mismatch:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesAllowHostNameCNMismatch
    :param allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :type allow_self_signed_server_cert:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesAllowSelfSignedServerCert
    :param time_zone_id: The local time zone used by the connection. Valid values for this option
     are specified in the IANA Time Zone Database. The default value is the system time zone.
    :type time_zone_id:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesTimeZoneID
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.PrestoLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
        'server_version': {'required': True},
        'catalog': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'PrestoLinkedServiceTypePropertiesHost'},
        'server_version': {'key': 'serverVersion', 'type': 'PrestoLinkedServiceTypePropertiesServerVersion'},
        'catalog': {'key': 'catalog', 'type': 'PrestoLinkedServiceTypePropertiesCatalog'},
        'port': {'key': 'port', 'type': 'PrestoLinkedServiceTypePropertiesPort'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'username': {'key': 'username', 'type': 'PrestoLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'enable_ssl': {'key': 'enableSsl', 'type': 'PrestoLinkedServiceTypePropertiesEnableSsl'},
        'trusted_cert_path': {'key': 'trustedCertPath', 'type': 'PrestoLinkedServiceTypePropertiesTrustedCertPath'},
        'use_system_trust_store': {'key': 'useSystemTrustStore', 'type': 'PrestoLinkedServiceTypePropertiesUseSystemTrustStore'},
        'allow_host_name_cn_mismatch': {'key': 'allowHostNameCNMismatch', 'type': 'PrestoLinkedServiceTypePropertiesAllowHostNameCNMismatch'},
        'allow_self_signed_server_cert': {'key': 'allowSelfSignedServerCert', 'type': 'PrestoLinkedServiceTypePropertiesAllowSelfSignedServerCert'},
        'time_zone_id': {'key': 'timeZoneID', 'type': 'PrestoLinkedServiceTypePropertiesTimeZoneID'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'PrestoLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "PrestoLinkedServiceTypePropertiesHost",
        server_version: "PrestoLinkedServiceTypePropertiesServerVersion",
        catalog: "PrestoLinkedServiceTypePropertiesCatalog",
        authentication_type: Union[str, "PrestoAuthenticationType"],
        port: Optional["PrestoLinkedServiceTypePropertiesPort"] = None,
        username: Optional["PrestoLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        enable_ssl: Optional["PrestoLinkedServiceTypePropertiesEnableSsl"] = None,
        trusted_cert_path: Optional["PrestoLinkedServiceTypePropertiesTrustedCertPath"] = None,
        use_system_trust_store: Optional["PrestoLinkedServiceTypePropertiesUseSystemTrustStore"] = None,
        allow_host_name_cn_mismatch: Optional["PrestoLinkedServiceTypePropertiesAllowHostNameCNMismatch"] = None,
        allow_self_signed_server_cert: Optional["PrestoLinkedServiceTypePropertiesAllowSelfSignedServerCert"] = None,
        time_zone_id: Optional["PrestoLinkedServiceTypePropertiesTimeZoneID"] = None,
        encrypted_credential: Optional["PrestoLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(PrestoLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.server_version = server_version
        self.catalog = catalog
        self.port = port
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.time_zone_id = time_zone_id
        self.encrypted_credential = encrypted_credential


class PrestoLinkedServiceTypePropertiesAllowHostNameCNMismatch(msrest.serialization.Model):
    """Specifies whether to require a CA-issued SSL certificate name to match the host name of the server when connecting over SSL. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoLinkedServiceTypePropertiesAllowHostNameCNMismatch, self).__init__(**kwargs)


class PrestoLinkedServiceTypePropertiesAllowSelfSignedServerCert(msrest.serialization.Model):
    """Specifies whether to allow self-signed certificates from the server. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoLinkedServiceTypePropertiesAllowSelfSignedServerCert, self).__init__(**kwargs)


class PrestoLinkedServiceTypePropertiesCatalog(msrest.serialization.Model):
    """The catalog context for all request against the server.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoLinkedServiceTypePropertiesCatalog, self).__init__(**kwargs)


class PrestoLinkedServiceTypePropertiesEnableSsl(msrest.serialization.Model):
    """Specifies whether the connections to the server are encrypted using SSL. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoLinkedServiceTypePropertiesEnableSsl, self).__init__(**kwargs)


class PrestoLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class PrestoLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """The IP address or host name of the Presto server. (i.e. 192.168.222.160).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class PrestoLinkedServiceTypePropertiesPort(msrest.serialization.Model):
    """The TCP port that the Presto server uses to listen for client connections. The default value is 8080.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoLinkedServiceTypePropertiesPort, self).__init__(**kwargs)


class PrestoLinkedServiceTypePropertiesServerVersion(msrest.serialization.Model):
    """The version of the Presto server. (i.e. 0.148-t).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoLinkedServiceTypePropertiesServerVersion, self).__init__(**kwargs)


class PrestoLinkedServiceTypePropertiesTimeZoneID(msrest.serialization.Model):
    """The local time zone used by the connection. Valid values for this option are specified in the IANA Time Zone Database. The default value is the system time zone.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoLinkedServiceTypePropertiesTimeZoneID, self).__init__(**kwargs)


class PrestoLinkedServiceTypePropertiesTrustedCertPath(msrest.serialization.Model):
    """The full path of the .pem file containing trusted CA certificates for verifying the server when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The default value is the cacerts.pem file installed with the IR.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoLinkedServiceTypePropertiesTrustedCertPath, self).__init__(**kwargs)


class PrestoLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """The user name used to connect to the Presto server.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class PrestoLinkedServiceTypePropertiesUseSystemTrustStore(msrest.serialization.Model):
    """Specifies whether to use a CA certificate from the system trust store or from a specified PEM file. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoLinkedServiceTypePropertiesUseSystemTrustStore, self).__init__(**kwargs)


class PrestoObjectDataset(Dataset):
    """Presto server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.PrestoDatasetTypePropertiesTableName
    :param table: The table name of the Presto. Type: string (or Expression with resultType
     string).
    :type table: ~data_factory_management_client.models.PrestoDatasetTypePropertiesTable
    :param schema_type_properties_schema: The schema name of the Presto. Type: string (or
     Expression with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.PrestoDatasetTypePropertiesSchema
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'PrestoDatasetTypePropertiesTableName'},
        'table': {'key': 'typeProperties.table', 'type': 'PrestoDatasetTypePropertiesTable'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'PrestoDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["PrestoDatasetTypePropertiesTableName"] = None,
        table: Optional["PrestoDatasetTypePropertiesTable"] = None,
        schema_type_properties_schema: Optional["PrestoDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(PrestoObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'PrestoObject'
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class PrestoSource(TabularSource):
    """A copy activity Presto server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.PrestoSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'PrestoSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["PrestoSourceQuery"] = None,
        **kwargs
    ):
        super(PrestoSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'PrestoSource'
        self.query = query


class PrestoSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(PrestoSourceQuery, self).__init__(**kwargs)


class QueryDataFlowDebugSessionsResponse(msrest.serialization.Model):
    """A list of active debug sessions.

    :param value: Array with all active debug sessions.
    :type value: list[~data_factory_management_client.models.DataFlowDebugSessionInfo]
    :param next_link: The link to the next page of results, if any remaining results exist.
    :type next_link: str
    """

    _attribute_map = {
        'value': {'key': 'value', 'type': '[DataFlowDebugSessionInfo]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: Optional[List["DataFlowDebugSessionInfo"]] = None,
        next_link: Optional[str] = None,
        **kwargs
    ):
        super(QueryDataFlowDebugSessionsResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class QuickBooksLinkedService(LinkedService):
    """QuickBooks server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param endpoint: Required. The endpoint of the QuickBooks server. (i.e.
     quickbooks.api.intuit.com).
    :type endpoint:
     ~data_factory_management_client.models.QuickBooksLinkedServiceTypePropertiesEndpoint
    :param company_id: Required. The company ID of the QuickBooks company to authorize.
    :type company_id:
     ~data_factory_management_client.models.QuickBooksLinkedServiceTypePropertiesCompanyId
    :param consumer_key: Required. The consumer key for OAuth 1.0 authentication.
    :type consumer_key:
     ~data_factory_management_client.models.QuickBooksLinkedServiceTypePropertiesConsumerKey
    :param consumer_secret: Required. The base definition of a secret type.
    :type consumer_secret: ~data_factory_management_client.models.SecretBase
    :param access_token: Required. The base definition of a secret type.
    :type access_token: ~data_factory_management_client.models.SecretBase
    :param access_token_secret: Required. The base definition of a secret type.
    :type access_token_secret: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.QuickBooksLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.QuickBooksLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'endpoint': {'required': True},
        'company_id': {'required': True},
        'consumer_key': {'required': True},
        'consumer_secret': {'required': True},
        'access_token': {'required': True},
        'access_token_secret': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'QuickBooksLinkedServiceTypePropertiesEndpoint'},
        'company_id': {'key': 'typeProperties.companyId', 'type': 'QuickBooksLinkedServiceTypePropertiesCompanyId'},
        'consumer_key': {'key': 'typeProperties.consumerKey', 'type': 'QuickBooksLinkedServiceTypePropertiesConsumerKey'},
        'consumer_secret': {'key': 'typeProperties.consumerSecret', 'type': 'SecretBase'},
        'access_token': {'key': 'typeProperties.accessToken', 'type': 'SecretBase'},
        'access_token_secret': {'key': 'typeProperties.accessTokenSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'QuickBooksLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'QuickBooksLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        endpoint: "QuickBooksLinkedServiceTypePropertiesEndpoint",
        company_id: "QuickBooksLinkedServiceTypePropertiesCompanyId",
        consumer_key: "QuickBooksLinkedServiceTypePropertiesConsumerKey",
        consumer_secret: "SecretBase",
        access_token: "SecretBase",
        access_token_secret: "SecretBase",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        use_encrypted_endpoints: Optional["QuickBooksLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        encrypted_credential: Optional["QuickBooksLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(QuickBooksLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'QuickBooks'
        self.endpoint = endpoint
        self.company_id = company_id
        self.consumer_key = consumer_key
        self.consumer_secret = consumer_secret
        self.access_token = access_token
        self.access_token_secret = access_token_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.encrypted_credential = encrypted_credential


class QuickBooksLinkedServiceTypeProperties(msrest.serialization.Model):
    """QuickBooks server linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param endpoint: Required. The endpoint of the QuickBooks server. (i.e.
     quickbooks.api.intuit.com).
    :type endpoint:
     ~data_factory_management_client.models.QuickBooksLinkedServiceTypePropertiesEndpoint
    :param company_id: Required. The company ID of the QuickBooks company to authorize.
    :type company_id:
     ~data_factory_management_client.models.QuickBooksLinkedServiceTypePropertiesCompanyId
    :param consumer_key: Required. The consumer key for OAuth 1.0 authentication.
    :type consumer_key:
     ~data_factory_management_client.models.QuickBooksLinkedServiceTypePropertiesConsumerKey
    :param consumer_secret: Required. The base definition of a secret type.
    :type consumer_secret: ~data_factory_management_client.models.SecretBase
    :param access_token: Required. The base definition of a secret type.
    :type access_token: ~data_factory_management_client.models.SecretBase
    :param access_token_secret: Required. The base definition of a secret type.
    :type access_token_secret: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.QuickBooksLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.QuickBooksLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'endpoint': {'required': True},
        'company_id': {'required': True},
        'consumer_key': {'required': True},
        'consumer_secret': {'required': True},
        'access_token': {'required': True},
        'access_token_secret': {'required': True},
    }

    _attribute_map = {
        'endpoint': {'key': 'endpoint', 'type': 'QuickBooksLinkedServiceTypePropertiesEndpoint'},
        'company_id': {'key': 'companyId', 'type': 'QuickBooksLinkedServiceTypePropertiesCompanyId'},
        'consumer_key': {'key': 'consumerKey', 'type': 'QuickBooksLinkedServiceTypePropertiesConsumerKey'},
        'consumer_secret': {'key': 'consumerSecret', 'type': 'SecretBase'},
        'access_token': {'key': 'accessToken', 'type': 'SecretBase'},
        'access_token_secret': {'key': 'accessTokenSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'QuickBooksLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'QuickBooksLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        endpoint: "QuickBooksLinkedServiceTypePropertiesEndpoint",
        company_id: "QuickBooksLinkedServiceTypePropertiesCompanyId",
        consumer_key: "QuickBooksLinkedServiceTypePropertiesConsumerKey",
        consumer_secret: "SecretBase",
        access_token: "SecretBase",
        access_token_secret: "SecretBase",
        use_encrypted_endpoints: Optional["QuickBooksLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        encrypted_credential: Optional["QuickBooksLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(QuickBooksLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.endpoint = endpoint
        self.company_id = company_id
        self.consumer_key = consumer_key
        self.consumer_secret = consumer_secret
        self.access_token = access_token
        self.access_token_secret = access_token_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.encrypted_credential = encrypted_credential


class QuickBooksLinkedServiceTypePropertiesCompanyId(msrest.serialization.Model):
    """The company ID of the QuickBooks company to authorize.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(QuickBooksLinkedServiceTypePropertiesCompanyId, self).__init__(**kwargs)


class QuickBooksLinkedServiceTypePropertiesConsumerKey(msrest.serialization.Model):
    """The consumer key for OAuth 1.0 authentication.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(QuickBooksLinkedServiceTypePropertiesConsumerKey, self).__init__(**kwargs)


class QuickBooksLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(QuickBooksLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class QuickBooksLinkedServiceTypePropertiesEndpoint(msrest.serialization.Model):
    """The endpoint of the QuickBooks server. (i.e. quickbooks.api.intuit.com).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(QuickBooksLinkedServiceTypePropertiesEndpoint, self).__init__(**kwargs)


class QuickBooksLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(QuickBooksLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class QuickBooksObjectDataset(Dataset):
    """QuickBooks server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(QuickBooksObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'QuickBooksObject'
        self.table_name = table_name


class QuickBooksSource(TabularSource):
    """A copy activity QuickBooks server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.QuickBooksSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'QuickBooksSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["QuickBooksSourceQuery"] = None,
        **kwargs
    ):
        super(QuickBooksSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'QuickBooksSource'
        self.query = query


class QuickBooksSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(QuickBooksSourceQuery, self).__init__(**kwargs)


class RecurrenceSchedule(msrest.serialization.Model):
    """The recurrence schedule.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param minutes: The minutes.
    :type minutes: list[int]
    :param hours: The hours.
    :type hours: list[int]
    :param week_days: The days of the week.
    :type week_days: list[str or ~data_factory_management_client.models.DaysOfWeek]
    :param month_days: The month days.
    :type month_days: list[int]
    :param monthly_occurrences: The monthly occurrences.
    :type monthly_occurrences:
     list[~data_factory_management_client.models.RecurrenceScheduleOccurrence]
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'minutes': {'key': 'minutes', 'type': '[int]'},
        'hours': {'key': 'hours', 'type': '[int]'},
        'week_days': {'key': 'weekDays', 'type': '[str]'},
        'month_days': {'key': 'monthDays', 'type': '[int]'},
        'monthly_occurrences': {'key': 'monthlyOccurrences', 'type': '[RecurrenceScheduleOccurrence]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        minutes: Optional[List[int]] = None,
        hours: Optional[List[int]] = None,
        week_days: Optional[List[Union[str, "DaysOfWeek"]]] = None,
        month_days: Optional[List[int]] = None,
        monthly_occurrences: Optional[List["RecurrenceScheduleOccurrence"]] = None,
        **kwargs
    ):
        super(RecurrenceSchedule, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.minutes = minutes
        self.hours = hours
        self.week_days = week_days
        self.month_days = month_days
        self.monthly_occurrences = monthly_occurrences


class RecurrenceScheduleOccurrence(msrest.serialization.Model):
    """The recurrence schedule occurrence.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param day: The days of the week. Possible values include: 'Sunday', 'Monday', 'Tuesday',
     'Wednesday', 'Thursday', 'Friday', 'Saturday'.
    :type day: str or ~data_factory_management_client.models.DayOfWeek
    :param occurrence: The occurrence.
    :type occurrence: int
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'day': {'key': 'day', 'type': 'str'},
        'occurrence': {'key': 'occurrence', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        day: Optional[Union[str, "DayOfWeek"]] = None,
        occurrence: Optional[int] = None,
        **kwargs
    ):
        super(RecurrenceScheduleOccurrence, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.day = day
        self.occurrence = occurrence


class RedirectIncompatibleRowSettings(msrest.serialization.Model):
    """Redirect incompatible row settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param linked_service_name: Required. Name of the Azure Storage, Storage SAS, or Azure Data
     Lake Store linked service used for redirecting incompatible row. Must be specified if
     redirectIncompatibleRowSettings is specified. Type: string (or Expression with resultType
     string).
    :type linked_service_name:
     ~data_factory_management_client.models.RedirectIncompatibleRowSettingsLinkedServiceName
    :param path: The path for storing the redirect incompatible row data. Type: string (or
     Expression with resultType string).
    :type path: ~data_factory_management_client.models.RedirectIncompatibleRowSettingsPath
    """

    _validation = {
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'RedirectIncompatibleRowSettingsLinkedServiceName'},
        'path': {'key': 'path', 'type': 'RedirectIncompatibleRowSettingsPath'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "RedirectIncompatibleRowSettingsLinkedServiceName",
        additional_properties: Optional[Dict[str, object]] = None,
        path: Optional["RedirectIncompatibleRowSettingsPath"] = None,
        **kwargs
    ):
        super(RedirectIncompatibleRowSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.linked_service_name = linked_service_name
        self.path = path


class RedirectIncompatibleRowSettingsLinkedServiceName(msrest.serialization.Model):
    """Name of the Azure Storage, Storage SAS, or Azure Data Lake Store linked service used for redirecting incompatible row. Must be specified if redirectIncompatibleRowSettings is specified. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RedirectIncompatibleRowSettingsLinkedServiceName, self).__init__(**kwargs)


class RedirectIncompatibleRowSettingsPath(msrest.serialization.Model):
    """The path for storing the redirect incompatible row data. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RedirectIncompatibleRowSettingsPath, self).__init__(**kwargs)


class RedshiftUnloadSettings(msrest.serialization.Model):
    """The Amazon S3 settings needed for the interim Amazon S3 when copying from Amazon Redshift with unload. With this, data from Amazon Redshift source will be unloaded into S3 first and then copied into the targeted sink from the interim S3.

    All required parameters must be populated in order to send to Azure.

    :param s3_linked_service_name: Required. Linked service reference type.
    :type s3_linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param bucket_name: Required. The bucket of the interim Amazon S3 which will be used to store
     the unloaded data from Amazon Redshift source. The bucket must be in the same region as the
     Amazon Redshift source. Type: string (or Expression with resultType string).
    :type bucket_name: ~data_factory_management_client.models.RedshiftUnloadSettingsBucketName
    """

    _validation = {
        's3_linked_service_name': {'required': True},
        'bucket_name': {'required': True},
    }

    _attribute_map = {
        's3_linked_service_name': {'key': 's3LinkedServiceName', 'type': 'LinkedServiceReference'},
        'bucket_name': {'key': 'bucketName', 'type': 'RedshiftUnloadSettingsBucketName'},
    }

    def __init__(
        self,
        *,
        s3_linked_service_name: "LinkedServiceReference",
        bucket_name: "RedshiftUnloadSettingsBucketName",
        **kwargs
    ):
        super(RedshiftUnloadSettings, self).__init__(**kwargs)
        self.s3_linked_service_name = s3_linked_service_name
        self.bucket_name = bucket_name


class RedshiftUnloadSettingsBucketName(msrest.serialization.Model):
    """The bucket of the interim Amazon S3 which will be used to store the unloaded data from Amazon Redshift source. The bucket must be in the same region as the Amazon Redshift source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RedshiftUnloadSettingsBucketName, self).__init__(**kwargs)


class RelationalSource(CopySource):
    """A copy activity source for various relational databases.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query: Database query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.RelationalSourceQuery
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query': {'key': 'query', 'type': 'RelationalSourceQuery'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query: Optional["RelationalSourceQuery"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(RelationalSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'RelationalSource'
        self.query = query
        self.additional_columns = additional_columns


class RelationalSourceQuery(msrest.serialization.Model):
    """Database query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RelationalSourceQuery, self).__init__(**kwargs)


class RelationalTableDataset(Dataset):
    """The relational table dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The relational table name. Type: string (or Expression with resultType
     string).
    :type table_name:
     ~data_factory_management_client.models.RelationalTableDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'RelationalTableDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["RelationalTableDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(RelationalTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'RelationalTable'
        self.table_name = table_name


class RelationalTableDatasetTypeProperties(msrest.serialization.Model):
    """Relational table dataset properties.

    :param table_name: The relational table name. Type: string (or Expression with resultType
     string).
    :type table_name:
     ~data_factory_management_client.models.RelationalTableDatasetTypePropertiesTableName
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'RelationalTableDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["RelationalTableDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(RelationalTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name


class RelationalTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """The relational table name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RelationalTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class RerunTumblingWindowTrigger(Trigger):
    """Trigger that schedules pipeline reruns for all fixed time interval windows from a requested start time to requested end time.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Trigger type.Constant filled by server.
    :type type: str
    :param description: Trigger description.
    :type description: str
    :ivar runtime_state: Enumerates possible state of Triggers. Possible values include: 'Started',
     'Stopped', 'Disabled'.
    :vartype runtime_state: str or ~data_factory_management_client.models.TriggerRuntimeState
    :param annotations: List of tags that can be used for describing the trigger.
    :type annotations: list[~data_factory_management_client.models.TriggerAnnotationsItem]
    :param parent_trigger: Required. The parent trigger reference.
    :type parent_trigger:
     ~data_factory_management_client.models.RerunTumblingWindowTriggerTypePropertiesParentTrigger
    :param requested_start_time: Required. The start time for the time period for which restatement
     is initiated. Only UTC time is currently supported.
    :type requested_start_time: ~datetime.datetime
    :param requested_end_time: Required. The end time for the time period for which restatement is
     initiated. Only UTC time is currently supported.
    :type requested_end_time: ~datetime.datetime
    :param rerun_concurrency: Required. The max number of parallel time windows (ready for
     execution) for which a rerun is triggered.
    :type rerun_concurrency: int
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
        'parent_trigger': {'required': True},
        'requested_start_time': {'required': True},
        'requested_end_time': {'required': True},
        'rerun_concurrency': {'required': True, 'maximum': 50, 'minimum': 1},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[TriggerAnnotationsItem]'},
        'parent_trigger': {'key': 'typeProperties.parentTrigger', 'type': 'RerunTumblingWindowTriggerTypePropertiesParentTrigger'},
        'requested_start_time': {'key': 'typeProperties.requestedStartTime', 'type': 'iso-8601'},
        'requested_end_time': {'key': 'typeProperties.requestedEndTime', 'type': 'iso-8601'},
        'rerun_concurrency': {'key': 'typeProperties.rerunConcurrency', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        parent_trigger: "RerunTumblingWindowTriggerTypePropertiesParentTrigger",
        requested_start_time: datetime.datetime,
        requested_end_time: datetime.datetime,
        rerun_concurrency: int,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        annotations: Optional[List["TriggerAnnotationsItem"]] = None,
        **kwargs
    ):
        super(RerunTumblingWindowTrigger, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, **kwargs)
        self.type = 'RerunTumblingWindowTrigger'
        self.parent_trigger = parent_trigger
        self.requested_start_time = requested_start_time
        self.requested_end_time = requested_end_time
        self.rerun_concurrency = rerun_concurrency


class RerunTumblingWindowTriggerTypeProperties(msrest.serialization.Model):
    """Rerun Trigger properties.

    All required parameters must be populated in order to send to Azure.

    :param parent_trigger: Required. The parent trigger reference.
    :type parent_trigger:
     ~data_factory_management_client.models.RerunTumblingWindowTriggerTypePropertiesParentTrigger
    :param requested_start_time: Required. The start time for the time period for which restatement
     is initiated. Only UTC time is currently supported.
    :type requested_start_time: ~datetime.datetime
    :param requested_end_time: Required. The end time for the time period for which restatement is
     initiated. Only UTC time is currently supported.
    :type requested_end_time: ~datetime.datetime
    :param rerun_concurrency: Required. The max number of parallel time windows (ready for
     execution) for which a rerun is triggered.
    :type rerun_concurrency: int
    """

    _validation = {
        'parent_trigger': {'required': True},
        'requested_start_time': {'required': True},
        'requested_end_time': {'required': True},
        'rerun_concurrency': {'required': True, 'maximum': 50, 'minimum': 1},
    }

    _attribute_map = {
        'parent_trigger': {'key': 'parentTrigger', 'type': 'RerunTumblingWindowTriggerTypePropertiesParentTrigger'},
        'requested_start_time': {'key': 'requestedStartTime', 'type': 'iso-8601'},
        'requested_end_time': {'key': 'requestedEndTime', 'type': 'iso-8601'},
        'rerun_concurrency': {'key': 'rerunConcurrency', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        parent_trigger: "RerunTumblingWindowTriggerTypePropertiesParentTrigger",
        requested_start_time: datetime.datetime,
        requested_end_time: datetime.datetime,
        rerun_concurrency: int,
        **kwargs
    ):
        super(RerunTumblingWindowTriggerTypeProperties, self).__init__(**kwargs)
        self.parent_trigger = parent_trigger
        self.requested_start_time = requested_start_time
        self.requested_end_time = requested_end_time
        self.rerun_concurrency = rerun_concurrency


class RerunTumblingWindowTriggerTypePropertiesParentTrigger(msrest.serialization.Model):
    """The parent trigger reference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RerunTumblingWindowTriggerTypePropertiesParentTrigger, self).__init__(**kwargs)


class ResponsysLinkedService(LinkedService):
    """Responsys linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param endpoint: Required. The endpoint of the Responsys server.
    :type endpoint:
     ~data_factory_management_client.models.ResponsysLinkedServiceTypePropertiesEndpoint
    :param client_id: Required. The client ID associated with the Responsys application. Type:
     string (or Expression with resultType string).
    :type client_id:
     ~data_factory_management_client.models.ResponsysLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true. Type: boolean (or Expression with resultType boolean).
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.ResponsysLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true. Type: boolean (or Expression with resultType boolean).
    :type use_host_verification:
     ~data_factory_management_client.models.ResponsysLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true. Type: boolean (or Expression with resultType
     boolean).
    :type use_peer_verification:
     ~data_factory_management_client.models.ResponsysLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.ResponsysLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'endpoint': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'ResponsysLinkedServiceTypePropertiesEndpoint'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'ResponsysLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'ResponsysLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'ResponsysLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'ResponsysLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'ResponsysLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        endpoint: "ResponsysLinkedServiceTypePropertiesEndpoint",
        client_id: "ResponsysLinkedServiceTypePropertiesClientId",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["ResponsysLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["ResponsysLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["ResponsysLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["ResponsysLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(ResponsysLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Responsys'
        self.endpoint = endpoint
        self.client_id = client_id
        self.client_secret = client_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class ResponsysLinkedServiceTypeProperties(msrest.serialization.Model):
    """Responsys linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param endpoint: Required. The endpoint of the Responsys server.
    :type endpoint:
     ~data_factory_management_client.models.ResponsysLinkedServiceTypePropertiesEndpoint
    :param client_id: Required. The client ID associated with the Responsys application. Type:
     string (or Expression with resultType string).
    :type client_id:
     ~data_factory_management_client.models.ResponsysLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true. Type: boolean (or Expression with resultType boolean).
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.ResponsysLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true. Type: boolean (or Expression with resultType boolean).
    :type use_host_verification:
     ~data_factory_management_client.models.ResponsysLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true. Type: boolean (or Expression with resultType
     boolean).
    :type use_peer_verification:
     ~data_factory_management_client.models.ResponsysLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.ResponsysLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'endpoint': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'endpoint': {'key': 'endpoint', 'type': 'ResponsysLinkedServiceTypePropertiesEndpoint'},
        'client_id': {'key': 'clientId', 'type': 'ResponsysLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'clientSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'ResponsysLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'ResponsysLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'ResponsysLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'ResponsysLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        endpoint: "ResponsysLinkedServiceTypePropertiesEndpoint",
        client_id: "ResponsysLinkedServiceTypePropertiesClientId",
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["ResponsysLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["ResponsysLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["ResponsysLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["ResponsysLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(ResponsysLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.endpoint = endpoint
        self.client_id = client_id
        self.client_secret = client_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class ResponsysLinkedServiceTypePropertiesClientId(msrest.serialization.Model):
    """The client ID associated with the Responsys application. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ResponsysLinkedServiceTypePropertiesClientId, self).__init__(**kwargs)


class ResponsysLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ResponsysLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class ResponsysLinkedServiceTypePropertiesEndpoint(msrest.serialization.Model):
    """The endpoint of the Responsys server.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ResponsysLinkedServiceTypePropertiesEndpoint, self).__init__(**kwargs)


class ResponsysLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ResponsysLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class ResponsysLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ResponsysLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class ResponsysLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ResponsysLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class ResponsysObjectDataset(Dataset):
    """Responsys dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(ResponsysObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'ResponsysObject'
        self.table_name = table_name


class ResponsysSource(TabularSource):
    """A copy activity Responsys source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.ResponsysSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'ResponsysSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["ResponsysSourceQuery"] = None,
        **kwargs
    ):
        super(ResponsysSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'ResponsysSource'
        self.query = query


class ResponsysSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ResponsysSourceQuery, self).__init__(**kwargs)


class RestResourceDataset(Dataset):
    """A Rest service dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param relative_url: The relative URL to the resource that the RESTful API provides. Type:
     string (or Expression with resultType string).
    :type relative_url:
     ~data_factory_management_client.models.RestResourceDatasetTypePropertiesRelativeUrl
    :param request_method: The HTTP method used to call the RESTful API. The default is GET. Type:
     string (or Expression with resultType string).
    :type request_method:
     ~data_factory_management_client.models.RestResourceDatasetTypePropertiesRequestMethod
    :param request_body: The HTTP request body to the RESTful API if requestMethod is POST. Type:
     string (or Expression with resultType string).
    :type request_body:
     ~data_factory_management_client.models.RestResourceDatasetTypePropertiesRequestBody
    :param additional_headers: The additional HTTP headers in the request to the RESTful API. Type:
     string (or Expression with resultType string).
    :type additional_headers:
     ~data_factory_management_client.models.RestResourceDatasetTypePropertiesAdditionalHeaders
    :param pagination_rules: The pagination rules to compose next page requests. Type: string (or
     Expression with resultType string).
    :type pagination_rules:
     ~data_factory_management_client.models.RestResourceDatasetTypePropertiesPaginationRules
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'relative_url': {'key': 'typeProperties.relativeUrl', 'type': 'RestResourceDatasetTypePropertiesRelativeUrl'},
        'request_method': {'key': 'typeProperties.requestMethod', 'type': 'RestResourceDatasetTypePropertiesRequestMethod'},
        'request_body': {'key': 'typeProperties.requestBody', 'type': 'RestResourceDatasetTypePropertiesRequestBody'},
        'additional_headers': {'key': 'typeProperties.additionalHeaders', 'type': 'RestResourceDatasetTypePropertiesAdditionalHeaders'},
        'pagination_rules': {'key': 'typeProperties.paginationRules', 'type': 'RestResourceDatasetTypePropertiesPaginationRules'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        relative_url: Optional["RestResourceDatasetTypePropertiesRelativeUrl"] = None,
        request_method: Optional["RestResourceDatasetTypePropertiesRequestMethod"] = None,
        request_body: Optional["RestResourceDatasetTypePropertiesRequestBody"] = None,
        additional_headers: Optional["RestResourceDatasetTypePropertiesAdditionalHeaders"] = None,
        pagination_rules: Optional["RestResourceDatasetTypePropertiesPaginationRules"] = None,
        **kwargs
    ):
        super(RestResourceDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'RestResource'
        self.relative_url = relative_url
        self.request_method = request_method
        self.request_body = request_body
        self.additional_headers = additional_headers
        self.pagination_rules = pagination_rules


class RestResourceDatasetTypeProperties(msrest.serialization.Model):
    """Properties specific to this dataset type.

    :param relative_url: The relative URL to the resource that the RESTful API provides. Type:
     string (or Expression with resultType string).
    :type relative_url:
     ~data_factory_management_client.models.RestResourceDatasetTypePropertiesRelativeUrl
    :param request_method: The HTTP method used to call the RESTful API. The default is GET. Type:
     string (or Expression with resultType string).
    :type request_method:
     ~data_factory_management_client.models.RestResourceDatasetTypePropertiesRequestMethod
    :param request_body: The HTTP request body to the RESTful API if requestMethod is POST. Type:
     string (or Expression with resultType string).
    :type request_body:
     ~data_factory_management_client.models.RestResourceDatasetTypePropertiesRequestBody
    :param additional_headers: The additional HTTP headers in the request to the RESTful API. Type:
     string (or Expression with resultType string).
    :type additional_headers:
     ~data_factory_management_client.models.RestResourceDatasetTypePropertiesAdditionalHeaders
    :param pagination_rules: The pagination rules to compose next page requests. Type: string (or
     Expression with resultType string).
    :type pagination_rules:
     ~data_factory_management_client.models.RestResourceDatasetTypePropertiesPaginationRules
    """

    _attribute_map = {
        'relative_url': {'key': 'relativeUrl', 'type': 'RestResourceDatasetTypePropertiesRelativeUrl'},
        'request_method': {'key': 'requestMethod', 'type': 'RestResourceDatasetTypePropertiesRequestMethod'},
        'request_body': {'key': 'requestBody', 'type': 'RestResourceDatasetTypePropertiesRequestBody'},
        'additional_headers': {'key': 'additionalHeaders', 'type': 'RestResourceDatasetTypePropertiesAdditionalHeaders'},
        'pagination_rules': {'key': 'paginationRules', 'type': 'RestResourceDatasetTypePropertiesPaginationRules'},
    }

    def __init__(
        self,
        *,
        relative_url: Optional["RestResourceDatasetTypePropertiesRelativeUrl"] = None,
        request_method: Optional["RestResourceDatasetTypePropertiesRequestMethod"] = None,
        request_body: Optional["RestResourceDatasetTypePropertiesRequestBody"] = None,
        additional_headers: Optional["RestResourceDatasetTypePropertiesAdditionalHeaders"] = None,
        pagination_rules: Optional["RestResourceDatasetTypePropertiesPaginationRules"] = None,
        **kwargs
    ):
        super(RestResourceDatasetTypeProperties, self).__init__(**kwargs)
        self.relative_url = relative_url
        self.request_method = request_method
        self.request_body = request_body
        self.additional_headers = additional_headers
        self.pagination_rules = pagination_rules


class RestResourceDatasetTypePropertiesAdditionalHeaders(msrest.serialization.Model):
    """The additional HTTP headers in the request to the RESTful API. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestResourceDatasetTypePropertiesAdditionalHeaders, self).__init__(**kwargs)


class RestResourceDatasetTypePropertiesPaginationRules(msrest.serialization.Model):
    """The pagination rules to compose next page requests. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestResourceDatasetTypePropertiesPaginationRules, self).__init__(**kwargs)


class RestResourceDatasetTypePropertiesRelativeUrl(msrest.serialization.Model):
    """The relative URL to the resource that the RESTful API provides. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestResourceDatasetTypePropertiesRelativeUrl, self).__init__(**kwargs)


class RestResourceDatasetTypePropertiesRequestBody(msrest.serialization.Model):
    """The HTTP request body to the RESTful API if requestMethod is POST. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestResourceDatasetTypePropertiesRequestBody, self).__init__(**kwargs)


class RestResourceDatasetTypePropertiesRequestMethod(msrest.serialization.Model):
    """The HTTP method used to call the RESTful API. The default is GET. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestResourceDatasetTypePropertiesRequestMethod, self).__init__(**kwargs)


class RestServiceLinkedService(LinkedService):
    """Rest Service linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param url: Required. The base URL of the REST service.
    :type url: ~data_factory_management_client.models.RestServiceLinkedServiceTypePropertiesUrl
    :param enable_server_certificate_validation: Whether to validate server side SSL certificate
     when connecting to the endpoint.The default value is true. Type: boolean (or Expression with
     resultType boolean).
    :type enable_server_certificate_validation:
     ~data_factory_management_client.models.RestServiceLinkedServiceTypePropertiesEnableServerCertificateValidation
    :param authentication_type: Required. Type of authentication used to connect to the REST
     service. Possible values include: 'Anonymous', 'Basic', 'AadServicePrincipal',
     'ManagedServiceIdentity'.
    :type authentication_type: str or
     ~data_factory_management_client.models.RestServiceAuthenticationType
    :param user_name: The user name used in Basic authentication type.
    :type user_name:
     ~data_factory_management_client.models.RestServiceLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param service_principal_id: The application's client ID used in AadServicePrincipal
     authentication type.
    :type service_principal_id:
     ~data_factory_management_client.models.RestServiceLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The tenant information (domain name or tenant ID) used in AadServicePrincipal
     authentication type under which your application resides.
    :type tenant:
     ~data_factory_management_client.models.RestServiceLinkedServiceTypePropertiesTenant
    :param aad_resource_id: The resource you are requesting authorization to use.
    :type aad_resource_id:
     ~data_factory_management_client.models.RestServiceLinkedServiceTypePropertiesAadResourceId
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.RestServiceLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'url': {'key': 'typeProperties.url', 'type': 'RestServiceLinkedServiceTypePropertiesUrl'},
        'enable_server_certificate_validation': {'key': 'typeProperties.enableServerCertificateValidation', 'type': 'RestServiceLinkedServiceTypePropertiesEnableServerCertificateValidation'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'RestServiceLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'RestServiceLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'RestServiceLinkedServiceTypePropertiesTenant'},
        'aad_resource_id': {'key': 'typeProperties.aadResourceId', 'type': 'RestServiceLinkedServiceTypePropertiesAadResourceId'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'RestServiceLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        url: "RestServiceLinkedServiceTypePropertiesUrl",
        authentication_type: Union[str, "RestServiceAuthenticationType"],
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        enable_server_certificate_validation: Optional["RestServiceLinkedServiceTypePropertiesEnableServerCertificateValidation"] = None,
        user_name: Optional["RestServiceLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        service_principal_id: Optional["RestServiceLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["RestServiceLinkedServiceTypePropertiesTenant"] = None,
        aad_resource_id: Optional["RestServiceLinkedServiceTypePropertiesAadResourceId"] = None,
        encrypted_credential: Optional["RestServiceLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(RestServiceLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'RestService'
        self.url = url
        self.enable_server_certificate_validation = enable_server_certificate_validation
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.aad_resource_id = aad_resource_id
        self.encrypted_credential = encrypted_credential


class RestServiceLinkedServiceTypeProperties(msrest.serialization.Model):
    """Rest Service linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param url: Required. The base URL of the REST service.
    :type url: ~data_factory_management_client.models.RestServiceLinkedServiceTypePropertiesUrl
    :param enable_server_certificate_validation: Whether to validate server side SSL certificate
     when connecting to the endpoint.The default value is true. Type: boolean (or Expression with
     resultType boolean).
    :type enable_server_certificate_validation:
     ~data_factory_management_client.models.RestServiceLinkedServiceTypePropertiesEnableServerCertificateValidation
    :param authentication_type: Required. Type of authentication used to connect to the REST
     service. Possible values include: 'Anonymous', 'Basic', 'AadServicePrincipal',
     'ManagedServiceIdentity'.
    :type authentication_type: str or
     ~data_factory_management_client.models.RestServiceAuthenticationType
    :param user_name: The user name used in Basic authentication type.
    :type user_name:
     ~data_factory_management_client.models.RestServiceLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param service_principal_id: The application's client ID used in AadServicePrincipal
     authentication type.
    :type service_principal_id:
     ~data_factory_management_client.models.RestServiceLinkedServiceTypePropertiesServicePrincipalId
    :param service_principal_key: The base definition of a secret type.
    :type service_principal_key: ~data_factory_management_client.models.SecretBase
    :param tenant: The tenant information (domain name or tenant ID) used in AadServicePrincipal
     authentication type under which your application resides.
    :type tenant:
     ~data_factory_management_client.models.RestServiceLinkedServiceTypePropertiesTenant
    :param aad_resource_id: The resource you are requesting authorization to use.
    :type aad_resource_id:
     ~data_factory_management_client.models.RestServiceLinkedServiceTypePropertiesAadResourceId
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.RestServiceLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'url': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'RestServiceLinkedServiceTypePropertiesUrl'},
        'enable_server_certificate_validation': {'key': 'enableServerCertificateValidation', 'type': 'RestServiceLinkedServiceTypePropertiesEnableServerCertificateValidation'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'user_name': {'key': 'userName', 'type': 'RestServiceLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'RestServiceLinkedServiceTypePropertiesServicePrincipalId'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'tenant', 'type': 'RestServiceLinkedServiceTypePropertiesTenant'},
        'aad_resource_id': {'key': 'aadResourceId', 'type': 'RestServiceLinkedServiceTypePropertiesAadResourceId'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'RestServiceLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        url: "RestServiceLinkedServiceTypePropertiesUrl",
        authentication_type: Union[str, "RestServiceAuthenticationType"],
        enable_server_certificate_validation: Optional["RestServiceLinkedServiceTypePropertiesEnableServerCertificateValidation"] = None,
        user_name: Optional["RestServiceLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        service_principal_id: Optional["RestServiceLinkedServiceTypePropertiesServicePrincipalId"] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional["RestServiceLinkedServiceTypePropertiesTenant"] = None,
        aad_resource_id: Optional["RestServiceLinkedServiceTypePropertiesAadResourceId"] = None,
        encrypted_credential: Optional["RestServiceLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(RestServiceLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.url = url
        self.enable_server_certificate_validation = enable_server_certificate_validation
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.aad_resource_id = aad_resource_id
        self.encrypted_credential = encrypted_credential


class RestServiceLinkedServiceTypePropertiesAadResourceId(msrest.serialization.Model):
    """The resource you are requesting authorization to use.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestServiceLinkedServiceTypePropertiesAadResourceId, self).__init__(**kwargs)


class RestServiceLinkedServiceTypePropertiesEnableServerCertificateValidation(msrest.serialization.Model):
    """Whether to validate server side SSL certificate when connecting to the endpoint.The default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestServiceLinkedServiceTypePropertiesEnableServerCertificateValidation, self).__init__(**kwargs)


class RestServiceLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestServiceLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class RestServiceLinkedServiceTypePropertiesServicePrincipalId(msrest.serialization.Model):
    """The application's client ID used in AadServicePrincipal authentication type.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestServiceLinkedServiceTypePropertiesServicePrincipalId, self).__init__(**kwargs)


class RestServiceLinkedServiceTypePropertiesTenant(msrest.serialization.Model):
    """The tenant information (domain name or tenant ID) used in AadServicePrincipal authentication type under which your application resides.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestServiceLinkedServiceTypePropertiesTenant, self).__init__(**kwargs)


class RestServiceLinkedServiceTypePropertiesUrl(msrest.serialization.Model):
    """The base URL of the REST service.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestServiceLinkedServiceTypePropertiesUrl, self).__init__(**kwargs)


class RestServiceLinkedServiceTypePropertiesUserName(msrest.serialization.Model):
    """The user name used in Basic authentication type.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestServiceLinkedServiceTypePropertiesUserName, self).__init__(**kwargs)


class RestSource(CopySource):
    """A copy activity Rest service source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param request_method: The HTTP method used to call the RESTful API. The default is GET. Type:
     string (or Expression with resultType string).
    :type request_method: ~data_factory_management_client.models.RestSourceRequestMethod
    :param request_body: The HTTP request body to the RESTful API if requestMethod is POST. Type:
     string (or Expression with resultType string).
    :type request_body: ~data_factory_management_client.models.RestSourceRequestBody
    :param additional_headers: The additional HTTP headers in the request to the RESTful API. Type:
     string (or Expression with resultType string).
    :type additional_headers: ~data_factory_management_client.models.RestSourceAdditionalHeaders
    :param pagination_rules: The pagination rules to compose next page requests. Type: string (or
     Expression with resultType string).
    :type pagination_rules: ~data_factory_management_client.models.RestSourcePaginationRules
    :param http_request_timeout: The timeout (TimeSpan) to get an HTTP response. It is the timeout
     to get a response, not the timeout to read response data. Default value: 00:01:40. Type: string
     (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type http_request_timeout: ~data_factory_management_client.models.RestSourceHttpRequestTimeout
    :param request_interval: The time to await before sending next page request.
    :type request_interval: ~data_factory_management_client.models.RestSourceRequestInterval
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'request_method': {'key': 'requestMethod', 'type': 'RestSourceRequestMethod'},
        'request_body': {'key': 'requestBody', 'type': 'RestSourceRequestBody'},
        'additional_headers': {'key': 'additionalHeaders', 'type': 'RestSourceAdditionalHeaders'},
        'pagination_rules': {'key': 'paginationRules', 'type': 'RestSourcePaginationRules'},
        'http_request_timeout': {'key': 'httpRequestTimeout', 'type': 'RestSourceHttpRequestTimeout'},
        'request_interval': {'key': 'requestInterval', 'type': 'RestSourceRequestInterval'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        request_method: Optional["RestSourceRequestMethod"] = None,
        request_body: Optional["RestSourceRequestBody"] = None,
        additional_headers: Optional["RestSourceAdditionalHeaders"] = None,
        pagination_rules: Optional["RestSourcePaginationRules"] = None,
        http_request_timeout: Optional["RestSourceHttpRequestTimeout"] = None,
        request_interval: Optional["RestSourceRequestInterval"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(RestSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'RestSource'
        self.request_method = request_method
        self.request_body = request_body
        self.additional_headers = additional_headers
        self.pagination_rules = pagination_rules
        self.http_request_timeout = http_request_timeout
        self.request_interval = request_interval
        self.additional_columns = additional_columns


class RestSourceAdditionalHeaders(msrest.serialization.Model):
    """The additional HTTP headers in the request to the RESTful API. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestSourceAdditionalHeaders, self).__init__(**kwargs)


class RestSourceHttpRequestTimeout(msrest.serialization.Model):
    """The timeout (TimeSpan) to get an HTTP response. It is the timeout to get a response, not the timeout to read response data. Default value: 00:01:40. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestSourceHttpRequestTimeout, self).__init__(**kwargs)


class RestSourcePaginationRules(msrest.serialization.Model):
    """The pagination rules to compose next page requests. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestSourcePaginationRules, self).__init__(**kwargs)


class RestSourceRequestBody(msrest.serialization.Model):
    """The HTTP request body to the RESTful API if requestMethod is POST. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestSourceRequestBody, self).__init__(**kwargs)


class RestSourceRequestInterval(msrest.serialization.Model):
    """The time to await before sending next page request.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestSourceRequestInterval, self).__init__(**kwargs)


class RestSourceRequestMethod(msrest.serialization.Model):
    """The HTTP method used to call the RESTful API. The default is GET. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RestSourceRequestMethod, self).__init__(**kwargs)


class RetryPolicy(msrest.serialization.Model):
    """Execution policy for an activity.

    :param count: Maximum ordinary retry attempts. Default is 0. Type: integer (or Expression with
     resultType integer), minimum: 0.
    :type count: ~data_factory_management_client.models.RetryPolicyCount
    :param interval_in_seconds: Interval between retries in seconds. Default is 30.
    :type interval_in_seconds: int
    """

    _validation = {
        'interval_in_seconds': {'maximum': 86400, 'minimum': 30},
    }

    _attribute_map = {
        'count': {'key': 'count', 'type': 'RetryPolicyCount'},
        'interval_in_seconds': {'key': 'intervalInSeconds', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        count: Optional["RetryPolicyCount"] = None,
        interval_in_seconds: Optional[int] = None,
        **kwargs
    ):
        super(RetryPolicy, self).__init__(**kwargs)
        self.count = count
        self.interval_in_seconds = interval_in_seconds


class RetryPolicyCount(msrest.serialization.Model):
    """Maximum ordinary retry attempts. Default is 0. Type: integer (or Expression with resultType integer), minimum: 0.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(RetryPolicyCount, self).__init__(**kwargs)


class RunFilterParameters(msrest.serialization.Model):
    """Query parameters for listing runs.

    All required parameters must be populated in order to send to Azure.

    :param continuation_token: The continuation token for getting the next page of results. Null
     for first page.
    :type continuation_token: str
    :param last_updated_after: Required. The time at or after which the run event was updated in
     'ISO 8601' format.
    :type last_updated_after: ~datetime.datetime
    :param last_updated_before: Required. The time at or before which the run event was updated in
     'ISO 8601' format.
    :type last_updated_before: ~datetime.datetime
    :param filters: List of filters.
    :type filters: list[~data_factory_management_client.models.RunQueryFilter]
    :param order_by: List of OrderBy option.
    :type order_by: list[~data_factory_management_client.models.RunQueryOrderBy]
    """

    _validation = {
        'last_updated_after': {'required': True},
        'last_updated_before': {'required': True},
    }

    _attribute_map = {
        'continuation_token': {'key': 'continuationToken', 'type': 'str'},
        'last_updated_after': {'key': 'lastUpdatedAfter', 'type': 'iso-8601'},
        'last_updated_before': {'key': 'lastUpdatedBefore', 'type': 'iso-8601'},
        'filters': {'key': 'filters', 'type': '[RunQueryFilter]'},
        'order_by': {'key': 'orderBy', 'type': '[RunQueryOrderBy]'},
    }

    def __init__(
        self,
        *,
        last_updated_after: datetime.datetime,
        last_updated_before: datetime.datetime,
        continuation_token: Optional[str] = None,
        filters: Optional[List["RunQueryFilter"]] = None,
        order_by: Optional[List["RunQueryOrderBy"]] = None,
        **kwargs
    ):
        super(RunFilterParameters, self).__init__(**kwargs)
        self.continuation_token = continuation_token
        self.last_updated_after = last_updated_after
        self.last_updated_before = last_updated_before
        self.filters = filters
        self.order_by = order_by


class RunQueryFilter(msrest.serialization.Model):
    """Query filter option for listing runs.

    All required parameters must be populated in order to send to Azure.

    :param operand: Required. Parameter name to be used for filter. The allowed operands to query
     pipeline runs are PipelineName, RunStart, RunEnd and Status; to query activity runs are
     ActivityName, ActivityRunStart, ActivityRunEnd, ActivityType and Status, and to query trigger
     runs are TriggerName, TriggerRunTimestamp and Status. Possible values include: 'PipelineName',
     'Status', 'RunStart', 'RunEnd', 'ActivityName', 'ActivityRunStart', 'ActivityRunEnd',
     'ActivityType', 'TriggerName', 'TriggerRunTimestamp', 'RunGroupId', 'LatestOnly'.
    :type operand: str or ~data_factory_management_client.models.RunQueryFilterOperand
    :param operator: Required. Operator to be used for filter. Possible values include: 'Equals',
     'NotEquals', 'In', 'NotIn'.
    :type operator: str or ~data_factory_management_client.models.RunQueryFilterOperator
    :param values: Required. List of filter values.
    :type values: list[str]
    """

    _validation = {
        'operand': {'required': True},
        'operator': {'required': True},
        'values': {'required': True},
    }

    _attribute_map = {
        'operand': {'key': 'operand', 'type': 'str'},
        'operator': {'key': 'operator', 'type': 'str'},
        'values': {'key': 'values', 'type': '[str]'},
    }

    def __init__(
        self,
        *,
        operand: Union[str, "RunQueryFilterOperand"],
        operator: Union[str, "RunQueryFilterOperator"],
        values: List[str],
        **kwargs
    ):
        super(RunQueryFilter, self).__init__(**kwargs)
        self.operand = operand
        self.operator = operator
        self.values = values


class RunQueryOrderBy(msrest.serialization.Model):
    """An object to provide order by options for listing runs.

    All required parameters must be populated in order to send to Azure.

    :param order_by: Required. Parameter name to be used for order by. The allowed parameters to
     order by for pipeline runs are PipelineName, RunStart, RunEnd and Status; for activity runs are
     ActivityName, ActivityRunStart, ActivityRunEnd and Status; for trigger runs are TriggerName,
     TriggerRunTimestamp and Status. Possible values include: 'RunStart', 'RunEnd', 'PipelineName',
     'Status', 'ActivityName', 'ActivityRunStart', 'ActivityRunEnd', 'TriggerName',
     'TriggerRunTimestamp'.
    :type order_by: str or ~data_factory_management_client.models.RunQueryOrderByField
    :param order: Required. Sorting order of the parameter. Possible values include: 'ASC', 'DESC'.
    :type order: str or ~data_factory_management_client.models.RunQueryOrder
    """

    _validation = {
        'order_by': {'required': True},
        'order': {'required': True},
    }

    _attribute_map = {
        'order_by': {'key': 'orderBy', 'type': 'str'},
        'order': {'key': 'order', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        order_by: Union[str, "RunQueryOrderByField"],
        order: Union[str, "RunQueryOrder"],
        **kwargs
    ):
        super(RunQueryOrderBy, self).__init__(**kwargs)
        self.order_by = order_by
        self.order = order


class SalesforceLinkedService(LinkedService):
    """Linked service for Salesforce.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param environment_url: The URL of Salesforce instance. Default is
     'https://login.salesforce.com'. To copy data from sandbox, specify
     'https://test.salesforce.com'. To copy data from custom domain, specify, for example,
     'https://[domain].my.salesforce.com'. Type: string (or Expression with resultType string).
    :type environment_url:
     ~data_factory_management_client.models.SalesforceLinkedServiceTypePropertiesEnvironmentUrl
    :param username: The username for Basic authentication of the Salesforce instance. Type: string
     (or Expression with resultType string).
    :type username:
     ~data_factory_management_client.models.SalesforceLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param security_token: The base definition of a secret type.
    :type security_token: ~data_factory_management_client.models.SecretBase
    :param api_version: The Salesforce API version used in ADF. Type: string (or Expression with
     resultType string).
    :type api_version:
     ~data_factory_management_client.models.SalesforceLinkedServiceTypePropertiesApiVersion
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SalesforceLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'environment_url': {'key': 'typeProperties.environmentUrl', 'type': 'SalesforceLinkedServiceTypePropertiesEnvironmentUrl'},
        'username': {'key': 'typeProperties.username', 'type': 'SalesforceLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'security_token': {'key': 'typeProperties.securityToken', 'type': 'SecretBase'},
        'api_version': {'key': 'typeProperties.apiVersion', 'type': 'SalesforceLinkedServiceTypePropertiesApiVersion'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'SalesforceLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        environment_url: Optional["SalesforceLinkedServiceTypePropertiesEnvironmentUrl"] = None,
        username: Optional["SalesforceLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        security_token: Optional["SecretBase"] = None,
        api_version: Optional["SalesforceLinkedServiceTypePropertiesApiVersion"] = None,
        encrypted_credential: Optional["SalesforceLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SalesforceLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Salesforce'
        self.environment_url = environment_url
        self.username = username
        self.password = password
        self.security_token = security_token
        self.api_version = api_version
        self.encrypted_credential = encrypted_credential


class SalesforceLinkedServiceTypeProperties(msrest.serialization.Model):
    """Salesforce linked service properties.

    :param environment_url: The URL of Salesforce instance. Default is
     'https://login.salesforce.com'. To copy data from sandbox, specify
     'https://test.salesforce.com'. To copy data from custom domain, specify, for example,
     'https://[domain].my.salesforce.com'. Type: string (or Expression with resultType string).
    :type environment_url:
     ~data_factory_management_client.models.SalesforceLinkedServiceTypePropertiesEnvironmentUrl
    :param username: The username for Basic authentication of the Salesforce instance. Type: string
     (or Expression with resultType string).
    :type username:
     ~data_factory_management_client.models.SalesforceLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param security_token: The base definition of a secret type.
    :type security_token: ~data_factory_management_client.models.SecretBase
    :param api_version: The Salesforce API version used in ADF. Type: string (or Expression with
     resultType string).
    :type api_version:
     ~data_factory_management_client.models.SalesforceLinkedServiceTypePropertiesApiVersion
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SalesforceLinkedServiceTypePropertiesEncryptedCredential
    """

    _attribute_map = {
        'environment_url': {'key': 'environmentUrl', 'type': 'SalesforceLinkedServiceTypePropertiesEnvironmentUrl'},
        'username': {'key': 'username', 'type': 'SalesforceLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'security_token': {'key': 'securityToken', 'type': 'SecretBase'},
        'api_version': {'key': 'apiVersion', 'type': 'SalesforceLinkedServiceTypePropertiesApiVersion'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'SalesforceLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        environment_url: Optional["SalesforceLinkedServiceTypePropertiesEnvironmentUrl"] = None,
        username: Optional["SalesforceLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        security_token: Optional["SecretBase"] = None,
        api_version: Optional["SalesforceLinkedServiceTypePropertiesApiVersion"] = None,
        encrypted_credential: Optional["SalesforceLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SalesforceLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.environment_url = environment_url
        self.username = username
        self.password = password
        self.security_token = security_token
        self.api_version = api_version
        self.encrypted_credential = encrypted_credential


class SalesforceLinkedServiceTypePropertiesApiVersion(msrest.serialization.Model):
    """The Salesforce API version used in ADF. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceLinkedServiceTypePropertiesApiVersion, self).__init__(**kwargs)


class SalesforceLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class SalesforceLinkedServiceTypePropertiesEnvironmentUrl(msrest.serialization.Model):
    """The URL of Salesforce instance. Default is 'https://login.salesforce.com'. To copy data from sandbox, specify 'https://test.salesforce.com'. To copy data from custom domain, specify, for example, 'https://[domain].my.salesforce.com'. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceLinkedServiceTypePropertiesEnvironmentUrl, self).__init__(**kwargs)


class SalesforceLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """The username for Basic authentication of the Salesforce instance. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class SalesforceMarketingCloudLinkedService(LinkedService):
    """Salesforce Marketing Cloud linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param client_id: Required. The client ID associated with the Salesforce Marketing Cloud
     application. Type: string (or Expression with resultType string).
    :type client_id:
     ~data_factory_management_client.models.SalesforceMarketingCloudLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true. Type: boolean (or Expression with resultType boolean).
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.SalesforceMarketingCloudLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true. Type: boolean (or Expression with resultType boolean).
    :type use_host_verification:
     ~data_factory_management_client.models.SalesforceMarketingCloudLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true. Type: boolean (or Expression with resultType
     boolean).
    :type use_peer_verification:
     ~data_factory_management_client.models.SalesforceMarketingCloudLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SalesforceMarketingCloudLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'SalesforceMarketingCloudLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'SalesforceMarketingCloudLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'SalesforceMarketingCloudLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'SalesforceMarketingCloudLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'SalesforceMarketingCloudLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        client_id: "SalesforceMarketingCloudLinkedServiceTypePropertiesClientId",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["SalesforceMarketingCloudLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["SalesforceMarketingCloudLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["SalesforceMarketingCloudLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["SalesforceMarketingCloudLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SalesforceMarketingCloudLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SalesforceMarketingCloud'
        self.client_id = client_id
        self.client_secret = client_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class SalesforceMarketingCloudLinkedServiceTypeProperties(msrest.serialization.Model):
    """Salesforce Marketing Cloud linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param client_id: Required. The client ID associated with the Salesforce Marketing Cloud
     application. Type: string (or Expression with resultType string).
    :type client_id:
     ~data_factory_management_client.models.SalesforceMarketingCloudLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true. Type: boolean (or Expression with resultType boolean).
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.SalesforceMarketingCloudLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true. Type: boolean (or Expression with resultType boolean).
    :type use_host_verification:
     ~data_factory_management_client.models.SalesforceMarketingCloudLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true. Type: boolean (or Expression with resultType
     boolean).
    :type use_peer_verification:
     ~data_factory_management_client.models.SalesforceMarketingCloudLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SalesforceMarketingCloudLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'client_id': {'required': True},
    }

    _attribute_map = {
        'client_id': {'key': 'clientId', 'type': 'SalesforceMarketingCloudLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'clientSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'SalesforceMarketingCloudLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'SalesforceMarketingCloudLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'SalesforceMarketingCloudLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'SalesforceMarketingCloudLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        client_id: "SalesforceMarketingCloudLinkedServiceTypePropertiesClientId",
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["SalesforceMarketingCloudLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["SalesforceMarketingCloudLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["SalesforceMarketingCloudLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["SalesforceMarketingCloudLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SalesforceMarketingCloudLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.client_id = client_id
        self.client_secret = client_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class SalesforceMarketingCloudLinkedServiceTypePropertiesClientId(msrest.serialization.Model):
    """The client ID associated with the Salesforce Marketing Cloud application. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceMarketingCloudLinkedServiceTypePropertiesClientId, self).__init__(**kwargs)


class SalesforceMarketingCloudLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceMarketingCloudLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class SalesforceMarketingCloudLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceMarketingCloudLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class SalesforceMarketingCloudLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceMarketingCloudLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class SalesforceMarketingCloudLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceMarketingCloudLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class SalesforceMarketingCloudObjectDataset(Dataset):
    """Salesforce Marketing Cloud dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(SalesforceMarketingCloudObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SalesforceMarketingCloudObject'
        self.table_name = table_name


class SalesforceMarketingCloudSource(TabularSource):
    """A copy activity Salesforce Marketing Cloud source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.SalesforceMarketingCloudSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'SalesforceMarketingCloudSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["SalesforceMarketingCloudSourceQuery"] = None,
        **kwargs
    ):
        super(SalesforceMarketingCloudSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SalesforceMarketingCloudSource'
        self.query = query


class SalesforceMarketingCloudSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceMarketingCloudSourceQuery, self).__init__(**kwargs)


class SalesforceObjectDataset(Dataset):
    """The Salesforce object dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param object_api_name: The Salesforce object API name. Type: string (or Expression with
     resultType string).
    :type object_api_name:
     ~data_factory_management_client.models.SalesforceObjectDatasetTypePropertiesObjectApiName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'object_api_name': {'key': 'typeProperties.objectApiName', 'type': 'SalesforceObjectDatasetTypePropertiesObjectApiName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        object_api_name: Optional["SalesforceObjectDatasetTypePropertiesObjectApiName"] = None,
        **kwargs
    ):
        super(SalesforceObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SalesforceObject'
        self.object_api_name = object_api_name


class SalesforceObjectDatasetTypeProperties(msrest.serialization.Model):
    """Salesforce object dataset properties.

    :param object_api_name: The Salesforce object API name. Type: string (or Expression with
     resultType string).
    :type object_api_name:
     ~data_factory_management_client.models.SalesforceObjectDatasetTypePropertiesObjectApiName
    """

    _attribute_map = {
        'object_api_name': {'key': 'objectApiName', 'type': 'SalesforceObjectDatasetTypePropertiesObjectApiName'},
    }

    def __init__(
        self,
        *,
        object_api_name: Optional["SalesforceObjectDatasetTypePropertiesObjectApiName"] = None,
        **kwargs
    ):
        super(SalesforceObjectDatasetTypeProperties, self).__init__(**kwargs)
        self.object_api_name = object_api_name


class SalesforceObjectDatasetTypePropertiesObjectApiName(msrest.serialization.Model):
    """The Salesforce object API name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceObjectDatasetTypePropertiesObjectApiName, self).__init__(**kwargs)


class SalesforceServiceCloudLinkedService(LinkedService):
    """Linked service for Salesforce Service Cloud.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param environment_url: The URL of Salesforce Service Cloud instance. Default is
     'https://login.salesforce.com'. To copy data from sandbox, specify
     'https://test.salesforce.com'. To copy data from custom domain, specify, for example,
     'https://[domain].my.salesforce.com'. Type: string (or Expression with resultType string).
    :type environment_url:
     ~data_factory_management_client.models.SalesforceServiceCloudLinkedServiceTypePropertiesEnvironmentUrl
    :param username: The username for Basic authentication of the Salesforce instance. Type: string
     (or Expression with resultType string).
    :type username:
     ~data_factory_management_client.models.SalesforceServiceCloudLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param security_token: The base definition of a secret type.
    :type security_token: ~data_factory_management_client.models.SecretBase
    :param api_version: The Salesforce API version used in ADF. Type: string (or Expression with
     resultType string).
    :type api_version:
     ~data_factory_management_client.models.SalesforceServiceCloudLinkedServiceTypePropertiesApiVersion
    :param extended_properties: Extended properties appended to the connection string. Type: string
     (or Expression with resultType string).
    :type extended_properties:
     ~data_factory_management_client.models.SalesforceServiceCloudLinkedServiceTypePropertiesExtendedProperties
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SalesforceServiceCloudLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'environment_url': {'key': 'typeProperties.environmentUrl', 'type': 'SalesforceServiceCloudLinkedServiceTypePropertiesEnvironmentUrl'},
        'username': {'key': 'typeProperties.username', 'type': 'SalesforceServiceCloudLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'security_token': {'key': 'typeProperties.securityToken', 'type': 'SecretBase'},
        'api_version': {'key': 'typeProperties.apiVersion', 'type': 'SalesforceServiceCloudLinkedServiceTypePropertiesApiVersion'},
        'extended_properties': {'key': 'typeProperties.extendedProperties', 'type': 'SalesforceServiceCloudLinkedServiceTypePropertiesExtendedProperties'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'SalesforceServiceCloudLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        environment_url: Optional["SalesforceServiceCloudLinkedServiceTypePropertiesEnvironmentUrl"] = None,
        username: Optional["SalesforceServiceCloudLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        security_token: Optional["SecretBase"] = None,
        api_version: Optional["SalesforceServiceCloudLinkedServiceTypePropertiesApiVersion"] = None,
        extended_properties: Optional["SalesforceServiceCloudLinkedServiceTypePropertiesExtendedProperties"] = None,
        encrypted_credential: Optional["SalesforceServiceCloudLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SalesforceServiceCloudLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SalesforceServiceCloud'
        self.environment_url = environment_url
        self.username = username
        self.password = password
        self.security_token = security_token
        self.api_version = api_version
        self.extended_properties = extended_properties
        self.encrypted_credential = encrypted_credential


class SalesforceServiceCloudLinkedServiceTypeProperties(msrest.serialization.Model):
    """Salesforce Service Cloud linked service properties.

    :param environment_url: The URL of Salesforce Service Cloud instance. Default is
     'https://login.salesforce.com'. To copy data from sandbox, specify
     'https://test.salesforce.com'. To copy data from custom domain, specify, for example,
     'https://[domain].my.salesforce.com'. Type: string (or Expression with resultType string).
    :type environment_url:
     ~data_factory_management_client.models.SalesforceServiceCloudLinkedServiceTypePropertiesEnvironmentUrl
    :param username: The username for Basic authentication of the Salesforce instance. Type: string
     (or Expression with resultType string).
    :type username:
     ~data_factory_management_client.models.SalesforceServiceCloudLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param security_token: The base definition of a secret type.
    :type security_token: ~data_factory_management_client.models.SecretBase
    :param api_version: The Salesforce API version used in ADF. Type: string (or Expression with
     resultType string).
    :type api_version:
     ~data_factory_management_client.models.SalesforceServiceCloudLinkedServiceTypePropertiesApiVersion
    :param extended_properties: Extended properties appended to the connection string. Type: string
     (or Expression with resultType string).
    :type extended_properties:
     ~data_factory_management_client.models.SalesforceServiceCloudLinkedServiceTypePropertiesExtendedProperties
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SalesforceServiceCloudLinkedServiceTypePropertiesEncryptedCredential
    """

    _attribute_map = {
        'environment_url': {'key': 'environmentUrl', 'type': 'SalesforceServiceCloudLinkedServiceTypePropertiesEnvironmentUrl'},
        'username': {'key': 'username', 'type': 'SalesforceServiceCloudLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'security_token': {'key': 'securityToken', 'type': 'SecretBase'},
        'api_version': {'key': 'apiVersion', 'type': 'SalesforceServiceCloudLinkedServiceTypePropertiesApiVersion'},
        'extended_properties': {'key': 'extendedProperties', 'type': 'SalesforceServiceCloudLinkedServiceTypePropertiesExtendedProperties'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'SalesforceServiceCloudLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        environment_url: Optional["SalesforceServiceCloudLinkedServiceTypePropertiesEnvironmentUrl"] = None,
        username: Optional["SalesforceServiceCloudLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        security_token: Optional["SecretBase"] = None,
        api_version: Optional["SalesforceServiceCloudLinkedServiceTypePropertiesApiVersion"] = None,
        extended_properties: Optional["SalesforceServiceCloudLinkedServiceTypePropertiesExtendedProperties"] = None,
        encrypted_credential: Optional["SalesforceServiceCloudLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SalesforceServiceCloudLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.environment_url = environment_url
        self.username = username
        self.password = password
        self.security_token = security_token
        self.api_version = api_version
        self.extended_properties = extended_properties
        self.encrypted_credential = encrypted_credential


class SalesforceServiceCloudLinkedServiceTypePropertiesApiVersion(msrest.serialization.Model):
    """The Salesforce API version used in ADF. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceServiceCloudLinkedServiceTypePropertiesApiVersion, self).__init__(**kwargs)


class SalesforceServiceCloudLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceServiceCloudLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class SalesforceServiceCloudLinkedServiceTypePropertiesEnvironmentUrl(msrest.serialization.Model):
    """The URL of Salesforce Service Cloud instance. Default is 'https://login.salesforce.com'. To copy data from sandbox, specify 'https://test.salesforce.com'. To copy data from custom domain, specify, for example, 'https://[domain].my.salesforce.com'. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceServiceCloudLinkedServiceTypePropertiesEnvironmentUrl, self).__init__(**kwargs)


class SalesforceServiceCloudLinkedServiceTypePropertiesExtendedProperties(msrest.serialization.Model):
    """Extended properties appended to the connection string. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceServiceCloudLinkedServiceTypePropertiesExtendedProperties, self).__init__(**kwargs)


class SalesforceServiceCloudLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """The username for Basic authentication of the Salesforce instance. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceServiceCloudLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class SalesforceServiceCloudObjectDataset(Dataset):
    """The Salesforce Service Cloud object dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param object_api_name: The Salesforce Service Cloud object API name. Type: string (or
     Expression with resultType string).
    :type object_api_name:
     ~data_factory_management_client.models.SalesforceServiceCloudObjectDatasetTypePropertiesObjectApiName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'object_api_name': {'key': 'typeProperties.objectApiName', 'type': 'SalesforceServiceCloudObjectDatasetTypePropertiesObjectApiName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        object_api_name: Optional["SalesforceServiceCloudObjectDatasetTypePropertiesObjectApiName"] = None,
        **kwargs
    ):
        super(SalesforceServiceCloudObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SalesforceServiceCloudObject'
        self.object_api_name = object_api_name


class SalesforceServiceCloudObjectDatasetTypeProperties(msrest.serialization.Model):
    """Salesforce Service Cloud object dataset properties.

    :param object_api_name: The Salesforce Service Cloud object API name. Type: string (or
     Expression with resultType string).
    :type object_api_name:
     ~data_factory_management_client.models.SalesforceServiceCloudObjectDatasetTypePropertiesObjectApiName
    """

    _attribute_map = {
        'object_api_name': {'key': 'objectApiName', 'type': 'SalesforceServiceCloudObjectDatasetTypePropertiesObjectApiName'},
    }

    def __init__(
        self,
        *,
        object_api_name: Optional["SalesforceServiceCloudObjectDatasetTypePropertiesObjectApiName"] = None,
        **kwargs
    ):
        super(SalesforceServiceCloudObjectDatasetTypeProperties, self).__init__(**kwargs)
        self.object_api_name = object_api_name


class SalesforceServiceCloudObjectDatasetTypePropertiesObjectApiName(msrest.serialization.Model):
    """The Salesforce Service Cloud object API name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceServiceCloudObjectDatasetTypePropertiesObjectApiName, self).__init__(**kwargs)


class SalesforceServiceCloudSink(CopySink):
    """A copy activity Salesforce Service Cloud sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param write_behavior: The write behavior for the operation. Default is Insert. Possible values
     include: 'Insert', 'Upsert'.
    :type write_behavior: str or ~data_factory_management_client.models.SalesforceSinkWriteBehavior
    :param external_id_field_name: The name of the external ID field for upsert operation. Default
     value is 'Id' column. Type: string (or Expression with resultType string).
    :type external_id_field_name:
     ~data_factory_management_client.models.SalesforceServiceCloudSinkExternalIdFieldName
    :param ignore_null_values: The flag indicating whether or not to ignore null values from input
     dataset (except key fields) during write operation. Default value is false. If set it to true,
     it means ADF will leave the data in the destination object unchanged when doing upsert/update
     operation and insert defined default value when doing insert operation, versus ADF will update
     the data in the destination object to NULL when doing upsert/update operation and insert NULL
     value when doing insert operation. Type: boolean (or Expression with resultType boolean).
    :type ignore_null_values:
     ~data_factory_management_client.models.SalesforceServiceCloudSinkIgnoreNullValues
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'str'},
        'external_id_field_name': {'key': 'externalIdFieldName', 'type': 'SalesforceServiceCloudSinkExternalIdFieldName'},
        'ignore_null_values': {'key': 'ignoreNullValues', 'type': 'SalesforceServiceCloudSinkIgnoreNullValues'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        write_behavior: Optional[Union[str, "SalesforceSinkWriteBehavior"]] = None,
        external_id_field_name: Optional["SalesforceServiceCloudSinkExternalIdFieldName"] = None,
        ignore_null_values: Optional["SalesforceServiceCloudSinkIgnoreNullValues"] = None,
        **kwargs
    ):
        super(SalesforceServiceCloudSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'SalesforceServiceCloudSink'
        self.write_behavior = write_behavior
        self.external_id_field_name = external_id_field_name
        self.ignore_null_values = ignore_null_values


class SalesforceServiceCloudSinkExternalIdFieldName(msrest.serialization.Model):
    """The name of the external ID field for upsert operation. Default value is 'Id' column. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceServiceCloudSinkExternalIdFieldName, self).__init__(**kwargs)


class SalesforceServiceCloudSinkIgnoreNullValues(msrest.serialization.Model):
    """The flag indicating whether or not to ignore null values from input dataset (except key fields) during write operation. Default value is false. If set it to true, it means ADF will leave the data in the destination object unchanged when doing upsert/update operation and insert defined default value when doing insert operation, versus ADF will update the data in the destination object to NULL when doing upsert/update operation and insert NULL value when doing insert operation. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceServiceCloudSinkIgnoreNullValues, self).__init__(**kwargs)


class SalesforceServiceCloudSource(CopySource):
    """A copy activity Salesforce Service Cloud source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query: Database query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.SalesforceServiceCloudSourceQuery
    :param read_behavior: The read behavior for the operation. Default is Query. Possible values
     include: 'Query', 'QueryAll'.
    :type read_behavior: str or ~data_factory_management_client.models.SalesforceSourceReadBehavior
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query': {'key': 'query', 'type': 'SalesforceServiceCloudSourceQuery'},
        'read_behavior': {'key': 'readBehavior', 'type': 'str'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query: Optional["SalesforceServiceCloudSourceQuery"] = None,
        read_behavior: Optional[Union[str, "SalesforceSourceReadBehavior"]] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(SalesforceServiceCloudSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'SalesforceServiceCloudSource'
        self.query = query
        self.read_behavior = read_behavior
        self.additional_columns = additional_columns


class SalesforceServiceCloudSourceQuery(msrest.serialization.Model):
    """Database query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceServiceCloudSourceQuery, self).__init__(**kwargs)


class SalesforceSink(CopySink):
    """A copy activity Salesforce sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param write_behavior: The write behavior for the operation. Default is Insert. Possible values
     include: 'Insert', 'Upsert'.
    :type write_behavior: str or ~data_factory_management_client.models.SalesforceSinkWriteBehavior
    :param external_id_field_name: The name of the external ID field for upsert operation. Default
     value is 'Id' column. Type: string (or Expression with resultType string).
    :type external_id_field_name:
     ~data_factory_management_client.models.SalesforceSinkExternalIdFieldName
    :param ignore_null_values: The flag indicating whether or not to ignore null values from input
     dataset (except key fields) during write operation. Default value is false. If set it to true,
     it means ADF will leave the data in the destination object unchanged when doing upsert/update
     operation and insert defined default value when doing insert operation, versus ADF will update
     the data in the destination object to NULL when doing upsert/update operation and insert NULL
     value when doing insert operation. Type: boolean (or Expression with resultType boolean).
    :type ignore_null_values: ~data_factory_management_client.models.SalesforceSinkIgnoreNullValues
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'str'},
        'external_id_field_name': {'key': 'externalIdFieldName', 'type': 'SalesforceSinkExternalIdFieldName'},
        'ignore_null_values': {'key': 'ignoreNullValues', 'type': 'SalesforceSinkIgnoreNullValues'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        write_behavior: Optional[Union[str, "SalesforceSinkWriteBehavior"]] = None,
        external_id_field_name: Optional["SalesforceSinkExternalIdFieldName"] = None,
        ignore_null_values: Optional["SalesforceSinkIgnoreNullValues"] = None,
        **kwargs
    ):
        super(SalesforceSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'SalesforceSink'
        self.write_behavior = write_behavior
        self.external_id_field_name = external_id_field_name
        self.ignore_null_values = ignore_null_values


class SalesforceSinkExternalIdFieldName(msrest.serialization.Model):
    """The name of the external ID field for upsert operation. Default value is 'Id' column. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceSinkExternalIdFieldName, self).__init__(**kwargs)


class SalesforceSinkIgnoreNullValues(msrest.serialization.Model):
    """The flag indicating whether or not to ignore null values from input dataset (except key fields) during write operation. Default value is false. If set it to true, it means ADF will leave the data in the destination object unchanged when doing upsert/update operation and insert defined default value when doing insert operation, versus ADF will update the data in the destination object to NULL when doing upsert/update operation and insert NULL value when doing insert operation. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceSinkIgnoreNullValues, self).__init__(**kwargs)


class SalesforceSource(TabularSource):
    """A copy activity Salesforce source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: Database query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.SalesforceSourceQuery
    :param read_behavior: The read behavior for the operation. Default is Query. Possible values
     include: 'Query', 'QueryAll'.
    :type read_behavior: str or ~data_factory_management_client.models.SalesforceSourceReadBehavior
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'SalesforceSourceQuery'},
        'read_behavior': {'key': 'readBehavior', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["SalesforceSourceQuery"] = None,
        read_behavior: Optional[Union[str, "SalesforceSourceReadBehavior"]] = None,
        **kwargs
    ):
        super(SalesforceSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SalesforceSource'
        self.query = query
        self.read_behavior = read_behavior


class SalesforceSourceQuery(msrest.serialization.Model):
    """Database query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SalesforceSourceQuery, self).__init__(**kwargs)


class SapBwCubeDataset(Dataset):
    """The SAP BW cube dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        super(SapBwCubeDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SapBwCube'


class SapBWLinkedService(LinkedService):
    """SAP Business Warehouse Linked Service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param server: Required. Host name of the SAP BW instance. Type: string (or Expression with
     resultType string).
    :type server: ~data_factory_management_client.models.SapBWLinkedServiceTypePropertiesServer
    :param system_number: Required. System number of the BW system. (Usually a two-digit decimal
     number represented as a string.) Type: string (or Expression with resultType string).
    :type system_number:
     ~data_factory_management_client.models.SapBWLinkedServiceTypePropertiesSystemNumber
    :param client_id: Required. Client ID of the client on the BW system. (Usually a three-digit
     decimal number represented as a string) Type: string (or Expression with resultType string).
    :type client_id:
     ~data_factory_management_client.models.SapBWLinkedServiceTypePropertiesClientId
    :param user_name: Username to access the SAP BW server. Type: string (or Expression with
     resultType string).
    :type user_name:
     ~data_factory_management_client.models.SapBWLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SapBWLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'server': {'required': True},
        'system_number': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'server': {'key': 'typeProperties.server', 'type': 'SapBWLinkedServiceTypePropertiesServer'},
        'system_number': {'key': 'typeProperties.systemNumber', 'type': 'SapBWLinkedServiceTypePropertiesSystemNumber'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'SapBWLinkedServiceTypePropertiesClientId'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'SapBWLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'SapBWLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        server: "SapBWLinkedServiceTypePropertiesServer",
        system_number: "SapBWLinkedServiceTypePropertiesSystemNumber",
        client_id: "SapBWLinkedServiceTypePropertiesClientId",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        user_name: Optional["SapBWLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["SapBWLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SapBWLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SapBW'
        self.server = server
        self.system_number = system_number
        self.client_id = client_id
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class SapBWLinkedServiceTypeProperties(msrest.serialization.Model):
    """Properties specific to this linked service type.

    All required parameters must be populated in order to send to Azure.

    :param server: Required. Host name of the SAP BW instance. Type: string (or Expression with
     resultType string).
    :type server: ~data_factory_management_client.models.SapBWLinkedServiceTypePropertiesServer
    :param system_number: Required. System number of the BW system. (Usually a two-digit decimal
     number represented as a string.) Type: string (or Expression with resultType string).
    :type system_number:
     ~data_factory_management_client.models.SapBWLinkedServiceTypePropertiesSystemNumber
    :param client_id: Required. Client ID of the client on the BW system. (Usually a three-digit
     decimal number represented as a string) Type: string (or Expression with resultType string).
    :type client_id:
     ~data_factory_management_client.models.SapBWLinkedServiceTypePropertiesClientId
    :param user_name: Username to access the SAP BW server. Type: string (or Expression with
     resultType string).
    :type user_name:
     ~data_factory_management_client.models.SapBWLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SapBWLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'server': {'required': True},
        'system_number': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'server': {'key': 'server', 'type': 'SapBWLinkedServiceTypePropertiesServer'},
        'system_number': {'key': 'systemNumber', 'type': 'SapBWLinkedServiceTypePropertiesSystemNumber'},
        'client_id': {'key': 'clientId', 'type': 'SapBWLinkedServiceTypePropertiesClientId'},
        'user_name': {'key': 'userName', 'type': 'SapBWLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'SapBWLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        server: "SapBWLinkedServiceTypePropertiesServer",
        system_number: "SapBWLinkedServiceTypePropertiesSystemNumber",
        client_id: "SapBWLinkedServiceTypePropertiesClientId",
        user_name: Optional["SapBWLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["SapBWLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SapBWLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.server = server
        self.system_number = system_number
        self.client_id = client_id
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class SapBWLinkedServiceTypePropertiesClientId(msrest.serialization.Model):
    """Client ID of the client on the BW system. (Usually a three-digit decimal number represented as a string) Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapBWLinkedServiceTypePropertiesClientId, self).__init__(**kwargs)


class SapBWLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapBWLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class SapBWLinkedServiceTypePropertiesServer(msrest.serialization.Model):
    """Host name of the SAP BW instance. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapBWLinkedServiceTypePropertiesServer, self).__init__(**kwargs)


class SapBWLinkedServiceTypePropertiesSystemNumber(msrest.serialization.Model):
    """System number of the BW system. (Usually a two-digit decimal number represented as a string.) Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapBWLinkedServiceTypePropertiesSystemNumber, self).__init__(**kwargs)


class SapBWLinkedServiceTypePropertiesUserName(msrest.serialization.Model):
    """Username to access the SAP BW server. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapBWLinkedServiceTypePropertiesUserName, self).__init__(**kwargs)


class SapBwSource(TabularSource):
    """A copy activity source for SapBW server via MDX.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: MDX query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.SapBwSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'SapBwSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["SapBwSourceQuery"] = None,
        **kwargs
    ):
        super(SapBwSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SapBwSource'
        self.query = query


class SapBwSourceQuery(msrest.serialization.Model):
    """MDX query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapBwSourceQuery, self).__init__(**kwargs)


class SapCloudForCustomerLinkedService(LinkedService):
    """Linked service for SAP Cloud for Customer.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param url: Required. The URL of SAP Cloud for Customer OData API. For example,
     '[https://[tenantname].crm.ondemand.com/sap/c4c/odata/v1]'. Type: string (or Expression with
     resultType string).
    :type url:
     ~data_factory_management_client.models.SapCloudForCustomerLinkedServiceTypePropertiesUrl
    :param username: The username for Basic authentication. Type: string (or Expression with
     resultType string).
    :type username:
     ~data_factory_management_client.models.SapCloudForCustomerLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Either encryptedCredential or
     username/password must be provided. Type: string (or Expression with resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SapCloudForCustomerLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'url': {'key': 'typeProperties.url', 'type': 'SapCloudForCustomerLinkedServiceTypePropertiesUrl'},
        'username': {'key': 'typeProperties.username', 'type': 'SapCloudForCustomerLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'SapCloudForCustomerLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        url: "SapCloudForCustomerLinkedServiceTypePropertiesUrl",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        username: Optional["SapCloudForCustomerLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["SapCloudForCustomerLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SapCloudForCustomerLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SapCloudForCustomer'
        self.url = url
        self.username = username
        self.password = password
        self.encrypted_credential = encrypted_credential


class SapCloudForCustomerLinkedServiceTypeProperties(msrest.serialization.Model):
    """SAP Cloud for Customer linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param url: Required. The URL of SAP Cloud for Customer OData API. For example,
     '[https://[tenantname].crm.ondemand.com/sap/c4c/odata/v1]'. Type: string (or Expression with
     resultType string).
    :type url:
     ~data_factory_management_client.models.SapCloudForCustomerLinkedServiceTypePropertiesUrl
    :param username: The username for Basic authentication. Type: string (or Expression with
     resultType string).
    :type username:
     ~data_factory_management_client.models.SapCloudForCustomerLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Either encryptedCredential or
     username/password must be provided. Type: string (or Expression with resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SapCloudForCustomerLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'url': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'SapCloudForCustomerLinkedServiceTypePropertiesUrl'},
        'username': {'key': 'username', 'type': 'SapCloudForCustomerLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'SapCloudForCustomerLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        url: "SapCloudForCustomerLinkedServiceTypePropertiesUrl",
        username: Optional["SapCloudForCustomerLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["SapCloudForCustomerLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SapCloudForCustomerLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.url = url
        self.username = username
        self.password = password
        self.encrypted_credential = encrypted_credential


class SapCloudForCustomerLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Either encryptedCredential or username/password must be provided. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapCloudForCustomerLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class SapCloudForCustomerLinkedServiceTypePropertiesUrl(msrest.serialization.Model):
    """The URL of SAP Cloud for Customer OData API. For example, '[https://[tenantname].crm.ondemand.com/sap/c4c/odata/v1]'. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapCloudForCustomerLinkedServiceTypePropertiesUrl, self).__init__(**kwargs)


class SapCloudForCustomerLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """The username for Basic authentication. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapCloudForCustomerLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class SapCloudForCustomerResourceDataset(Dataset):
    """The path of the SAP Cloud for Customer OData entity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param path: Required. The path of the SAP Cloud for Customer OData entity. Type: string (or
     Expression with resultType string).
    :type path:
     ~data_factory_management_client.models.SapCloudForCustomerResourceDatasetTypePropertiesPath
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'path': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'path': {'key': 'typeProperties.path', 'type': 'SapCloudForCustomerResourceDatasetTypePropertiesPath'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        path: "SapCloudForCustomerResourceDatasetTypePropertiesPath",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        super(SapCloudForCustomerResourceDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SapCloudForCustomerResource'
        self.path = path


class SapCloudForCustomerResourceDatasetTypeProperties(msrest.serialization.Model):
    """Sap Cloud For Customer OData resource dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param path: Required. The path of the SAP Cloud for Customer OData entity. Type: string (or
     Expression with resultType string).
    :type path:
     ~data_factory_management_client.models.SapCloudForCustomerResourceDatasetTypePropertiesPath
    """

    _validation = {
        'path': {'required': True},
    }

    _attribute_map = {
        'path': {'key': 'path', 'type': 'SapCloudForCustomerResourceDatasetTypePropertiesPath'},
    }

    def __init__(
        self,
        *,
        path: "SapCloudForCustomerResourceDatasetTypePropertiesPath",
        **kwargs
    ):
        super(SapCloudForCustomerResourceDatasetTypeProperties, self).__init__(**kwargs)
        self.path = path


class SapCloudForCustomerResourceDatasetTypePropertiesPath(msrest.serialization.Model):
    """The path of the SAP Cloud for Customer OData entity. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapCloudForCustomerResourceDatasetTypePropertiesPath, self).__init__(**kwargs)


class SapCloudForCustomerSink(CopySink):
    """A copy activity SAP Cloud for Customer sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param write_behavior: The write behavior for the operation. Default is 'Insert'. Possible
     values include: 'Insert', 'Update'.
    :type write_behavior: str or
     ~data_factory_management_client.models.SapCloudForCustomerSinkWriteBehavior
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        write_behavior: Optional[Union[str, "SapCloudForCustomerSinkWriteBehavior"]] = None,
        **kwargs
    ):
        super(SapCloudForCustomerSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'SapCloudForCustomerSink'
        self.write_behavior = write_behavior


class SapCloudForCustomerSource(TabularSource):
    """A copy activity source for SAP Cloud for Customer source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: SAP Cloud for Customer OData query. For example, "$top=1". Type: string (or
     Expression with resultType string).
    :type query: ~data_factory_management_client.models.SapCloudForCustomerSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'SapCloudForCustomerSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["SapCloudForCustomerSourceQuery"] = None,
        **kwargs
    ):
        super(SapCloudForCustomerSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SapCloudForCustomerSource'
        self.query = query


class SapCloudForCustomerSourceQuery(msrest.serialization.Model):
    """SAP Cloud for Customer OData query. For example, "$top=1". Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapCloudForCustomerSourceQuery, self).__init__(**kwargs)


class SapEccLinkedService(LinkedService):
    """Linked service for SAP ERP Central Component(SAP ECC).

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param url: Required. The URL of SAP ECC OData API. For example,
     '[https://hostname:port/sap/opu/odata/sap/servicename/]'. Type: string (or Expression with
     resultType string).
    :type url: str
    :param username: The username for Basic authentication. Type: string (or Expression with
     resultType string).
    :type username: str
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Either encryptedCredential or
     username/password must be provided. Type: string (or Expression with resultType string).
    :type encrypted_credential: str
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'url': {'key': 'typeProperties.url', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'str'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        url: str,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        username: Optional[str] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[str] = None,
        **kwargs
    ):
        super(SapEccLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SapEcc'
        self.url = url
        self.username = username
        self.password = password
        self.encrypted_credential = encrypted_credential


class SapEccLinkedServiceTypeProperties(msrest.serialization.Model):
    """SAP ECC linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param url: Required. The URL of SAP ECC OData API. For example,
     '[https://hostname:port/sap/opu/odata/sap/servicename/]'. Type: string (or Expression with
     resultType string).
    :type url: str
    :param username: The username for Basic authentication. Type: string (or Expression with
     resultType string).
    :type username: str
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Either encryptedCredential or
     username/password must be provided. Type: string (or Expression with resultType string).
    :type encrypted_credential: str
    """

    _validation = {
        'url': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'str'},
        'username': {'key': 'username', 'type': 'str'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        url: str,
        username: Optional[str] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[str] = None,
        **kwargs
    ):
        super(SapEccLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.url = url
        self.username = username
        self.password = password
        self.encrypted_credential = encrypted_credential


class SapEccResourceDataset(Dataset):
    """The path of the SAP ECC OData entity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param path: Required. The path of the SAP ECC OData entity. Type: string (or Expression with
     resultType string).
    :type path: ~data_factory_management_client.models.SapEccResourceDatasetTypePropertiesPath
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'path': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'path': {'key': 'typeProperties.path', 'type': 'SapEccResourceDatasetTypePropertiesPath'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        path: "SapEccResourceDatasetTypePropertiesPath",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        super(SapEccResourceDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SapEccResource'
        self.path = path


class SapEccResourceDatasetTypeProperties(msrest.serialization.Model):
    """Sap ECC OData resource dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param path: Required. The path of the SAP ECC OData entity. Type: string (or Expression with
     resultType string).
    :type path: ~data_factory_management_client.models.SapEccResourceDatasetTypePropertiesPath
    """

    _validation = {
        'path': {'required': True},
    }

    _attribute_map = {
        'path': {'key': 'path', 'type': 'SapEccResourceDatasetTypePropertiesPath'},
    }

    def __init__(
        self,
        *,
        path: "SapEccResourceDatasetTypePropertiesPath",
        **kwargs
    ):
        super(SapEccResourceDatasetTypeProperties, self).__init__(**kwargs)
        self.path = path


class SapEccResourceDatasetTypePropertiesPath(msrest.serialization.Model):
    """The path of the SAP ECC OData entity. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapEccResourceDatasetTypePropertiesPath, self).__init__(**kwargs)


class SapEccSource(TabularSource):
    """A copy activity source for SAP ECC source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: SAP ECC OData query. For example, "$top=1". Type: string (or Expression with
     resultType string).
    :type query: ~data_factory_management_client.models.SapEccSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'SapEccSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["SapEccSourceQuery"] = None,
        **kwargs
    ):
        super(SapEccSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SapEccSource'
        self.query = query


class SapEccSourceQuery(msrest.serialization.Model):
    """SAP ECC OData query. For example, "$top=1". Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapEccSourceQuery, self).__init__(**kwargs)


class SapHanaLinkedService(LinkedService):
    """SAP HANA Linked Service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: SAP HANA ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.SapHanaLinkedServicePropertiesConnectionString
    :param server: Required. Host name of the SAP HANA server. Type: string (or Expression with
     resultType string).
    :type server: ~data_factory_management_client.models.SapHanaLinkedServicePropertiesServer
    :param authentication_type: The authentication type to be used to connect to the SAP HANA
     server. Possible values include: 'Basic', 'Windows'.
    :type authentication_type: str or
     ~data_factory_management_client.models.SapHanaAuthenticationType
    :param user_name: Username to access the SAP HANA server. Type: string (or Expression with
     resultType string).
    :type user_name: ~data_factory_management_client.models.SapHanaLinkedServicePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SapHanaLinkedServicePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'server': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'SapHanaLinkedServicePropertiesConnectionString'},
        'server': {'key': 'typeProperties.server', 'type': 'SapHanaLinkedServicePropertiesServer'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'SapHanaLinkedServicePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'SapHanaLinkedServicePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        server: "SapHanaLinkedServicePropertiesServer",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        connection_string: Optional["SapHanaLinkedServicePropertiesConnectionString"] = None,
        authentication_type: Optional[Union[str, "SapHanaAuthenticationType"]] = None,
        user_name: Optional["SapHanaLinkedServicePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["SapHanaLinkedServicePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SapHanaLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SapHana'
        self.connection_string = connection_string
        self.server = server
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class SapHanaLinkedServiceProperties(msrest.serialization.Model):
    """Properties specific to this linked service type.

    All required parameters must be populated in order to send to Azure.

    :param connection_string: SAP HANA ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.SapHanaLinkedServicePropertiesConnectionString
    :param server: Required. Host name of the SAP HANA server. Type: string (or Expression with
     resultType string).
    :type server: ~data_factory_management_client.models.SapHanaLinkedServicePropertiesServer
    :param authentication_type: The authentication type to be used to connect to the SAP HANA
     server. Possible values include: 'Basic', 'Windows'.
    :type authentication_type: str or
     ~data_factory_management_client.models.SapHanaAuthenticationType
    :param user_name: Username to access the SAP HANA server. Type: string (or Expression with
     resultType string).
    :type user_name: ~data_factory_management_client.models.SapHanaLinkedServicePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SapHanaLinkedServicePropertiesEncryptedCredential
    """

    _validation = {
        'server': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'SapHanaLinkedServicePropertiesConnectionString'},
        'server': {'key': 'server', 'type': 'SapHanaLinkedServicePropertiesServer'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'user_name': {'key': 'userName', 'type': 'SapHanaLinkedServicePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'SapHanaLinkedServicePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        server: "SapHanaLinkedServicePropertiesServer",
        connection_string: Optional["SapHanaLinkedServicePropertiesConnectionString"] = None,
        authentication_type: Optional[Union[str, "SapHanaAuthenticationType"]] = None,
        user_name: Optional["SapHanaLinkedServicePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["SapHanaLinkedServicePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SapHanaLinkedServiceProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.server = server
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class SapHanaLinkedServicePropertiesConnectionString(msrest.serialization.Model):
    """SAP HANA ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapHanaLinkedServicePropertiesConnectionString, self).__init__(**kwargs)


class SapHanaLinkedServicePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapHanaLinkedServicePropertiesEncryptedCredential, self).__init__(**kwargs)


class SapHanaLinkedServicePropertiesServer(msrest.serialization.Model):
    """Host name of the SAP HANA server. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapHanaLinkedServicePropertiesServer, self).__init__(**kwargs)


class SapHanaLinkedServicePropertiesUserName(msrest.serialization.Model):
    """Username to access the SAP HANA server. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapHanaLinkedServicePropertiesUserName, self).__init__(**kwargs)


class SapHanaPartitionSettings(msrest.serialization.Model):
    """The settings that will be leveraged for SAP HANA source partitioning.

    :param partition_column_name: The name of the column that will be used for proceeding range
     partitioning. Type: string (or Expression with resultType string).
    :type partition_column_name:
     ~data_factory_management_client.models.SapHanaPartitionSettingsPartitionColumnName
    """

    _attribute_map = {
        'partition_column_name': {'key': 'partitionColumnName', 'type': 'SapHanaPartitionSettingsPartitionColumnName'},
    }

    def __init__(
        self,
        *,
        partition_column_name: Optional["SapHanaPartitionSettingsPartitionColumnName"] = None,
        **kwargs
    ):
        super(SapHanaPartitionSettings, self).__init__(**kwargs)
        self.partition_column_name = partition_column_name


class SapHanaPartitionSettingsPartitionColumnName(msrest.serialization.Model):
    """The name of the column that will be used for proceeding range partitioning. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapHanaPartitionSettingsPartitionColumnName, self).__init__(**kwargs)


class SapHanaSource(TabularSource):
    """A copy activity source for SAP HANA source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: SAP HANA Sql query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.SapHanaSourceQuery
    :param packet_size: The packet size of data read from SAP HANA. Type: integer(or Expression
     with resultType integer).
    :type packet_size: ~data_factory_management_client.models.SapHanaSourcePacketSize
    :param partition_option: The partition mechanism that will be used for SAP HANA read in
     parallel. Possible values include: 'None', 'PhysicalPartitionsOfTable', 'SapHanaDynamicRange'.
    :type partition_option: str or ~data_factory_management_client.models.SapHanaPartitionOption
    :param partition_settings: The settings that will be leveraged for SAP HANA source
     partitioning.
    :type partition_settings: ~data_factory_management_client.models.SapHanaPartitionSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'SapHanaSourceQuery'},
        'packet_size': {'key': 'packetSize', 'type': 'SapHanaSourcePacketSize'},
        'partition_option': {'key': 'partitionOption', 'type': 'str'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'SapHanaPartitionSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["SapHanaSourceQuery"] = None,
        packet_size: Optional["SapHanaSourcePacketSize"] = None,
        partition_option: Optional[Union[str, "SapHanaPartitionOption"]] = None,
        partition_settings: Optional["SapHanaPartitionSettings"] = None,
        **kwargs
    ):
        super(SapHanaSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SapHanaSource'
        self.query = query
        self.packet_size = packet_size
        self.partition_option = partition_option
        self.partition_settings = partition_settings


class SapHanaSourcePacketSize(msrest.serialization.Model):
    """The packet size of data read from SAP HANA. Type: integer(or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapHanaSourcePacketSize, self).__init__(**kwargs)


class SapHanaSourceQuery(msrest.serialization.Model):
    """SAP HANA Sql query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapHanaSourceQuery, self).__init__(**kwargs)


class SapHanaTableDataset(Dataset):
    """SAP HANA Table properties.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param schema_type_properties_schema: The schema name of SAP HANA. Type: string (or Expression
     with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.SapHanaTableDatasetTypePropertiesSchema
    :param table: The table name of SAP HANA. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.SapHanaTableDatasetTypePropertiesTable
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'SapHanaTableDatasetTypePropertiesSchema'},
        'table': {'key': 'typeProperties.table', 'type': 'SapHanaTableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        schema_type_properties_schema: Optional["SapHanaTableDatasetTypePropertiesSchema"] = None,
        table: Optional["SapHanaTableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(SapHanaTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SapHanaTable'
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class SapHanaTableDatasetTypeProperties(msrest.serialization.Model):
    """SAP HANA Table properties.

    :param schema: The schema name of SAP HANA. Type: string (or Expression with resultType
     string).
    :type schema: ~data_factory_management_client.models.SapHanaTableDatasetTypePropertiesSchema
    :param table: The table name of SAP HANA. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.SapHanaTableDatasetTypePropertiesTable
    """

    _attribute_map = {
        'schema': {'key': 'schema', 'type': 'SapHanaTableDatasetTypePropertiesSchema'},
        'table': {'key': 'table', 'type': 'SapHanaTableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        schema: Optional["SapHanaTableDatasetTypePropertiesSchema"] = None,
        table: Optional["SapHanaTableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(SapHanaTableDatasetTypeProperties, self).__init__(**kwargs)
        self.schema = schema
        self.table = table


class SapHanaTableDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of SAP HANA. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapHanaTableDatasetTypePropertiesSchema, self).__init__(**kwargs)


class SapHanaTableDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of SAP HANA. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapHanaTableDatasetTypePropertiesTable, self).__init__(**kwargs)


class SapOpenHubLinkedService(LinkedService):
    """SAP Business Warehouse Open Hub Destination Linked Service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param server: Required. Host name of the SAP BW instance where the open hub destination is
     located. Type: string (or Expression with resultType string).
    :type server:
     ~data_factory_management_client.models.SapOpenHubLinkedServiceTypePropertiesServer
    :param system_number: Required. System number of the BW system where the open hub destination
     is located. (Usually a two-digit decimal number represented as a string.) Type: string (or
     Expression with resultType string).
    :type system_number:
     ~data_factory_management_client.models.SapOpenHubLinkedServiceTypePropertiesSystemNumber
    :param client_id: Required. Client ID of the client on the BW system where the open hub
     destination is located. (Usually a three-digit decimal number represented as a string) Type:
     string (or Expression with resultType string).
    :type client_id:
     ~data_factory_management_client.models.SapOpenHubLinkedServiceTypePropertiesClientId
    :param language: Language of the BW system where the open hub destination is located. The
     default value is EN. Type: string (or Expression with resultType string).
    :type language:
     ~data_factory_management_client.models.SapOpenHubLinkedServiceTypePropertiesLanguage
    :param user_name: Username to access the SAP BW server where the open hub destination is
     located. Type: string (or Expression with resultType string).
    :type user_name:
     ~data_factory_management_client.models.SapOpenHubLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SapOpenHubLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'server': {'required': True},
        'system_number': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'server': {'key': 'typeProperties.server', 'type': 'SapOpenHubLinkedServiceTypePropertiesServer'},
        'system_number': {'key': 'typeProperties.systemNumber', 'type': 'SapOpenHubLinkedServiceTypePropertiesSystemNumber'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'SapOpenHubLinkedServiceTypePropertiesClientId'},
        'language': {'key': 'typeProperties.language', 'type': 'SapOpenHubLinkedServiceTypePropertiesLanguage'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'SapOpenHubLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'SapOpenHubLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        server: "SapOpenHubLinkedServiceTypePropertiesServer",
        system_number: "SapOpenHubLinkedServiceTypePropertiesSystemNumber",
        client_id: "SapOpenHubLinkedServiceTypePropertiesClientId",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        language: Optional["SapOpenHubLinkedServiceTypePropertiesLanguage"] = None,
        user_name: Optional["SapOpenHubLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["SapOpenHubLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SapOpenHubLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SapOpenHub'
        self.server = server
        self.system_number = system_number
        self.client_id = client_id
        self.language = language
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class SapOpenHubLinkedServiceTypeProperties(msrest.serialization.Model):
    """Properties specific to SAP Business Warehouse Open Hub Destination linked service type.

    All required parameters must be populated in order to send to Azure.

    :param server: Required. Host name of the SAP BW instance where the open hub destination is
     located. Type: string (or Expression with resultType string).
    :type server:
     ~data_factory_management_client.models.SapOpenHubLinkedServiceTypePropertiesServer
    :param system_number: Required. System number of the BW system where the open hub destination
     is located. (Usually a two-digit decimal number represented as a string.) Type: string (or
     Expression with resultType string).
    :type system_number:
     ~data_factory_management_client.models.SapOpenHubLinkedServiceTypePropertiesSystemNumber
    :param client_id: Required. Client ID of the client on the BW system where the open hub
     destination is located. (Usually a three-digit decimal number represented as a string) Type:
     string (or Expression with resultType string).
    :type client_id:
     ~data_factory_management_client.models.SapOpenHubLinkedServiceTypePropertiesClientId
    :param language: Language of the BW system where the open hub destination is located. The
     default value is EN. Type: string (or Expression with resultType string).
    :type language:
     ~data_factory_management_client.models.SapOpenHubLinkedServiceTypePropertiesLanguage
    :param user_name: Username to access the SAP BW server where the open hub destination is
     located. Type: string (or Expression with resultType string).
    :type user_name:
     ~data_factory_management_client.models.SapOpenHubLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SapOpenHubLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'server': {'required': True},
        'system_number': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'server': {'key': 'server', 'type': 'SapOpenHubLinkedServiceTypePropertiesServer'},
        'system_number': {'key': 'systemNumber', 'type': 'SapOpenHubLinkedServiceTypePropertiesSystemNumber'},
        'client_id': {'key': 'clientId', 'type': 'SapOpenHubLinkedServiceTypePropertiesClientId'},
        'language': {'key': 'language', 'type': 'SapOpenHubLinkedServiceTypePropertiesLanguage'},
        'user_name': {'key': 'userName', 'type': 'SapOpenHubLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'SapOpenHubLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        server: "SapOpenHubLinkedServiceTypePropertiesServer",
        system_number: "SapOpenHubLinkedServiceTypePropertiesSystemNumber",
        client_id: "SapOpenHubLinkedServiceTypePropertiesClientId",
        language: Optional["SapOpenHubLinkedServiceTypePropertiesLanguage"] = None,
        user_name: Optional["SapOpenHubLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["SapOpenHubLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SapOpenHubLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.server = server
        self.system_number = system_number
        self.client_id = client_id
        self.language = language
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class SapOpenHubLinkedServiceTypePropertiesClientId(msrest.serialization.Model):
    """Client ID of the client on the BW system where the open hub destination is located. (Usually a three-digit decimal number represented as a string) Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapOpenHubLinkedServiceTypePropertiesClientId, self).__init__(**kwargs)


class SapOpenHubLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapOpenHubLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class SapOpenHubLinkedServiceTypePropertiesLanguage(msrest.serialization.Model):
    """Language of the BW system where the open hub destination is located. The default value is EN. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapOpenHubLinkedServiceTypePropertiesLanguage, self).__init__(**kwargs)


class SapOpenHubLinkedServiceTypePropertiesServer(msrest.serialization.Model):
    """Host name of the SAP BW instance where the open hub destination is located. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapOpenHubLinkedServiceTypePropertiesServer, self).__init__(**kwargs)


class SapOpenHubLinkedServiceTypePropertiesSystemNumber(msrest.serialization.Model):
    """System number of the BW system where the open hub destination is located. (Usually a two-digit decimal number represented as a string.) Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapOpenHubLinkedServiceTypePropertiesSystemNumber, self).__init__(**kwargs)


class SapOpenHubLinkedServiceTypePropertiesUserName(msrest.serialization.Model):
    """Username to access the SAP BW server where the open hub destination is located. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapOpenHubLinkedServiceTypePropertiesUserName, self).__init__(**kwargs)


class SapOpenHubSource(TabularSource):
    """A copy activity source for SAP Business Warehouse Open Hub Destination source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param exclude_last_request: Whether to exclude the records of the last request. The default
     value is true. Type: boolean (or Expression with resultType boolean).
    :type exclude_last_request:
     ~data_factory_management_client.models.SapOpenHubSourceExcludeLastRequest
    :param base_request_id: The ID of request for delta loading. Once it is set, only data with
     requestId larger than the value of this property will be retrieved. The default value is 0.
     Type: integer (or Expression with resultType integer ).
    :type base_request_id: ~data_factory_management_client.models.SapOpenHubSourceBaseRequestId
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'exclude_last_request': {'key': 'excludeLastRequest', 'type': 'SapOpenHubSourceExcludeLastRequest'},
        'base_request_id': {'key': 'baseRequestId', 'type': 'SapOpenHubSourceBaseRequestId'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        exclude_last_request: Optional["SapOpenHubSourceExcludeLastRequest"] = None,
        base_request_id: Optional["SapOpenHubSourceBaseRequestId"] = None,
        **kwargs
    ):
        super(SapOpenHubSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SapOpenHubSource'
        self.exclude_last_request = exclude_last_request
        self.base_request_id = base_request_id


class SapOpenHubSourceBaseRequestId(msrest.serialization.Model):
    """The ID of request for delta loading. Once it is set, only data with requestId larger than the value of this property will be retrieved. The default value is 0. Type: integer (or Expression with resultType integer ).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapOpenHubSourceBaseRequestId, self).__init__(**kwargs)


class SapOpenHubSourceExcludeLastRequest(msrest.serialization.Model):
    """Whether to exclude the records of the last request. The default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapOpenHubSourceExcludeLastRequest, self).__init__(**kwargs)


class SapOpenHubTableDataset(Dataset):
    """Sap Business Warehouse Open Hub Destination Table properties.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param open_hub_destination_name: Required. The name of the Open Hub Destination with
     destination type as Database Table. Type: string (or Expression with resultType string).
    :type open_hub_destination_name:
     ~data_factory_management_client.models.SapOpenHubTableDatasetTypePropertiesOpenHubDestinationName
    :param exclude_last_request: Whether to exclude the records of the last request. The default
     value is true. Type: boolean (or Expression with resultType boolean).
    :type exclude_last_request:
     ~data_factory_management_client.models.SapOpenHubTableDatasetTypePropertiesExcludeLastRequest
    :param base_request_id: The ID of request for delta loading. Once it is set, only data with
     requestId larger than the value of this property will be retrieved. The default value is 0.
     Type: integer (or Expression with resultType integer ).
    :type base_request_id:
     ~data_factory_management_client.models.SapOpenHubTableDatasetTypePropertiesBaseRequestId
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'open_hub_destination_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'open_hub_destination_name': {'key': 'typeProperties.openHubDestinationName', 'type': 'SapOpenHubTableDatasetTypePropertiesOpenHubDestinationName'},
        'exclude_last_request': {'key': 'typeProperties.excludeLastRequest', 'type': 'SapOpenHubTableDatasetTypePropertiesExcludeLastRequest'},
        'base_request_id': {'key': 'typeProperties.baseRequestId', 'type': 'SapOpenHubTableDatasetTypePropertiesBaseRequestId'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        open_hub_destination_name: "SapOpenHubTableDatasetTypePropertiesOpenHubDestinationName",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        exclude_last_request: Optional["SapOpenHubTableDatasetTypePropertiesExcludeLastRequest"] = None,
        base_request_id: Optional["SapOpenHubTableDatasetTypePropertiesBaseRequestId"] = None,
        **kwargs
    ):
        super(SapOpenHubTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SapOpenHubTable'
        self.open_hub_destination_name = open_hub_destination_name
        self.exclude_last_request = exclude_last_request
        self.base_request_id = base_request_id


class SapOpenHubTableDatasetTypeProperties(msrest.serialization.Model):
    """Sap Business Warehouse Open Hub Destination Table properties.

    All required parameters must be populated in order to send to Azure.

    :param open_hub_destination_name: Required. The name of the Open Hub Destination with
     destination type as Database Table. Type: string (or Expression with resultType string).
    :type open_hub_destination_name:
     ~data_factory_management_client.models.SapOpenHubTableDatasetTypePropertiesOpenHubDestinationName
    :param exclude_last_request: Whether to exclude the records of the last request. The default
     value is true. Type: boolean (or Expression with resultType boolean).
    :type exclude_last_request:
     ~data_factory_management_client.models.SapOpenHubTableDatasetTypePropertiesExcludeLastRequest
    :param base_request_id: The ID of request for delta loading. Once it is set, only data with
     requestId larger than the value of this property will be retrieved. The default value is 0.
     Type: integer (or Expression with resultType integer ).
    :type base_request_id:
     ~data_factory_management_client.models.SapOpenHubTableDatasetTypePropertiesBaseRequestId
    """

    _validation = {
        'open_hub_destination_name': {'required': True},
    }

    _attribute_map = {
        'open_hub_destination_name': {'key': 'openHubDestinationName', 'type': 'SapOpenHubTableDatasetTypePropertiesOpenHubDestinationName'},
        'exclude_last_request': {'key': 'excludeLastRequest', 'type': 'SapOpenHubTableDatasetTypePropertiesExcludeLastRequest'},
        'base_request_id': {'key': 'baseRequestId', 'type': 'SapOpenHubTableDatasetTypePropertiesBaseRequestId'},
    }

    def __init__(
        self,
        *,
        open_hub_destination_name: "SapOpenHubTableDatasetTypePropertiesOpenHubDestinationName",
        exclude_last_request: Optional["SapOpenHubTableDatasetTypePropertiesExcludeLastRequest"] = None,
        base_request_id: Optional["SapOpenHubTableDatasetTypePropertiesBaseRequestId"] = None,
        **kwargs
    ):
        super(SapOpenHubTableDatasetTypeProperties, self).__init__(**kwargs)
        self.open_hub_destination_name = open_hub_destination_name
        self.exclude_last_request = exclude_last_request
        self.base_request_id = base_request_id


class SapOpenHubTableDatasetTypePropertiesBaseRequestId(msrest.serialization.Model):
    """The ID of request for delta loading. Once it is set, only data with requestId larger than the value of this property will be retrieved. The default value is 0. Type: integer (or Expression with resultType integer ).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapOpenHubTableDatasetTypePropertiesBaseRequestId, self).__init__(**kwargs)


class SapOpenHubTableDatasetTypePropertiesExcludeLastRequest(msrest.serialization.Model):
    """Whether to exclude the records of the last request. The default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapOpenHubTableDatasetTypePropertiesExcludeLastRequest, self).__init__(**kwargs)


class SapOpenHubTableDatasetTypePropertiesOpenHubDestinationName(msrest.serialization.Model):
    """The name of the Open Hub Destination with destination type as Database Table. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapOpenHubTableDatasetTypePropertiesOpenHubDestinationName, self).__init__(**kwargs)


class SapTableLinkedService(LinkedService):
    """SAP Table Linked Service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param server: Host name of the SAP instance where the table is located. Type: string (or
     Expression with resultType string).
    :type server: ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesServer
    :param system_number: System number of the SAP system where the table is located. (Usually a
     two-digit decimal number represented as a string.) Type: string (or Expression with resultType
     string).
    :type system_number:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesSystemNumber
    :param client_id: Client ID of the client on the SAP system where the table is located.
     (Usually a three-digit decimal number represented as a string) Type: string (or Expression with
     resultType string).
    :type client_id:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesClientId
    :param language: Language of the SAP system where the table is located. The default value is
     EN. Type: string (or Expression with resultType string).
    :type language:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesLanguage
    :param system_id: SystemID of the SAP system where the table is located. Type: string (or
     Expression with resultType string).
    :type system_id:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesSystemId
    :param user_name: Username to access the SAP server where the table is located. Type: string
     (or Expression with resultType string).
    :type user_name:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param message_server: The hostname of the SAP Message Server. Type: string (or Expression with
     resultType string).
    :type message_server:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesMessageServer
    :param message_server_service: The service name or port number of the Message Server. Type:
     string (or Expression with resultType string).
    :type message_server_service:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesMessageServerService
    :param snc_mode: SNC activation indicator to access the SAP server where the table is located.
     Must be either 0 (off) or 1 (on). Type: string (or Expression with resultType string).
    :type snc_mode:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesSncMode
    :param snc_my_name: Initiator's SNC name to access the SAP server where the table is located.
     Type: string (or Expression with resultType string).
    :type snc_my_name:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesSncMyName
    :param snc_partner_name: Communication partner's SNC name to access the SAP server where the
     table is located. Type: string (or Expression with resultType string).
    :type snc_partner_name:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesSncPartnerName
    :param snc_library_path: External security product's library to access the SAP server where the
     table is located. Type: string (or Expression with resultType string).
    :type snc_library_path:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesSncLibraryPath
    :param snc_qop: SNC Quality of Protection. Allowed value include: 1, 2, 3, 8, 9. Type: string
     (or Expression with resultType string).
    :type snc_qop: ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesSncQop
    :param logon_group: The Logon Group for the SAP System. Type: string (or Expression with
     resultType string).
    :type logon_group:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesLogonGroup
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'server': {'key': 'typeProperties.server', 'type': 'SapTableLinkedServiceTypePropertiesServer'},
        'system_number': {'key': 'typeProperties.systemNumber', 'type': 'SapTableLinkedServiceTypePropertiesSystemNumber'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'SapTableLinkedServiceTypePropertiesClientId'},
        'language': {'key': 'typeProperties.language', 'type': 'SapTableLinkedServiceTypePropertiesLanguage'},
        'system_id': {'key': 'typeProperties.systemId', 'type': 'SapTableLinkedServiceTypePropertiesSystemId'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'SapTableLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'message_server': {'key': 'typeProperties.messageServer', 'type': 'SapTableLinkedServiceTypePropertiesMessageServer'},
        'message_server_service': {'key': 'typeProperties.messageServerService', 'type': 'SapTableLinkedServiceTypePropertiesMessageServerService'},
        'snc_mode': {'key': 'typeProperties.sncMode', 'type': 'SapTableLinkedServiceTypePropertiesSncMode'},
        'snc_my_name': {'key': 'typeProperties.sncMyName', 'type': 'SapTableLinkedServiceTypePropertiesSncMyName'},
        'snc_partner_name': {'key': 'typeProperties.sncPartnerName', 'type': 'SapTableLinkedServiceTypePropertiesSncPartnerName'},
        'snc_library_path': {'key': 'typeProperties.sncLibraryPath', 'type': 'SapTableLinkedServiceTypePropertiesSncLibraryPath'},
        'snc_qop': {'key': 'typeProperties.sncQop', 'type': 'SapTableLinkedServiceTypePropertiesSncQop'},
        'logon_group': {'key': 'typeProperties.logonGroup', 'type': 'SapTableLinkedServiceTypePropertiesLogonGroup'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'SapTableLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        server: Optional["SapTableLinkedServiceTypePropertiesServer"] = None,
        system_number: Optional["SapTableLinkedServiceTypePropertiesSystemNumber"] = None,
        client_id: Optional["SapTableLinkedServiceTypePropertiesClientId"] = None,
        language: Optional["SapTableLinkedServiceTypePropertiesLanguage"] = None,
        system_id: Optional["SapTableLinkedServiceTypePropertiesSystemId"] = None,
        user_name: Optional["SapTableLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        message_server: Optional["SapTableLinkedServiceTypePropertiesMessageServer"] = None,
        message_server_service: Optional["SapTableLinkedServiceTypePropertiesMessageServerService"] = None,
        snc_mode: Optional["SapTableLinkedServiceTypePropertiesSncMode"] = None,
        snc_my_name: Optional["SapTableLinkedServiceTypePropertiesSncMyName"] = None,
        snc_partner_name: Optional["SapTableLinkedServiceTypePropertiesSncPartnerName"] = None,
        snc_library_path: Optional["SapTableLinkedServiceTypePropertiesSncLibraryPath"] = None,
        snc_qop: Optional["SapTableLinkedServiceTypePropertiesSncQop"] = None,
        logon_group: Optional["SapTableLinkedServiceTypePropertiesLogonGroup"] = None,
        encrypted_credential: Optional["SapTableLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SapTableLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SapTable'
        self.server = server
        self.system_number = system_number
        self.client_id = client_id
        self.language = language
        self.system_id = system_id
        self.user_name = user_name
        self.password = password
        self.message_server = message_server
        self.message_server_service = message_server_service
        self.snc_mode = snc_mode
        self.snc_my_name = snc_my_name
        self.snc_partner_name = snc_partner_name
        self.snc_library_path = snc_library_path
        self.snc_qop = snc_qop
        self.logon_group = logon_group
        self.encrypted_credential = encrypted_credential


class SapTableLinkedServiceTypeProperties(msrest.serialization.Model):
    """Properties specific to this linked service type.

    :param server: Host name of the SAP instance where the table is located. Type: string (or
     Expression with resultType string).
    :type server: ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesServer
    :param system_number: System number of the SAP system where the table is located. (Usually a
     two-digit decimal number represented as a string.) Type: string (or Expression with resultType
     string).
    :type system_number:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesSystemNumber
    :param client_id: Client ID of the client on the SAP system where the table is located.
     (Usually a three-digit decimal number represented as a string) Type: string (or Expression with
     resultType string).
    :type client_id:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesClientId
    :param language: Language of the SAP system where the table is located. The default value is
     EN. Type: string (or Expression with resultType string).
    :type language:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesLanguage
    :param system_id: SystemID of the SAP system where the table is located. Type: string (or
     Expression with resultType string).
    :type system_id:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesSystemId
    :param user_name: Username to access the SAP server where the table is located. Type: string
     (or Expression with resultType string).
    :type user_name:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param message_server: The hostname of the SAP Message Server. Type: string (or Expression with
     resultType string).
    :type message_server:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesMessageServer
    :param message_server_service: The service name or port number of the Message Server. Type:
     string (or Expression with resultType string).
    :type message_server_service:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesMessageServerService
    :param snc_mode: SNC activation indicator to access the SAP server where the table is located.
     Must be either 0 (off) or 1 (on). Type: string (or Expression with resultType string).
    :type snc_mode:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesSncMode
    :param snc_my_name: Initiator's SNC name to access the SAP server where the table is located.
     Type: string (or Expression with resultType string).
    :type snc_my_name:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesSncMyName
    :param snc_partner_name: Communication partner's SNC name to access the SAP server where the
     table is located. Type: string (or Expression with resultType string).
    :type snc_partner_name:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesSncPartnerName
    :param snc_library_path: External security product's library to access the SAP server where the
     table is located. Type: string (or Expression with resultType string).
    :type snc_library_path:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesSncLibraryPath
    :param snc_qop: SNC Quality of Protection. Allowed value include: 1, 2, 3, 8, 9. Type: string
     (or Expression with resultType string).
    :type snc_qop: ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesSncQop
    :param logon_group: The Logon Group for the SAP System. Type: string (or Expression with
     resultType string).
    :type logon_group:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesLogonGroup
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SapTableLinkedServiceTypePropertiesEncryptedCredential
    """

    _attribute_map = {
        'server': {'key': 'server', 'type': 'SapTableLinkedServiceTypePropertiesServer'},
        'system_number': {'key': 'systemNumber', 'type': 'SapTableLinkedServiceTypePropertiesSystemNumber'},
        'client_id': {'key': 'clientId', 'type': 'SapTableLinkedServiceTypePropertiesClientId'},
        'language': {'key': 'language', 'type': 'SapTableLinkedServiceTypePropertiesLanguage'},
        'system_id': {'key': 'systemId', 'type': 'SapTableLinkedServiceTypePropertiesSystemId'},
        'user_name': {'key': 'userName', 'type': 'SapTableLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'message_server': {'key': 'messageServer', 'type': 'SapTableLinkedServiceTypePropertiesMessageServer'},
        'message_server_service': {'key': 'messageServerService', 'type': 'SapTableLinkedServiceTypePropertiesMessageServerService'},
        'snc_mode': {'key': 'sncMode', 'type': 'SapTableLinkedServiceTypePropertiesSncMode'},
        'snc_my_name': {'key': 'sncMyName', 'type': 'SapTableLinkedServiceTypePropertiesSncMyName'},
        'snc_partner_name': {'key': 'sncPartnerName', 'type': 'SapTableLinkedServiceTypePropertiesSncPartnerName'},
        'snc_library_path': {'key': 'sncLibraryPath', 'type': 'SapTableLinkedServiceTypePropertiesSncLibraryPath'},
        'snc_qop': {'key': 'sncQop', 'type': 'SapTableLinkedServiceTypePropertiesSncQop'},
        'logon_group': {'key': 'logonGroup', 'type': 'SapTableLinkedServiceTypePropertiesLogonGroup'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'SapTableLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        server: Optional["SapTableLinkedServiceTypePropertiesServer"] = None,
        system_number: Optional["SapTableLinkedServiceTypePropertiesSystemNumber"] = None,
        client_id: Optional["SapTableLinkedServiceTypePropertiesClientId"] = None,
        language: Optional["SapTableLinkedServiceTypePropertiesLanguage"] = None,
        system_id: Optional["SapTableLinkedServiceTypePropertiesSystemId"] = None,
        user_name: Optional["SapTableLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        message_server: Optional["SapTableLinkedServiceTypePropertiesMessageServer"] = None,
        message_server_service: Optional["SapTableLinkedServiceTypePropertiesMessageServerService"] = None,
        snc_mode: Optional["SapTableLinkedServiceTypePropertiesSncMode"] = None,
        snc_my_name: Optional["SapTableLinkedServiceTypePropertiesSncMyName"] = None,
        snc_partner_name: Optional["SapTableLinkedServiceTypePropertiesSncPartnerName"] = None,
        snc_library_path: Optional["SapTableLinkedServiceTypePropertiesSncLibraryPath"] = None,
        snc_qop: Optional["SapTableLinkedServiceTypePropertiesSncQop"] = None,
        logon_group: Optional["SapTableLinkedServiceTypePropertiesLogonGroup"] = None,
        encrypted_credential: Optional["SapTableLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SapTableLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.server = server
        self.system_number = system_number
        self.client_id = client_id
        self.language = language
        self.system_id = system_id
        self.user_name = user_name
        self.password = password
        self.message_server = message_server
        self.message_server_service = message_server_service
        self.snc_mode = snc_mode
        self.snc_my_name = snc_my_name
        self.snc_partner_name = snc_partner_name
        self.snc_library_path = snc_library_path
        self.snc_qop = snc_qop
        self.logon_group = logon_group
        self.encrypted_credential = encrypted_credential


class SapTableLinkedServiceTypePropertiesClientId(msrest.serialization.Model):
    """Client ID of the client on the SAP system where the table is located. (Usually a three-digit decimal number represented as a string) Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableLinkedServiceTypePropertiesClientId, self).__init__(**kwargs)


class SapTableLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class SapTableLinkedServiceTypePropertiesLanguage(msrest.serialization.Model):
    """Language of the SAP system where the table is located. The default value is EN. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableLinkedServiceTypePropertiesLanguage, self).__init__(**kwargs)


class SapTableLinkedServiceTypePropertiesLogonGroup(msrest.serialization.Model):
    """The Logon Group for the SAP System. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableLinkedServiceTypePropertiesLogonGroup, self).__init__(**kwargs)


class SapTableLinkedServiceTypePropertiesMessageServer(msrest.serialization.Model):
    """The hostname of the SAP Message Server. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableLinkedServiceTypePropertiesMessageServer, self).__init__(**kwargs)


class SapTableLinkedServiceTypePropertiesMessageServerService(msrest.serialization.Model):
    """The service name or port number of the Message Server. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableLinkedServiceTypePropertiesMessageServerService, self).__init__(**kwargs)


class SapTableLinkedServiceTypePropertiesServer(msrest.serialization.Model):
    """Host name of the SAP instance where the table is located. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableLinkedServiceTypePropertiesServer, self).__init__(**kwargs)


class SapTableLinkedServiceTypePropertiesSncLibraryPath(msrest.serialization.Model):
    """External security product's library to access the SAP server where the table is located. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableLinkedServiceTypePropertiesSncLibraryPath, self).__init__(**kwargs)


class SapTableLinkedServiceTypePropertiesSncMode(msrest.serialization.Model):
    """SNC activation indicator to access the SAP server where the table is located. Must be either 0 (off) or 1 (on). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableLinkedServiceTypePropertiesSncMode, self).__init__(**kwargs)


class SapTableLinkedServiceTypePropertiesSncMyName(msrest.serialization.Model):
    """Initiator's SNC name to access the SAP server where the table is located. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableLinkedServiceTypePropertiesSncMyName, self).__init__(**kwargs)


class SapTableLinkedServiceTypePropertiesSncPartnerName(msrest.serialization.Model):
    """Communication partner's SNC name to access the SAP server where the table is located. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableLinkedServiceTypePropertiesSncPartnerName, self).__init__(**kwargs)


class SapTableLinkedServiceTypePropertiesSncQop(msrest.serialization.Model):
    """SNC Quality of Protection. Allowed value include: 1, 2, 3, 8, 9. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableLinkedServiceTypePropertiesSncQop, self).__init__(**kwargs)


class SapTableLinkedServiceTypePropertiesSystemId(msrest.serialization.Model):
    """SystemID of the SAP system where the table is located. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableLinkedServiceTypePropertiesSystemId, self).__init__(**kwargs)


class SapTableLinkedServiceTypePropertiesSystemNumber(msrest.serialization.Model):
    """System number of the SAP system where the table is located. (Usually a two-digit decimal number represented as a string.) Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableLinkedServiceTypePropertiesSystemNumber, self).__init__(**kwargs)


class SapTableLinkedServiceTypePropertiesUserName(msrest.serialization.Model):
    """Username to access the SAP server where the table is located. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableLinkedServiceTypePropertiesUserName, self).__init__(**kwargs)


class SapTablePartitionSettings(msrest.serialization.Model):
    """The settings that will be leveraged for SAP table source partitioning.

    :param partition_column_name: The name of the column that will be used for proceeding range
     partitioning. Type: string (or Expression with resultType string).
    :type partition_column_name:
     ~data_factory_management_client.models.SapTablePartitionSettingsPartitionColumnName
    :param partition_upper_bound: The maximum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :type partition_upper_bound:
     ~data_factory_management_client.models.SapTablePartitionSettingsPartitionUpperBound
    :param partition_lower_bound: The minimum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :type partition_lower_bound:
     ~data_factory_management_client.models.SapTablePartitionSettingsPartitionLowerBound
    :param max_partitions_number: The maximum value of partitions the table will be split into.
     Type: integer (or Expression with resultType string).
    :type max_partitions_number:
     ~data_factory_management_client.models.SapTablePartitionSettingsMaxPartitionsNumber
    """

    _attribute_map = {
        'partition_column_name': {'key': 'partitionColumnName', 'type': 'SapTablePartitionSettingsPartitionColumnName'},
        'partition_upper_bound': {'key': 'partitionUpperBound', 'type': 'SapTablePartitionSettingsPartitionUpperBound'},
        'partition_lower_bound': {'key': 'partitionLowerBound', 'type': 'SapTablePartitionSettingsPartitionLowerBound'},
        'max_partitions_number': {'key': 'maxPartitionsNumber', 'type': 'SapTablePartitionSettingsMaxPartitionsNumber'},
    }

    def __init__(
        self,
        *,
        partition_column_name: Optional["SapTablePartitionSettingsPartitionColumnName"] = None,
        partition_upper_bound: Optional["SapTablePartitionSettingsPartitionUpperBound"] = None,
        partition_lower_bound: Optional["SapTablePartitionSettingsPartitionLowerBound"] = None,
        max_partitions_number: Optional["SapTablePartitionSettingsMaxPartitionsNumber"] = None,
        **kwargs
    ):
        super(SapTablePartitionSettings, self).__init__(**kwargs)
        self.partition_column_name = partition_column_name
        self.partition_upper_bound = partition_upper_bound
        self.partition_lower_bound = partition_lower_bound
        self.max_partitions_number = max_partitions_number


class SapTablePartitionSettingsMaxPartitionsNumber(msrest.serialization.Model):
    """The maximum value of partitions the table will be split into. Type: integer (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTablePartitionSettingsMaxPartitionsNumber, self).__init__(**kwargs)


class SapTablePartitionSettingsPartitionColumnName(msrest.serialization.Model):
    """The name of the column that will be used for proceeding range partitioning. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTablePartitionSettingsPartitionColumnName, self).__init__(**kwargs)


class SapTablePartitionSettingsPartitionLowerBound(msrest.serialization.Model):
    """The minimum value of column specified in partitionColumnName that will be used for proceeding range partitioning. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTablePartitionSettingsPartitionLowerBound, self).__init__(**kwargs)


class SapTablePartitionSettingsPartitionUpperBound(msrest.serialization.Model):
    """The maximum value of column specified in partitionColumnName that will be used for proceeding range partitioning. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTablePartitionSettingsPartitionUpperBound, self).__init__(**kwargs)


class SapTableResourceDataset(Dataset):
    """SAP Table Resource properties.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: Required. The name of the SAP Table. Type: string (or Expression with
     resultType string).
    :type table_name:
     ~data_factory_management_client.models.SapTableResourceDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'table_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'SapTableResourceDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        table_name: "SapTableResourceDatasetTypePropertiesTableName",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        super(SapTableResourceDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SapTableResource'
        self.table_name = table_name


class SapTableResourceDatasetTypeProperties(msrest.serialization.Model):
    """SAP Table Resource properties.

    All required parameters must be populated in order to send to Azure.

    :param table_name: Required. The name of the SAP Table. Type: string (or Expression with
     resultType string).
    :type table_name:
     ~data_factory_management_client.models.SapTableResourceDatasetTypePropertiesTableName
    """

    _validation = {
        'table_name': {'required': True},
    }

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'SapTableResourceDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        table_name: "SapTableResourceDatasetTypePropertiesTableName",
        **kwargs
    ):
        super(SapTableResourceDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name


class SapTableResourceDatasetTypePropertiesTableName(msrest.serialization.Model):
    """The name of the SAP Table. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableResourceDatasetTypePropertiesTableName, self).__init__(**kwargs)


class SapTableSource(TabularSource):
    """A copy activity source for SAP Table source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param row_count: The number of rows to be retrieved. Type: integer(or Expression with
     resultType integer).
    :type row_count: ~data_factory_management_client.models.SapTableSourceRowCount
    :param row_skips: The number of rows that will be skipped. Type: integer (or Expression with
     resultType integer).
    :type row_skips: ~data_factory_management_client.models.SapTableSourceRowSkips
    :param rfc_table_fields: The fields of the SAP table that will be retrieved. For example,
     column0, column1. Type: string (or Expression with resultType string).
    :type rfc_table_fields: ~data_factory_management_client.models.SapTableSourceRfcTableFields
    :param rfc_table_options: The options for the filtering of the SAP Table. For example, COLUMN0
     EQ SOME VALUE. Type: string (or Expression with resultType string).
    :type rfc_table_options: ~data_factory_management_client.models.SapTableSourceRfcTableOptions
    :param batch_size: Specifies the maximum number of rows that will be retrieved at a time when
     retrieving data from SAP Table. Type: integer (or Expression with resultType integer).
    :type batch_size: ~data_factory_management_client.models.SapTableSourceBatchSize
    :param custom_rfc_read_table_function_module: Specifies the custom RFC function module that
     will be used to read data from SAP Table. Type: string (or Expression with resultType string).
    :type custom_rfc_read_table_function_module:
     ~data_factory_management_client.models.SapTableSourceCustomRfcReadTableFunctionModule
    :param partition_option: The partition mechanism that will be used for SAP table read in
     parallel. Possible values include: 'None', 'PartitionOnInt', 'PartitionOnCalendarYear',
     'PartitionOnCalendarMonth', 'PartitionOnCalendarDate', 'PartitionOnTime'.
    :type partition_option: str or ~data_factory_management_client.models.SapTablePartitionOption
    :param partition_settings: The settings that will be leveraged for SAP table source
     partitioning.
    :type partition_settings: ~data_factory_management_client.models.SapTablePartitionSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'row_count': {'key': 'rowCount', 'type': 'SapTableSourceRowCount'},
        'row_skips': {'key': 'rowSkips', 'type': 'SapTableSourceRowSkips'},
        'rfc_table_fields': {'key': 'rfcTableFields', 'type': 'SapTableSourceRfcTableFields'},
        'rfc_table_options': {'key': 'rfcTableOptions', 'type': 'SapTableSourceRfcTableOptions'},
        'batch_size': {'key': 'batchSize', 'type': 'SapTableSourceBatchSize'},
        'custom_rfc_read_table_function_module': {'key': 'customRfcReadTableFunctionModule', 'type': 'SapTableSourceCustomRfcReadTableFunctionModule'},
        'partition_option': {'key': 'partitionOption', 'type': 'str'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'SapTablePartitionSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        row_count: Optional["SapTableSourceRowCount"] = None,
        row_skips: Optional["SapTableSourceRowSkips"] = None,
        rfc_table_fields: Optional["SapTableSourceRfcTableFields"] = None,
        rfc_table_options: Optional["SapTableSourceRfcTableOptions"] = None,
        batch_size: Optional["SapTableSourceBatchSize"] = None,
        custom_rfc_read_table_function_module: Optional["SapTableSourceCustomRfcReadTableFunctionModule"] = None,
        partition_option: Optional[Union[str, "SapTablePartitionOption"]] = None,
        partition_settings: Optional["SapTablePartitionSettings"] = None,
        **kwargs
    ):
        super(SapTableSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SapTableSource'
        self.row_count = row_count
        self.row_skips = row_skips
        self.rfc_table_fields = rfc_table_fields
        self.rfc_table_options = rfc_table_options
        self.batch_size = batch_size
        self.custom_rfc_read_table_function_module = custom_rfc_read_table_function_module
        self.partition_option = partition_option
        self.partition_settings = partition_settings


class SapTableSourceBatchSize(msrest.serialization.Model):
    """Specifies the maximum number of rows that will be retrieved at a time when retrieving data from SAP Table. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableSourceBatchSize, self).__init__(**kwargs)


class SapTableSourceCustomRfcReadTableFunctionModule(msrest.serialization.Model):
    """Specifies the custom RFC function module that will be used to read data from SAP Table. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableSourceCustomRfcReadTableFunctionModule, self).__init__(**kwargs)


class SapTableSourceRfcTableFields(msrest.serialization.Model):
    """The fields of the SAP table that will be retrieved. For example, column0, column1. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableSourceRfcTableFields, self).__init__(**kwargs)


class SapTableSourceRfcTableOptions(msrest.serialization.Model):
    """The options for the filtering of the SAP Table. For example, COLUMN0 EQ SOME VALUE. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableSourceRfcTableOptions, self).__init__(**kwargs)


class SapTableSourceRowCount(msrest.serialization.Model):
    """The number of rows to be retrieved. Type: integer(or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableSourceRowCount, self).__init__(**kwargs)


class SapTableSourceRowSkips(msrest.serialization.Model):
    """The number of rows that will be skipped. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SapTableSourceRowSkips, self).__init__(**kwargs)


class ScheduleTrigger(MultiplePipelineTrigger):
    """Trigger that creates pipeline runs periodically, on schedule.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Trigger type.Constant filled by server.
    :type type: str
    :param description: Trigger description.
    :type description: str
    :ivar runtime_state: Enumerates possible state of Triggers. Possible values include: 'Started',
     'Stopped', 'Disabled'.
    :vartype runtime_state: str or ~data_factory_management_client.models.TriggerRuntimeState
    :param annotations: List of tags that can be used for describing the trigger.
    :type annotations: list[~data_factory_management_client.models.TriggerAnnotationsItem]
    :param pipelines: Pipelines that need to be started.
    :type pipelines: list[~data_factory_management_client.models.TriggerPipelineReference]
    :param recurrence: Required. The workflow trigger recurrence.
    :type recurrence: ~data_factory_management_client.models.ScheduleTriggerRecurrence
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
        'recurrence': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[TriggerAnnotationsItem]'},
        'pipelines': {'key': 'pipelines', 'type': '[TriggerPipelineReference]'},
        'recurrence': {'key': 'typeProperties.recurrence', 'type': 'ScheduleTriggerRecurrence'},
    }

    def __init__(
        self,
        *,
        recurrence: "ScheduleTriggerRecurrence",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        annotations: Optional[List["TriggerAnnotationsItem"]] = None,
        pipelines: Optional[List["TriggerPipelineReference"]] = None,
        **kwargs
    ):
        super(ScheduleTrigger, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, pipelines=pipelines, **kwargs)
        self.type = 'ScheduleTrigger'
        self.recurrence = recurrence


class ScheduleTriggerRecurrence(msrest.serialization.Model):
    """The workflow trigger recurrence.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param frequency: Enumerates possible frequency option for the schedule trigger. Possible
     values include: 'NotSpecified', 'Minute', 'Hour', 'Day', 'Week', 'Month', 'Year'.
    :type frequency: str or ~data_factory_management_client.models.RecurrenceFrequency
    :param interval: The interval.
    :type interval: int
    :param start_time: The start time.
    :type start_time: ~datetime.datetime
    :param end_time: The end time.
    :type end_time: ~datetime.datetime
    :param time_zone: The time zone.
    :type time_zone: str
    :param schedule: The recurrence schedule.
    :type schedule: ~data_factory_management_client.models.RecurrenceSchedule
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'frequency': {'key': 'frequency', 'type': 'str'},
        'interval': {'key': 'interval', 'type': 'int'},
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'end_time': {'key': 'endTime', 'type': 'iso-8601'},
        'time_zone': {'key': 'timeZone', 'type': 'str'},
        'schedule': {'key': 'schedule', 'type': 'RecurrenceSchedule'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        frequency: Optional[Union[str, "RecurrenceFrequency"]] = None,
        interval: Optional[int] = None,
        start_time: Optional[datetime.datetime] = None,
        end_time: Optional[datetime.datetime] = None,
        time_zone: Optional[str] = None,
        schedule: Optional["RecurrenceSchedule"] = None,
        **kwargs
    ):
        super(ScheduleTriggerRecurrence, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.frequency = frequency
        self.interval = interval
        self.start_time = start_time
        self.end_time = end_time
        self.time_zone = time_zone
        self.schedule = schedule


class ScheduleTriggerTypeProperties(msrest.serialization.Model):
    """Schedule Trigger properties.

    All required parameters must be populated in order to send to Azure.

    :param recurrence: Required. The workflow trigger recurrence.
    :type recurrence: ~data_factory_management_client.models.ScheduleTriggerRecurrence
    """

    _validation = {
        'recurrence': {'required': True},
    }

    _attribute_map = {
        'recurrence': {'key': 'recurrence', 'type': 'ScheduleTriggerRecurrence'},
    }

    def __init__(
        self,
        *,
        recurrence: "ScheduleTriggerRecurrence",
        **kwargs
    ):
        super(ScheduleTriggerTypeProperties, self).__init__(**kwargs)
        self.recurrence = recurrence


class ScriptAction(msrest.serialization.Model):
    """Custom script action to run on HDI ondemand cluster once it's up.

    All required parameters must be populated in order to send to Azure.

    :param name: Required. The user provided name of the script action.
    :type name: str
    :param uri: Required. The URI for the script action.
    :type uri: str
    :param roles: Required. The node types on which the script action should be executed. Possible
     values include: 'Headnode', 'Workernode', 'Zookeeper'.
    :type roles: str or ~data_factory_management_client.models.HdiNodeTypes
    :param parameters: The parameters for the script action.
    :type parameters: str
    """

    _validation = {
        'name': {'required': True},
        'uri': {'required': True},
        'roles': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'uri': {'key': 'uri', 'type': 'str'},
        'roles': {'key': 'roles', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: str,
        uri: str,
        roles: Union[str, "HdiNodeTypes"],
        parameters: Optional[str] = None,
        **kwargs
    ):
        super(ScriptAction, self).__init__(**kwargs)
        self.name = name
        self.uri = uri
        self.roles = roles
        self.parameters = parameters


class SecureString(SecretBase):
    """Azure Data Factory secure string definition. The string value will be masked with asterisks '*' during Get or List API calls.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. Type of the secret.Constant filled by server.
    :type type: str
    :param value: Required. Value of secure string.
    :type value: str
    """

    _validation = {
        'type': {'required': True},
        'value': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'value': {'key': 'value', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: str,
        **kwargs
    ):
        super(SecureString, self).__init__(**kwargs)
        self.type = 'SecureString'
        self.value = value


class SelfDependencyTumblingWindowTriggerReference(DependencyReference):
    """Self referenced tumbling window trigger dependency.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. The type of dependency reference.Constant filled by server.
    :type type: str
    :param offset: Required. Timespan applied to the start time of a tumbling window when
     evaluating dependency.
    :type offset: str
    :param size: The size of the window when evaluating the dependency. If undefined the frequency
     of the tumbling window will be used.
    :type size: str
    """

    _validation = {
        'type': {'required': True},
        'offset': {'required': True, 'max_length': 15, 'min_length': 8, 'pattern': '-((\\d+)\\.)?(\\d\\d):(60|([0-5][0-9])):(60|([0-5][0-9]))'},
        'size': {'max_length': 15, 'min_length': 8, 'pattern': '((\\d+)\\.)?(\\d\\d):(60|([0-5][0-9])):(60|([0-5][0-9]))'},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'offset': {'key': 'offset', 'type': 'str'},
        'size': {'key': 'size', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        offset: str,
        size: Optional[str] = None,
        **kwargs
    ):
        super(SelfDependencyTumblingWindowTriggerReference, self).__init__(**kwargs)
        self.type = 'SelfDependencyTumblingWindowTriggerReference'
        self.offset = offset
        self.size = size


class SelfHostedIntegrationRuntime(IntegrationRuntime):
    """Self-hosted integration runtime.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The type of integration runtime.Constant filled by server.  Possible
     values include: 'Managed', 'SelfHosted'.
    :type type: str or ~data_factory_management_client.models.IntegrationRuntimeType
    :param description: Integration runtime description.
    :type description: str
    :param linked_info: The base definition of a linked integration runtime.
    :type linked_info: ~data_factory_management_client.models.LinkedIntegrationRuntimeType
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'linked_info': {'key': 'typeProperties.linkedInfo', 'type': 'LinkedIntegrationRuntimeType'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        linked_info: Optional["LinkedIntegrationRuntimeType"] = None,
        **kwargs
    ):
        super(SelfHostedIntegrationRuntime, self).__init__(additional_properties=additional_properties, description=description, **kwargs)
        self.type = 'SelfHosted'
        self.linked_info = linked_info


class SelfHostedIntegrationRuntimeNode(msrest.serialization.Model):
    """Properties of Self-hosted integration runtime node.

    Variables are only populated by the server, and will be ignored when sending a request.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :ivar node_name: Name of the integration runtime node.
    :vartype node_name: str
    :ivar machine_name: Machine name of the integration runtime node.
    :vartype machine_name: str
    :ivar host_service_uri: URI for the host machine of the integration runtime.
    :vartype host_service_uri: str
    :ivar status: Status of the integration runtime node. Possible values include:
     'NeedRegistration', 'Online', 'Limited', 'Offline', 'Upgrading', 'Initializing',
     'InitializeFailed'.
    :vartype status: str or
     ~data_factory_management_client.models.SelfHostedIntegrationRuntimeNodeStatus
    :ivar capabilities: The integration runtime capabilities dictionary.
    :vartype capabilities: dict[str, str]
    :ivar version_status: Status of the integration runtime node version.
    :vartype version_status: str
    :ivar version: Version of the integration runtime node.
    :vartype version: str
    :ivar register_time: The time at which the integration runtime node was registered in ISO8601
     format.
    :vartype register_time: ~datetime.datetime
    :ivar last_connect_time: The most recent time at which the integration runtime was connected in
     ISO8601 format.
    :vartype last_connect_time: ~datetime.datetime
    :ivar expiry_time: The time at which the integration runtime will expire in ISO8601 format.
    :vartype expiry_time: ~datetime.datetime
    :ivar last_start_time: The time the node last started up.
    :vartype last_start_time: ~datetime.datetime
    :ivar last_stop_time: The integration runtime node last stop time.
    :vartype last_stop_time: ~datetime.datetime
    :ivar last_update_result: The result of the last integration runtime node update. Possible
     values include: 'None', 'Succeed', 'Fail'.
    :vartype last_update_result: str or
     ~data_factory_management_client.models.IntegrationRuntimeUpdateResult
    :ivar last_start_update_time: The last time for the integration runtime node update start.
    :vartype last_start_update_time: ~datetime.datetime
    :ivar last_end_update_time: The last time for the integration runtime node update end.
    :vartype last_end_update_time: ~datetime.datetime
    :ivar is_active_dispatcher: Indicates whether this node is the active dispatcher for
     integration runtime requests.
    :vartype is_active_dispatcher: bool
    :ivar concurrent_jobs_limit: Maximum concurrent jobs on the integration runtime node.
    :vartype concurrent_jobs_limit: int
    :ivar max_concurrent_jobs: The maximum concurrent jobs in this integration runtime.
    :vartype max_concurrent_jobs: int
    """

    _validation = {
        'node_name': {'readonly': True},
        'machine_name': {'readonly': True},
        'host_service_uri': {'readonly': True},
        'status': {'readonly': True},
        'capabilities': {'readonly': True},
        'version_status': {'readonly': True},
        'version': {'readonly': True},
        'register_time': {'readonly': True},
        'last_connect_time': {'readonly': True},
        'expiry_time': {'readonly': True},
        'last_start_time': {'readonly': True},
        'last_stop_time': {'readonly': True},
        'last_update_result': {'readonly': True},
        'last_start_update_time': {'readonly': True},
        'last_end_update_time': {'readonly': True},
        'is_active_dispatcher': {'readonly': True},
        'concurrent_jobs_limit': {'readonly': True},
        'max_concurrent_jobs': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'node_name': {'key': 'nodeName', 'type': 'str'},
        'machine_name': {'key': 'machineName', 'type': 'str'},
        'host_service_uri': {'key': 'hostServiceUri', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'capabilities': {'key': 'capabilities', 'type': '{str}'},
        'version_status': {'key': 'versionStatus', 'type': 'str'},
        'version': {'key': 'version', 'type': 'str'},
        'register_time': {'key': 'registerTime', 'type': 'iso-8601'},
        'last_connect_time': {'key': 'lastConnectTime', 'type': 'iso-8601'},
        'expiry_time': {'key': 'expiryTime', 'type': 'iso-8601'},
        'last_start_time': {'key': 'lastStartTime', 'type': 'iso-8601'},
        'last_stop_time': {'key': 'lastStopTime', 'type': 'iso-8601'},
        'last_update_result': {'key': 'lastUpdateResult', 'type': 'str'},
        'last_start_update_time': {'key': 'lastStartUpdateTime', 'type': 'iso-8601'},
        'last_end_update_time': {'key': 'lastEndUpdateTime', 'type': 'iso-8601'},
        'is_active_dispatcher': {'key': 'isActiveDispatcher', 'type': 'bool'},
        'concurrent_jobs_limit': {'key': 'concurrentJobsLimit', 'type': 'int'},
        'max_concurrent_jobs': {'key': 'maxConcurrentJobs', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(SelfHostedIntegrationRuntimeNode, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.node_name = None
        self.machine_name = None
        self.host_service_uri = None
        self.status = None
        self.capabilities = None
        self.version_status = None
        self.version = None
        self.register_time = None
        self.last_connect_time = None
        self.expiry_time = None
        self.last_start_time = None
        self.last_stop_time = None
        self.last_update_result = None
        self.last_start_update_time = None
        self.last_end_update_time = None
        self.is_active_dispatcher = None
        self.concurrent_jobs_limit = None
        self.max_concurrent_jobs = None


class SelfHostedIntegrationRuntimeStatus(IntegrationRuntimeStatus):
    """Self-hosted integration runtime status.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The type of integration runtime.Constant filled by server.  Possible
     values include: 'Managed', 'SelfHosted'.
    :type type: str or ~data_factory_management_client.models.IntegrationRuntimeType
    :ivar data_factory_name: The data factory name which the integration runtime belong to.
    :vartype data_factory_name: str
    :ivar state: The state of integration runtime. Possible values include: 'Initial', 'Stopped',
     'Started', 'Starting', 'Stopping', 'NeedRegistration', 'Online', 'Limited', 'Offline',
     'AccessDenied'.
    :vartype state: str or ~data_factory_management_client.models.IntegrationRuntimeState
    :ivar create_time: The time at which the integration runtime was created, in ISO8601 format.
    :vartype create_time: ~datetime.datetime
    :ivar task_queue_id: The task queue id of the integration runtime.
    :vartype task_queue_id: str
    :ivar internal_channel_encryption: It is used to set the encryption mode for node-node
     communication channel (when more than 2 self-hosted integration runtime nodes exist). Possible
     values include: 'NotSet', 'SslEncrypted', 'NotEncrypted'.
    :vartype internal_channel_encryption: str or
     ~data_factory_management_client.models.IntegrationRuntimeInternalChannelEncryptionMode
    :ivar version: Version of the integration runtime.
    :vartype version: str
    :param nodes: The list of nodes for this integration runtime.
    :type nodes: list[~data_factory_management_client.models.SelfHostedIntegrationRuntimeNode]
    :ivar scheduled_update_date: The date at which the integration runtime will be scheduled to
     update, in ISO8601 format.
    :vartype scheduled_update_date: ~datetime.datetime
    :ivar update_delay_offset: The time in the date scheduled by service to update the integration
     runtime, e.g., PT03H is 3 hours.
    :vartype update_delay_offset: str
    :ivar local_time_zone_offset: The local time zone offset in hours.
    :vartype local_time_zone_offset: str
    :ivar capabilities: Object with additional information about integration runtime capabilities.
    :vartype capabilities: dict[str, str]
    :ivar service_urls: The URLs for the services used in integration runtime backend service.
    :vartype service_urls: list[str]
    :ivar auto_update: The state of integration runtime auto update. Possible values include: 'On',
     'Off'.
    :vartype auto_update: str or
     ~data_factory_management_client.models.IntegrationRuntimeAutoUpdate
    :ivar version_status: Status of the integration runtime version.
    :vartype version_status: str
    :param links: The list of linked integration runtimes that are created to share with this
     integration runtime.
    :type links: list[~data_factory_management_client.models.LinkedIntegrationRuntime]
    :ivar pushed_version: The version that the integration runtime is going to update to.
    :vartype pushed_version: str
    :ivar latest_version: The latest version on download center.
    :vartype latest_version: str
    :ivar auto_update_eta: The estimated time when the self-hosted integration runtime will be
     updated.
    :vartype auto_update_eta: ~datetime.datetime
    """

    _validation = {
        'type': {'required': True},
        'data_factory_name': {'readonly': True},
        'state': {'readonly': True},
        'create_time': {'readonly': True},
        'task_queue_id': {'readonly': True},
        'internal_channel_encryption': {'readonly': True},
        'version': {'readonly': True},
        'scheduled_update_date': {'readonly': True},
        'update_delay_offset': {'readonly': True},
        'local_time_zone_offset': {'readonly': True},
        'capabilities': {'readonly': True},
        'service_urls': {'readonly': True},
        'auto_update': {'readonly': True},
        'version_status': {'readonly': True},
        'pushed_version': {'readonly': True},
        'latest_version': {'readonly': True},
        'auto_update_eta': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'data_factory_name': {'key': 'dataFactoryName', 'type': 'str'},
        'state': {'key': 'state', 'type': 'str'},
        'create_time': {'key': 'typeProperties.createTime', 'type': 'iso-8601'},
        'task_queue_id': {'key': 'typeProperties.taskQueueId', 'type': 'str'},
        'internal_channel_encryption': {'key': 'typeProperties.internalChannelEncryption', 'type': 'str'},
        'version': {'key': 'typeProperties.version', 'type': 'str'},
        'nodes': {'key': 'typeProperties.nodes', 'type': '[SelfHostedIntegrationRuntimeNode]'},
        'scheduled_update_date': {'key': 'typeProperties.scheduledUpdateDate', 'type': 'iso-8601'},
        'update_delay_offset': {'key': 'typeProperties.updateDelayOffset', 'type': 'str'},
        'local_time_zone_offset': {'key': 'typeProperties.localTimeZoneOffset', 'type': 'str'},
        'capabilities': {'key': 'typeProperties.capabilities', 'type': '{str}'},
        'service_urls': {'key': 'typeProperties.serviceUrls', 'type': '[str]'},
        'auto_update': {'key': 'typeProperties.autoUpdate', 'type': 'str'},
        'version_status': {'key': 'typeProperties.versionStatus', 'type': 'str'},
        'links': {'key': 'typeProperties.links', 'type': '[LinkedIntegrationRuntime]'},
        'pushed_version': {'key': 'typeProperties.pushedVersion', 'type': 'str'},
        'latest_version': {'key': 'typeProperties.latestVersion', 'type': 'str'},
        'auto_update_eta': {'key': 'typeProperties.autoUpdateETA', 'type': 'iso-8601'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        nodes: Optional[List["SelfHostedIntegrationRuntimeNode"]] = None,
        links: Optional[List["LinkedIntegrationRuntime"]] = None,
        **kwargs
    ):
        super(SelfHostedIntegrationRuntimeStatus, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'SelfHosted'
        self.create_time = None
        self.task_queue_id = None
        self.internal_channel_encryption = None
        self.version = None
        self.nodes = nodes
        self.scheduled_update_date = None
        self.update_delay_offset = None
        self.local_time_zone_offset = None
        self.capabilities = None
        self.service_urls = None
        self.auto_update = None
        self.version_status = None
        self.links = links
        self.pushed_version = None
        self.latest_version = None
        self.auto_update_eta = None


class SelfHostedIntegrationRuntimeStatusTypeProperties(msrest.serialization.Model):
    """Self-hosted integration runtime status type properties.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar create_time: The time at which the integration runtime was created, in ISO8601 format.
    :vartype create_time: ~datetime.datetime
    :ivar task_queue_id: The task queue id of the integration runtime.
    :vartype task_queue_id: str
    :ivar internal_channel_encryption: It is used to set the encryption mode for node-node
     communication channel (when more than 2 self-hosted integration runtime nodes exist). Possible
     values include: 'NotSet', 'SslEncrypted', 'NotEncrypted'.
    :vartype internal_channel_encryption: str or
     ~data_factory_management_client.models.IntegrationRuntimeInternalChannelEncryptionMode
    :ivar version: Version of the integration runtime.
    :vartype version: str
    :param nodes: The list of nodes for this integration runtime.
    :type nodes: list[~data_factory_management_client.models.SelfHostedIntegrationRuntimeNode]
    :ivar scheduled_update_date: The date at which the integration runtime will be scheduled to
     update, in ISO8601 format.
    :vartype scheduled_update_date: ~datetime.datetime
    :ivar update_delay_offset: The time in the date scheduled by service to update the integration
     runtime, e.g., PT03H is 3 hours.
    :vartype update_delay_offset: str
    :ivar local_time_zone_offset: The local time zone offset in hours.
    :vartype local_time_zone_offset: str
    :ivar capabilities: Object with additional information about integration runtime capabilities.
    :vartype capabilities: dict[str, str]
    :ivar service_urls: The URLs for the services used in integration runtime backend service.
    :vartype service_urls: list[str]
    :ivar auto_update: The state of integration runtime auto update. Possible values include: 'On',
     'Off'.
    :vartype auto_update: str or
     ~data_factory_management_client.models.IntegrationRuntimeAutoUpdate
    :ivar version_status: Status of the integration runtime version.
    :vartype version_status: str
    :param links: The list of linked integration runtimes that are created to share with this
     integration runtime.
    :type links: list[~data_factory_management_client.models.LinkedIntegrationRuntime]
    :ivar pushed_version: The version that the integration runtime is going to update to.
    :vartype pushed_version: str
    :ivar latest_version: The latest version on download center.
    :vartype latest_version: str
    :ivar auto_update_eta: The estimated time when the self-hosted integration runtime will be
     updated.
    :vartype auto_update_eta: ~datetime.datetime
    """

    _validation = {
        'create_time': {'readonly': True},
        'task_queue_id': {'readonly': True},
        'internal_channel_encryption': {'readonly': True},
        'version': {'readonly': True},
        'scheduled_update_date': {'readonly': True},
        'update_delay_offset': {'readonly': True},
        'local_time_zone_offset': {'readonly': True},
        'capabilities': {'readonly': True},
        'service_urls': {'readonly': True},
        'auto_update': {'readonly': True},
        'version_status': {'readonly': True},
        'pushed_version': {'readonly': True},
        'latest_version': {'readonly': True},
        'auto_update_eta': {'readonly': True},
    }

    _attribute_map = {
        'create_time': {'key': 'createTime', 'type': 'iso-8601'},
        'task_queue_id': {'key': 'taskQueueId', 'type': 'str'},
        'internal_channel_encryption': {'key': 'internalChannelEncryption', 'type': 'str'},
        'version': {'key': 'version', 'type': 'str'},
        'nodes': {'key': 'nodes', 'type': '[SelfHostedIntegrationRuntimeNode]'},
        'scheduled_update_date': {'key': 'scheduledUpdateDate', 'type': 'iso-8601'},
        'update_delay_offset': {'key': 'updateDelayOffset', 'type': 'str'},
        'local_time_zone_offset': {'key': 'localTimeZoneOffset', 'type': 'str'},
        'capabilities': {'key': 'capabilities', 'type': '{str}'},
        'service_urls': {'key': 'serviceUrls', 'type': '[str]'},
        'auto_update': {'key': 'autoUpdate', 'type': 'str'},
        'version_status': {'key': 'versionStatus', 'type': 'str'},
        'links': {'key': 'links', 'type': '[LinkedIntegrationRuntime]'},
        'pushed_version': {'key': 'pushedVersion', 'type': 'str'},
        'latest_version': {'key': 'latestVersion', 'type': 'str'},
        'auto_update_eta': {'key': 'autoUpdateETA', 'type': 'iso-8601'},
    }

    def __init__(
        self,
        *,
        nodes: Optional[List["SelfHostedIntegrationRuntimeNode"]] = None,
        links: Optional[List["LinkedIntegrationRuntime"]] = None,
        **kwargs
    ):
        super(SelfHostedIntegrationRuntimeStatusTypeProperties, self).__init__(**kwargs)
        self.create_time = None
        self.task_queue_id = None
        self.internal_channel_encryption = None
        self.version = None
        self.nodes = nodes
        self.scheduled_update_date = None
        self.update_delay_offset = None
        self.local_time_zone_offset = None
        self.capabilities = None
        self.service_urls = None
        self.auto_update = None
        self.version_status = None
        self.links = links
        self.pushed_version = None
        self.latest_version = None
        self.auto_update_eta = None


class SelfHostedIntegrationRuntimeTypeProperties(msrest.serialization.Model):
    """The self-hosted integration runtime properties.

    :param linked_info: The base definition of a linked integration runtime.
    :type linked_info: ~data_factory_management_client.models.LinkedIntegrationRuntimeType
    """

    _attribute_map = {
        'linked_info': {'key': 'linkedInfo', 'type': 'LinkedIntegrationRuntimeType'},
    }

    def __init__(
        self,
        *,
        linked_info: Optional["LinkedIntegrationRuntimeType"] = None,
        **kwargs
    ):
        super(SelfHostedIntegrationRuntimeTypeProperties, self).__init__(**kwargs)
        self.linked_info = linked_info


class ServiceNowLinkedService(LinkedService):
    """ServiceNow server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param endpoint: Required. The endpoint of the ServiceNow server. (i.e.
     :code:`<instance>`.service-now.com).
    :type endpoint:
     ~data_factory_management_client.models.ServiceNowLinkedServiceTypePropertiesEndpoint
    :param authentication_type: Required. The authentication type to use. Possible values include:
     'Basic', 'OAuth2'.
    :type authentication_type: str or
     ~data_factory_management_client.models.ServiceNowAuthenticationType
    :param username: The user name used to connect to the ServiceNow server for Basic and OAuth2
     authentication.
    :type username:
     ~data_factory_management_client.models.ServiceNowLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param client_id: The client id for OAuth2 authentication.
    :type client_id:
     ~data_factory_management_client.models.ServiceNowLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.ServiceNowLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.ServiceNowLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.ServiceNowLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.ServiceNowLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'endpoint': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'ServiceNowLinkedServiceTypePropertiesEndpoint'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'ServiceNowLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'ServiceNowLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'ServiceNowLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'ServiceNowLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'ServiceNowLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'ServiceNowLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        endpoint: "ServiceNowLinkedServiceTypePropertiesEndpoint",
        authentication_type: Union[str, "ServiceNowAuthenticationType"],
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        username: Optional["ServiceNowLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        client_id: Optional["ServiceNowLinkedServiceTypePropertiesClientId"] = None,
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["ServiceNowLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["ServiceNowLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["ServiceNowLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["ServiceNowLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(ServiceNowLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'ServiceNow'
        self.endpoint = endpoint
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.client_id = client_id
        self.client_secret = client_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class ServiceNowLinkedServiceTypeProperties(msrest.serialization.Model):
    """ServiceNow server linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param endpoint: Required. The endpoint of the ServiceNow server. (i.e.
     :code:`<instance>`.service-now.com).
    :type endpoint:
     ~data_factory_management_client.models.ServiceNowLinkedServiceTypePropertiesEndpoint
    :param authentication_type: Required. The authentication type to use. Possible values include:
     'Basic', 'OAuth2'.
    :type authentication_type: str or
     ~data_factory_management_client.models.ServiceNowAuthenticationType
    :param username: The user name used to connect to the ServiceNow server for Basic and OAuth2
     authentication.
    :type username:
     ~data_factory_management_client.models.ServiceNowLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param client_id: The client id for OAuth2 authentication.
    :type client_id:
     ~data_factory_management_client.models.ServiceNowLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.ServiceNowLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.ServiceNowLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.ServiceNowLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.ServiceNowLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'endpoint': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'endpoint': {'key': 'endpoint', 'type': 'ServiceNowLinkedServiceTypePropertiesEndpoint'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'username': {'key': 'username', 'type': 'ServiceNowLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'client_id': {'key': 'clientId', 'type': 'ServiceNowLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'clientSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'ServiceNowLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'ServiceNowLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'ServiceNowLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'ServiceNowLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        endpoint: "ServiceNowLinkedServiceTypePropertiesEndpoint",
        authentication_type: Union[str, "ServiceNowAuthenticationType"],
        username: Optional["ServiceNowLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        client_id: Optional["ServiceNowLinkedServiceTypePropertiesClientId"] = None,
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["ServiceNowLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["ServiceNowLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["ServiceNowLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["ServiceNowLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(ServiceNowLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.endpoint = endpoint
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.client_id = client_id
        self.client_secret = client_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class ServiceNowLinkedServiceTypePropertiesClientId(msrest.serialization.Model):
    """The client id for OAuth2 authentication.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ServiceNowLinkedServiceTypePropertiesClientId, self).__init__(**kwargs)


class ServiceNowLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ServiceNowLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class ServiceNowLinkedServiceTypePropertiesEndpoint(msrest.serialization.Model):
    """The endpoint of the ServiceNow server. (i.e. :code:`<instance>`.service-now.com).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ServiceNowLinkedServiceTypePropertiesEndpoint, self).__init__(**kwargs)


class ServiceNowLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ServiceNowLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class ServiceNowLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ServiceNowLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class ServiceNowLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ServiceNowLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class ServiceNowLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """The user name used to connect to the ServiceNow server for Basic and OAuth2 authentication.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ServiceNowLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class ServiceNowObjectDataset(Dataset):
    """ServiceNow server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(ServiceNowObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'ServiceNowObject'
        self.table_name = table_name


class ServiceNowSource(TabularSource):
    """A copy activity ServiceNow server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.ServiceNowSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'ServiceNowSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["ServiceNowSourceQuery"] = None,
        **kwargs
    ):
        super(ServiceNowSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'ServiceNowSource'
        self.query = query


class ServiceNowSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ServiceNowSourceQuery, self).__init__(**kwargs)


class SetVariableActivity(ControlActivity):
    """Set value for a Variable.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param variable_name: Name of the variable whose value needs to be set.
    :type variable_name: str
    :param value: Value to be set. Could be a static value or Expression.
    :type value: ~data_factory_management_client.models.SetVariableActivityTypePropertiesValue
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'variable_name': {'key': 'typeProperties.variableName', 'type': 'str'},
        'value': {'key': 'typeProperties.value', 'type': 'SetVariableActivityTypePropertiesValue'},
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        variable_name: Optional[str] = None,
        value: Optional["SetVariableActivityTypePropertiesValue"] = None,
        **kwargs
    ):
        super(SetVariableActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'SetVariable'
        self.variable_name = variable_name
        self.value = value


class SetVariableActivityTypeProperties(msrest.serialization.Model):
    """SetVariable activity properties.

    :param variable_name: Name of the variable whose value needs to be set.
    :type variable_name: str
    :param value: Value to be set. Could be a static value or Expression.
    :type value: ~data_factory_management_client.models.SetVariableActivityTypePropertiesValue
    """

    _attribute_map = {
        'variable_name': {'key': 'variableName', 'type': 'str'},
        'value': {'key': 'value', 'type': 'SetVariableActivityTypePropertiesValue'},
    }

    def __init__(
        self,
        *,
        variable_name: Optional[str] = None,
        value: Optional["SetVariableActivityTypePropertiesValue"] = None,
        **kwargs
    ):
        super(SetVariableActivityTypeProperties, self).__init__(**kwargs)
        self.variable_name = variable_name
        self.value = value


class SetVariableActivityTypePropertiesValue(msrest.serialization.Model):
    """Value to be set. Could be a static value or Expression.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SetVariableActivityTypePropertiesValue, self).__init__(**kwargs)


class SftpLocation(DatasetLocation):
    """The location of SFTP dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage location.Constant filled by server.
    :type type: str
    :param folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :type folder_path: ~data_factory_management_client.models.DatasetLocationFolderPath
    :param file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :type file_name: ~data_factory_management_client.models.DatasetLocationFileName
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'DatasetLocationFolderPath'},
        'file_name': {'key': 'fileName', 'type': 'DatasetLocationFileName'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        folder_path: Optional["DatasetLocationFolderPath"] = None,
        file_name: Optional["DatasetLocationFileName"] = None,
        **kwargs
    ):
        super(SftpLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'SftpLocation'


class SftpReadSettings(StoreReadSettings):
    """Sftp read settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The read setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreReadSettingsMaxConcurrentConnections
    :param recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :type recursive: ~data_factory_management_client.models.SftpReadSettingsRecursive
    :param wildcard_folder_path: Sftp wildcardFolderPath. Type: string (or Expression with
     resultType string).
    :type wildcard_folder_path:
     ~data_factory_management_client.models.SftpReadSettingsWildcardFolderPath
    :param wildcard_file_name: Sftp wildcardFileName. Type: string (or Expression with resultType
     string).
    :type wildcard_file_name:
     ~data_factory_management_client.models.SftpReadSettingsWildcardFileName
    :param file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :type file_list_path: ~data_factory_management_client.models.SftpReadSettingsFileListPath
    :param modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :type modified_datetime_start:
     ~data_factory_management_client.models.SftpReadSettingsModifiedDatetimeStart
    :param modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :type modified_datetime_end:
     ~data_factory_management_client.models.SftpReadSettingsModifiedDatetimeEnd
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreReadSettingsMaxConcurrentConnections'},
        'recursive': {'key': 'recursive', 'type': 'SftpReadSettingsRecursive'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'SftpReadSettingsWildcardFolderPath'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'SftpReadSettingsWildcardFileName'},
        'file_list_path': {'key': 'fileListPath', 'type': 'SftpReadSettingsFileListPath'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'SftpReadSettingsModifiedDatetimeStart'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'SftpReadSettingsModifiedDatetimeEnd'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreReadSettingsMaxConcurrentConnections"] = None,
        recursive: Optional["SftpReadSettingsRecursive"] = None,
        wildcard_folder_path: Optional["SftpReadSettingsWildcardFolderPath"] = None,
        wildcard_file_name: Optional["SftpReadSettingsWildcardFileName"] = None,
        file_list_path: Optional["SftpReadSettingsFileListPath"] = None,
        modified_datetime_start: Optional["SftpReadSettingsModifiedDatetimeStart"] = None,
        modified_datetime_end: Optional["SftpReadSettingsModifiedDatetimeEnd"] = None,
        **kwargs
    ):
        super(SftpReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'SftpReadSettings'
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.file_list_path = file_list_path
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class SftpReadSettingsFileListPath(msrest.serialization.Model):
    """Point to a text file that lists each file (relative path to the path configured in the dataset) that you want to copy. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SftpReadSettingsFileListPath, self).__init__(**kwargs)


class SftpReadSettingsModifiedDatetimeEnd(msrest.serialization.Model):
    """The end of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SftpReadSettingsModifiedDatetimeEnd, self).__init__(**kwargs)


class SftpReadSettingsModifiedDatetimeStart(msrest.serialization.Model):
    """The start of file's modified datetime. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SftpReadSettingsModifiedDatetimeStart, self).__init__(**kwargs)


class SftpReadSettingsRecursive(msrest.serialization.Model):
    """If true, files under the folder path will be read recursively. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SftpReadSettingsRecursive, self).__init__(**kwargs)


class SftpReadSettingsWildcardFileName(msrest.serialization.Model):
    """Sftp wildcardFileName. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SftpReadSettingsWildcardFileName, self).__init__(**kwargs)


class SftpReadSettingsWildcardFolderPath(msrest.serialization.Model):
    """Sftp wildcardFolderPath. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SftpReadSettingsWildcardFolderPath, self).__init__(**kwargs)


class SftpServerLinkedService(LinkedService):
    """A linked service for an SSH File Transfer Protocol (SFTP) server.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. The SFTP server host name. Type: string (or Expression with resultType
     string).
    :type host: ~data_factory_management_client.models.SftpServerLinkedServiceTypePropertiesHost
    :param port: The TCP port number that the SFTP server uses to listen for client connections.
     Default value is 22. Type: integer (or Expression with resultType integer), minimum: 0.
    :type port: ~data_factory_management_client.models.SftpServerLinkedServiceTypePropertiesPort
    :param authentication_type: The authentication type to be used to connect to the FTP server.
     Possible values include: 'Basic', 'SshPublicKey'.
    :type authentication_type: str or ~data_factory_management_client.models.SftpAuthenticationType
    :param user_name: The username used to log on to the SFTP server. Type: string (or Expression
     with resultType string).
    :type user_name:
     ~data_factory_management_client.models.SftpServerLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SftpServerLinkedServiceTypePropertiesEncryptedCredential
    :param private_key_path: The SSH private key file path for SshPublicKey authentication. Only
     valid for on-premises copy. For on-premises copy with SshPublicKey authentication, either
     PrivateKeyPath or PrivateKeyContent should be specified. SSH private key should be OpenSSH
     format. Type: string (or Expression with resultType string).
    :type private_key_path:
     ~data_factory_management_client.models.SftpServerLinkedServiceTypePropertiesPrivateKeyPath
    :param private_key_content: The base definition of a secret type.
    :type private_key_content: ~data_factory_management_client.models.SecretBase
    :param pass_phrase: The base definition of a secret type.
    :type pass_phrase: ~data_factory_management_client.models.SecretBase
    :param skip_host_key_validation: If true, skip the SSH host key validation. Default value is
     false. Type: boolean (or Expression with resultType boolean).
    :type skip_host_key_validation:
     ~data_factory_management_client.models.SftpServerLinkedServiceTypePropertiesSkipHostKeyValidation
    :param host_key_fingerprint: The host key finger-print of the SFTP server. When
     SkipHostKeyValidation is false, HostKeyFingerprint should be specified. Type: string (or
     Expression with resultType string).
    :type host_key_fingerprint:
     ~data_factory_management_client.models.SftpServerLinkedServiceTypePropertiesHostKeyFingerprint
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'SftpServerLinkedServiceTypePropertiesHost'},
        'port': {'key': 'typeProperties.port', 'type': 'SftpServerLinkedServiceTypePropertiesPort'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'SftpServerLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'SftpServerLinkedServiceTypePropertiesEncryptedCredential'},
        'private_key_path': {'key': 'typeProperties.privateKeyPath', 'type': 'SftpServerLinkedServiceTypePropertiesPrivateKeyPath'},
        'private_key_content': {'key': 'typeProperties.privateKeyContent', 'type': 'SecretBase'},
        'pass_phrase': {'key': 'typeProperties.passPhrase', 'type': 'SecretBase'},
        'skip_host_key_validation': {'key': 'typeProperties.skipHostKeyValidation', 'type': 'SftpServerLinkedServiceTypePropertiesSkipHostKeyValidation'},
        'host_key_fingerprint': {'key': 'typeProperties.hostKeyFingerprint', 'type': 'SftpServerLinkedServiceTypePropertiesHostKeyFingerprint'},
    }

    def __init__(
        self,
        *,
        host: "SftpServerLinkedServiceTypePropertiesHost",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        port: Optional["SftpServerLinkedServiceTypePropertiesPort"] = None,
        authentication_type: Optional[Union[str, "SftpAuthenticationType"]] = None,
        user_name: Optional["SftpServerLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["SftpServerLinkedServiceTypePropertiesEncryptedCredential"] = None,
        private_key_path: Optional["SftpServerLinkedServiceTypePropertiesPrivateKeyPath"] = None,
        private_key_content: Optional["SecretBase"] = None,
        pass_phrase: Optional["SecretBase"] = None,
        skip_host_key_validation: Optional["SftpServerLinkedServiceTypePropertiesSkipHostKeyValidation"] = None,
        host_key_fingerprint: Optional["SftpServerLinkedServiceTypePropertiesHostKeyFingerprint"] = None,
        **kwargs
    ):
        super(SftpServerLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Sftp'
        self.host = host
        self.port = port
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential
        self.private_key_path = private_key_path
        self.private_key_content = private_key_content
        self.pass_phrase = pass_phrase
        self.skip_host_key_validation = skip_host_key_validation
        self.host_key_fingerprint = host_key_fingerprint


class SftpServerLinkedServiceTypeProperties(msrest.serialization.Model):
    """Properties specific to this linked service type.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. The SFTP server host name. Type: string (or Expression with resultType
     string).
    :type host: ~data_factory_management_client.models.SftpServerLinkedServiceTypePropertiesHost
    :param port: The TCP port number that the SFTP server uses to listen for client connections.
     Default value is 22. Type: integer (or Expression with resultType integer), minimum: 0.
    :type port: ~data_factory_management_client.models.SftpServerLinkedServiceTypePropertiesPort
    :param authentication_type: The authentication type to be used to connect to the FTP server.
     Possible values include: 'Basic', 'SshPublicKey'.
    :type authentication_type: str or ~data_factory_management_client.models.SftpAuthenticationType
    :param user_name: The username used to log on to the SFTP server. Type: string (or Expression
     with resultType string).
    :type user_name:
     ~data_factory_management_client.models.SftpServerLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SftpServerLinkedServiceTypePropertiesEncryptedCredential
    :param private_key_path: The SSH private key file path for SshPublicKey authentication. Only
     valid for on-premises copy. For on-premises copy with SshPublicKey authentication, either
     PrivateKeyPath or PrivateKeyContent should be specified. SSH private key should be OpenSSH
     format. Type: string (or Expression with resultType string).
    :type private_key_path:
     ~data_factory_management_client.models.SftpServerLinkedServiceTypePropertiesPrivateKeyPath
    :param private_key_content: The base definition of a secret type.
    :type private_key_content: ~data_factory_management_client.models.SecretBase
    :param pass_phrase: The base definition of a secret type.
    :type pass_phrase: ~data_factory_management_client.models.SecretBase
    :param skip_host_key_validation: If true, skip the SSH host key validation. Default value is
     false. Type: boolean (or Expression with resultType boolean).
    :type skip_host_key_validation:
     ~data_factory_management_client.models.SftpServerLinkedServiceTypePropertiesSkipHostKeyValidation
    :param host_key_fingerprint: The host key finger-print of the SFTP server. When
     SkipHostKeyValidation is false, HostKeyFingerprint should be specified. Type: string (or
     Expression with resultType string).
    :type host_key_fingerprint:
     ~data_factory_management_client.models.SftpServerLinkedServiceTypePropertiesHostKeyFingerprint
    """

    _validation = {
        'host': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'SftpServerLinkedServiceTypePropertiesHost'},
        'port': {'key': 'port', 'type': 'SftpServerLinkedServiceTypePropertiesPort'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'user_name': {'key': 'userName', 'type': 'SftpServerLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'SftpServerLinkedServiceTypePropertiesEncryptedCredential'},
        'private_key_path': {'key': 'privateKeyPath', 'type': 'SftpServerLinkedServiceTypePropertiesPrivateKeyPath'},
        'private_key_content': {'key': 'privateKeyContent', 'type': 'SecretBase'},
        'pass_phrase': {'key': 'passPhrase', 'type': 'SecretBase'},
        'skip_host_key_validation': {'key': 'skipHostKeyValidation', 'type': 'SftpServerLinkedServiceTypePropertiesSkipHostKeyValidation'},
        'host_key_fingerprint': {'key': 'hostKeyFingerprint', 'type': 'SftpServerLinkedServiceTypePropertiesHostKeyFingerprint'},
    }

    def __init__(
        self,
        *,
        host: "SftpServerLinkedServiceTypePropertiesHost",
        port: Optional["SftpServerLinkedServiceTypePropertiesPort"] = None,
        authentication_type: Optional[Union[str, "SftpAuthenticationType"]] = None,
        user_name: Optional["SftpServerLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["SftpServerLinkedServiceTypePropertiesEncryptedCredential"] = None,
        private_key_path: Optional["SftpServerLinkedServiceTypePropertiesPrivateKeyPath"] = None,
        private_key_content: Optional["SecretBase"] = None,
        pass_phrase: Optional["SecretBase"] = None,
        skip_host_key_validation: Optional["SftpServerLinkedServiceTypePropertiesSkipHostKeyValidation"] = None,
        host_key_fingerprint: Optional["SftpServerLinkedServiceTypePropertiesHostKeyFingerprint"] = None,
        **kwargs
    ):
        super(SftpServerLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.port = port
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential
        self.private_key_path = private_key_path
        self.private_key_content = private_key_content
        self.pass_phrase = pass_phrase
        self.skip_host_key_validation = skip_host_key_validation
        self.host_key_fingerprint = host_key_fingerprint


class SftpServerLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SftpServerLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class SftpServerLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """The SFTP server host name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SftpServerLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class SftpServerLinkedServiceTypePropertiesHostKeyFingerprint(msrest.serialization.Model):
    """The host key finger-print of the SFTP server. When SkipHostKeyValidation is false, HostKeyFingerprint should be specified. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SftpServerLinkedServiceTypePropertiesHostKeyFingerprint, self).__init__(**kwargs)


class SftpServerLinkedServiceTypePropertiesPort(msrest.serialization.Model):
    """The TCP port number that the SFTP server uses to listen for client connections. Default value is 22. Type: integer (or Expression with resultType integer), minimum: 0.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SftpServerLinkedServiceTypePropertiesPort, self).__init__(**kwargs)


class SftpServerLinkedServiceTypePropertiesPrivateKeyPath(msrest.serialization.Model):
    """The SSH private key file path for SshPublicKey authentication. Only valid for on-premises copy. For on-premises copy with SshPublicKey authentication, either PrivateKeyPath or PrivateKeyContent should be specified. SSH private key should be OpenSSH format. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SftpServerLinkedServiceTypePropertiesPrivateKeyPath, self).__init__(**kwargs)


class SftpServerLinkedServiceTypePropertiesSkipHostKeyValidation(msrest.serialization.Model):
    """If true, skip the SSH host key validation. Default value is false. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SftpServerLinkedServiceTypePropertiesSkipHostKeyValidation, self).__init__(**kwargs)


class SftpServerLinkedServiceTypePropertiesUserName(msrest.serialization.Model):
    """The username used to log on to the SFTP server. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SftpServerLinkedServiceTypePropertiesUserName, self).__init__(**kwargs)


class SftpWriteSettings(StoreWriteSettings):
    """Sftp write settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. The write setting type.Constant filled by server.
    :type type: str
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.StoreWriteSettingsMaxConcurrentConnections
    :param copy_behavior: The type of copy behavior for copy sink.
    :type copy_behavior: ~data_factory_management_client.models.StoreWriteSettingsCopyBehavior
    :param operation_timeout: Specifies the timeout for writing each chunk to SFTP server. Default
     value: 01:00:00 (one hour). Type: string (or Expression with resultType string).
    :type operation_timeout:
     ~data_factory_management_client.models.SftpWriteSettingsOperationTimeout
    :param use_temp_file_rename: Upload to temporary file(s) and rename. Disable this option if
     your SFTP server doesn't support rename operation. Type: boolean (or Expression with resultType
     boolean).
    :type use_temp_file_rename:
     ~data_factory_management_client.models.SftpWriteSettingsUseTempFileRename
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'StoreWriteSettingsMaxConcurrentConnections'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'StoreWriteSettingsCopyBehavior'},
        'operation_timeout': {'key': 'operationTimeout', 'type': 'SftpWriteSettingsOperationTimeout'},
        'use_temp_file_rename': {'key': 'useTempFileRename', 'type': 'SftpWriteSettingsUseTempFileRename'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        max_concurrent_connections: Optional["StoreWriteSettingsMaxConcurrentConnections"] = None,
        copy_behavior: Optional["StoreWriteSettingsCopyBehavior"] = None,
        operation_timeout: Optional["SftpWriteSettingsOperationTimeout"] = None,
        use_temp_file_rename: Optional["SftpWriteSettingsUseTempFileRename"] = None,
        **kwargs
    ):
        super(SftpWriteSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, copy_behavior=copy_behavior, **kwargs)
        self.type = 'SftpWriteSettings'
        self.operation_timeout = operation_timeout
        self.use_temp_file_rename = use_temp_file_rename


class SftpWriteSettingsOperationTimeout(msrest.serialization.Model):
    """Specifies the timeout for writing each chunk to SFTP server. Default value: 01:00:00 (one hour). Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SftpWriteSettingsOperationTimeout, self).__init__(**kwargs)


class SftpWriteSettingsUseTempFileRename(msrest.serialization.Model):
    """Upload to temporary file(s) and rename. Disable this option if your SFTP server doesn't support rename operation. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SftpWriteSettingsUseTempFileRename, self).__init__(**kwargs)


class ShopifyLinkedService(LinkedService):
    """Shopify Service linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. The endpoint of the Shopify server. (i.e. mystore.myshopify.com).
    :type host: ~data_factory_management_client.models.ShopifyLinkedServiceTypePropertiesHost
    :param access_token: The base definition of a secret type.
    :type access_token: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.ShopifyLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.ShopifyLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.ShopifyLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.ShopifyLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'ShopifyLinkedServiceTypePropertiesHost'},
        'access_token': {'key': 'typeProperties.accessToken', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'ShopifyLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'ShopifyLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'ShopifyLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'ShopifyLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "ShopifyLinkedServiceTypePropertiesHost",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        access_token: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["ShopifyLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["ShopifyLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["ShopifyLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["ShopifyLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(ShopifyLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Shopify'
        self.host = host
        self.access_token = access_token
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class ShopifyLinkedServiceTypeProperties(msrest.serialization.Model):
    """Shopify Service linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. The endpoint of the Shopify server. (i.e. mystore.myshopify.com).
    :type host: ~data_factory_management_client.models.ShopifyLinkedServiceTypePropertiesHost
    :param access_token: The base definition of a secret type.
    :type access_token: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.ShopifyLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.ShopifyLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.ShopifyLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.ShopifyLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'ShopifyLinkedServiceTypePropertiesHost'},
        'access_token': {'key': 'accessToken', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'ShopifyLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'ShopifyLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'ShopifyLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'ShopifyLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "ShopifyLinkedServiceTypePropertiesHost",
        access_token: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["ShopifyLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["ShopifyLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["ShopifyLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["ShopifyLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(ShopifyLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.access_token = access_token
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class ShopifyLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ShopifyLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class ShopifyLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """The endpoint of the Shopify server. (i.e. mystore.myshopify.com).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ShopifyLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class ShopifyLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ShopifyLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class ShopifyLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ShopifyLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class ShopifyLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ShopifyLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class ShopifyObjectDataset(Dataset):
    """Shopify Service dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(ShopifyObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'ShopifyObject'
        self.table_name = table_name


class ShopifySource(TabularSource):
    """A copy activity Shopify Service source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.ShopifySourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'ShopifySourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["ShopifySourceQuery"] = None,
        **kwargs
    ):
        super(ShopifySource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'ShopifySource'
        self.query = query


class ShopifySourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ShopifySourceQuery, self).__init__(**kwargs)


class SkipErrorFile(msrest.serialization.Model):
    """Skip error file.

    :param file_missing: Skip if file is deleted by other client during copy. Default is true.
     Type: boolean (or Expression with resultType boolean).
    :type file_missing: ~data_factory_management_client.models.SkipErrorFileFileMissing
    :param data_inconsistency: Skip if source/sink file changed by other concurrent write. Default
     is false. Type: boolean (or Expression with resultType boolean).
    :type data_inconsistency: ~data_factory_management_client.models.SkipErrorFileDataInconsistency
    """

    _attribute_map = {
        'file_missing': {'key': 'fileMissing', 'type': 'SkipErrorFileFileMissing'},
        'data_inconsistency': {'key': 'dataInconsistency', 'type': 'SkipErrorFileDataInconsistency'},
    }

    def __init__(
        self,
        *,
        file_missing: Optional["SkipErrorFileFileMissing"] = None,
        data_inconsistency: Optional["SkipErrorFileDataInconsistency"] = None,
        **kwargs
    ):
        super(SkipErrorFile, self).__init__(**kwargs)
        self.file_missing = file_missing
        self.data_inconsistency = data_inconsistency


class SkipErrorFileDataInconsistency(msrest.serialization.Model):
    """Skip if source/sink file changed by other concurrent write. Default is false. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SkipErrorFileDataInconsistency, self).__init__(**kwargs)


class SkipErrorFileFileMissing(msrest.serialization.Model):
    """Skip if file is deleted by other client during copy. Default is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SkipErrorFileFileMissing, self).__init__(**kwargs)


class SparkDatasetTypeProperties(msrest.serialization.Model):
    """Spark Properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.SparkDatasetTypePropertiesTableName
    :param table: The table name of the Spark. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.SparkDatasetTypePropertiesTable
    :param schema: The schema name of the Spark. Type: string (or Expression with resultType
     string).
    :type schema: ~data_factory_management_client.models.SparkDatasetTypePropertiesSchema
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'SparkDatasetTypePropertiesTableName'},
        'table': {'key': 'table', 'type': 'SparkDatasetTypePropertiesTable'},
        'schema': {'key': 'schema', 'type': 'SparkDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["SparkDatasetTypePropertiesTableName"] = None,
        table: Optional["SparkDatasetTypePropertiesTable"] = None,
        schema: Optional["SparkDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(SparkDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.table = table
        self.schema = schema


class SparkDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of the Spark. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SparkDatasetTypePropertiesSchema, self).__init__(**kwargs)


class SparkDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the Spark. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SparkDatasetTypePropertiesTable, self).__init__(**kwargs)


class SparkDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SparkDatasetTypePropertiesTableName, self).__init__(**kwargs)


class SparkLinkedService(LinkedService):
    """Spark Server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. IP address or host name of the Spark server.
    :type host: ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesHost
    :param port: Required. The TCP port that the Spark server uses to listen for client
     connections.
    :type port: ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesPort
    :param server_type: The type of Spark server. Possible values include: 'SharkServer',
     'SharkServer2', 'SparkThriftServer'.
    :type server_type: str or ~data_factory_management_client.models.SparkServerType
    :param thrift_transport_protocol: The transport protocol to use in the Thrift layer. Possible
     values include: 'Binary', 'SASL', 'HTTP '.
    :type thrift_transport_protocol: str or
     ~data_factory_management_client.models.SparkThriftTransportProtocol
    :param authentication_type: Required. The authentication method used to access the Spark
     server. Possible values include: 'Anonymous', 'Username', 'UsernameAndPassword',
     'WindowsAzureHDInsightService'.
    :type authentication_type: str or
     ~data_factory_management_client.models.SparkAuthenticationType
    :param username: The user name that you use to access Spark Server.
    :type username: ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param http_path: The partial URL corresponding to the Spark server.
    :type http_path:
     ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesHttpPath
    :param enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :type enable_ssl:
     ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesEnableSsl
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesTrustedCertPath
    :param use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :type use_system_trust_store:
     ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesUseSystemTrustStore
    :param allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :type allow_host_name_cn_mismatch:
     ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesAllowHostNameCNMismatch
    :param allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :type allow_self_signed_server_cert:
     ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesAllowSelfSignedServerCert
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'port': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'SparkLinkedServiceTypePropertiesHost'},
        'port': {'key': 'typeProperties.port', 'type': 'SparkLinkedServiceTypePropertiesPort'},
        'server_type': {'key': 'typeProperties.serverType', 'type': 'str'},
        'thrift_transport_protocol': {'key': 'typeProperties.thriftTransportProtocol', 'type': 'str'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'SparkLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'http_path': {'key': 'typeProperties.httpPath', 'type': 'SparkLinkedServiceTypePropertiesHttpPath'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'SparkLinkedServiceTypePropertiesEnableSsl'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'SparkLinkedServiceTypePropertiesTrustedCertPath'},
        'use_system_trust_store': {'key': 'typeProperties.useSystemTrustStore', 'type': 'SparkLinkedServiceTypePropertiesUseSystemTrustStore'},
        'allow_host_name_cn_mismatch': {'key': 'typeProperties.allowHostNameCNMismatch', 'type': 'SparkLinkedServiceTypePropertiesAllowHostNameCNMismatch'},
        'allow_self_signed_server_cert': {'key': 'typeProperties.allowSelfSignedServerCert', 'type': 'SparkLinkedServiceTypePropertiesAllowSelfSignedServerCert'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'SparkLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "SparkLinkedServiceTypePropertiesHost",
        port: "SparkLinkedServiceTypePropertiesPort",
        authentication_type: Union[str, "SparkAuthenticationType"],
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        server_type: Optional[Union[str, "SparkServerType"]] = None,
        thrift_transport_protocol: Optional[Union[str, "SparkThriftTransportProtocol"]] = None,
        username: Optional["SparkLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        http_path: Optional["SparkLinkedServiceTypePropertiesHttpPath"] = None,
        enable_ssl: Optional["SparkLinkedServiceTypePropertiesEnableSsl"] = None,
        trusted_cert_path: Optional["SparkLinkedServiceTypePropertiesTrustedCertPath"] = None,
        use_system_trust_store: Optional["SparkLinkedServiceTypePropertiesUseSystemTrustStore"] = None,
        allow_host_name_cn_mismatch: Optional["SparkLinkedServiceTypePropertiesAllowHostNameCNMismatch"] = None,
        allow_self_signed_server_cert: Optional["SparkLinkedServiceTypePropertiesAllowSelfSignedServerCert"] = None,
        encrypted_credential: Optional["SparkLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SparkLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Spark'
        self.host = host
        self.port = port
        self.server_type = server_type
        self.thrift_transport_protocol = thrift_transport_protocol
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.http_path = http_path
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class SparkLinkedServiceTypeProperties(msrest.serialization.Model):
    """Spark Server linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. IP address or host name of the Spark server.
    :type host: ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesHost
    :param port: Required. The TCP port that the Spark server uses to listen for client
     connections.
    :type port: ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesPort
    :param server_type: The type of Spark server. Possible values include: 'SharkServer',
     'SharkServer2', 'SparkThriftServer'.
    :type server_type: str or ~data_factory_management_client.models.SparkServerType
    :param thrift_transport_protocol: The transport protocol to use in the Thrift layer. Possible
     values include: 'Binary', 'SASL', 'HTTP '.
    :type thrift_transport_protocol: str or
     ~data_factory_management_client.models.SparkThriftTransportProtocol
    :param authentication_type: Required. The authentication method used to access the Spark
     server. Possible values include: 'Anonymous', 'Username', 'UsernameAndPassword',
     'WindowsAzureHDInsightService'.
    :type authentication_type: str or
     ~data_factory_management_client.models.SparkAuthenticationType
    :param username: The user name that you use to access Spark Server.
    :type username: ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param http_path: The partial URL corresponding to the Spark server.
    :type http_path:
     ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesHttpPath
    :param enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :type enable_ssl:
     ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesEnableSsl
    :param trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :type trusted_cert_path:
     ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesTrustedCertPath
    :param use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :type use_system_trust_store:
     ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesUseSystemTrustStore
    :param allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :type allow_host_name_cn_mismatch:
     ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesAllowHostNameCNMismatch
    :param allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :type allow_self_signed_server_cert:
     ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesAllowSelfSignedServerCert
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SparkLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
        'port': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'SparkLinkedServiceTypePropertiesHost'},
        'port': {'key': 'port', 'type': 'SparkLinkedServiceTypePropertiesPort'},
        'server_type': {'key': 'serverType', 'type': 'str'},
        'thrift_transport_protocol': {'key': 'thriftTransportProtocol', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'username': {'key': 'username', 'type': 'SparkLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'http_path': {'key': 'httpPath', 'type': 'SparkLinkedServiceTypePropertiesHttpPath'},
        'enable_ssl': {'key': 'enableSsl', 'type': 'SparkLinkedServiceTypePropertiesEnableSsl'},
        'trusted_cert_path': {'key': 'trustedCertPath', 'type': 'SparkLinkedServiceTypePropertiesTrustedCertPath'},
        'use_system_trust_store': {'key': 'useSystemTrustStore', 'type': 'SparkLinkedServiceTypePropertiesUseSystemTrustStore'},
        'allow_host_name_cn_mismatch': {'key': 'allowHostNameCNMismatch', 'type': 'SparkLinkedServiceTypePropertiesAllowHostNameCNMismatch'},
        'allow_self_signed_server_cert': {'key': 'allowSelfSignedServerCert', 'type': 'SparkLinkedServiceTypePropertiesAllowSelfSignedServerCert'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'SparkLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "SparkLinkedServiceTypePropertiesHost",
        port: "SparkLinkedServiceTypePropertiesPort",
        authentication_type: Union[str, "SparkAuthenticationType"],
        server_type: Optional[Union[str, "SparkServerType"]] = None,
        thrift_transport_protocol: Optional[Union[str, "SparkThriftTransportProtocol"]] = None,
        username: Optional["SparkLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        http_path: Optional["SparkLinkedServiceTypePropertiesHttpPath"] = None,
        enable_ssl: Optional["SparkLinkedServiceTypePropertiesEnableSsl"] = None,
        trusted_cert_path: Optional["SparkLinkedServiceTypePropertiesTrustedCertPath"] = None,
        use_system_trust_store: Optional["SparkLinkedServiceTypePropertiesUseSystemTrustStore"] = None,
        allow_host_name_cn_mismatch: Optional["SparkLinkedServiceTypePropertiesAllowHostNameCNMismatch"] = None,
        allow_self_signed_server_cert: Optional["SparkLinkedServiceTypePropertiesAllowSelfSignedServerCert"] = None,
        encrypted_credential: Optional["SparkLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SparkLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.port = port
        self.server_type = server_type
        self.thrift_transport_protocol = thrift_transport_protocol
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.http_path = http_path
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class SparkLinkedServiceTypePropertiesAllowHostNameCNMismatch(msrest.serialization.Model):
    """Specifies whether to require a CA-issued SSL certificate name to match the host name of the server when connecting over SSL. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SparkLinkedServiceTypePropertiesAllowHostNameCNMismatch, self).__init__(**kwargs)


class SparkLinkedServiceTypePropertiesAllowSelfSignedServerCert(msrest.serialization.Model):
    """Specifies whether to allow self-signed certificates from the server. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SparkLinkedServiceTypePropertiesAllowSelfSignedServerCert, self).__init__(**kwargs)


class SparkLinkedServiceTypePropertiesEnableSsl(msrest.serialization.Model):
    """Specifies whether the connections to the server are encrypted using SSL. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SparkLinkedServiceTypePropertiesEnableSsl, self).__init__(**kwargs)


class SparkLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SparkLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class SparkLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """IP address or host name of the Spark server.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SparkLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class SparkLinkedServiceTypePropertiesHttpPath(msrest.serialization.Model):
    """The partial URL corresponding to the Spark server.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SparkLinkedServiceTypePropertiesHttpPath, self).__init__(**kwargs)


class SparkLinkedServiceTypePropertiesPort(msrest.serialization.Model):
    """The TCP port that the Spark server uses to listen for client connections.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SparkLinkedServiceTypePropertiesPort, self).__init__(**kwargs)


class SparkLinkedServiceTypePropertiesTrustedCertPath(msrest.serialization.Model):
    """The full path of the .pem file containing trusted CA certificates for verifying the server when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The default value is the cacerts.pem file installed with the IR.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SparkLinkedServiceTypePropertiesTrustedCertPath, self).__init__(**kwargs)


class SparkLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """The user name that you use to access Spark Server.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SparkLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class SparkLinkedServiceTypePropertiesUseSystemTrustStore(msrest.serialization.Model):
    """Specifies whether to use a CA certificate from the system trust store or from a specified PEM file. The default value is false.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SparkLinkedServiceTypePropertiesUseSystemTrustStore, self).__init__(**kwargs)


class SparkObjectDataset(Dataset):
    """Spark Server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.SparkDatasetTypePropertiesTableName
    :param table: The table name of the Spark. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.SparkDatasetTypePropertiesTable
    :param schema_type_properties_schema: The schema name of the Spark. Type: string (or Expression
     with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.SparkDatasetTypePropertiesSchema
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'SparkDatasetTypePropertiesTableName'},
        'table': {'key': 'typeProperties.table', 'type': 'SparkDatasetTypePropertiesTable'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'SparkDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["SparkDatasetTypePropertiesTableName"] = None,
        table: Optional["SparkDatasetTypePropertiesTable"] = None,
        schema_type_properties_schema: Optional["SparkDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(SparkObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SparkObject'
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class SparkSource(TabularSource):
    """A copy activity Spark Server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.SparkSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'SparkSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["SparkSourceQuery"] = None,
        **kwargs
    ):
        super(SparkSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SparkSource'
        self.query = query


class SparkSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SparkSourceQuery, self).__init__(**kwargs)


class SqlDWSink(CopySink):
    """A copy activity SQL Data Warehouse sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
     string).
    :type pre_copy_script: ~data_factory_management_client.models.SqlDWSinkPreCopyScript
    :param allow_poly_base: Indicates to use PolyBase to copy data into SQL Data Warehouse when
     applicable. Type: boolean (or Expression with resultType boolean).
    :type allow_poly_base: ~data_factory_management_client.models.SqlDWSinkAllowPolyBase
    :param poly_base_settings: PolyBase settings.
    :type poly_base_settings: ~data_factory_management_client.models.PolybaseSettings
    :param allow_copy_command: Indicates to use Copy Command to copy data into SQL Data Warehouse.
     Type: boolean (or Expression with resultType boolean).
    :type allow_copy_command: ~data_factory_management_client.models.SqlDWSinkAllowCopyCommand
    :param copy_command_settings: DW Copy Command settings.
    :type copy_command_settings: ~data_factory_management_client.models.DWCopyCommandSettings
    :param table_option: The option to handle sink table, such as autoCreate. For now only
     'autoCreate' value is supported. Type: string (or Expression with resultType string).
    :type table_option: ~data_factory_management_client.models.SqlDWSinkTableOption
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'SqlDWSinkPreCopyScript'},
        'allow_poly_base': {'key': 'allowPolyBase', 'type': 'SqlDWSinkAllowPolyBase'},
        'poly_base_settings': {'key': 'polyBaseSettings', 'type': 'PolybaseSettings'},
        'allow_copy_command': {'key': 'allowCopyCommand', 'type': 'SqlDWSinkAllowCopyCommand'},
        'copy_command_settings': {'key': 'copyCommandSettings', 'type': 'DWCopyCommandSettings'},
        'table_option': {'key': 'tableOption', 'type': 'SqlDWSinkTableOption'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        pre_copy_script: Optional["SqlDWSinkPreCopyScript"] = None,
        allow_poly_base: Optional["SqlDWSinkAllowPolyBase"] = None,
        poly_base_settings: Optional["PolybaseSettings"] = None,
        allow_copy_command: Optional["SqlDWSinkAllowCopyCommand"] = None,
        copy_command_settings: Optional["DWCopyCommandSettings"] = None,
        table_option: Optional["SqlDWSinkTableOption"] = None,
        **kwargs
    ):
        super(SqlDWSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'SqlDWSink'
        self.pre_copy_script = pre_copy_script
        self.allow_poly_base = allow_poly_base
        self.poly_base_settings = poly_base_settings
        self.allow_copy_command = allow_copy_command
        self.copy_command_settings = copy_command_settings
        self.table_option = table_option


class SqlDWSinkAllowCopyCommand(msrest.serialization.Model):
    """Indicates to use Copy Command to copy data into SQL Data Warehouse. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlDWSinkAllowCopyCommand, self).__init__(**kwargs)


class SqlDWSinkAllowPolyBase(msrest.serialization.Model):
    """Indicates to use PolyBase to copy data into SQL Data Warehouse when applicable. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlDWSinkAllowPolyBase, self).__init__(**kwargs)


class SqlDWSinkPreCopyScript(msrest.serialization.Model):
    """SQL pre-copy script. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlDWSinkPreCopyScript, self).__init__(**kwargs)


class SqlDWSinkTableOption(msrest.serialization.Model):
    """The option to handle sink table, such as autoCreate. For now only 'autoCreate' value is supported. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlDWSinkTableOption, self).__init__(**kwargs)


class SqlDWSource(TabularSource):
    """A copy activity SQL Data Warehouse source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param sql_reader_query: SQL Data Warehouse reader query. Type: string (or Expression with
     resultType string).
    :type sql_reader_query: ~data_factory_management_client.models.SqlDWSourceSqlReaderQuery
    :param sql_reader_stored_procedure_name: Name of the stored procedure for a SQL Data Warehouse
     source. This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression
     with resultType string).
    :type sql_reader_stored_procedure_name:
     ~data_factory_management_client.models.SqlDWSourceSqlReaderStoredProcedureName
    :param stored_procedure_parameters: Value and type setting for stored procedure parameters.
     Example: "{Parameter1: {value: "1", type: "int"}}". Type: object (or Expression with resultType
     object), itemType: StoredProcedureParameter.
    :type stored_procedure_parameters:
     ~data_factory_management_client.models.SqlDWSourceStoredProcedureParameters
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'sql_reader_query': {'key': 'sqlReaderQuery', 'type': 'SqlDWSourceSqlReaderQuery'},
        'sql_reader_stored_procedure_name': {'key': 'sqlReaderStoredProcedureName', 'type': 'SqlDWSourceSqlReaderStoredProcedureName'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': 'SqlDWSourceStoredProcedureParameters'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        sql_reader_query: Optional["SqlDWSourceSqlReaderQuery"] = None,
        sql_reader_stored_procedure_name: Optional["SqlDWSourceSqlReaderStoredProcedureName"] = None,
        stored_procedure_parameters: Optional["SqlDWSourceStoredProcedureParameters"] = None,
        **kwargs
    ):
        super(SqlDWSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SqlDWSource'
        self.sql_reader_query = sql_reader_query
        self.sql_reader_stored_procedure_name = sql_reader_stored_procedure_name
        self.stored_procedure_parameters = stored_procedure_parameters


class SqlDWSourceSqlReaderQuery(msrest.serialization.Model):
    """SQL Data Warehouse reader query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlDWSourceSqlReaderQuery, self).__init__(**kwargs)


class SqlDWSourceSqlReaderStoredProcedureName(msrest.serialization.Model):
    """Name of the stored procedure for a SQL Data Warehouse source. This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlDWSourceSqlReaderStoredProcedureName, self).__init__(**kwargs)


class SqlDWSourceStoredProcedureParameters(msrest.serialization.Model):
    """Value and type setting for stored procedure parameters. Example: "{Parameter1: {value: "1", type: "int"}}". Type: object (or Expression with resultType object), itemType: StoredProcedureParameter.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlDWSourceStoredProcedureParameters, self).__init__(**kwargs)


class SqlMISink(CopySink):
    """A copy activity Azure SQL Managed Instance sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param sql_writer_stored_procedure_name: SQL writer stored procedure name. Type: string (or
     Expression with resultType string).
    :type sql_writer_stored_procedure_name:
     ~data_factory_management_client.models.SqlMISinkSqlWriterStoredProcedureName
    :param sql_writer_table_type: SQL writer table type. Type: string (or Expression with
     resultType string).
    :type sql_writer_table_type: ~data_factory_management_client.models.SqlMISinkSqlWriterTableType
    :param pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
     string).
    :type pre_copy_script: ~data_factory_management_client.models.SqlMISinkPreCopyScript
    :param stored_procedure_parameters: SQL stored procedure parameters.
    :type stored_procedure_parameters: dict[str,
     ~data_factory_management_client.models.StoredProcedureParameter]
    :param stored_procedure_table_type_parameter_name: The stored procedure parameter name of the
     table type. Type: string (or Expression with resultType string).
    :type stored_procedure_table_type_parameter_name:
     ~data_factory_management_client.models.SqlMISinkStoredProcedureTableTypeParameterName
    :param table_option: The option to handle sink table, such as autoCreate. For now only
     'autoCreate' value is supported. Type: string (or Expression with resultType string).
    :type table_option: ~data_factory_management_client.models.SqlMISinkTableOption
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'sql_writer_stored_procedure_name': {'key': 'sqlWriterStoredProcedureName', 'type': 'SqlMISinkSqlWriterStoredProcedureName'},
        'sql_writer_table_type': {'key': 'sqlWriterTableType', 'type': 'SqlMISinkSqlWriterTableType'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'SqlMISinkPreCopyScript'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'stored_procedure_table_type_parameter_name': {'key': 'storedProcedureTableTypeParameterName', 'type': 'SqlMISinkStoredProcedureTableTypeParameterName'},
        'table_option': {'key': 'tableOption', 'type': 'SqlMISinkTableOption'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        sql_writer_stored_procedure_name: Optional["SqlMISinkSqlWriterStoredProcedureName"] = None,
        sql_writer_table_type: Optional["SqlMISinkSqlWriterTableType"] = None,
        pre_copy_script: Optional["SqlMISinkPreCopyScript"] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        stored_procedure_table_type_parameter_name: Optional["SqlMISinkStoredProcedureTableTypeParameterName"] = None,
        table_option: Optional["SqlMISinkTableOption"] = None,
        **kwargs
    ):
        super(SqlMISink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'SqlMISink'
        self.sql_writer_stored_procedure_name = sql_writer_stored_procedure_name
        self.sql_writer_table_type = sql_writer_table_type
        self.pre_copy_script = pre_copy_script
        self.stored_procedure_parameters = stored_procedure_parameters
        self.stored_procedure_table_type_parameter_name = stored_procedure_table_type_parameter_name
        self.table_option = table_option


class SqlMISinkPreCopyScript(msrest.serialization.Model):
    """SQL pre-copy script. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlMISinkPreCopyScript, self).__init__(**kwargs)


class SqlMISinkSqlWriterStoredProcedureName(msrest.serialization.Model):
    """SQL writer stored procedure name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlMISinkSqlWriterStoredProcedureName, self).__init__(**kwargs)


class SqlMISinkSqlWriterTableType(msrest.serialization.Model):
    """SQL writer table type. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlMISinkSqlWriterTableType, self).__init__(**kwargs)


class SqlMISinkStoredProcedureTableTypeParameterName(msrest.serialization.Model):
    """The stored procedure parameter name of the table type. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlMISinkStoredProcedureTableTypeParameterName, self).__init__(**kwargs)


class SqlMISinkTableOption(msrest.serialization.Model):
    """The option to handle sink table, such as autoCreate. For now only 'autoCreate' value is supported. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlMISinkTableOption, self).__init__(**kwargs)


class SqlMISource(TabularSource):
    """A copy activity Azure SQL Managed Instance source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param sql_reader_query: SQL reader query. Type: string (or Expression with resultType string).
    :type sql_reader_query: ~data_factory_management_client.models.SqlMISourceSqlReaderQuery
    :param sql_reader_stored_procedure_name: Name of the stored procedure for a Azure SQL Managed
     Instance source. This cannot be used at the same time as SqlReaderQuery. Type: string (or
     Expression with resultType string).
    :type sql_reader_stored_procedure_name:
     ~data_factory_management_client.models.SqlMISourceSqlReaderStoredProcedureName
    :param stored_procedure_parameters: Value and type setting for stored procedure parameters.
     Example: "{Parameter1: {value: "1", type: "int"}}".
    :type stored_procedure_parameters: dict[str,
     ~data_factory_management_client.models.StoredProcedureParameter]
    :param produce_additional_types: Which additional types to produce.
    :type produce_additional_types:
     ~data_factory_management_client.models.SqlMISourceProduceAdditionalTypes
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'sql_reader_query': {'key': 'sqlReaderQuery', 'type': 'SqlMISourceSqlReaderQuery'},
        'sql_reader_stored_procedure_name': {'key': 'sqlReaderStoredProcedureName', 'type': 'SqlMISourceSqlReaderStoredProcedureName'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'produce_additional_types': {'key': 'produceAdditionalTypes', 'type': 'SqlMISourceProduceAdditionalTypes'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        sql_reader_query: Optional["SqlMISourceSqlReaderQuery"] = None,
        sql_reader_stored_procedure_name: Optional["SqlMISourceSqlReaderStoredProcedureName"] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        produce_additional_types: Optional["SqlMISourceProduceAdditionalTypes"] = None,
        **kwargs
    ):
        super(SqlMISource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SqlMISource'
        self.sql_reader_query = sql_reader_query
        self.sql_reader_stored_procedure_name = sql_reader_stored_procedure_name
        self.stored_procedure_parameters = stored_procedure_parameters
        self.produce_additional_types = produce_additional_types


class SqlMISourceProduceAdditionalTypes(msrest.serialization.Model):
    """Which additional types to produce.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlMISourceProduceAdditionalTypes, self).__init__(**kwargs)


class SqlMISourceSqlReaderQuery(msrest.serialization.Model):
    """SQL reader query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlMISourceSqlReaderQuery, self).__init__(**kwargs)


class SqlMISourceSqlReaderStoredProcedureName(msrest.serialization.Model):
    """Name of the stored procedure for a Azure SQL Managed Instance source. This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlMISourceSqlReaderStoredProcedureName, self).__init__(**kwargs)


class SqlServerLinkedService(LinkedService):
    """SQL Server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.SqlServerLinkedServiceTypePropertiesConnectionString
    :param user_name: The on-premises Windows authentication user name. Type: string (or Expression
     with resultType string).
    :type user_name:
     ~data_factory_management_client.models.SqlServerLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SqlServerLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'SqlServerLinkedServiceTypePropertiesConnectionString'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'SqlServerLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'SqlServerLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "SqlServerLinkedServiceTypePropertiesConnectionString",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        user_name: Optional["SqlServerLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["SqlServerLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SqlServerLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SqlServer'
        self.connection_string = connection_string
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class SqlServerLinkedServiceTypeProperties(msrest.serialization.Model):
    """SQL Server linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.SqlServerLinkedServiceTypePropertiesConnectionString
    :param user_name: The on-premises Windows authentication user name. Type: string (or Expression
     with resultType string).
    :type user_name:
     ~data_factory_management_client.models.SqlServerLinkedServiceTypePropertiesUserName
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SqlServerLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'SqlServerLinkedServiceTypePropertiesConnectionString'},
        'user_name': {'key': 'userName', 'type': 'SqlServerLinkedServiceTypePropertiesUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'SqlServerLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: "SqlServerLinkedServiceTypePropertiesConnectionString",
        user_name: Optional["SqlServerLinkedServiceTypePropertiesUserName"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["SqlServerLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SqlServerLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class SqlServerLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """The connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlServerLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class SqlServerLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlServerLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class SqlServerLinkedServiceTypePropertiesUserName(msrest.serialization.Model):
    """The on-premises Windows authentication user name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlServerLinkedServiceTypePropertiesUserName, self).__init__(**kwargs)


class SqlServerSink(CopySink):
    """A copy activity SQL server sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param sql_writer_stored_procedure_name: SQL writer stored procedure name. Type: string (or
     Expression with resultType string).
    :type sql_writer_stored_procedure_name:
     ~data_factory_management_client.models.SqlServerSinkSqlWriterStoredProcedureName
    :param sql_writer_table_type: SQL writer table type. Type: string (or Expression with
     resultType string).
    :type sql_writer_table_type:
     ~data_factory_management_client.models.SqlServerSinkSqlWriterTableType
    :param pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
     string).
    :type pre_copy_script: ~data_factory_management_client.models.SqlServerSinkPreCopyScript
    :param stored_procedure_parameters: SQL stored procedure parameters.
    :type stored_procedure_parameters: dict[str,
     ~data_factory_management_client.models.StoredProcedureParameter]
    :param stored_procedure_table_type_parameter_name: The stored procedure parameter name of the
     table type. Type: string (or Expression with resultType string).
    :type stored_procedure_table_type_parameter_name:
     ~data_factory_management_client.models.SqlServerSinkStoredProcedureTableTypeParameterName
    :param table_option: The option to handle sink table, such as autoCreate. For now only
     'autoCreate' value is supported. Type: string (or Expression with resultType string).
    :type table_option: ~data_factory_management_client.models.SqlServerSinkTableOption
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'sql_writer_stored_procedure_name': {'key': 'sqlWriterStoredProcedureName', 'type': 'SqlServerSinkSqlWriterStoredProcedureName'},
        'sql_writer_table_type': {'key': 'sqlWriterTableType', 'type': 'SqlServerSinkSqlWriterTableType'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'SqlServerSinkPreCopyScript'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'stored_procedure_table_type_parameter_name': {'key': 'storedProcedureTableTypeParameterName', 'type': 'SqlServerSinkStoredProcedureTableTypeParameterName'},
        'table_option': {'key': 'tableOption', 'type': 'SqlServerSinkTableOption'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        sql_writer_stored_procedure_name: Optional["SqlServerSinkSqlWriterStoredProcedureName"] = None,
        sql_writer_table_type: Optional["SqlServerSinkSqlWriterTableType"] = None,
        pre_copy_script: Optional["SqlServerSinkPreCopyScript"] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        stored_procedure_table_type_parameter_name: Optional["SqlServerSinkStoredProcedureTableTypeParameterName"] = None,
        table_option: Optional["SqlServerSinkTableOption"] = None,
        **kwargs
    ):
        super(SqlServerSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'SqlServerSink'
        self.sql_writer_stored_procedure_name = sql_writer_stored_procedure_name
        self.sql_writer_table_type = sql_writer_table_type
        self.pre_copy_script = pre_copy_script
        self.stored_procedure_parameters = stored_procedure_parameters
        self.stored_procedure_table_type_parameter_name = stored_procedure_table_type_parameter_name
        self.table_option = table_option


class SqlServerSinkPreCopyScript(msrest.serialization.Model):
    """SQL pre-copy script. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlServerSinkPreCopyScript, self).__init__(**kwargs)


class SqlServerSinkSqlWriterStoredProcedureName(msrest.serialization.Model):
    """SQL writer stored procedure name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlServerSinkSqlWriterStoredProcedureName, self).__init__(**kwargs)


class SqlServerSinkSqlWriterTableType(msrest.serialization.Model):
    """SQL writer table type. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlServerSinkSqlWriterTableType, self).__init__(**kwargs)


class SqlServerSinkStoredProcedureTableTypeParameterName(msrest.serialization.Model):
    """The stored procedure parameter name of the table type. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlServerSinkStoredProcedureTableTypeParameterName, self).__init__(**kwargs)


class SqlServerSinkTableOption(msrest.serialization.Model):
    """The option to handle sink table, such as autoCreate. For now only 'autoCreate' value is supported. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlServerSinkTableOption, self).__init__(**kwargs)


class SqlServerSource(TabularSource):
    """A copy activity SQL server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param sql_reader_query: SQL reader query. Type: string (or Expression with resultType string).
    :type sql_reader_query: ~data_factory_management_client.models.SqlServerSourceSqlReaderQuery
    :param sql_reader_stored_procedure_name: Name of the stored procedure for a SQL Database
     source. This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression
     with resultType string).
    :type sql_reader_stored_procedure_name:
     ~data_factory_management_client.models.SqlServerSourceSqlReaderStoredProcedureName
    :param stored_procedure_parameters: Value and type setting for stored procedure parameters.
     Example: "{Parameter1: {value: "1", type: "int"}}".
    :type stored_procedure_parameters: dict[str,
     ~data_factory_management_client.models.StoredProcedureParameter]
    :param produce_additional_types: Which additional types to produce.
    :type produce_additional_types:
     ~data_factory_management_client.models.SqlServerSourceProduceAdditionalTypes
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'sql_reader_query': {'key': 'sqlReaderQuery', 'type': 'SqlServerSourceSqlReaderQuery'},
        'sql_reader_stored_procedure_name': {'key': 'sqlReaderStoredProcedureName', 'type': 'SqlServerSourceSqlReaderStoredProcedureName'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'produce_additional_types': {'key': 'produceAdditionalTypes', 'type': 'SqlServerSourceProduceAdditionalTypes'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        sql_reader_query: Optional["SqlServerSourceSqlReaderQuery"] = None,
        sql_reader_stored_procedure_name: Optional["SqlServerSourceSqlReaderStoredProcedureName"] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        produce_additional_types: Optional["SqlServerSourceProduceAdditionalTypes"] = None,
        **kwargs
    ):
        super(SqlServerSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SqlServerSource'
        self.sql_reader_query = sql_reader_query
        self.sql_reader_stored_procedure_name = sql_reader_stored_procedure_name
        self.stored_procedure_parameters = stored_procedure_parameters
        self.produce_additional_types = produce_additional_types


class SqlServerSourceProduceAdditionalTypes(msrest.serialization.Model):
    """Which additional types to produce.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlServerSourceProduceAdditionalTypes, self).__init__(**kwargs)


class SqlServerSourceSqlReaderQuery(msrest.serialization.Model):
    """SQL reader query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlServerSourceSqlReaderQuery, self).__init__(**kwargs)


class SqlServerSourceSqlReaderStoredProcedureName(msrest.serialization.Model):
    """Name of the stored procedure for a SQL Database source. This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlServerSourceSqlReaderStoredProcedureName, self).__init__(**kwargs)


class SqlServerStoredProcedureActivity(ExecutionActivity):
    """SQL stored procedure activity type.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param stored_procedure_name: Required. Stored procedure name. Type: string (or Expression with
     resultType string).
    :type stored_procedure_name:
     ~data_factory_management_client.models.SqlServerStoredProcedureActivityTypePropertiesStoredProcedureName
    :param stored_procedure_parameters: Value and type setting for stored procedure parameters.
     Example: "{Parameter1: {value: "1", type: "int"}}".
    :type stored_procedure_parameters: dict[str,
     ~data_factory_management_client.models.StoredProcedureParameter]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'stored_procedure_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'stored_procedure_name': {'key': 'typeProperties.storedProcedureName', 'type': 'SqlServerStoredProcedureActivityTypePropertiesStoredProcedureName'},
        'stored_procedure_parameters': {'key': 'typeProperties.storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
    }

    def __init__(
        self,
        *,
        name: str,
        stored_procedure_name: "SqlServerStoredProcedureActivityTypePropertiesStoredProcedureName",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        **kwargs
    ):
        super(SqlServerStoredProcedureActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'SqlServerStoredProcedure'
        self.stored_procedure_name = stored_procedure_name
        self.stored_procedure_parameters = stored_procedure_parameters


class SqlServerStoredProcedureActivityTypeProperties(msrest.serialization.Model):
    """SQL stored procedure activity properties.

    All required parameters must be populated in order to send to Azure.

    :param stored_procedure_name: Required. Stored procedure name. Type: string (or Expression with
     resultType string).
    :type stored_procedure_name:
     ~data_factory_management_client.models.SqlServerStoredProcedureActivityTypePropertiesStoredProcedureName
    :param stored_procedure_parameters: Value and type setting for stored procedure parameters.
     Example: "{Parameter1: {value: "1", type: "int"}}".
    :type stored_procedure_parameters: dict[str,
     ~data_factory_management_client.models.StoredProcedureParameter]
    """

    _validation = {
        'stored_procedure_name': {'required': True},
    }

    _attribute_map = {
        'stored_procedure_name': {'key': 'storedProcedureName', 'type': 'SqlServerStoredProcedureActivityTypePropertiesStoredProcedureName'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
    }

    def __init__(
        self,
        *,
        stored_procedure_name: "SqlServerStoredProcedureActivityTypePropertiesStoredProcedureName",
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        **kwargs
    ):
        super(SqlServerStoredProcedureActivityTypeProperties, self).__init__(**kwargs)
        self.stored_procedure_name = stored_procedure_name
        self.stored_procedure_parameters = stored_procedure_parameters


class SqlServerStoredProcedureActivityTypePropertiesStoredProcedureName(msrest.serialization.Model):
    """Stored procedure name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlServerStoredProcedureActivityTypePropertiesStoredProcedureName, self).__init__(**kwargs)


class SqlServerTableDataset(Dataset):
    """The on-premises SQL Server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.SqlServerTableDatasetTypePropertiesTableName
    :param schema_type_properties_schema: The schema name of the SQL Server dataset. Type: string
     (or Expression with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.SqlServerTableDatasetTypePropertiesSchema
    :param table: The table name of the SQL Server dataset. Type: string (or Expression with
     resultType string).
    :type table: ~data_factory_management_client.models.SqlServerTableDatasetTypePropertiesTable
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'SqlServerTableDatasetTypePropertiesTableName'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'SqlServerTableDatasetTypePropertiesSchema'},
        'table': {'key': 'typeProperties.table', 'type': 'SqlServerTableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["SqlServerTableDatasetTypePropertiesTableName"] = None,
        schema_type_properties_schema: Optional["SqlServerTableDatasetTypePropertiesSchema"] = None,
        table: Optional["SqlServerTableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(SqlServerTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SqlServerTable'
        self.table_name = table_name
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class SqlServerTableDatasetTypeProperties(msrest.serialization.Model):
    """On-premises SQL Server dataset properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name:
     ~data_factory_management_client.models.SqlServerTableDatasetTypePropertiesTableName
    :param schema: The schema name of the SQL Server dataset. Type: string (or Expression with
     resultType string).
    :type schema: ~data_factory_management_client.models.SqlServerTableDatasetTypePropertiesSchema
    :param table: The table name of the SQL Server dataset. Type: string (or Expression with
     resultType string).
    :type table: ~data_factory_management_client.models.SqlServerTableDatasetTypePropertiesTable
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'SqlServerTableDatasetTypePropertiesTableName'},
        'schema': {'key': 'schema', 'type': 'SqlServerTableDatasetTypePropertiesSchema'},
        'table': {'key': 'table', 'type': 'SqlServerTableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["SqlServerTableDatasetTypePropertiesTableName"] = None,
        schema: Optional["SqlServerTableDatasetTypePropertiesSchema"] = None,
        table: Optional["SqlServerTableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(SqlServerTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.schema = schema
        self.table = table


class SqlServerTableDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of the SQL Server dataset. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlServerTableDatasetTypePropertiesSchema, self).__init__(**kwargs)


class SqlServerTableDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the SQL Server dataset. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlServerTableDatasetTypePropertiesTable, self).__init__(**kwargs)


class SqlServerTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlServerTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class SqlSink(CopySink):
    """A copy activity SQL sink.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy sink type.Constant filled by server.
    :type type: str
    :param write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :type write_batch_size: ~data_factory_management_client.models.CopySinkWriteBatchSize
    :param write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type write_batch_timeout: ~data_factory_management_client.models.CopySinkWriteBatchTimeout
    :param sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :type sink_retry_count: ~data_factory_management_client.models.CopySinkSinkRetryCount
    :param sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type sink_retry_wait: ~data_factory_management_client.models.CopySinkSinkRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySinkMaxConcurrentConnections
    :param sql_writer_stored_procedure_name: SQL writer stored procedure name. Type: string (or
     Expression with resultType string).
    :type sql_writer_stored_procedure_name:
     ~data_factory_management_client.models.SqlSinkSqlWriterStoredProcedureName
    :param sql_writer_table_type: SQL writer table type. Type: string (or Expression with
     resultType string).
    :type sql_writer_table_type: ~data_factory_management_client.models.SqlSinkSqlWriterTableType
    :param pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
     string).
    :type pre_copy_script: ~data_factory_management_client.models.SqlSinkPreCopyScript
    :param stored_procedure_parameters: SQL stored procedure parameters.
    :type stored_procedure_parameters: dict[str,
     ~data_factory_management_client.models.StoredProcedureParameter]
    :param stored_procedure_table_type_parameter_name: The stored procedure parameter name of the
     table type. Type: string (or Expression with resultType string).
    :type stored_procedure_table_type_parameter_name:
     ~data_factory_management_client.models.SqlSinkStoredProcedureTableTypeParameterName
    :param table_option: The option to handle sink table, such as autoCreate. For now only
     'autoCreate' value is supported. Type: string (or Expression with resultType string).
    :type table_option: ~data_factory_management_client.models.SqlSinkTableOption
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'CopySinkWriteBatchSize'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'CopySinkWriteBatchTimeout'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'CopySinkSinkRetryCount'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'CopySinkSinkRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySinkMaxConcurrentConnections'},
        'sql_writer_stored_procedure_name': {'key': 'sqlWriterStoredProcedureName', 'type': 'SqlSinkSqlWriterStoredProcedureName'},
        'sql_writer_table_type': {'key': 'sqlWriterTableType', 'type': 'SqlSinkSqlWriterTableType'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'SqlSinkPreCopyScript'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'stored_procedure_table_type_parameter_name': {'key': 'storedProcedureTableTypeParameterName', 'type': 'SqlSinkStoredProcedureTableTypeParameterName'},
        'table_option': {'key': 'tableOption', 'type': 'SqlSinkTableOption'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        write_batch_size: Optional["CopySinkWriteBatchSize"] = None,
        write_batch_timeout: Optional["CopySinkWriteBatchTimeout"] = None,
        sink_retry_count: Optional["CopySinkSinkRetryCount"] = None,
        sink_retry_wait: Optional["CopySinkSinkRetryWait"] = None,
        max_concurrent_connections: Optional["CopySinkMaxConcurrentConnections"] = None,
        sql_writer_stored_procedure_name: Optional["SqlSinkSqlWriterStoredProcedureName"] = None,
        sql_writer_table_type: Optional["SqlSinkSqlWriterTableType"] = None,
        pre_copy_script: Optional["SqlSinkPreCopyScript"] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        stored_procedure_table_type_parameter_name: Optional["SqlSinkStoredProcedureTableTypeParameterName"] = None,
        table_option: Optional["SqlSinkTableOption"] = None,
        **kwargs
    ):
        super(SqlSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'SqlSink'
        self.sql_writer_stored_procedure_name = sql_writer_stored_procedure_name
        self.sql_writer_table_type = sql_writer_table_type
        self.pre_copy_script = pre_copy_script
        self.stored_procedure_parameters = stored_procedure_parameters
        self.stored_procedure_table_type_parameter_name = stored_procedure_table_type_parameter_name
        self.table_option = table_option


class SqlSinkPreCopyScript(msrest.serialization.Model):
    """SQL pre-copy script. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlSinkPreCopyScript, self).__init__(**kwargs)


class SqlSinkSqlWriterStoredProcedureName(msrest.serialization.Model):
    """SQL writer stored procedure name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlSinkSqlWriterStoredProcedureName, self).__init__(**kwargs)


class SqlSinkSqlWriterTableType(msrest.serialization.Model):
    """SQL writer table type. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlSinkSqlWriterTableType, self).__init__(**kwargs)


class SqlSinkStoredProcedureTableTypeParameterName(msrest.serialization.Model):
    """The stored procedure parameter name of the table type. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlSinkStoredProcedureTableTypeParameterName, self).__init__(**kwargs)


class SqlSinkTableOption(msrest.serialization.Model):
    """The option to handle sink table, such as autoCreate. For now only 'autoCreate' value is supported. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlSinkTableOption, self).__init__(**kwargs)


class SqlSource(TabularSource):
    """A copy activity SQL source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param sql_reader_query: SQL reader query. Type: string (or Expression with resultType string).
    :type sql_reader_query: ~data_factory_management_client.models.SqlSourceSqlReaderQuery
    :param sql_reader_stored_procedure_name: Name of the stored procedure for a SQL Database
     source. This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression
     with resultType string).
    :type sql_reader_stored_procedure_name:
     ~data_factory_management_client.models.SqlSourceSqlReaderStoredProcedureName
    :param stored_procedure_parameters: Value and type setting for stored procedure parameters.
     Example: "{Parameter1: {value: "1", type: "int"}}".
    :type stored_procedure_parameters: dict[str,
     ~data_factory_management_client.models.StoredProcedureParameter]
    :param isolation_level: Specifies the transaction locking behavior for the SQL source. Allowed
     values: ReadCommitted/ReadUncommitted/RepeatableRead/Serializable/Snapshot. The default value
     is ReadCommitted. Type: string (or Expression with resultType string).
    :type isolation_level: ~data_factory_management_client.models.SqlSourceIsolationLevel
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'sql_reader_query': {'key': 'sqlReaderQuery', 'type': 'SqlSourceSqlReaderQuery'},
        'sql_reader_stored_procedure_name': {'key': 'sqlReaderStoredProcedureName', 'type': 'SqlSourceSqlReaderStoredProcedureName'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'isolation_level': {'key': 'isolationLevel', 'type': 'SqlSourceIsolationLevel'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        sql_reader_query: Optional["SqlSourceSqlReaderQuery"] = None,
        sql_reader_stored_procedure_name: Optional["SqlSourceSqlReaderStoredProcedureName"] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        isolation_level: Optional["SqlSourceIsolationLevel"] = None,
        **kwargs
    ):
        super(SqlSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SqlSource'
        self.sql_reader_query = sql_reader_query
        self.sql_reader_stored_procedure_name = sql_reader_stored_procedure_name
        self.stored_procedure_parameters = stored_procedure_parameters
        self.isolation_level = isolation_level


class SqlSourceIsolationLevel(msrest.serialization.Model):
    """Specifies the transaction locking behavior for the SQL source. Allowed values: ReadCommitted/ReadUncommitted/RepeatableRead/Serializable/Snapshot. The default value is ReadCommitted. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlSourceIsolationLevel, self).__init__(**kwargs)


class SqlSourceSqlReaderQuery(msrest.serialization.Model):
    """SQL reader query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlSourceSqlReaderQuery, self).__init__(**kwargs)


class SqlSourceSqlReaderStoredProcedureName(msrest.serialization.Model):
    """Name of the stored procedure for a SQL Database source. This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SqlSourceSqlReaderStoredProcedureName, self).__init__(**kwargs)


class SquareLinkedService(LinkedService):
    """Square Service linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. The URL of the Square instance. (i.e. mystore.mysquare.com).
    :type host: ~data_factory_management_client.models.SquareLinkedServiceTypePropertiesHost
    :param client_id: Required. The client ID associated with your Square application.
    :type client_id:
     ~data_factory_management_client.models.SquareLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param redirect_uri: Required. The redirect URL assigned in the Square application dashboard.
     (i.e. http://localhost:2500).
    :type redirect_uri:
     ~data_factory_management_client.models.SquareLinkedServiceTypePropertiesRedirectUri
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.SquareLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.SquareLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.SquareLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SquareLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'client_id': {'required': True},
        'redirect_uri': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'SquareLinkedServiceTypePropertiesHost'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'SquareLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'redirect_uri': {'key': 'typeProperties.redirectUri', 'type': 'SquareLinkedServiceTypePropertiesRedirectUri'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'SquareLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'SquareLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'SquareLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'SquareLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "SquareLinkedServiceTypePropertiesHost",
        client_id: "SquareLinkedServiceTypePropertiesClientId",
        redirect_uri: "SquareLinkedServiceTypePropertiesRedirectUri",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["SquareLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["SquareLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["SquareLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["SquareLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SquareLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Square'
        self.host = host
        self.client_id = client_id
        self.client_secret = client_secret
        self.redirect_uri = redirect_uri
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class SquareLinkedServiceTypeProperties(msrest.serialization.Model):
    """Square Service linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. The URL of the Square instance. (i.e. mystore.mysquare.com).
    :type host: ~data_factory_management_client.models.SquareLinkedServiceTypePropertiesHost
    :param client_id: Required. The client ID associated with your Square application.
    :type client_id:
     ~data_factory_management_client.models.SquareLinkedServiceTypePropertiesClientId
    :param client_secret: The base definition of a secret type.
    :type client_secret: ~data_factory_management_client.models.SecretBase
    :param redirect_uri: Required. The redirect URL assigned in the Square application dashboard.
     (i.e. http://localhost:2500).
    :type redirect_uri:
     ~data_factory_management_client.models.SquareLinkedServiceTypePropertiesRedirectUri
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.SquareLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.SquareLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.SquareLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SquareLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
        'client_id': {'required': True},
        'redirect_uri': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'SquareLinkedServiceTypePropertiesHost'},
        'client_id': {'key': 'clientId', 'type': 'SquareLinkedServiceTypePropertiesClientId'},
        'client_secret': {'key': 'clientSecret', 'type': 'SecretBase'},
        'redirect_uri': {'key': 'redirectUri', 'type': 'SquareLinkedServiceTypePropertiesRedirectUri'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'SquareLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'SquareLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'SquareLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'SquareLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "SquareLinkedServiceTypePropertiesHost",
        client_id: "SquareLinkedServiceTypePropertiesClientId",
        redirect_uri: "SquareLinkedServiceTypePropertiesRedirectUri",
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["SquareLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["SquareLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["SquareLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["SquareLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SquareLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.client_id = client_id
        self.client_secret = client_secret
        self.redirect_uri = redirect_uri
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class SquareLinkedServiceTypePropertiesClientId(msrest.serialization.Model):
    """The client ID associated with your Square application.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SquareLinkedServiceTypePropertiesClientId, self).__init__(**kwargs)


class SquareLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SquareLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class SquareLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """The URL of the Square instance. (i.e. mystore.mysquare.com).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SquareLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class SquareLinkedServiceTypePropertiesRedirectUri(msrest.serialization.Model):
    """The redirect URL assigned in the Square application dashboard. (i.e. http://localhost:2500).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SquareLinkedServiceTypePropertiesRedirectUri, self).__init__(**kwargs)


class SquareLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SquareLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class SquareLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SquareLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class SquareLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SquareLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class SquareObjectDataset(Dataset):
    """Square Service dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(SquareObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SquareObject'
        self.table_name = table_name


class SquareSource(TabularSource):
    """A copy activity Square Service source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.SquareSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'SquareSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["SquareSourceQuery"] = None,
        **kwargs
    ):
        super(SquareSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SquareSource'
        self.query = query


class SquareSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SquareSourceQuery, self).__init__(**kwargs)


class SSISAccessCredential(msrest.serialization.Model):
    """SSIS access credential.

    All required parameters must be populated in order to send to Azure.

    :param domain: Required. Domain for windows authentication.
    :type domain: ~data_factory_management_client.models.SSISAccessCredentialDomain
    :param user_name: Required. UseName for windows authentication.
    :type user_name: ~data_factory_management_client.models.SSISAccessCredentialUserName
    :param password: Required. The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    """

    _validation = {
        'domain': {'required': True},
        'user_name': {'required': True},
        'password': {'required': True},
    }

    _attribute_map = {
        'domain': {'key': 'domain', 'type': 'SSISAccessCredentialDomain'},
        'user_name': {'key': 'userName', 'type': 'SSISAccessCredentialUserName'},
        'password': {'key': 'password', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        domain: "SSISAccessCredentialDomain",
        user_name: "SSISAccessCredentialUserName",
        password: "SecretBase",
        **kwargs
    ):
        super(SSISAccessCredential, self).__init__(**kwargs)
        self.domain = domain
        self.user_name = user_name
        self.password = password


class SSISAccessCredentialDomain(msrest.serialization.Model):
    """Domain for windows authentication.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SSISAccessCredentialDomain, self).__init__(**kwargs)


class SSISAccessCredentialUserName(msrest.serialization.Model):
    """UseName for windows authentication.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SSISAccessCredentialUserName, self).__init__(**kwargs)


class SSISChildPackage(msrest.serialization.Model):
    """SSIS embedded child package.

    All required parameters must be populated in order to send to Azure.

    :param package_path: Required. Path for embedded child package. Type: string (or Expression
     with resultType string).
    :type package_path: ~data_factory_management_client.models.SSISChildPackagePackagePath
    :param package_name: Name for embedded child package.
    :type package_name: str
    :param package_content: Required. Content for embedded child package. Type: string (or
     Expression with resultType string).
    :type package_content: ~data_factory_management_client.models.SSISChildPackagePackageContent
    :param package_last_modified_date: Last modified date for embedded child package.
    :type package_last_modified_date: str
    """

    _validation = {
        'package_path': {'required': True},
        'package_content': {'required': True},
    }

    _attribute_map = {
        'package_path': {'key': 'packagePath', 'type': 'SSISChildPackagePackagePath'},
        'package_name': {'key': 'packageName', 'type': 'str'},
        'package_content': {'key': 'packageContent', 'type': 'SSISChildPackagePackageContent'},
        'package_last_modified_date': {'key': 'packageLastModifiedDate', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        package_path: "SSISChildPackagePackagePath",
        package_content: "SSISChildPackagePackageContent",
        package_name: Optional[str] = None,
        package_last_modified_date: Optional[str] = None,
        **kwargs
    ):
        super(SSISChildPackage, self).__init__(**kwargs)
        self.package_path = package_path
        self.package_name = package_name
        self.package_content = package_content
        self.package_last_modified_date = package_last_modified_date


class SSISChildPackagePackageContent(msrest.serialization.Model):
    """Content for embedded child package. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SSISChildPackagePackageContent, self).__init__(**kwargs)


class SSISChildPackagePackagePath(msrest.serialization.Model):
    """Path for embedded child package. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SSISChildPackagePackagePath, self).__init__(**kwargs)


class SsisObjectMetadata(msrest.serialization.Model):
    """SSIS object metadata.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: SsisEnvironment, SsisFolder, SsisPackage, SsisProject.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. The type of SSIS object metadata.Constant filled by server.  Possible
     values include: 'Folder', 'Project', 'Package', 'Environment'.
    :type type: str or ~data_factory_management_client.models.SsisObjectMetadataType
    :param id: Metadata id.
    :type id: long
    :param name: Metadata name.
    :type name: str
    :param description: Metadata description.
    :type description: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'id': {'key': 'id', 'type': 'long'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'Environment': 'SsisEnvironment', 'Folder': 'SsisFolder', 'Package': 'SsisPackage', 'Project': 'SsisProject'}
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        name: Optional[str] = None,
        description: Optional[str] = None,
        **kwargs
    ):
        super(SsisObjectMetadata, self).__init__(**kwargs)
        self.type = None
        self.id = id
        self.name = name
        self.description = description


class SsisEnvironment(SsisObjectMetadata):
    """Ssis environment.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. The type of SSIS object metadata.Constant filled by server.  Possible
     values include: 'Folder', 'Project', 'Package', 'Environment'.
    :type type: str or ~data_factory_management_client.models.SsisObjectMetadataType
    :param id: Metadata id.
    :type id: long
    :param name: Metadata name.
    :type name: str
    :param description: Metadata description.
    :type description: str
    :param folder_id: Folder id which contains environment.
    :type folder_id: long
    :param variables: Variable in environment.
    :type variables: list[~data_factory_management_client.models.SsisVariable]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'id': {'key': 'id', 'type': 'long'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'folder_id': {'key': 'folderId', 'type': 'long'},
        'variables': {'key': 'variables', 'type': '[SsisVariable]'},
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        name: Optional[str] = None,
        description: Optional[str] = None,
        folder_id: Optional[int] = None,
        variables: Optional[List["SsisVariable"]] = None,
        **kwargs
    ):
        super(SsisEnvironment, self).__init__(id=id, name=name, description=description, **kwargs)
        self.type = 'Environment'
        self.folder_id = folder_id
        self.variables = variables


class SsisEnvironmentReference(msrest.serialization.Model):
    """Ssis environment reference.

    :param id: Environment reference id.
    :type id: long
    :param environment_folder_name: Environment folder name.
    :type environment_folder_name: str
    :param environment_name: Environment name.
    :type environment_name: str
    :param reference_type: Reference type.
    :type reference_type: str
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'long'},
        'environment_folder_name': {'key': 'environmentFolderName', 'type': 'str'},
        'environment_name': {'key': 'environmentName', 'type': 'str'},
        'reference_type': {'key': 'referenceType', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        environment_folder_name: Optional[str] = None,
        environment_name: Optional[str] = None,
        reference_type: Optional[str] = None,
        **kwargs
    ):
        super(SsisEnvironmentReference, self).__init__(**kwargs)
        self.id = id
        self.environment_folder_name = environment_folder_name
        self.environment_name = environment_name
        self.reference_type = reference_type


class SSISExecutionCredential(msrest.serialization.Model):
    """SSIS package execution credential.

    All required parameters must be populated in order to send to Azure.

    :param domain: Required. Domain for windows authentication.
    :type domain: ~data_factory_management_client.models.SSISExecutionCredentialDomain
    :param user_name: Required. UseName for windows authentication.
    :type user_name: ~data_factory_management_client.models.SSISExecutionCredentialUserName
    :param password: Required. Azure Data Factory secure string definition. The string value will
     be masked with asterisks '*' during Get or List API calls.
    :type password: ~data_factory_management_client.models.SecureString
    """

    _validation = {
        'domain': {'required': True},
        'user_name': {'required': True},
        'password': {'required': True},
    }

    _attribute_map = {
        'domain': {'key': 'domain', 'type': 'SSISExecutionCredentialDomain'},
        'user_name': {'key': 'userName', 'type': 'SSISExecutionCredentialUserName'},
        'password': {'key': 'password', 'type': 'SecureString'},
    }

    def __init__(
        self,
        *,
        domain: "SSISExecutionCredentialDomain",
        user_name: "SSISExecutionCredentialUserName",
        password: "SecureString",
        **kwargs
    ):
        super(SSISExecutionCredential, self).__init__(**kwargs)
        self.domain = domain
        self.user_name = user_name
        self.password = password


class SSISExecutionCredentialDomain(msrest.serialization.Model):
    """Domain for windows authentication.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SSISExecutionCredentialDomain, self).__init__(**kwargs)


class SSISExecutionCredentialUserName(msrest.serialization.Model):
    """UseName for windows authentication.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SSISExecutionCredentialUserName, self).__init__(**kwargs)


class SSISExecutionParameter(msrest.serialization.Model):
    """SSIS execution parameter.

    All required parameters must be populated in order to send to Azure.

    :param value: Required. SSIS package execution parameter value. Type: string (or Expression
     with resultType string).
    :type value: ~data_factory_management_client.models.SSISExecutionParameterValue
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': 'SSISExecutionParameterValue'},
    }

    def __init__(
        self,
        *,
        value: "SSISExecutionParameterValue",
        **kwargs
    ):
        super(SSISExecutionParameter, self).__init__(**kwargs)
        self.value = value


class SSISExecutionParameterValue(msrest.serialization.Model):
    """SSIS package execution parameter value. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SSISExecutionParameterValue, self).__init__(**kwargs)


class SsisFolder(SsisObjectMetadata):
    """Ssis folder.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. The type of SSIS object metadata.Constant filled by server.  Possible
     values include: 'Folder', 'Project', 'Package', 'Environment'.
    :type type: str or ~data_factory_management_client.models.SsisObjectMetadataType
    :param id: Metadata id.
    :type id: long
    :param name: Metadata name.
    :type name: str
    :param description: Metadata description.
    :type description: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'id': {'key': 'id', 'type': 'long'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        name: Optional[str] = None,
        description: Optional[str] = None,
        **kwargs
    ):
        super(SsisFolder, self).__init__(id=id, name=name, description=description, **kwargs)
        self.type = 'Folder'


class SSISLogLocation(msrest.serialization.Model):
    """SSIS package execution log location.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param log_path: Required. The SSIS package execution log path. Type: string (or Expression
     with resultType string).
    :type log_path: ~data_factory_management_client.models.SSISLogLocationLogPath
    :ivar type: Required. The type of SSIS log location. Default value: "File".
    :vartype type: str
    :param access_credential: SSIS access credential.
    :type access_credential: ~data_factory_management_client.models.SSISAccessCredential
    :param log_refresh_interval: Specifies the interval to refresh log. The default interval is 5
     minutes. Type: string (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type log_refresh_interval:
     ~data_factory_management_client.models.SSISLogLocationTypePropertiesLogRefreshInterval
    """

    _validation = {
        'log_path': {'required': True},
        'type': {'required': True, 'constant': True},
    }

    _attribute_map = {
        'log_path': {'key': 'logPath', 'type': 'SSISLogLocationLogPath'},
        'type': {'key': 'type', 'type': 'str'},
        'access_credential': {'key': 'typeProperties.accessCredential', 'type': 'SSISAccessCredential'},
        'log_refresh_interval': {'key': 'typeProperties.logRefreshInterval', 'type': 'SSISLogLocationTypePropertiesLogRefreshInterval'},
    }

    type = "File"

    def __init__(
        self,
        *,
        log_path: "SSISLogLocationLogPath",
        access_credential: Optional["SSISAccessCredential"] = None,
        log_refresh_interval: Optional["SSISLogLocationTypePropertiesLogRefreshInterval"] = None,
        **kwargs
    ):
        super(SSISLogLocation, self).__init__(**kwargs)
        self.log_path = log_path
        self.access_credential = access_credential
        self.log_refresh_interval = log_refresh_interval


class SSISLogLocationLogPath(msrest.serialization.Model):
    """The SSIS package execution log path. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SSISLogLocationLogPath, self).__init__(**kwargs)


class SSISLogLocationTypeProperties(msrest.serialization.Model):
    """SSIS package execution log location properties.

    :param access_credential: SSIS access credential.
    :type access_credential: ~data_factory_management_client.models.SSISAccessCredential
    :param log_refresh_interval: Specifies the interval to refresh log. The default interval is 5
     minutes. Type: string (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type log_refresh_interval:
     ~data_factory_management_client.models.SSISLogLocationTypePropertiesLogRefreshInterval
    """

    _attribute_map = {
        'access_credential': {'key': 'accessCredential', 'type': 'SSISAccessCredential'},
        'log_refresh_interval': {'key': 'logRefreshInterval', 'type': 'SSISLogLocationTypePropertiesLogRefreshInterval'},
    }

    def __init__(
        self,
        *,
        access_credential: Optional["SSISAccessCredential"] = None,
        log_refresh_interval: Optional["SSISLogLocationTypePropertiesLogRefreshInterval"] = None,
        **kwargs
    ):
        super(SSISLogLocationTypeProperties, self).__init__(**kwargs)
        self.access_credential = access_credential
        self.log_refresh_interval = log_refresh_interval


class SSISLogLocationTypePropertiesLogRefreshInterval(msrest.serialization.Model):
    """Specifies the interval to refresh log. The default interval is 5 minutes. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SSISLogLocationTypePropertiesLogRefreshInterval, self).__init__(**kwargs)


class SsisObjectMetadataListResponse(msrest.serialization.Model):
    """A list of SSIS object metadata.

    :param value: List of SSIS object metadata.
    :type value: list[~data_factory_management_client.models.SsisObjectMetadata]
    :param next_link: The link to the next page of results, if any remaining results exist.
    :type next_link: str
    """

    _attribute_map = {
        'value': {'key': 'value', 'type': '[SsisObjectMetadata]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: Optional[List["SsisObjectMetadata"]] = None,
        next_link: Optional[str] = None,
        **kwargs
    ):
        super(SsisObjectMetadataListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class SsisObjectMetadataStatusResponse(msrest.serialization.Model):
    """The status of the operation.

    :param status: The status of the operation.
    :type status: str
    :param name: The operation name.
    :type name: str
    :param properties: The operation properties.
    :type properties: str
    :param error: The operation error message.
    :type error: str
    """

    _attribute_map = {
        'status': {'key': 'status', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'str'},
        'error': {'key': 'error', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        status: Optional[str] = None,
        name: Optional[str] = None,
        properties: Optional[str] = None,
        error: Optional[str] = None,
        **kwargs
    ):
        super(SsisObjectMetadataStatusResponse, self).__init__(**kwargs)
        self.status = status
        self.name = name
        self.properties = properties
        self.error = error


class SsisPackage(SsisObjectMetadata):
    """Ssis Package.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. The type of SSIS object metadata.Constant filled by server.  Possible
     values include: 'Folder', 'Project', 'Package', 'Environment'.
    :type type: str or ~data_factory_management_client.models.SsisObjectMetadataType
    :param id: Metadata id.
    :type id: long
    :param name: Metadata name.
    :type name: str
    :param description: Metadata description.
    :type description: str
    :param folder_id: Folder id which contains package.
    :type folder_id: long
    :param project_version: Project version which contains package.
    :type project_version: long
    :param project_id: Project id which contains package.
    :type project_id: long
    :param parameters: Parameters in package.
    :type parameters: list[~data_factory_management_client.models.SsisParameter]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'id': {'key': 'id', 'type': 'long'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'folder_id': {'key': 'folderId', 'type': 'long'},
        'project_version': {'key': 'projectVersion', 'type': 'long'},
        'project_id': {'key': 'projectId', 'type': 'long'},
        'parameters': {'key': 'parameters', 'type': '[SsisParameter]'},
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        name: Optional[str] = None,
        description: Optional[str] = None,
        folder_id: Optional[int] = None,
        project_version: Optional[int] = None,
        project_id: Optional[int] = None,
        parameters: Optional[List["SsisParameter"]] = None,
        **kwargs
    ):
        super(SsisPackage, self).__init__(id=id, name=name, description=description, **kwargs)
        self.type = 'Package'
        self.folder_id = folder_id
        self.project_version = project_version
        self.project_id = project_id
        self.parameters = parameters


class SSISPackageLocation(msrest.serialization.Model):
    """SSIS package location.

    :param package_path: The SSIS package path. Type: string (or Expression with resultType
     string).
    :type package_path: ~data_factory_management_client.models.SSISPackageLocationPackagePath
    :param type: The type of SSIS package location. Possible values include: 'SSISDB', 'File',
     'InlinePackage'.
    :type type: str or ~data_factory_management_client.models.SsisPackageLocationType
    :param package_password: The base definition of a secret type.
    :type package_password: ~data_factory_management_client.models.SecretBase
    :param access_credential: SSIS access credential.
    :type access_credential: ~data_factory_management_client.models.SSISAccessCredential
    :param configuration_path: The configuration file of the package execution. Type: string (or
     Expression with resultType string).
    :type configuration_path:
     ~data_factory_management_client.models.SSISPackageLocationTypePropertiesConfigurationPath
    :param package_name: The package name.
    :type package_name: str
    :param package_content: The embedded package content. Type: string (or Expression with
     resultType string).
    :type package_content:
     ~data_factory_management_client.models.SSISPackageLocationTypePropertiesPackageContent
    :param package_last_modified_date: The embedded package last modified date.
    :type package_last_modified_date: str
    :param child_packages: The embedded child package list.
    :type child_packages: list[~data_factory_management_client.models.SSISChildPackage]
    """

    _attribute_map = {
        'package_path': {'key': 'packagePath', 'type': 'SSISPackageLocationPackagePath'},
        'type': {'key': 'type', 'type': 'str'},
        'package_password': {'key': 'typeProperties.packagePassword', 'type': 'SecretBase'},
        'access_credential': {'key': 'typeProperties.accessCredential', 'type': 'SSISAccessCredential'},
        'configuration_path': {'key': 'typeProperties.configurationPath', 'type': 'SSISPackageLocationTypePropertiesConfigurationPath'},
        'package_name': {'key': 'typeProperties.packageName', 'type': 'str'},
        'package_content': {'key': 'typeProperties.packageContent', 'type': 'SSISPackageLocationTypePropertiesPackageContent'},
        'package_last_modified_date': {'key': 'typeProperties.packageLastModifiedDate', 'type': 'str'},
        'child_packages': {'key': 'typeProperties.childPackages', 'type': '[SSISChildPackage]'},
    }

    def __init__(
        self,
        *,
        package_path: Optional["SSISPackageLocationPackagePath"] = None,
        type: Optional[Union[str, "SsisPackageLocationType"]] = None,
        package_password: Optional["SecretBase"] = None,
        access_credential: Optional["SSISAccessCredential"] = None,
        configuration_path: Optional["SSISPackageLocationTypePropertiesConfigurationPath"] = None,
        package_name: Optional[str] = None,
        package_content: Optional["SSISPackageLocationTypePropertiesPackageContent"] = None,
        package_last_modified_date: Optional[str] = None,
        child_packages: Optional[List["SSISChildPackage"]] = None,
        **kwargs
    ):
        super(SSISPackageLocation, self).__init__(**kwargs)
        self.package_path = package_path
        self.type = type
        self.package_password = package_password
        self.access_credential = access_credential
        self.configuration_path = configuration_path
        self.package_name = package_name
        self.package_content = package_content
        self.package_last_modified_date = package_last_modified_date
        self.child_packages = child_packages


class SSISPackageLocationPackagePath(msrest.serialization.Model):
    """The SSIS package path. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SSISPackageLocationPackagePath, self).__init__(**kwargs)


class SSISPackageLocationTypeProperties(msrest.serialization.Model):
    """SSIS package location properties.

    :param package_password: The base definition of a secret type.
    :type package_password: ~data_factory_management_client.models.SecretBase
    :param access_credential: SSIS access credential.
    :type access_credential: ~data_factory_management_client.models.SSISAccessCredential
    :param configuration_path: The configuration file of the package execution. Type: string (or
     Expression with resultType string).
    :type configuration_path:
     ~data_factory_management_client.models.SSISPackageLocationTypePropertiesConfigurationPath
    :param package_name: The package name.
    :type package_name: str
    :param package_content: The embedded package content. Type: string (or Expression with
     resultType string).
    :type package_content:
     ~data_factory_management_client.models.SSISPackageLocationTypePropertiesPackageContent
    :param package_last_modified_date: The embedded package last modified date.
    :type package_last_modified_date: str
    :param child_packages: The embedded child package list.
    :type child_packages: list[~data_factory_management_client.models.SSISChildPackage]
    """

    _attribute_map = {
        'package_password': {'key': 'packagePassword', 'type': 'SecretBase'},
        'access_credential': {'key': 'accessCredential', 'type': 'SSISAccessCredential'},
        'configuration_path': {'key': 'configurationPath', 'type': 'SSISPackageLocationTypePropertiesConfigurationPath'},
        'package_name': {'key': 'packageName', 'type': 'str'},
        'package_content': {'key': 'packageContent', 'type': 'SSISPackageLocationTypePropertiesPackageContent'},
        'package_last_modified_date': {'key': 'packageLastModifiedDate', 'type': 'str'},
        'child_packages': {'key': 'childPackages', 'type': '[SSISChildPackage]'},
    }

    def __init__(
        self,
        *,
        package_password: Optional["SecretBase"] = None,
        access_credential: Optional["SSISAccessCredential"] = None,
        configuration_path: Optional["SSISPackageLocationTypePropertiesConfigurationPath"] = None,
        package_name: Optional[str] = None,
        package_content: Optional["SSISPackageLocationTypePropertiesPackageContent"] = None,
        package_last_modified_date: Optional[str] = None,
        child_packages: Optional[List["SSISChildPackage"]] = None,
        **kwargs
    ):
        super(SSISPackageLocationTypeProperties, self).__init__(**kwargs)
        self.package_password = package_password
        self.access_credential = access_credential
        self.configuration_path = configuration_path
        self.package_name = package_name
        self.package_content = package_content
        self.package_last_modified_date = package_last_modified_date
        self.child_packages = child_packages


class SSISPackageLocationTypePropertiesConfigurationPath(msrest.serialization.Model):
    """The configuration file of the package execution. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SSISPackageLocationTypePropertiesConfigurationPath, self).__init__(**kwargs)


class SSISPackageLocationTypePropertiesPackageContent(msrest.serialization.Model):
    """The embedded package content. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SSISPackageLocationTypePropertiesPackageContent, self).__init__(**kwargs)


class SsisParameter(msrest.serialization.Model):
    """Ssis parameter.

    :param id: Parameter id.
    :type id: long
    :param name: Parameter name.
    :type name: str
    :param description: Parameter description.
    :type description: str
    :param data_type: Parameter type.
    :type data_type: str
    :param required: Whether parameter is required.
    :type required: bool
    :param sensitive: Whether parameter is sensitive.
    :type sensitive: bool
    :param design_default_value: Design default value of parameter.
    :type design_default_value: str
    :param default_value: Default value of parameter.
    :type default_value: str
    :param sensitive_default_value: Default sensitive value of parameter.
    :type sensitive_default_value: str
    :param value_type: Parameter value type.
    :type value_type: str
    :param value_set: Parameter value set.
    :type value_set: bool
    :param variable: Parameter reference variable.
    :type variable: str
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'long'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'data_type': {'key': 'dataType', 'type': 'str'},
        'required': {'key': 'required', 'type': 'bool'},
        'sensitive': {'key': 'sensitive', 'type': 'bool'},
        'design_default_value': {'key': 'designDefaultValue', 'type': 'str'},
        'default_value': {'key': 'defaultValue', 'type': 'str'},
        'sensitive_default_value': {'key': 'sensitiveDefaultValue', 'type': 'str'},
        'value_type': {'key': 'valueType', 'type': 'str'},
        'value_set': {'key': 'valueSet', 'type': 'bool'},
        'variable': {'key': 'variable', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        name: Optional[str] = None,
        description: Optional[str] = None,
        data_type: Optional[str] = None,
        required: Optional[bool] = None,
        sensitive: Optional[bool] = None,
        design_default_value: Optional[str] = None,
        default_value: Optional[str] = None,
        sensitive_default_value: Optional[str] = None,
        value_type: Optional[str] = None,
        value_set: Optional[bool] = None,
        variable: Optional[str] = None,
        **kwargs
    ):
        super(SsisParameter, self).__init__(**kwargs)
        self.id = id
        self.name = name
        self.description = description
        self.data_type = data_type
        self.required = required
        self.sensitive = sensitive
        self.design_default_value = design_default_value
        self.default_value = default_value
        self.sensitive_default_value = sensitive_default_value
        self.value_type = value_type
        self.value_set = value_set
        self.variable = variable


class SsisProject(SsisObjectMetadata):
    """Ssis project.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. The type of SSIS object metadata.Constant filled by server.  Possible
     values include: 'Folder', 'Project', 'Package', 'Environment'.
    :type type: str or ~data_factory_management_client.models.SsisObjectMetadataType
    :param id: Metadata id.
    :type id: long
    :param name: Metadata name.
    :type name: str
    :param description: Metadata description.
    :type description: str
    :param folder_id: Folder id which contains project.
    :type folder_id: long
    :param version: Project version.
    :type version: long
    :param environment_refs: Environment reference in project.
    :type environment_refs: list[~data_factory_management_client.models.SsisEnvironmentReference]
    :param parameters: Parameters in project.
    :type parameters: list[~data_factory_management_client.models.SsisParameter]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'id': {'key': 'id', 'type': 'long'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'folder_id': {'key': 'folderId', 'type': 'long'},
        'version': {'key': 'version', 'type': 'long'},
        'environment_refs': {'key': 'environmentRefs', 'type': '[SsisEnvironmentReference]'},
        'parameters': {'key': 'parameters', 'type': '[SsisParameter]'},
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        name: Optional[str] = None,
        description: Optional[str] = None,
        folder_id: Optional[int] = None,
        version: Optional[int] = None,
        environment_refs: Optional[List["SsisEnvironmentReference"]] = None,
        parameters: Optional[List["SsisParameter"]] = None,
        **kwargs
    ):
        super(SsisProject, self).__init__(id=id, name=name, description=description, **kwargs)
        self.type = 'Project'
        self.folder_id = folder_id
        self.version = version
        self.environment_refs = environment_refs
        self.parameters = parameters


class SSISPropertyOverride(msrest.serialization.Model):
    """SSIS property override.

    All required parameters must be populated in order to send to Azure.

    :param value: Required. SSIS package property override value. Type: string (or Expression with
     resultType string).
    :type value: ~data_factory_management_client.models.SSISPropertyOverrideValue
    :param is_sensitive: Whether SSIS package property override value is sensitive data. Value will
     be encrypted in SSISDB if it is true.
    :type is_sensitive: bool
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': 'SSISPropertyOverrideValue'},
        'is_sensitive': {'key': 'isSensitive', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        value: "SSISPropertyOverrideValue",
        is_sensitive: Optional[bool] = None,
        **kwargs
    ):
        super(SSISPropertyOverride, self).__init__(**kwargs)
        self.value = value
        self.is_sensitive = is_sensitive


class SSISPropertyOverrideValue(msrest.serialization.Model):
    """SSIS package property override value. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SSISPropertyOverrideValue, self).__init__(**kwargs)


class SsisVariable(msrest.serialization.Model):
    """Ssis variable.

    :param id: Variable id.
    :type id: long
    :param name: Variable name.
    :type name: str
    :param description: Variable description.
    :type description: str
    :param data_type: Variable type.
    :type data_type: str
    :param sensitive: Whether variable is sensitive.
    :type sensitive: bool
    :param value: Variable value.
    :type value: str
    :param sensitive_value: Variable sensitive value.
    :type sensitive_value: str
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'long'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'data_type': {'key': 'dataType', 'type': 'str'},
        'sensitive': {'key': 'sensitive', 'type': 'bool'},
        'value': {'key': 'value', 'type': 'str'},
        'sensitive_value': {'key': 'sensitiveValue', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        name: Optional[str] = None,
        description: Optional[str] = None,
        data_type: Optional[str] = None,
        sensitive: Optional[bool] = None,
        value: Optional[str] = None,
        sensitive_value: Optional[str] = None,
        **kwargs
    ):
        super(SsisVariable, self).__init__(**kwargs)
        self.id = id
        self.name = name
        self.description = description
        self.data_type = data_type
        self.sensitive = sensitive
        self.value = value
        self.sensitive_value = sensitive_value


class StagingSettings(msrest.serialization.Model):
    """Staging settings.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param path: The path to storage for storing the interim data. Type: string (or Expression with
     resultType string).
    :type path: ~data_factory_management_client.models.StagingSettingsPath
    :param enable_compression: Specifies whether to use compression when copying data via an
     interim staging. Default value is false. Type: boolean (or Expression with resultType boolean).
    :type enable_compression:
     ~data_factory_management_client.models.StagingSettingsEnableCompression
    """

    _validation = {
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'path': {'key': 'path', 'type': 'StagingSettingsPath'},
        'enable_compression': {'key': 'enableCompression', 'type': 'StagingSettingsEnableCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        path: Optional["StagingSettingsPath"] = None,
        enable_compression: Optional["StagingSettingsEnableCompression"] = None,
        **kwargs
    ):
        super(StagingSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.linked_service_name = linked_service_name
        self.path = path
        self.enable_compression = enable_compression


class StagingSettingsEnableCompression(msrest.serialization.Model):
    """Specifies whether to use compression when copying data via an interim staging. Default value is false. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(StagingSettingsEnableCompression, self).__init__(**kwargs)


class StagingSettingsPath(msrest.serialization.Model):
    """The path to storage for storing the interim data. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(StagingSettingsPath, self).__init__(**kwargs)


class StoredProcedureParameter(msrest.serialization.Model):
    """SQL stored procedure parameter.

    :param value: Stored procedure parameter value. Type: string (or Expression with resultType
     string).
    :type value: ~data_factory_management_client.models.StoredProcedureParameterValue
    :param type: Stored procedure parameter type. Possible values include: 'String', 'Int',
     'Int64', 'Decimal', 'Guid', 'Boolean', 'Date'.
    :type type: str or ~data_factory_management_client.models.StoredProcedureParameterType
    """

    _attribute_map = {
        'value': {'key': 'value', 'type': 'StoredProcedureParameterValue'},
        'type': {'key': 'type', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: Optional["StoredProcedureParameterValue"] = None,
        type: Optional[Union[str, "StoredProcedureParameterType"]] = None,
        **kwargs
    ):
        super(StoredProcedureParameter, self).__init__(**kwargs)
        self.value = value
        self.type = type


class StoredProcedureParameterValue(msrest.serialization.Model):
    """Stored procedure parameter value. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(StoredProcedureParameterValue, self).__init__(**kwargs)


class StoreReadSettingsMaxConcurrentConnections(msrest.serialization.Model):
    """The maximum concurrent connection count for the source data store. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(StoreReadSettingsMaxConcurrentConnections, self).__init__(**kwargs)


class StoreWriteSettingsCopyBehavior(msrest.serialization.Model):
    """The type of copy behavior for copy sink.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(StoreWriteSettingsCopyBehavior, self).__init__(**kwargs)


class StoreWriteSettingsMaxConcurrentConnections(msrest.serialization.Model):
    """The maximum concurrent connection count for the source data store. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(StoreWriteSettingsMaxConcurrentConnections, self).__init__(**kwargs)


class SwitchActivity(ControlActivity):
    """This activity evaluates an expression and executes activities under the cases property that correspond to the expression evaluation expected in the equals property.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param on: Required. Azure Data Factory expression definition.
    :type on: ~data_factory_management_client.models.Expression
    :param cases: List of cases that correspond to expected values of the 'on' property. This is an
     optional property and if not provided, the activity will execute activities provided in
     defaultActivities.
    :type cases: list[~data_factory_management_client.models.SwitchCase]
    :param default_activities: List of activities to execute if no case condition is satisfied.
     This is an optional property and if not provided, the activity will exit without any action.
    :type default_activities: list[~data_factory_management_client.models.Activity]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'on': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'on': {'key': 'typeProperties.on', 'type': 'Expression'},
        'cases': {'key': 'typeProperties.cases', 'type': '[SwitchCase]'},
        'default_activities': {'key': 'typeProperties.defaultActivities', 'type': '[Activity]'},
    }

    def __init__(
        self,
        *,
        name: str,
        on: "Expression",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        cases: Optional[List["SwitchCase"]] = None,
        default_activities: Optional[List["Activity"]] = None,
        **kwargs
    ):
        super(SwitchActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'Switch'
        self.on = on
        self.cases = cases
        self.default_activities = default_activities


class SwitchActivityTypeProperties(msrest.serialization.Model):
    """Switch activity properties.

    All required parameters must be populated in order to send to Azure.

    :param on: Required. Azure Data Factory expression definition.
    :type on: ~data_factory_management_client.models.Expression
    :param cases: List of cases that correspond to expected values of the 'on' property. This is an
     optional property and if not provided, the activity will execute activities provided in
     defaultActivities.
    :type cases: list[~data_factory_management_client.models.SwitchCase]
    :param default_activities: List of activities to execute if no case condition is satisfied.
     This is an optional property and if not provided, the activity will exit without any action.
    :type default_activities: list[~data_factory_management_client.models.Activity]
    """

    _validation = {
        'on': {'required': True},
    }

    _attribute_map = {
        'on': {'key': 'on', 'type': 'Expression'},
        'cases': {'key': 'cases', 'type': '[SwitchCase]'},
        'default_activities': {'key': 'defaultActivities', 'type': '[Activity]'},
    }

    def __init__(
        self,
        *,
        on: "Expression",
        cases: Optional[List["SwitchCase"]] = None,
        default_activities: Optional[List["Activity"]] = None,
        **kwargs
    ):
        super(SwitchActivityTypeProperties, self).__init__(**kwargs)
        self.on = on
        self.cases = cases
        self.default_activities = default_activities


class SwitchCase(msrest.serialization.Model):
    """Switch cases with have a value and corresponding activities.

    :param value: Expected value that satisfies the expression result of the 'on' property.
    :type value: str
    :param activities: List of activities to execute for satisfied case condition.
    :type activities: list[~data_factory_management_client.models.Activity]
    """

    _attribute_map = {
        'value': {'key': 'value', 'type': 'str'},
        'activities': {'key': 'activities', 'type': '[Activity]'},
    }

    def __init__(
        self,
        *,
        value: Optional[str] = None,
        activities: Optional[List["Activity"]] = None,
        **kwargs
    ):
        super(SwitchCase, self).__init__(**kwargs)
        self.value = value
        self.activities = activities


class SybaseLinkedService(LinkedService):
    """Linked service for Sybase data source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param server: Required. Server name for connection. Type: string (or Expression with
     resultType string).
    :type server: ~data_factory_management_client.models.SybaseLinkedServiceTypePropertiesServer
    :param database: Required. Database name for connection. Type: string (or Expression with
     resultType string).
    :type database:
     ~data_factory_management_client.models.SybaseLinkedServiceTypePropertiesDatabase
    :param schema: Schema name for connection. Type: string (or Expression with resultType string).
    :type schema: ~data_factory_management_client.models.SybaseLinkedServiceTypePropertiesSchema
    :param authentication_type: AuthenticationType to be used for connection. Possible values
     include: 'Basic', 'Windows'.
    :type authentication_type: str or
     ~data_factory_management_client.models.SybaseAuthenticationType
    :param username: Username for authentication. Type: string (or Expression with resultType
     string).
    :type username:
     ~data_factory_management_client.models.SybaseLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SybaseLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'server': {'required': True},
        'database': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'server': {'key': 'typeProperties.server', 'type': 'SybaseLinkedServiceTypePropertiesServer'},
        'database': {'key': 'typeProperties.database', 'type': 'SybaseLinkedServiceTypePropertiesDatabase'},
        'schema': {'key': 'typeProperties.schema', 'type': 'SybaseLinkedServiceTypePropertiesSchema'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'SybaseLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'SybaseLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        server: "SybaseLinkedServiceTypePropertiesServer",
        database: "SybaseLinkedServiceTypePropertiesDatabase",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        schema: Optional["SybaseLinkedServiceTypePropertiesSchema"] = None,
        authentication_type: Optional[Union[str, "SybaseAuthenticationType"]] = None,
        username: Optional["SybaseLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["SybaseLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SybaseLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Sybase'
        self.server = server
        self.database = database
        self.schema = schema
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.encrypted_credential = encrypted_credential


class SybaseLinkedServiceTypeProperties(msrest.serialization.Model):
    """Sybase linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param server: Required. Server name for connection. Type: string (or Expression with
     resultType string).
    :type server: ~data_factory_management_client.models.SybaseLinkedServiceTypePropertiesServer
    :param database: Required. Database name for connection. Type: string (or Expression with
     resultType string).
    :type database:
     ~data_factory_management_client.models.SybaseLinkedServiceTypePropertiesDatabase
    :param schema: Schema name for connection. Type: string (or Expression with resultType string).
    :type schema: ~data_factory_management_client.models.SybaseLinkedServiceTypePropertiesSchema
    :param authentication_type: AuthenticationType to be used for connection. Possible values
     include: 'Basic', 'Windows'.
    :type authentication_type: str or
     ~data_factory_management_client.models.SybaseAuthenticationType
    :param username: Username for authentication. Type: string (or Expression with resultType
     string).
    :type username:
     ~data_factory_management_client.models.SybaseLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.SybaseLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'server': {'required': True},
        'database': {'required': True},
    }

    _attribute_map = {
        'server': {'key': 'server', 'type': 'SybaseLinkedServiceTypePropertiesServer'},
        'database': {'key': 'database', 'type': 'SybaseLinkedServiceTypePropertiesDatabase'},
        'schema': {'key': 'schema', 'type': 'SybaseLinkedServiceTypePropertiesSchema'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'username': {'key': 'username', 'type': 'SybaseLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'SybaseLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        server: "SybaseLinkedServiceTypePropertiesServer",
        database: "SybaseLinkedServiceTypePropertiesDatabase",
        schema: Optional["SybaseLinkedServiceTypePropertiesSchema"] = None,
        authentication_type: Optional[Union[str, "SybaseAuthenticationType"]] = None,
        username: Optional["SybaseLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["SybaseLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(SybaseLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.server = server
        self.database = database
        self.schema = schema
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.encrypted_credential = encrypted_credential


class SybaseLinkedServiceTypePropertiesDatabase(msrest.serialization.Model):
    """Database name for connection. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SybaseLinkedServiceTypePropertiesDatabase, self).__init__(**kwargs)


class SybaseLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SybaseLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class SybaseLinkedServiceTypePropertiesSchema(msrest.serialization.Model):
    """Schema name for connection. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SybaseLinkedServiceTypePropertiesSchema, self).__init__(**kwargs)


class SybaseLinkedServiceTypePropertiesServer(msrest.serialization.Model):
    """Server name for connection. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SybaseLinkedServiceTypePropertiesServer, self).__init__(**kwargs)


class SybaseLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """Username for authentication. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SybaseLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class SybaseSource(TabularSource):
    """A copy activity source for Sybase databases.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: Database query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.SybaseSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'SybaseSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["SybaseSourceQuery"] = None,
        **kwargs
    ):
        super(SybaseSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SybaseSource'
        self.query = query


class SybaseSourceQuery(msrest.serialization.Model):
    """Database query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SybaseSourceQuery, self).__init__(**kwargs)


class SybaseTableDataset(Dataset):
    """The Sybase table dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The Sybase table name. Type: string (or Expression with resultType string).
    :type table_name:
     ~data_factory_management_client.models.SybaseTableDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'SybaseTableDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["SybaseTableDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(SybaseTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SybaseTable'
        self.table_name = table_name


class SybaseTableDatasetTypeProperties(msrest.serialization.Model):
    """Sybase table dataset properties.

    :param table_name: The Sybase table name. Type: string (or Expression with resultType string).
    :type table_name:
     ~data_factory_management_client.models.SybaseTableDatasetTypePropertiesTableName
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'SybaseTableDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["SybaseTableDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(SybaseTableDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name


class SybaseTableDatasetTypePropertiesTableName(msrest.serialization.Model):
    """The Sybase table name. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(SybaseTableDatasetTypePropertiesTableName, self).__init__(**kwargs)


class TabularSourceQueryTimeout(msrest.serialization.Model):
    """Query timeout. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TabularSourceQueryTimeout, self).__init__(**kwargs)


class TeradataLinkedService(LinkedService):
    """Linked service for Teradata data source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: Teradata ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.TeradataLinkedServiceTypePropertiesConnectionString
    :param server: Server name for connection. Type: string (or Expression with resultType string).
    :type server: ~data_factory_management_client.models.TeradataLinkedServiceTypePropertiesServer
    :param authentication_type: AuthenticationType to be used for connection. Possible values
     include: 'Basic', 'Windows'.
    :type authentication_type: str or
     ~data_factory_management_client.models.TeradataAuthenticationType
    :param username: Username for authentication. Type: string (or Expression with resultType
     string).
    :type username:
     ~data_factory_management_client.models.TeradataLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.TeradataLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'TeradataLinkedServiceTypePropertiesConnectionString'},
        'server': {'key': 'typeProperties.server', 'type': 'TeradataLinkedServiceTypePropertiesServer'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'TeradataLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'TeradataLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        connection_string: Optional["TeradataLinkedServiceTypePropertiesConnectionString"] = None,
        server: Optional["TeradataLinkedServiceTypePropertiesServer"] = None,
        authentication_type: Optional[Union[str, "TeradataAuthenticationType"]] = None,
        username: Optional["TeradataLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["TeradataLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(TeradataLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Teradata'
        self.connection_string = connection_string
        self.server = server
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.encrypted_credential = encrypted_credential


class TeradataLinkedServiceTypeProperties(msrest.serialization.Model):
    """Teradata linked service properties.

    :param connection_string: Teradata ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.TeradataLinkedServiceTypePropertiesConnectionString
    :param server: Server name for connection. Type: string (or Expression with resultType string).
    :type server: ~data_factory_management_client.models.TeradataLinkedServiceTypePropertiesServer
    :param authentication_type: AuthenticationType to be used for connection. Possible values
     include: 'Basic', 'Windows'.
    :type authentication_type: str or
     ~data_factory_management_client.models.TeradataAuthenticationType
    :param username: Username for authentication. Type: string (or Expression with resultType
     string).
    :type username:
     ~data_factory_management_client.models.TeradataLinkedServiceTypePropertiesUsername
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.TeradataLinkedServiceTypePropertiesEncryptedCredential
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'TeradataLinkedServiceTypePropertiesConnectionString'},
        'server': {'key': 'server', 'type': 'TeradataLinkedServiceTypePropertiesServer'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'username': {'key': 'username', 'type': 'TeradataLinkedServiceTypePropertiesUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'TeradataLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional["TeradataLinkedServiceTypePropertiesConnectionString"] = None,
        server: Optional["TeradataLinkedServiceTypePropertiesServer"] = None,
        authentication_type: Optional[Union[str, "TeradataAuthenticationType"]] = None,
        username: Optional["TeradataLinkedServiceTypePropertiesUsername"] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional["TeradataLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(TeradataLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.server = server
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.encrypted_credential = encrypted_credential


class TeradataLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """Teradata ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TeradataLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class TeradataLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TeradataLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class TeradataLinkedServiceTypePropertiesServer(msrest.serialization.Model):
    """Server name for connection. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TeradataLinkedServiceTypePropertiesServer, self).__init__(**kwargs)


class TeradataLinkedServiceTypePropertiesUsername(msrest.serialization.Model):
    """Username for authentication. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TeradataLinkedServiceTypePropertiesUsername, self).__init__(**kwargs)


class TeradataPartitionSettings(msrest.serialization.Model):
    """The settings that will be leveraged for teradata source partitioning.

    :param partition_column_name: The name of the column that will be used for proceeding range or
     hash partitioning. Type: string (or Expression with resultType string).
    :type partition_column_name:
     ~data_factory_management_client.models.TeradataPartitionSettingsPartitionColumnName
    :param partition_upper_bound: The maximum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :type partition_upper_bound:
     ~data_factory_management_client.models.TeradataPartitionSettingsPartitionUpperBound
    :param partition_lower_bound: The minimum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :type partition_lower_bound:
     ~data_factory_management_client.models.TeradataPartitionSettingsPartitionLowerBound
    """

    _attribute_map = {
        'partition_column_name': {'key': 'partitionColumnName', 'type': 'TeradataPartitionSettingsPartitionColumnName'},
        'partition_upper_bound': {'key': 'partitionUpperBound', 'type': 'TeradataPartitionSettingsPartitionUpperBound'},
        'partition_lower_bound': {'key': 'partitionLowerBound', 'type': 'TeradataPartitionSettingsPartitionLowerBound'},
    }

    def __init__(
        self,
        *,
        partition_column_name: Optional["TeradataPartitionSettingsPartitionColumnName"] = None,
        partition_upper_bound: Optional["TeradataPartitionSettingsPartitionUpperBound"] = None,
        partition_lower_bound: Optional["TeradataPartitionSettingsPartitionLowerBound"] = None,
        **kwargs
    ):
        super(TeradataPartitionSettings, self).__init__(**kwargs)
        self.partition_column_name = partition_column_name
        self.partition_upper_bound = partition_upper_bound
        self.partition_lower_bound = partition_lower_bound


class TeradataPartitionSettingsPartitionColumnName(msrest.serialization.Model):
    """The name of the column that will be used for proceeding range or hash partitioning. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TeradataPartitionSettingsPartitionColumnName, self).__init__(**kwargs)


class TeradataPartitionSettingsPartitionLowerBound(msrest.serialization.Model):
    """The minimum value of column specified in partitionColumnName that will be used for proceeding range partitioning. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TeradataPartitionSettingsPartitionLowerBound, self).__init__(**kwargs)


class TeradataPartitionSettingsPartitionUpperBound(msrest.serialization.Model):
    """The maximum value of column specified in partitionColumnName that will be used for proceeding range partitioning. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TeradataPartitionSettingsPartitionUpperBound, self).__init__(**kwargs)


class TeradataSource(TabularSource):
    """A copy activity Teradata source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: Teradata query. Type: string (or Expression with resultType string).
    :type query: ~data_factory_management_client.models.TeradataSourceQuery
    :param partition_option: The partition mechanism that will be used for teradata read in
     parallel. Possible values include: 'None', 'Hash', 'DynamicRange'.
    :type partition_option: str or ~data_factory_management_client.models.TeradataPartitionOption
    :param partition_settings: The settings that will be leveraged for teradata source
     partitioning.
    :type partition_settings: ~data_factory_management_client.models.TeradataPartitionSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'TeradataSourceQuery'},
        'partition_option': {'key': 'partitionOption', 'type': 'str'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'TeradataPartitionSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["TeradataSourceQuery"] = None,
        partition_option: Optional[Union[str, "TeradataPartitionOption"]] = None,
        partition_settings: Optional["TeradataPartitionSettings"] = None,
        **kwargs
    ):
        super(TeradataSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'TeradataSource'
        self.query = query
        self.partition_option = partition_option
        self.partition_settings = partition_settings


class TeradataSourceQuery(msrest.serialization.Model):
    """Teradata query. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TeradataSourceQuery, self).__init__(**kwargs)


class TeradataTableDataset(Dataset):
    """The Teradata database dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param database: The database name of Teradata. Type: string (or Expression with resultType
     string).
    :type database:
     ~data_factory_management_client.models.TeradataTableDatasetTypePropertiesDatabase
    :param table: The table name of Teradata. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.TeradataTableDatasetTypePropertiesTable
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'database': {'key': 'typeProperties.database', 'type': 'TeradataTableDatasetTypePropertiesDatabase'},
        'table': {'key': 'typeProperties.table', 'type': 'TeradataTableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        database: Optional["TeradataTableDatasetTypePropertiesDatabase"] = None,
        table: Optional["TeradataTableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(TeradataTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'TeradataTable'
        self.database = database
        self.table = table


class TeradataTableDatasetTypeProperties(msrest.serialization.Model):
    """Teradata dataset properties.

    :param database: The database name of Teradata. Type: string (or Expression with resultType
     string).
    :type database:
     ~data_factory_management_client.models.TeradataTableDatasetTypePropertiesDatabase
    :param table: The table name of Teradata. Type: string (or Expression with resultType string).
    :type table: ~data_factory_management_client.models.TeradataTableDatasetTypePropertiesTable
    """

    _attribute_map = {
        'database': {'key': 'database', 'type': 'TeradataTableDatasetTypePropertiesDatabase'},
        'table': {'key': 'table', 'type': 'TeradataTableDatasetTypePropertiesTable'},
    }

    def __init__(
        self,
        *,
        database: Optional["TeradataTableDatasetTypePropertiesDatabase"] = None,
        table: Optional["TeradataTableDatasetTypePropertiesTable"] = None,
        **kwargs
    ):
        super(TeradataTableDatasetTypeProperties, self).__init__(**kwargs)
        self.database = database
        self.table = table


class TeradataTableDatasetTypePropertiesDatabase(msrest.serialization.Model):
    """The database name of Teradata. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TeradataTableDatasetTypePropertiesDatabase, self).__init__(**kwargs)


class TeradataTableDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of Teradata. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TeradataTableDatasetTypePropertiesTable, self).__init__(**kwargs)


class TextFormat(DatasetStorageFormat):
    """The data stored in text format.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset storage format.Constant filled by server.
    :type type: str
    :param serializer: Serializer. Type: string (or Expression with resultType string).
    :type serializer: ~data_factory_management_client.models.DatasetStorageFormatSerializer
    :param deserializer: Deserializer. Type: string (or Expression with resultType string).
    :type deserializer: ~data_factory_management_client.models.DatasetStorageFormatDeserializer
    :param column_delimiter: The column delimiter. Type: string (or Expression with resultType
     string).
    :type column_delimiter: ~data_factory_management_client.models.TextFormatColumnDelimiter
    :param row_delimiter: The row delimiter. Type: string (or Expression with resultType string).
    :type row_delimiter: ~data_factory_management_client.models.TextFormatRowDelimiter
    :param escape_char: The escape character. Type: string (or Expression with resultType string).
    :type escape_char: ~data_factory_management_client.models.TextFormatEscapeChar
    :param quote_char: The quote character. Type: string (or Expression with resultType string).
    :type quote_char: ~data_factory_management_client.models.TextFormatQuoteChar
    :param null_value: The null value string. Type: string (or Expression with resultType string).
    :type null_value: ~data_factory_management_client.models.TextFormatNullValue
    :param encoding_name: The code page name of the preferred encoding. If miss, the default value
     is ΓÇ£utf-8ΓÇ¥, unless BOM denotes another Unicode encoding. Refer to the ΓÇ£NameΓÇ¥ column of
     the table in the following link to set supported values:
     https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with
     resultType string).
    :type encoding_name: ~data_factory_management_client.models.TextFormatEncodingName
    :param treat_empty_as_null: Treat empty column values in the text file as null. The default
     value is true. Type: boolean (or Expression with resultType boolean).
    :type treat_empty_as_null: ~data_factory_management_client.models.TextFormatTreatEmptyAsNull
    :param skip_line_count: The number of lines/rows to be skipped when parsing text files. The
     default value is 0. Type: integer (or Expression with resultType integer).
    :type skip_line_count: ~data_factory_management_client.models.TextFormatSkipLineCount
    :param first_row_as_header: When used as input, treat the first row of data as headers. When
     used as output,write the headers into the output as the first row of data. The default value is
     false. Type: boolean (or Expression with resultType boolean).
    :type first_row_as_header: ~data_factory_management_client.models.TextFormatFirstRowAsHeader
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'serializer': {'key': 'serializer', 'type': 'DatasetStorageFormatSerializer'},
        'deserializer': {'key': 'deserializer', 'type': 'DatasetStorageFormatDeserializer'},
        'column_delimiter': {'key': 'columnDelimiter', 'type': 'TextFormatColumnDelimiter'},
        'row_delimiter': {'key': 'rowDelimiter', 'type': 'TextFormatRowDelimiter'},
        'escape_char': {'key': 'escapeChar', 'type': 'TextFormatEscapeChar'},
        'quote_char': {'key': 'quoteChar', 'type': 'TextFormatQuoteChar'},
        'null_value': {'key': 'nullValue', 'type': 'TextFormatNullValue'},
        'encoding_name': {'key': 'encodingName', 'type': 'TextFormatEncodingName'},
        'treat_empty_as_null': {'key': 'treatEmptyAsNull', 'type': 'TextFormatTreatEmptyAsNull'},
        'skip_line_count': {'key': 'skipLineCount', 'type': 'TextFormatSkipLineCount'},
        'first_row_as_header': {'key': 'firstRowAsHeader', 'type': 'TextFormatFirstRowAsHeader'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        serializer: Optional["DatasetStorageFormatSerializer"] = None,
        deserializer: Optional["DatasetStorageFormatDeserializer"] = None,
        column_delimiter: Optional["TextFormatColumnDelimiter"] = None,
        row_delimiter: Optional["TextFormatRowDelimiter"] = None,
        escape_char: Optional["TextFormatEscapeChar"] = None,
        quote_char: Optional["TextFormatQuoteChar"] = None,
        null_value: Optional["TextFormatNullValue"] = None,
        encoding_name: Optional["TextFormatEncodingName"] = None,
        treat_empty_as_null: Optional["TextFormatTreatEmptyAsNull"] = None,
        skip_line_count: Optional["TextFormatSkipLineCount"] = None,
        first_row_as_header: Optional["TextFormatFirstRowAsHeader"] = None,
        **kwargs
    ):
        super(TextFormat, self).__init__(additional_properties=additional_properties, serializer=serializer, deserializer=deserializer, **kwargs)
        self.type = 'TextFormat'
        self.column_delimiter = column_delimiter
        self.row_delimiter = row_delimiter
        self.escape_char = escape_char
        self.quote_char = quote_char
        self.null_value = null_value
        self.encoding_name = encoding_name
        self.treat_empty_as_null = treat_empty_as_null
        self.skip_line_count = skip_line_count
        self.first_row_as_header = first_row_as_header


class TextFormatColumnDelimiter(msrest.serialization.Model):
    """The column delimiter. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TextFormatColumnDelimiter, self).__init__(**kwargs)


class TextFormatEncodingName(msrest.serialization.Model):
    """The code page name of the preferred encoding. If miss, the default value is ΓÇ£utf-8ΓÇ¥, unless BOM denotes another Unicode encoding. Refer to the ΓÇ£NameΓÇ¥ column of the table in the following link to set supported values: https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TextFormatEncodingName, self).__init__(**kwargs)


class TextFormatEscapeChar(msrest.serialization.Model):
    """The escape character. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TextFormatEscapeChar, self).__init__(**kwargs)


class TextFormatFirstRowAsHeader(msrest.serialization.Model):
    """When used as input, treat the first row of data as headers. When used as output,write the headers into the output as the first row of data. The default value is false. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TextFormatFirstRowAsHeader, self).__init__(**kwargs)


class TextFormatNullValue(msrest.serialization.Model):
    """The null value string. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TextFormatNullValue, self).__init__(**kwargs)


class TextFormatQuoteChar(msrest.serialization.Model):
    """The quote character. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TextFormatQuoteChar, self).__init__(**kwargs)


class TextFormatRowDelimiter(msrest.serialization.Model):
    """The row delimiter. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TextFormatRowDelimiter, self).__init__(**kwargs)


class TextFormatSkipLineCount(msrest.serialization.Model):
    """The number of lines/rows to be skipped when parsing text files. The default value is 0. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TextFormatSkipLineCount, self).__init__(**kwargs)


class TextFormatTreatEmptyAsNull(msrest.serialization.Model):
    """Treat empty column values in the text file as null. The default value is true. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TextFormatTreatEmptyAsNull, self).__init__(**kwargs)


class TriggerAnnotationsItem(msrest.serialization.Model):
    """TriggerAnnotationsItem.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TriggerAnnotationsItem, self).__init__(**kwargs)


class TriggerDependencyReference(DependencyReference):
    """Trigger referenced dependency.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: TumblingWindowTriggerDependencyReference.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. The type of dependency reference.Constant filled by server.
    :type type: str
    :param reference_trigger: Required. Trigger reference type.
    :type reference_trigger: ~data_factory_management_client.models.TriggerReference
    """

    _validation = {
        'type': {'required': True},
        'reference_trigger': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_trigger': {'key': 'referenceTrigger', 'type': 'TriggerReference'},
    }

    _subtype_map = {
        'type': {'TumblingWindowTriggerDependencyReference': 'TumblingWindowTriggerDependencyReference'}
    }

    def __init__(
        self,
        *,
        reference_trigger: "TriggerReference",
        **kwargs
    ):
        super(TriggerDependencyReference, self).__init__(**kwargs)
        self.type = 'TriggerDependencyReference'
        self.reference_trigger = reference_trigger


class TriggerFilterParameters(msrest.serialization.Model):
    """Query parameters for triggers.

    :param continuation_token: The continuation token for getting the next page of results. Null
     for first page.
    :type continuation_token: str
    :param parent_trigger_name: The name of the parent TumblingWindowTrigger to get the child rerun
     triggers.
    :type parent_trigger_name: str
    """

    _attribute_map = {
        'continuation_token': {'key': 'continuationToken', 'type': 'str'},
        'parent_trigger_name': {'key': 'parentTriggerName', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        continuation_token: Optional[str] = None,
        parent_trigger_name: Optional[str] = None,
        **kwargs
    ):
        super(TriggerFilterParameters, self).__init__(**kwargs)
        self.continuation_token = continuation_token
        self.parent_trigger_name = parent_trigger_name


class TriggerListResponse(msrest.serialization.Model):
    """A list of trigger resources.

    All required parameters must be populated in order to send to Azure.

    :param value: Required. List of triggers.
    :type value: list[~data_factory_management_client.models.TriggerResource]
    :param next_link: The link to the next page of results, if any remaining results exist.
    :type next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[TriggerResource]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["TriggerResource"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        super(TriggerListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class TriggerPipelineReference(msrest.serialization.Model):
    """Pipeline that needs to be triggered with the given parameters.

    :param pipeline_reference: Pipeline reference type.
    :type pipeline_reference: ~data_factory_management_client.models.PipelineReference
    :param parameters: An object mapping parameter names to argument values.
    :type parameters: dict[str, object]
    """

    _attribute_map = {
        'pipeline_reference': {'key': 'pipelineReference', 'type': 'PipelineReference'},
        'parameters': {'key': 'parameters', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        pipeline_reference: Optional["PipelineReference"] = None,
        parameters: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(TriggerPipelineReference, self).__init__(**kwargs)
        self.pipeline_reference = pipeline_reference
        self.parameters = parameters


class TriggerQueryResponse(msrest.serialization.Model):
    """A query of triggers.

    All required parameters must be populated in order to send to Azure.

    :param value: Required. List of triggers.
    :type value: list[~data_factory_management_client.models.TriggerResource]
    :param continuation_token: The continuation token for getting the next page of results, if any
     remaining results exist, null otherwise.
    :type continuation_token: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[TriggerResource]'},
        'continuation_token': {'key': 'continuationToken', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["TriggerResource"],
        continuation_token: Optional[str] = None,
        **kwargs
    ):
        super(TriggerQueryResponse, self).__init__(**kwargs)
        self.value = value
        self.continuation_token = continuation_token


class TriggerReference(msrest.serialization.Model):
    """Trigger reference type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Trigger reference type. Default value: "TriggerReference".
    :vartype type: str
    :param reference_name: Required. Reference trigger name.
    :type reference_name: str
    """

    _validation = {
        'type': {'required': True, 'constant': True},
        'reference_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
    }

    type = "TriggerReference"

    def __init__(
        self,
        *,
        reference_name: str,
        **kwargs
    ):
        super(TriggerReference, self).__init__(**kwargs)
        self.reference_name = reference_name


class TriggerResource(SubResource):
    """Trigger resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :param properties: Required. Azure data factory nested object which contains information about
     creating pipeline run.
    :type properties: ~data_factory_management_client.models.Trigger
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
        'properties': {'required': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'Trigger'},
    }

    def __init__(
        self,
        *,
        properties: "Trigger",
        **kwargs
    ):
        super(TriggerResource, self).__init__(**kwargs)
        self.properties = properties


class TriggerRun(msrest.serialization.Model):
    """Trigger runs.

    Variables are only populated by the server, and will be ignored when sending a request.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :ivar trigger_run_id: Trigger run id.
    :vartype trigger_run_id: str
    :ivar trigger_name: Trigger name.
    :vartype trigger_name: str
    :ivar trigger_type: Trigger type.
    :vartype trigger_type: str
    :ivar trigger_run_timestamp: Trigger run start time.
    :vartype trigger_run_timestamp: ~datetime.datetime
    :ivar status: Trigger run status. Possible values include: 'Succeeded', 'Failed', 'Inprogress'.
    :vartype status: str or ~data_factory_management_client.models.TriggerRunStatus
    :ivar message: Trigger error message.
    :vartype message: str
    :ivar properties: List of property name and value related to trigger run. Name, value pair
     depends on type of trigger.
    :vartype properties: dict[str, str]
    :ivar triggered_pipelines: List of pipeline name and run Id triggered by the trigger run.
    :vartype triggered_pipelines: dict[str, str]
    :ivar run_dimension: Run dimension for which trigger was fired.
    :vartype run_dimension: dict[str, str]
    :ivar dependency_status: Status of the upstream pipelines.
    :vartype dependency_status: dict[str, object]
    """

    _validation = {
        'trigger_run_id': {'readonly': True},
        'trigger_name': {'readonly': True},
        'trigger_type': {'readonly': True},
        'trigger_run_timestamp': {'readonly': True},
        'status': {'readonly': True},
        'message': {'readonly': True},
        'properties': {'readonly': True},
        'triggered_pipelines': {'readonly': True},
        'run_dimension': {'readonly': True},
        'dependency_status': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'trigger_run_id': {'key': 'triggerRunId', 'type': 'str'},
        'trigger_name': {'key': 'triggerName', 'type': 'str'},
        'trigger_type': {'key': 'triggerType', 'type': 'str'},
        'trigger_run_timestamp': {'key': 'triggerRunTimestamp', 'type': 'iso-8601'},
        'status': {'key': 'status', 'type': 'str'},
        'message': {'key': 'message', 'type': 'str'},
        'properties': {'key': 'properties', 'type': '{str}'},
        'triggered_pipelines': {'key': 'triggeredPipelines', 'type': '{str}'},
        'run_dimension': {'key': 'runDimension', 'type': '{str}'},
        'dependency_status': {'key': 'dependencyStatus', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        **kwargs
    ):
        super(TriggerRun, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.trigger_run_id = None
        self.trigger_name = None
        self.trigger_type = None
        self.trigger_run_timestamp = None
        self.status = None
        self.message = None
        self.properties = None
        self.triggered_pipelines = None
        self.run_dimension = None
        self.dependency_status = None


class TriggerRunsQueryResponse(msrest.serialization.Model):
    """A list of trigger runs.

    All required parameters must be populated in order to send to Azure.

    :param value: Required. List of trigger runs.
    :type value: list[~data_factory_management_client.models.TriggerRun]
    :param continuation_token: The continuation token for getting the next page of results, if any
     remaining results exist, null otherwise.
    :type continuation_token: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[TriggerRun]'},
        'continuation_token': {'key': 'continuationToken', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["TriggerRun"],
        continuation_token: Optional[str] = None,
        **kwargs
    ):
        super(TriggerRunsQueryResponse, self).__init__(**kwargs)
        self.value = value
        self.continuation_token = continuation_token


class TriggerSubscriptionOperationStatus(msrest.serialization.Model):
    """Defines the response of a trigger subscription operation.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar trigger_name: Trigger name.
    :vartype trigger_name: str
    :ivar status: Event Subscription Status. Possible values include: 'Enabled', 'Provisioning',
     'Deprovisioning', 'Disabled', 'Unknown'.
    :vartype status: str or ~data_factory_management_client.models.EventSubscriptionStatus
    """

    _validation = {
        'trigger_name': {'readonly': True},
        'status': {'readonly': True},
    }

    _attribute_map = {
        'trigger_name': {'key': 'triggerName', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TriggerSubscriptionOperationStatus, self).__init__(**kwargs)
        self.trigger_name = None
        self.status = None


class TumblingWindowTrigger(Trigger):
    """Trigger that schedules pipeline runs for all fixed time interval windows from a start time without gaps and also supports backfill scenarios (when start time is in the past).

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Trigger type.Constant filled by server.
    :type type: str
    :param description: Trigger description.
    :type description: str
    :ivar runtime_state: Enumerates possible state of Triggers. Possible values include: 'Started',
     'Stopped', 'Disabled'.
    :vartype runtime_state: str or ~data_factory_management_client.models.TriggerRuntimeState
    :param annotations: List of tags that can be used for describing the trigger.
    :type annotations: list[~data_factory_management_client.models.TriggerAnnotationsItem]
    :param pipeline: Required. Pipeline that needs to be triggered with the given parameters.
    :type pipeline: ~data_factory_management_client.models.TriggerPipelineReference
    :param frequency: Required. Enumerates possible frequency option for the tumbling window
     trigger. Possible values include: 'Minute', 'Hour'.
    :type frequency: str or ~data_factory_management_client.models.TumblingWindowFrequency
    :param interval: Required. The interval of the time windows. The minimum interval allowed is 15
     Minutes.
    :type interval: int
    :param start_time: Required. The start time for the time period for the trigger during which
     events are fired for windows that are ready. Only UTC time is currently supported.
    :type start_time: ~datetime.datetime
    :param end_time: The end time for the time period for the trigger during which events are fired
     for windows that are ready. Only UTC time is currently supported.
    :type end_time: ~datetime.datetime
    :param delay: Specifies how long the trigger waits past due time before triggering new run. It
     doesn't alter window start and end time. The default is 0. Type: string (or Expression with
     resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type delay: ~data_factory_management_client.models.TumblingWindowTriggerTypePropertiesDelay
    :param max_concurrency: Required. The max number of parallel time windows (ready for execution)
     for which a new run is triggered.
    :type max_concurrency: int
    :param retry_policy: Execution policy for an activity.
    :type retry_policy: ~data_factory_management_client.models.RetryPolicy
    :param depends_on: Triggers that this trigger depends on. Only tumbling window triggers are
     supported.
    :type depends_on: list[~data_factory_management_client.models.DependencyReference]
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
        'pipeline': {'required': True},
        'frequency': {'required': True},
        'interval': {'required': True},
        'start_time': {'required': True},
        'max_concurrency': {'required': True, 'maximum': 50, 'minimum': 1},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[TriggerAnnotationsItem]'},
        'pipeline': {'key': 'pipeline', 'type': 'TriggerPipelineReference'},
        'frequency': {'key': 'typeProperties.frequency', 'type': 'str'},
        'interval': {'key': 'typeProperties.interval', 'type': 'int'},
        'start_time': {'key': 'typeProperties.startTime', 'type': 'iso-8601'},
        'end_time': {'key': 'typeProperties.endTime', 'type': 'iso-8601'},
        'delay': {'key': 'typeProperties.delay', 'type': 'TumblingWindowTriggerTypePropertiesDelay'},
        'max_concurrency': {'key': 'typeProperties.maxConcurrency', 'type': 'int'},
        'retry_policy': {'key': 'typeProperties.retryPolicy', 'type': 'RetryPolicy'},
        'depends_on': {'key': 'typeProperties.dependsOn', 'type': '[DependencyReference]'},
    }

    def __init__(
        self,
        *,
        pipeline: "TriggerPipelineReference",
        frequency: Union[str, "TumblingWindowFrequency"],
        interval: int,
        start_time: datetime.datetime,
        max_concurrency: int,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        annotations: Optional[List["TriggerAnnotationsItem"]] = None,
        end_time: Optional[datetime.datetime] = None,
        delay: Optional["TumblingWindowTriggerTypePropertiesDelay"] = None,
        retry_policy: Optional["RetryPolicy"] = None,
        depends_on: Optional[List["DependencyReference"]] = None,
        **kwargs
    ):
        super(TumblingWindowTrigger, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, **kwargs)
        self.type = 'TumblingWindowTrigger'
        self.pipeline = pipeline
        self.frequency = frequency
        self.interval = interval
        self.start_time = start_time
        self.end_time = end_time
        self.delay = delay
        self.max_concurrency = max_concurrency
        self.retry_policy = retry_policy
        self.depends_on = depends_on


class TumblingWindowTriggerDependencyReference(TriggerDependencyReference):
    """Referenced tumbling window trigger dependency.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. The type of dependency reference.Constant filled by server.
    :type type: str
    :param reference_trigger: Required. Trigger reference type.
    :type reference_trigger: ~data_factory_management_client.models.TriggerReference
    :param offset: Timespan applied to the start time of a tumbling window when evaluating
     dependency.
    :type offset: str
    :param size: The size of the window when evaluating the dependency. If undefined the frequency
     of the tumbling window will be used.
    :type size: str
    """

    _validation = {
        'type': {'required': True},
        'reference_trigger': {'required': True},
        'offset': {'max_length': 15, 'min_length': 8, 'pattern': '-?((\\d+)\\.)?(\\d\\d):(60|([0-5][0-9])):(60|([0-5][0-9]))'},
        'size': {'max_length': 15, 'min_length': 8, 'pattern': '((\\d+)\\.)?(\\d\\d):(60|([0-5][0-9])):(60|([0-5][0-9]))'},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_trigger': {'key': 'referenceTrigger', 'type': 'TriggerReference'},
        'offset': {'key': 'offset', 'type': 'str'},
        'size': {'key': 'size', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        reference_trigger: "TriggerReference",
        offset: Optional[str] = None,
        size: Optional[str] = None,
        **kwargs
    ):
        super(TumblingWindowTriggerDependencyReference, self).__init__(reference_trigger=reference_trigger, **kwargs)
        self.type = 'TumblingWindowTriggerDependencyReference'
        self.offset = offset
        self.size = size


class TumblingWindowTriggerTypeProperties(msrest.serialization.Model):
    """Tumbling Window Trigger properties.

    All required parameters must be populated in order to send to Azure.

    :param frequency: Required. Enumerates possible frequency option for the tumbling window
     trigger. Possible values include: 'Minute', 'Hour'.
    :type frequency: str or ~data_factory_management_client.models.TumblingWindowFrequency
    :param interval: Required. The interval of the time windows. The minimum interval allowed is 15
     Minutes.
    :type interval: int
    :param start_time: Required. The start time for the time period for the trigger during which
     events are fired for windows that are ready. Only UTC time is currently supported.
    :type start_time: ~datetime.datetime
    :param end_time: The end time for the time period for the trigger during which events are fired
     for windows that are ready. Only UTC time is currently supported.
    :type end_time: ~datetime.datetime
    :param delay: Specifies how long the trigger waits past due time before triggering new run. It
     doesn't alter window start and end time. The default is 0. Type: string (or Expression with
     resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type delay: ~data_factory_management_client.models.TumblingWindowTriggerTypePropertiesDelay
    :param max_concurrency: Required. The max number of parallel time windows (ready for execution)
     for which a new run is triggered.
    :type max_concurrency: int
    :param retry_policy: Execution policy for an activity.
    :type retry_policy: ~data_factory_management_client.models.RetryPolicy
    :param depends_on: Triggers that this trigger depends on. Only tumbling window triggers are
     supported.
    :type depends_on: list[~data_factory_management_client.models.DependencyReference]
    """

    _validation = {
        'frequency': {'required': True},
        'interval': {'required': True},
        'start_time': {'required': True},
        'max_concurrency': {'required': True, 'maximum': 50, 'minimum': 1},
    }

    _attribute_map = {
        'frequency': {'key': 'frequency', 'type': 'str'},
        'interval': {'key': 'interval', 'type': 'int'},
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'end_time': {'key': 'endTime', 'type': 'iso-8601'},
        'delay': {'key': 'delay', 'type': 'TumblingWindowTriggerTypePropertiesDelay'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'retry_policy': {'key': 'retryPolicy', 'type': 'RetryPolicy'},
        'depends_on': {'key': 'dependsOn', 'type': '[DependencyReference]'},
    }

    def __init__(
        self,
        *,
        frequency: Union[str, "TumblingWindowFrequency"],
        interval: int,
        start_time: datetime.datetime,
        max_concurrency: int,
        end_time: Optional[datetime.datetime] = None,
        delay: Optional["TumblingWindowTriggerTypePropertiesDelay"] = None,
        retry_policy: Optional["RetryPolicy"] = None,
        depends_on: Optional[List["DependencyReference"]] = None,
        **kwargs
    ):
        super(TumblingWindowTriggerTypeProperties, self).__init__(**kwargs)
        self.frequency = frequency
        self.interval = interval
        self.start_time = start_time
        self.end_time = end_time
        self.delay = delay
        self.max_concurrency = max_concurrency
        self.retry_policy = retry_policy
        self.depends_on = depends_on


class TumblingWindowTriggerTypePropertiesDelay(msrest.serialization.Model):
    """Specifies how long the trigger waits past due time before triggering new run. It doesn't alter window start and end time. The default is 0. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(TumblingWindowTriggerTypePropertiesDelay, self).__init__(**kwargs)


class UntilActivity(ControlActivity):
    """This activity executes inner activities until the specified boolean expression results to true or timeout is reached, whichever is earlier.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param expression: Required. Azure Data Factory expression definition.
    :type expression: ~data_factory_management_client.models.Expression
    :param timeout: Specifies the timeout for the activity to run. If there is no value specified,
     it takes the value of TimeSpan.FromDays(7) which is 1 week as default. Type: string (or
     Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])). Type: string (or Expression with
     resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type timeout: ~data_factory_management_client.models.UntilActivityTypePropertiesTimeout
    :param activities: Required. List of activities to execute.
    :type activities: list[~data_factory_management_client.models.Activity]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'expression': {'required': True},
        'activities': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'expression': {'key': 'typeProperties.expression', 'type': 'Expression'},
        'timeout': {'key': 'typeProperties.timeout', 'type': 'UntilActivityTypePropertiesTimeout'},
        'activities': {'key': 'typeProperties.activities', 'type': '[Activity]'},
    }

    def __init__(
        self,
        *,
        name: str,
        expression: "Expression",
        activities: List["Activity"],
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        timeout: Optional["UntilActivityTypePropertiesTimeout"] = None,
        **kwargs
    ):
        super(UntilActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'Until'
        self.expression = expression
        self.timeout = timeout
        self.activities = activities


class UntilActivityTypeProperties(msrest.serialization.Model):
    """Until activity properties.

    All required parameters must be populated in order to send to Azure.

    :param expression: Required. Azure Data Factory expression definition.
    :type expression: ~data_factory_management_client.models.Expression
    :param timeout: Specifies the timeout for the activity to run. If there is no value specified,
     it takes the value of TimeSpan.FromDays(7) which is 1 week as default. Type: string (or
     Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])). Type: string (or Expression with
     resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type timeout: ~data_factory_management_client.models.UntilActivityTypePropertiesTimeout
    :param activities: Required. List of activities to execute.
    :type activities: list[~data_factory_management_client.models.Activity]
    """

    _validation = {
        'expression': {'required': True},
        'activities': {'required': True},
    }

    _attribute_map = {
        'expression': {'key': 'expression', 'type': 'Expression'},
        'timeout': {'key': 'timeout', 'type': 'UntilActivityTypePropertiesTimeout'},
        'activities': {'key': 'activities', 'type': '[Activity]'},
    }

    def __init__(
        self,
        *,
        expression: "Expression",
        activities: List["Activity"],
        timeout: Optional["UntilActivityTypePropertiesTimeout"] = None,
        **kwargs
    ):
        super(UntilActivityTypeProperties, self).__init__(**kwargs)
        self.expression = expression
        self.timeout = timeout
        self.activities = activities


class UntilActivityTypePropertiesTimeout(msrest.serialization.Model):
    """Specifies the timeout for the activity to run. If there is no value specified, it takes the value of TimeSpan.FromDays(7) which is 1 week as default. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])). Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(UntilActivityTypePropertiesTimeout, self).__init__(**kwargs)


class UpdateIntegrationRuntimeNodeRequest(msrest.serialization.Model):
    """Update integration runtime node request.

    :param concurrent_jobs_limit: The number of concurrent jobs permitted to run on the integration
     runtime node. Values between 1 and maxConcurrentJobs(inclusive) are allowed.
    :type concurrent_jobs_limit: int
    """

    _validation = {
        'concurrent_jobs_limit': {'minimum': 1},
    }

    _attribute_map = {
        'concurrent_jobs_limit': {'key': 'concurrentJobsLimit', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        concurrent_jobs_limit: Optional[int] = None,
        **kwargs
    ):
        super(UpdateIntegrationRuntimeNodeRequest, self).__init__(**kwargs)
        self.concurrent_jobs_limit = concurrent_jobs_limit


class UpdateIntegrationRuntimeRequest(msrest.serialization.Model):
    """Update integration runtime request.

    :param auto_update: The state of integration runtime auto update. Possible values include:
     'On', 'Off'.
    :type auto_update: str or ~data_factory_management_client.models.IntegrationRuntimeAutoUpdate
    :param update_delay_offset: The time offset (in hours) in the day, e.g., PT03H is 3 hours. The
     integration runtime auto update will happen on that time.
    :type update_delay_offset: str
    """

    _attribute_map = {
        'auto_update': {'key': 'autoUpdate', 'type': 'str'},
        'update_delay_offset': {'key': 'updateDelayOffset', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        auto_update: Optional[Union[str, "IntegrationRuntimeAutoUpdate"]] = None,
        update_delay_offset: Optional[str] = None,
        **kwargs
    ):
        super(UpdateIntegrationRuntimeRequest, self).__init__(**kwargs)
        self.auto_update = auto_update
        self.update_delay_offset = update_delay_offset


class UserAccessPolicy(msrest.serialization.Model):
    """Get Data Plane read only token request definition.

    :param permissions: The string with permissions for Data Plane access. Currently only 'r' is
     supported which grants read only access.
    :type permissions: str
    :param access_resource_path: The resource path to get access relative to factory. Currently
     only empty string is supported which corresponds to the factory resource.
    :type access_resource_path: str
    :param profile_name: The name of the profile. Currently only the default is supported. The
     default value is DefaultProfile.
    :type profile_name: str
    :param start_time: Start time for the token. If not specified the current time will be used.
    :type start_time: str
    :param expire_time: Expiration time for the token. Maximum duration for the token is eight
     hours and by default the token will expire in eight hours.
    :type expire_time: str
    """

    _attribute_map = {
        'permissions': {'key': 'permissions', 'type': 'str'},
        'access_resource_path': {'key': 'accessResourcePath', 'type': 'str'},
        'profile_name': {'key': 'profileName', 'type': 'str'},
        'start_time': {'key': 'startTime', 'type': 'str'},
        'expire_time': {'key': 'expireTime', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        permissions: Optional[str] = None,
        access_resource_path: Optional[str] = None,
        profile_name: Optional[str] = None,
        start_time: Optional[str] = None,
        expire_time: Optional[str] = None,
        **kwargs
    ):
        super(UserAccessPolicy, self).__init__(**kwargs)
        self.permissions = permissions
        self.access_resource_path = access_resource_path
        self.profile_name = profile_name
        self.start_time = start_time
        self.expire_time = expire_time


class UserProperty(msrest.serialization.Model):
    """User property.

    All required parameters must be populated in order to send to Azure.

    :param name: Required. User property name.
    :type name: str
    :param value: Required. User property value. Type: string (or Expression with resultType
     string).
    :type value: ~data_factory_management_client.models.UserPropertyValue
    """

    _validation = {
        'name': {'required': True},
        'value': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'value': {'key': 'value', 'type': 'UserPropertyValue'},
    }

    def __init__(
        self,
        *,
        name: str,
        value: "UserPropertyValue",
        **kwargs
    ):
        super(UserProperty, self).__init__(**kwargs)
        self.name = name
        self.value = value


class UserPropertyValue(msrest.serialization.Model):
    """User property value. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(UserPropertyValue, self).__init__(**kwargs)


class ValidationActivity(ControlActivity):
    """This activity verifies that an external resource exists.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param timeout: Specifies the timeout for the activity to run. If there is no value specified,
     it takes the value of TimeSpan.FromDays(7) which is 1 week as default. Type: string (or
     Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type timeout: ~data_factory_management_client.models.ValidationActivityTypePropertiesTimeout
    :param sleep: A delay in seconds between validation attempts. If no value is specified, 10
     seconds will be used as the default. Type: integer (or Expression with resultType integer).
    :type sleep: ~data_factory_management_client.models.ValidationActivityTypePropertiesSleep
    :param minimum_size: Can be used if dataset points to a file. The file must be greater than or
     equal in size to the value specified. Type: integer (or Expression with resultType integer).
    :type minimum_size:
     ~data_factory_management_client.models.ValidationActivityTypePropertiesMinimumSize
    :param child_items: Can be used if dataset points to a folder. If set to true, the folder must
     have at least one file. If set to false, the folder must be empty. Type: boolean (or Expression
     with resultType boolean).
    :type child_items:
     ~data_factory_management_client.models.ValidationActivityTypePropertiesChildItems
    :param dataset: Required. Dataset reference type.
    :type dataset: ~data_factory_management_client.models.DatasetReference
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'dataset': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'timeout': {'key': 'typeProperties.timeout', 'type': 'ValidationActivityTypePropertiesTimeout'},
        'sleep': {'key': 'typeProperties.sleep', 'type': 'ValidationActivityTypePropertiesSleep'},
        'minimum_size': {'key': 'typeProperties.minimumSize', 'type': 'ValidationActivityTypePropertiesMinimumSize'},
        'child_items': {'key': 'typeProperties.childItems', 'type': 'ValidationActivityTypePropertiesChildItems'},
        'dataset': {'key': 'typeProperties.dataset', 'type': 'DatasetReference'},
    }

    def __init__(
        self,
        *,
        name: str,
        dataset: "DatasetReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        timeout: Optional["ValidationActivityTypePropertiesTimeout"] = None,
        sleep: Optional["ValidationActivityTypePropertiesSleep"] = None,
        minimum_size: Optional["ValidationActivityTypePropertiesMinimumSize"] = None,
        child_items: Optional["ValidationActivityTypePropertiesChildItems"] = None,
        **kwargs
    ):
        super(ValidationActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'Validation'
        self.timeout = timeout
        self.sleep = sleep
        self.minimum_size = minimum_size
        self.child_items = child_items
        self.dataset = dataset


class ValidationActivityTypeProperties(msrest.serialization.Model):
    """Validation activity properties.

    All required parameters must be populated in order to send to Azure.

    :param timeout: Specifies the timeout for the activity to run. If there is no value specified,
     it takes the value of TimeSpan.FromDays(7) which is 1 week as default. Type: string (or
     Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type timeout: ~data_factory_management_client.models.ValidationActivityTypePropertiesTimeout
    :param sleep: A delay in seconds between validation attempts. If no value is specified, 10
     seconds will be used as the default. Type: integer (or Expression with resultType integer).
    :type sleep: ~data_factory_management_client.models.ValidationActivityTypePropertiesSleep
    :param minimum_size: Can be used if dataset points to a file. The file must be greater than or
     equal in size to the value specified. Type: integer (or Expression with resultType integer).
    :type minimum_size:
     ~data_factory_management_client.models.ValidationActivityTypePropertiesMinimumSize
    :param child_items: Can be used if dataset points to a folder. If set to true, the folder must
     have at least one file. If set to false, the folder must be empty. Type: boolean (or Expression
     with resultType boolean).
    :type child_items:
     ~data_factory_management_client.models.ValidationActivityTypePropertiesChildItems
    :param dataset: Required. Dataset reference type.
    :type dataset: ~data_factory_management_client.models.DatasetReference
    """

    _validation = {
        'dataset': {'required': True},
    }

    _attribute_map = {
        'timeout': {'key': 'timeout', 'type': 'ValidationActivityTypePropertiesTimeout'},
        'sleep': {'key': 'sleep', 'type': 'ValidationActivityTypePropertiesSleep'},
        'minimum_size': {'key': 'minimumSize', 'type': 'ValidationActivityTypePropertiesMinimumSize'},
        'child_items': {'key': 'childItems', 'type': 'ValidationActivityTypePropertiesChildItems'},
        'dataset': {'key': 'dataset', 'type': 'DatasetReference'},
    }

    def __init__(
        self,
        *,
        dataset: "DatasetReference",
        timeout: Optional["ValidationActivityTypePropertiesTimeout"] = None,
        sleep: Optional["ValidationActivityTypePropertiesSleep"] = None,
        minimum_size: Optional["ValidationActivityTypePropertiesMinimumSize"] = None,
        child_items: Optional["ValidationActivityTypePropertiesChildItems"] = None,
        **kwargs
    ):
        super(ValidationActivityTypeProperties, self).__init__(**kwargs)
        self.timeout = timeout
        self.sleep = sleep
        self.minimum_size = minimum_size
        self.child_items = child_items
        self.dataset = dataset


class ValidationActivityTypePropertiesChildItems(msrest.serialization.Model):
    """Can be used if dataset points to a folder. If set to true, the folder must have at least one file. If set to false, the folder must be empty. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ValidationActivityTypePropertiesChildItems, self).__init__(**kwargs)


class ValidationActivityTypePropertiesMinimumSize(msrest.serialization.Model):
    """Can be used if dataset points to a file. The file must be greater than or equal in size to the value specified. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ValidationActivityTypePropertiesMinimumSize, self).__init__(**kwargs)


class ValidationActivityTypePropertiesSleep(msrest.serialization.Model):
    """A delay in seconds between validation attempts. If no value is specified, 10 seconds will be used as the default. Type: integer (or Expression with resultType integer).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ValidationActivityTypePropertiesSleep, self).__init__(**kwargs)


class ValidationActivityTypePropertiesTimeout(msrest.serialization.Model):
    """Specifies the timeout for the activity to run. If there is no value specified, it takes the value of TimeSpan.FromDays(7) which is 1 week as default. Type: string (or Expression with resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ValidationActivityTypePropertiesTimeout, self).__init__(**kwargs)


class VariableSpecification(msrest.serialization.Model):
    """Definition of a single variable for a Pipeline.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. Variable type. Possible values include: 'String', 'Bool', 'Array'.
    :type type: str or ~data_factory_management_client.models.VariableType
    :param default_value: Default value of variable.
    :type default_value: ~data_factory_management_client.models.VariableSpecificationDefaultValue
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'default_value': {'key': 'defaultValue', 'type': 'VariableSpecificationDefaultValue'},
    }

    def __init__(
        self,
        *,
        type: Union[str, "VariableType"],
        default_value: Optional["VariableSpecificationDefaultValue"] = None,
        **kwargs
    ):
        super(VariableSpecification, self).__init__(**kwargs)
        self.type = type
        self.default_value = default_value


class VariableSpecificationDefaultValue(msrest.serialization.Model):
    """Default value of variable.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(VariableSpecificationDefaultValue, self).__init__(**kwargs)


class VerticaDatasetTypeProperties(msrest.serialization.Model):
    """Vertica Properties.

    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.VerticaDatasetTypePropertiesTableName
    :param table: The table name of the Vertica. Type: string (or Expression with resultType
     string).
    :type table: ~data_factory_management_client.models.VerticaDatasetTypePropertiesTable
    :param schema: The schema name of the Vertica. Type: string (or Expression with resultType
     string).
    :type schema: ~data_factory_management_client.models.VerticaDatasetTypePropertiesSchema
    """

    _attribute_map = {
        'table_name': {'key': 'tableName', 'type': 'VerticaDatasetTypePropertiesTableName'},
        'table': {'key': 'table', 'type': 'VerticaDatasetTypePropertiesTable'},
        'schema': {'key': 'schema', 'type': 'VerticaDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        table_name: Optional["VerticaDatasetTypePropertiesTableName"] = None,
        table: Optional["VerticaDatasetTypePropertiesTable"] = None,
        schema: Optional["VerticaDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(VerticaDatasetTypeProperties, self).__init__(**kwargs)
        self.table_name = table_name
        self.table = table
        self.schema = schema


class VerticaDatasetTypePropertiesSchema(msrest.serialization.Model):
    """The schema name of the Vertica. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(VerticaDatasetTypePropertiesSchema, self).__init__(**kwargs)


class VerticaDatasetTypePropertiesTable(msrest.serialization.Model):
    """The table name of the Vertica. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(VerticaDatasetTypePropertiesTable, self).__init__(**kwargs)


class VerticaDatasetTypePropertiesTableName(msrest.serialization.Model):
    """This property will be retired. Please consider using schema + table properties instead.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(VerticaDatasetTypePropertiesTableName, self).__init__(**kwargs)


class VerticaLinkedService(LinkedService):
    """Vertica linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.VerticaLinkedServiceTypePropertiesConnectionString
    :param pwd: Azure Key Vault secret reference.
    :type pwd: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.VerticaLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'VerticaLinkedServiceTypePropertiesConnectionString'},
        'pwd': {'key': 'typeProperties.pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'VerticaLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        connection_string: Optional["VerticaLinkedServiceTypePropertiesConnectionString"] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["VerticaLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(VerticaLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Vertica'
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class VerticaLinkedServiceTypeProperties(msrest.serialization.Model):
    """Vertica linked service properties.

    :param connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :type connection_string:
     ~data_factory_management_client.models.VerticaLinkedServiceTypePropertiesConnectionString
    :param pwd: Azure Key Vault secret reference.
    :type pwd: ~data_factory_management_client.models.AzureKeyVaultSecretReference
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.VerticaLinkedServiceTypePropertiesEncryptedCredential
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'VerticaLinkedServiceTypePropertiesConnectionString'},
        'pwd': {'key': 'pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'VerticaLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional["VerticaLinkedServiceTypePropertiesConnectionString"] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional["VerticaLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(VerticaLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class VerticaLinkedServiceTypePropertiesConnectionString(msrest.serialization.Model):
    """An ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(VerticaLinkedServiceTypePropertiesConnectionString, self).__init__(**kwargs)


class VerticaLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(VerticaLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class VerticaSource(TabularSource):
    """A copy activity Vertica source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.VerticaSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'VerticaSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["VerticaSourceQuery"] = None,
        **kwargs
    ):
        super(VerticaSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'VerticaSource'
        self.query = query


class VerticaSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(VerticaSourceQuery, self).__init__(**kwargs)


class VerticaTableDataset(Dataset):
    """Vertica dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :type table_name: ~data_factory_management_client.models.VerticaDatasetTypePropertiesTableName
    :param table: The table name of the Vertica. Type: string (or Expression with resultType
     string).
    :type table: ~data_factory_management_client.models.VerticaDatasetTypePropertiesTable
    :param schema_type_properties_schema: The schema name of the Vertica. Type: string (or
     Expression with resultType string).
    :type schema_type_properties_schema:
     ~data_factory_management_client.models.VerticaDatasetTypePropertiesSchema
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'VerticaDatasetTypePropertiesTableName'},
        'table': {'key': 'typeProperties.table', 'type': 'VerticaDatasetTypePropertiesTable'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'VerticaDatasetTypePropertiesSchema'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["VerticaDatasetTypePropertiesTableName"] = None,
        table: Optional["VerticaDatasetTypePropertiesTable"] = None,
        schema_type_properties_schema: Optional["VerticaDatasetTypePropertiesSchema"] = None,
        **kwargs
    ):
        super(VerticaTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'VerticaTable'
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class WaitActivity(ControlActivity):
    """This activity suspends pipeline execution for the specified interval.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param wait_time_in_seconds: Required. Duration in seconds.
    :type wait_time_in_seconds: int
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'wait_time_in_seconds': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'wait_time_in_seconds': {'key': 'typeProperties.waitTimeInSeconds', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        name: str,
        wait_time_in_seconds: int,
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        **kwargs
    ):
        super(WaitActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'Wait'
        self.wait_time_in_seconds = wait_time_in_seconds


class WaitActivityTypeProperties(msrest.serialization.Model):
    """Wait activity properties.

    All required parameters must be populated in order to send to Azure.

    :param wait_time_in_seconds: Required. Duration in seconds.
    :type wait_time_in_seconds: int
    """

    _validation = {
        'wait_time_in_seconds': {'required': True},
    }

    _attribute_map = {
        'wait_time_in_seconds': {'key': 'waitTimeInSeconds', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        wait_time_in_seconds: int,
        **kwargs
    ):
        super(WaitActivityTypeProperties, self).__init__(**kwargs)
        self.wait_time_in_seconds = wait_time_in_seconds


class WebActivity(ExecutionActivity):
    """Web activity.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :param linked_service_name: Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param policy: Execution policy for an activity.
    :type policy: ~data_factory_management_client.models.ActivityPolicy
    :param method: Required. The list of HTTP methods supported by a WebActivity. Possible values
     include: 'GET', 'POST', 'PUT', 'DELETE'.
    :type method: str or ~data_factory_management_client.models.WebActivityMethod
    :param url: Required. Web activity target endpoint and path. Type: string (or Expression with
     resultType string).
    :type url: ~data_factory_management_client.models.WebActivityTypePropertiesUrl
    :param headers: Represents the headers that will be sent to the request. For example, to set
     the language and type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type":
     "application/json" }. Type: string (or Expression with resultType string).
    :type headers: ~data_factory_management_client.models.WebActivityTypePropertiesHeaders
    :param body: Represents the payload that will be sent to the endpoint. Required for POST/PUT
     method, not allowed for GET method Type: string (or Expression with resultType string).
    :type body: ~data_factory_management_client.models.WebActivityTypePropertiesBody
    :param authentication: Web activity authentication properties.
    :type authentication: ~data_factory_management_client.models.WebActivityAuthentication
    :param datasets: List of datasets passed to web endpoint.
    :type datasets: list[~data_factory_management_client.models.DatasetReference]
    :param linked_services: List of linked services passed to web endpoint.
    :type linked_services: list[~data_factory_management_client.models.LinkedServiceReference]
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'method': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'method': {'key': 'typeProperties.method', 'type': 'str'},
        'url': {'key': 'typeProperties.url', 'type': 'WebActivityTypePropertiesUrl'},
        'headers': {'key': 'typeProperties.headers', 'type': 'WebActivityTypePropertiesHeaders'},
        'body': {'key': 'typeProperties.body', 'type': 'WebActivityTypePropertiesBody'},
        'authentication': {'key': 'typeProperties.authentication', 'type': 'WebActivityAuthentication'},
        'datasets': {'key': 'typeProperties.datasets', 'type': '[DatasetReference]'},
        'linked_services': {'key': 'typeProperties.linkedServices', 'type': '[LinkedServiceReference]'},
        'connect_via': {'key': 'typeProperties.connectVia', 'type': 'IntegrationRuntimeReference'},
    }

    def __init__(
        self,
        *,
        name: str,
        method: Union[str, "WebActivityMethod"],
        url: "WebActivityTypePropertiesUrl",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        headers: Optional["WebActivityTypePropertiesHeaders"] = None,
        body: Optional["WebActivityTypePropertiesBody"] = None,
        authentication: Optional["WebActivityAuthentication"] = None,
        datasets: Optional[List["DatasetReference"]] = None,
        linked_services: Optional[List["LinkedServiceReference"]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        **kwargs
    ):
        super(WebActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'WebActivity'
        self.method = method
        self.url = url
        self.headers = headers
        self.body = body
        self.authentication = authentication
        self.datasets = datasets
        self.linked_services = linked_services
        self.connect_via = connect_via


class WebActivityAuthentication(msrest.serialization.Model):
    """Web activity authentication properties.

    All required parameters must be populated in order to send to Azure.

    :param type: Required. Web activity authentication (Basic/ClientCertificate/MSI).
    :type type: str
    :param pfx: The base definition of a secret type.
    :type pfx: ~data_factory_management_client.models.SecretBase
    :param username: Web activity authentication user name for basic authentication.
    :type username: str
    :param password: The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    :param resource: Resource for which Azure Auth token will be requested when using MSI
     Authentication.
    :type resource: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'pfx': {'key': 'pfx', 'type': 'SecretBase'},
        'username': {'key': 'username', 'type': 'str'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'resource': {'key': 'resource', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        type: str,
        pfx: Optional["SecretBase"] = None,
        username: Optional[str] = None,
        password: Optional["SecretBase"] = None,
        resource: Optional[str] = None,
        **kwargs
    ):
        super(WebActivityAuthentication, self).__init__(**kwargs)
        self.type = type
        self.pfx = pfx
        self.username = username
        self.password = password
        self.resource = resource


class WebActivityTypeProperties(msrest.serialization.Model):
    """Web activity type properties.

    All required parameters must be populated in order to send to Azure.

    :param method: Required. The list of HTTP methods supported by a WebActivity. Possible values
     include: 'GET', 'POST', 'PUT', 'DELETE'.
    :type method: str or ~data_factory_management_client.models.WebActivityMethod
    :param url: Required. Web activity target endpoint and path. Type: string (or Expression with
     resultType string).
    :type url: ~data_factory_management_client.models.WebActivityTypePropertiesUrl
    :param headers: Represents the headers that will be sent to the request. For example, to set
     the language and type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type":
     "application/json" }. Type: string (or Expression with resultType string).
    :type headers: ~data_factory_management_client.models.WebActivityTypePropertiesHeaders
    :param body: Represents the payload that will be sent to the endpoint. Required for POST/PUT
     method, not allowed for GET method Type: string (or Expression with resultType string).
    :type body: ~data_factory_management_client.models.WebActivityTypePropertiesBody
    :param authentication: Web activity authentication properties.
    :type authentication: ~data_factory_management_client.models.WebActivityAuthentication
    :param datasets: List of datasets passed to web endpoint.
    :type datasets: list[~data_factory_management_client.models.DatasetReference]
    :param linked_services: List of linked services passed to web endpoint.
    :type linked_services: list[~data_factory_management_client.models.LinkedServiceReference]
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    """

    _validation = {
        'method': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'method': {'key': 'method', 'type': 'str'},
        'url': {'key': 'url', 'type': 'WebActivityTypePropertiesUrl'},
        'headers': {'key': 'headers', 'type': 'WebActivityTypePropertiesHeaders'},
        'body': {'key': 'body', 'type': 'WebActivityTypePropertiesBody'},
        'authentication': {'key': 'authentication', 'type': 'WebActivityAuthentication'},
        'datasets': {'key': 'datasets', 'type': '[DatasetReference]'},
        'linked_services': {'key': 'linkedServices', 'type': '[LinkedServiceReference]'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
    }

    def __init__(
        self,
        *,
        method: Union[str, "WebActivityMethod"],
        url: "WebActivityTypePropertiesUrl",
        headers: Optional["WebActivityTypePropertiesHeaders"] = None,
        body: Optional["WebActivityTypePropertiesBody"] = None,
        authentication: Optional["WebActivityAuthentication"] = None,
        datasets: Optional[List["DatasetReference"]] = None,
        linked_services: Optional[List["LinkedServiceReference"]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        **kwargs
    ):
        super(WebActivityTypeProperties, self).__init__(**kwargs)
        self.method = method
        self.url = url
        self.headers = headers
        self.body = body
        self.authentication = authentication
        self.datasets = datasets
        self.linked_services = linked_services
        self.connect_via = connect_via


class WebActivityTypePropertiesBody(msrest.serialization.Model):
    """Represents the payload that will be sent to the endpoint. Required for POST/PUT method, not allowed for GET method Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(WebActivityTypePropertiesBody, self).__init__(**kwargs)


class WebActivityTypePropertiesHeaders(msrest.serialization.Model):
    """Represents the headers that will be sent to the request. For example, to set the language and type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type": "application/json" }. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(WebActivityTypePropertiesHeaders, self).__init__(**kwargs)


class WebActivityTypePropertiesUrl(msrest.serialization.Model):
    """Web activity target endpoint and path. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(WebActivityTypePropertiesUrl, self).__init__(**kwargs)


class WebLinkedServiceTypeProperties(msrest.serialization.Model):
    """Base definition of WebLinkedServiceTypeProperties, this typeProperties is polymorphic based on authenticationType, so not flattened in SDK models.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: WebAnonymousAuthentication, WebBasicAuthentication, WebClientCertificateAuthentication.

    All required parameters must be populated in order to send to Azure.

    :param url: Required. The URL of the web service endpoint, e.g. http://www.microsoft.com .
     Type: string (or Expression with resultType string).
    :type url: ~data_factory_management_client.models.WebLinkedServiceTypePropertiesUrl
    :param authentication_type: Required. Type of authentication used to connect to the web table
     source.Constant filled by server.  Possible values include: 'Basic', 'Anonymous',
     'ClientCertificate'.
    :type authentication_type: str or ~data_factory_management_client.models.WebAuthenticationType
    """

    _validation = {
        'url': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'WebLinkedServiceTypePropertiesUrl'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
    }

    _subtype_map = {
        'authentication_type': {'Anonymous': 'WebAnonymousAuthentication', 'Basic': 'WebBasicAuthentication', 'ClientCertificate': 'WebClientCertificateAuthentication'}
    }

    def __init__(
        self,
        *,
        url: "WebLinkedServiceTypePropertiesUrl",
        **kwargs
    ):
        super(WebLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.url = url
        self.authentication_type = None


class WebAnonymousAuthentication(WebLinkedServiceTypeProperties):
    """A WebLinkedService that uses anonymous authentication to communicate with an HTTP endpoint.

    All required parameters must be populated in order to send to Azure.

    :param url: Required. The URL of the web service endpoint, e.g. http://www.microsoft.com .
     Type: string (or Expression with resultType string).
    :type url: ~data_factory_management_client.models.WebLinkedServiceTypePropertiesUrl
    :param authentication_type: Required. Type of authentication used to connect to the web table
     source.Constant filled by server.  Possible values include: 'Basic', 'Anonymous',
     'ClientCertificate'.
    :type authentication_type: str or ~data_factory_management_client.models.WebAuthenticationType
    """

    _validation = {
        'url': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'WebLinkedServiceTypePropertiesUrl'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        url: "WebLinkedServiceTypePropertiesUrl",
        **kwargs
    ):
        super(WebAnonymousAuthentication, self).__init__(url=url, **kwargs)
        self.authentication_type = 'Anonymous'


class WebBasicAuthentication(WebLinkedServiceTypeProperties):
    """A WebLinkedService that uses basic authentication to communicate with an HTTP endpoint.

    All required parameters must be populated in order to send to Azure.

    :param url: Required. The URL of the web service endpoint, e.g. http://www.microsoft.com .
     Type: string (or Expression with resultType string).
    :type url: ~data_factory_management_client.models.WebLinkedServiceTypePropertiesUrl
    :param authentication_type: Required. Type of authentication used to connect to the web table
     source.Constant filled by server.  Possible values include: 'Basic', 'Anonymous',
     'ClientCertificate'.
    :type authentication_type: str or ~data_factory_management_client.models.WebAuthenticationType
    :param username: Required. User name for Basic authentication. Type: string (or Expression with
     resultType string).
    :type username: ~data_factory_management_client.models.WebBasicAuthenticationUsername
    :param password: Required. The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    """

    _validation = {
        'url': {'required': True},
        'authentication_type': {'required': True},
        'username': {'required': True},
        'password': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'WebLinkedServiceTypePropertiesUrl'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'username': {'key': 'username', 'type': 'WebBasicAuthenticationUsername'},
        'password': {'key': 'password', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        url: "WebLinkedServiceTypePropertiesUrl",
        username: "WebBasicAuthenticationUsername",
        password: "SecretBase",
        **kwargs
    ):
        super(WebBasicAuthentication, self).__init__(url=url, **kwargs)
        self.authentication_type = 'Basic'
        self.username = username
        self.password = password


class WebBasicAuthenticationUsername(msrest.serialization.Model):
    """User name for Basic authentication. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(WebBasicAuthenticationUsername, self).__init__(**kwargs)


class WebClientCertificateAuthentication(WebLinkedServiceTypeProperties):
    """A WebLinkedService that uses client certificate based authentication to communicate with an HTTP endpoint. This scheme follows mutual authentication; the server must also provide valid credentials to the client.

    All required parameters must be populated in order to send to Azure.

    :param url: Required. The URL of the web service endpoint, e.g. http://www.microsoft.com .
     Type: string (or Expression with resultType string).
    :type url: ~data_factory_management_client.models.WebLinkedServiceTypePropertiesUrl
    :param authentication_type: Required. Type of authentication used to connect to the web table
     source.Constant filled by server.  Possible values include: 'Basic', 'Anonymous',
     'ClientCertificate'.
    :type authentication_type: str or ~data_factory_management_client.models.WebAuthenticationType
    :param pfx: Required. The base definition of a secret type.
    :type pfx: ~data_factory_management_client.models.SecretBase
    :param password: Required. The base definition of a secret type.
    :type password: ~data_factory_management_client.models.SecretBase
    """

    _validation = {
        'url': {'required': True},
        'authentication_type': {'required': True},
        'pfx': {'required': True},
        'password': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'WebLinkedServiceTypePropertiesUrl'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'pfx': {'key': 'pfx', 'type': 'SecretBase'},
        'password': {'key': 'password', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        url: "WebLinkedServiceTypePropertiesUrl",
        pfx: "SecretBase",
        password: "SecretBase",
        **kwargs
    ):
        super(WebClientCertificateAuthentication, self).__init__(url=url, **kwargs)
        self.authentication_type = 'ClientCertificate'
        self.pfx = pfx
        self.password = password


class WebHookActivity(ControlActivity):
    """WebHook activity.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param name: Required. Activity name.
    :type name: str
    :param type: Required. Type of activity.Constant filled by server.
    :type type: str
    :param description: Activity description.
    :type description: str
    :param depends_on: Activity depends on condition.
    :type depends_on: list[~data_factory_management_client.models.ActivityDependency]
    :param user_properties: Activity user properties.
    :type user_properties: list[~data_factory_management_client.models.UserProperty]
    :ivar method: Required. The list of HTTP methods supported by a WebHook activity. Default
     value: "POST".
    :vartype method: str
    :param url: Required. WebHook activity target endpoint and path. Type: string (or Expression
     with resultType string).
    :type url: ~data_factory_management_client.models.WebHookActivityTypePropertiesUrl
    :param timeout: The timeout within which the webhook should be called back. If there is no
     value specified, it defaults to 10 minutes. Type: string. Pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type timeout: str
    :param headers: Represents the headers that will be sent to the request. For example, to set
     the language and type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type":
     "application/json" }. Type: string (or Expression with resultType string).
    :type headers: ~data_factory_management_client.models.WebHookActivityTypePropertiesHeaders
    :param body: Represents the payload that will be sent to the endpoint. Required for POST/PUT
     method, not allowed for GET method Type: string (or Expression with resultType string).
    :type body: ~data_factory_management_client.models.WebHookActivityTypePropertiesBody
    :param authentication: Web activity authentication properties.
    :type authentication: ~data_factory_management_client.models.WebActivityAuthentication
    :param report_status_on_call_back: When set to true,
     statusCode, output and error in callback request body will be
     consumed by activity. The activity can be marked as failed by setting statusCode >= 400 in
     callback request. Default is false. Type: boolean (or Expression with resultType boolean).
    :type report_status_on_call_back:
     ~data_factory_management_client.models.WebHookActivityTypePropertiesReportStatusOnCallBack
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'method': {'required': True, 'constant': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'method': {'key': 'typeProperties.method', 'type': 'str'},
        'url': {'key': 'typeProperties.url', 'type': 'WebHookActivityTypePropertiesUrl'},
        'timeout': {'key': 'typeProperties.timeout', 'type': 'str'},
        'headers': {'key': 'typeProperties.headers', 'type': 'WebHookActivityTypePropertiesHeaders'},
        'body': {'key': 'typeProperties.body', 'type': 'WebHookActivityTypePropertiesBody'},
        'authentication': {'key': 'typeProperties.authentication', 'type': 'WebActivityAuthentication'},
        'report_status_on_call_back': {'key': 'typeProperties.reportStatusOnCallBack', 'type': 'WebHookActivityTypePropertiesReportStatusOnCallBack'},
    }

    method = "POST"

    def __init__(
        self,
        *,
        name: str,
        url: "WebHookActivityTypePropertiesUrl",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        timeout: Optional[str] = None,
        headers: Optional["WebHookActivityTypePropertiesHeaders"] = None,
        body: Optional["WebHookActivityTypePropertiesBody"] = None,
        authentication: Optional["WebActivityAuthentication"] = None,
        report_status_on_call_back: Optional["WebHookActivityTypePropertiesReportStatusOnCallBack"] = None,
        **kwargs
    ):
        super(WebHookActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'WebHook'
        self.url = url
        self.timeout = timeout
        self.headers = headers
        self.body = body
        self.authentication = authentication
        self.report_status_on_call_back = report_status_on_call_back


class WebHookActivityTypeProperties(msrest.serialization.Model):
    """WebHook activity type properties.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar method: Required. The list of HTTP methods supported by a WebHook activity. Default
     value: "POST".
    :vartype method: str
    :param url: Required. WebHook activity target endpoint and path. Type: string (or Expression
     with resultType string).
    :type url: ~data_factory_management_client.models.WebHookActivityTypePropertiesUrl
    :param timeout: The timeout within which the webhook should be called back. If there is no
     value specified, it defaults to 10 minutes. Type: string. Pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type timeout: str
    :param headers: Represents the headers that will be sent to the request. For example, to set
     the language and type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type":
     "application/json" }. Type: string (or Expression with resultType string).
    :type headers: ~data_factory_management_client.models.WebHookActivityTypePropertiesHeaders
    :param body: Represents the payload that will be sent to the endpoint. Required for POST/PUT
     method, not allowed for GET method Type: string (or Expression with resultType string).
    :type body: ~data_factory_management_client.models.WebHookActivityTypePropertiesBody
    :param authentication: Web activity authentication properties.
    :type authentication: ~data_factory_management_client.models.WebActivityAuthentication
    :param report_status_on_call_back: When set to true,
     statusCode, output and error in callback request body will be
     consumed by activity. The activity can be marked as failed by setting statusCode >= 400 in
     callback request. Default is false. Type: boolean (or Expression with resultType boolean).
    :type report_status_on_call_back:
     ~data_factory_management_client.models.WebHookActivityTypePropertiesReportStatusOnCallBack
    """

    _validation = {
        'method': {'required': True, 'constant': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'method': {'key': 'method', 'type': 'str'},
        'url': {'key': 'url', 'type': 'WebHookActivityTypePropertiesUrl'},
        'timeout': {'key': 'timeout', 'type': 'str'},
        'headers': {'key': 'headers', 'type': 'WebHookActivityTypePropertiesHeaders'},
        'body': {'key': 'body', 'type': 'WebHookActivityTypePropertiesBody'},
        'authentication': {'key': 'authentication', 'type': 'WebActivityAuthentication'},
        'report_status_on_call_back': {'key': 'reportStatusOnCallBack', 'type': 'WebHookActivityTypePropertiesReportStatusOnCallBack'},
    }

    method = "POST"

    def __init__(
        self,
        *,
        url: "WebHookActivityTypePropertiesUrl",
        timeout: Optional[str] = None,
        headers: Optional["WebHookActivityTypePropertiesHeaders"] = None,
        body: Optional["WebHookActivityTypePropertiesBody"] = None,
        authentication: Optional["WebActivityAuthentication"] = None,
        report_status_on_call_back: Optional["WebHookActivityTypePropertiesReportStatusOnCallBack"] = None,
        **kwargs
    ):
        super(WebHookActivityTypeProperties, self).__init__(**kwargs)
        self.url = url
        self.timeout = timeout
        self.headers = headers
        self.body = body
        self.authentication = authentication
        self.report_status_on_call_back = report_status_on_call_back


class WebHookActivityTypePropertiesBody(msrest.serialization.Model):
    """Represents the payload that will be sent to the endpoint. Required for POST/PUT method, not allowed for GET method Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(WebHookActivityTypePropertiesBody, self).__init__(**kwargs)


class WebHookActivityTypePropertiesHeaders(msrest.serialization.Model):
    """Represents the headers that will be sent to the request. For example, to set the language and type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type": "application/json" }. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(WebHookActivityTypePropertiesHeaders, self).__init__(**kwargs)


class WebHookActivityTypePropertiesReportStatusOnCallBack(msrest.serialization.Model):
    """When set to true, statusCode, output and error in callback request body will be consumed by activity. The activity can be marked as failed by setting statusCode >= 400 in callback request. Default is false. Type: boolean (or Expression with resultType boolean).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(WebHookActivityTypePropertiesReportStatusOnCallBack, self).__init__(**kwargs)


class WebHookActivityTypePropertiesUrl(msrest.serialization.Model):
    """WebHook activity target endpoint and path. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(WebHookActivityTypePropertiesUrl, self).__init__(**kwargs)


class WebLinkedService(LinkedService):
    """Web linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param type_properties: Required. Base definition of WebLinkedServiceTypeProperties, this
     typeProperties is polymorphic based on authenticationType, so not flattened in SDK models.
    :type type_properties: ~data_factory_management_client.models.WebLinkedServiceTypeProperties
    """

    _validation = {
        'type': {'required': True},
        'type_properties': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'type_properties': {'key': 'typeProperties', 'type': 'WebLinkedServiceTypeProperties'},
    }

    def __init__(
        self,
        *,
        type_properties: "WebLinkedServiceTypeProperties",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        **kwargs
    ):
        super(WebLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Web'
        self.type_properties = type_properties


class WebLinkedServiceTypePropertiesUrl(msrest.serialization.Model):
    """The URL of the web service endpoint, e.g. http://www.microsoft.com . Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(WebLinkedServiceTypePropertiesUrl, self).__init__(**kwargs)


class WebSource(CopySource):
    """A copy activity source for web page table.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        **kwargs
    ):
        super(WebSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, **kwargs)
        self.type = 'WebSource'
        self.additional_columns = additional_columns


class WebTableDataset(Dataset):
    """The dataset points to a HTML table in the web page.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param index: Required. The zero-based index of the table in the web page. Type: integer (or
     Expression with resultType integer), minimum: 0.
    :type index: ~data_factory_management_client.models.WebTableDatasetTypePropertiesIndex
    :param path: The relative URL to the web page from the linked service URL. Type: string (or
     Expression with resultType string).
    :type path: ~data_factory_management_client.models.WebTableDatasetTypePropertiesPath
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'index': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'index': {'key': 'typeProperties.index', 'type': 'WebTableDatasetTypePropertiesIndex'},
        'path': {'key': 'typeProperties.path', 'type': 'WebTableDatasetTypePropertiesPath'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        index: "WebTableDatasetTypePropertiesIndex",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        path: Optional["WebTableDatasetTypePropertiesPath"] = None,
        **kwargs
    ):
        super(WebTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'WebTable'
        self.index = index
        self.path = path


class WebTableDatasetTypeProperties(msrest.serialization.Model):
    """Web table dataset properties.

    All required parameters must be populated in order to send to Azure.

    :param index: Required. The zero-based index of the table in the web page. Type: integer (or
     Expression with resultType integer), minimum: 0.
    :type index: ~data_factory_management_client.models.WebTableDatasetTypePropertiesIndex
    :param path: The relative URL to the web page from the linked service URL. Type: string (or
     Expression with resultType string).
    :type path: ~data_factory_management_client.models.WebTableDatasetTypePropertiesPath
    """

    _validation = {
        'index': {'required': True},
    }

    _attribute_map = {
        'index': {'key': 'index', 'type': 'WebTableDatasetTypePropertiesIndex'},
        'path': {'key': 'path', 'type': 'WebTableDatasetTypePropertiesPath'},
    }

    def __init__(
        self,
        *,
        index: "WebTableDatasetTypePropertiesIndex",
        path: Optional["WebTableDatasetTypePropertiesPath"] = None,
        **kwargs
    ):
        super(WebTableDatasetTypeProperties, self).__init__(**kwargs)
        self.index = index
        self.path = path


class WebTableDatasetTypePropertiesIndex(msrest.serialization.Model):
    """The zero-based index of the table in the web page. Type: integer (or Expression with resultType integer), minimum: 0.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(WebTableDatasetTypePropertiesIndex, self).__init__(**kwargs)


class WebTableDatasetTypePropertiesPath(msrest.serialization.Model):
    """The relative URL to the web page from the linked service URL. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(WebTableDatasetTypePropertiesPath, self).__init__(**kwargs)


class XeroLinkedService(LinkedService):
    """Xero Service linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param host: Required. The endpoint of the Xero server. (i.e. api.xero.com).
    :type host: ~data_factory_management_client.models.XeroLinkedServiceTypePropertiesHost
    :param consumer_key: The base definition of a secret type.
    :type consumer_key: ~data_factory_management_client.models.SecretBase
    :param private_key: The base definition of a secret type.
    :type private_key: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.XeroLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.XeroLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.XeroLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.XeroLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'host': {'key': 'typeProperties.host', 'type': 'XeroLinkedServiceTypePropertiesHost'},
        'consumer_key': {'key': 'typeProperties.consumerKey', 'type': 'SecretBase'},
        'private_key': {'key': 'typeProperties.privateKey', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'XeroLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'XeroLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'XeroLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'XeroLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "XeroLinkedServiceTypePropertiesHost",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        consumer_key: Optional["SecretBase"] = None,
        private_key: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["XeroLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["XeroLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["XeroLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["XeroLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(XeroLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Xero'
        self.host = host
        self.consumer_key = consumer_key
        self.private_key = private_key
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class XeroLinkedServiceTypeProperties(msrest.serialization.Model):
    """Xero Service linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param host: Required. The endpoint of the Xero server. (i.e. api.xero.com).
    :type host: ~data_factory_management_client.models.XeroLinkedServiceTypePropertiesHost
    :param consumer_key: The base definition of a secret type.
    :type consumer_key: ~data_factory_management_client.models.SecretBase
    :param private_key: The base definition of a secret type.
    :type private_key: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.XeroLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.XeroLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.XeroLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.XeroLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'host': {'required': True},
    }

    _attribute_map = {
        'host': {'key': 'host', 'type': 'XeroLinkedServiceTypePropertiesHost'},
        'consumer_key': {'key': 'consumerKey', 'type': 'SecretBase'},
        'private_key': {'key': 'privateKey', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'XeroLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'XeroLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'XeroLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'XeroLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        host: "XeroLinkedServiceTypePropertiesHost",
        consumer_key: Optional["SecretBase"] = None,
        private_key: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["XeroLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["XeroLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["XeroLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["XeroLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(XeroLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.host = host
        self.consumer_key = consumer_key
        self.private_key = private_key
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class XeroLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(XeroLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class XeroLinkedServiceTypePropertiesHost(msrest.serialization.Model):
    """The endpoint of the Xero server. (i.e. api.xero.com).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(XeroLinkedServiceTypePropertiesHost, self).__init__(**kwargs)


class XeroLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(XeroLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class XeroLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(XeroLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class XeroLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(XeroLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class XeroObjectDataset(Dataset):
    """Xero Service dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(XeroObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'XeroObject'
        self.table_name = table_name


class XeroSource(TabularSource):
    """A copy activity Xero Service source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.XeroSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'XeroSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["XeroSourceQuery"] = None,
        **kwargs
    ):
        super(XeroSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'XeroSource'
        self.query = query


class XeroSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(XeroSourceQuery, self).__init__(**kwargs)


class ZohoLinkedService(LinkedService):
    """Zoho server linked service.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of linked service.Constant filled by server.
    :type type: str
    :param connect_via: Integration runtime reference type.
    :type connect_via: ~data_factory_management_client.models.IntegrationRuntimeReference
    :param description: Linked service description.
    :type description: str
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the linked service.
    :type annotations: list[~data_factory_management_client.models.LinkedServiceAnnotationsItem]
    :param endpoint: Required. The endpoint of the Zoho server. (i.e. crm.zoho.com/crm/private).
    :type endpoint: ~data_factory_management_client.models.ZohoLinkedServiceTypePropertiesEndpoint
    :param access_token: The base definition of a secret type.
    :type access_token: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.ZohoLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.ZohoLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.ZohoLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.ZohoLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'type': {'required': True},
        'endpoint': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[LinkedServiceAnnotationsItem]'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'ZohoLinkedServiceTypePropertiesEndpoint'},
        'access_token': {'key': 'typeProperties.accessToken', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'ZohoLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'ZohoLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'ZohoLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'ZohoLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        endpoint: "ZohoLinkedServiceTypePropertiesEndpoint",
        additional_properties: Optional[Dict[str, object]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["LinkedServiceAnnotationsItem"]] = None,
        access_token: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["ZohoLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["ZohoLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["ZohoLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["ZohoLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(ZohoLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Zoho'
        self.endpoint = endpoint
        self.access_token = access_token
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class ZohoLinkedServiceTypeProperties(msrest.serialization.Model):
    """Zoho server linked service properties.

    All required parameters must be populated in order to send to Azure.

    :param endpoint: Required. The endpoint of the Zoho server. (i.e. crm.zoho.com/crm/private).
    :type endpoint: ~data_factory_management_client.models.ZohoLinkedServiceTypePropertiesEndpoint
    :param access_token: The base definition of a secret type.
    :type access_token: ~data_factory_management_client.models.SecretBase
    :param use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :type use_encrypted_endpoints:
     ~data_factory_management_client.models.ZohoLinkedServiceTypePropertiesUseEncryptedEndpoints
    :param use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :type use_host_verification:
     ~data_factory_management_client.models.ZohoLinkedServiceTypePropertiesUseHostVerification
    :param use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :type use_peer_verification:
     ~data_factory_management_client.models.ZohoLinkedServiceTypePropertiesUsePeerVerification
    :param encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :type encrypted_credential:
     ~data_factory_management_client.models.ZohoLinkedServiceTypePropertiesEncryptedCredential
    """

    _validation = {
        'endpoint': {'required': True},
    }

    _attribute_map = {
        'endpoint': {'key': 'endpoint', 'type': 'ZohoLinkedServiceTypePropertiesEndpoint'},
        'access_token': {'key': 'accessToken', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'useEncryptedEndpoints', 'type': 'ZohoLinkedServiceTypePropertiesUseEncryptedEndpoints'},
        'use_host_verification': {'key': 'useHostVerification', 'type': 'ZohoLinkedServiceTypePropertiesUseHostVerification'},
        'use_peer_verification': {'key': 'usePeerVerification', 'type': 'ZohoLinkedServiceTypePropertiesUsePeerVerification'},
        'encrypted_credential': {'key': 'encryptedCredential', 'type': 'ZohoLinkedServiceTypePropertiesEncryptedCredential'},
    }

    def __init__(
        self,
        *,
        endpoint: "ZohoLinkedServiceTypePropertiesEndpoint",
        access_token: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional["ZohoLinkedServiceTypePropertiesUseEncryptedEndpoints"] = None,
        use_host_verification: Optional["ZohoLinkedServiceTypePropertiesUseHostVerification"] = None,
        use_peer_verification: Optional["ZohoLinkedServiceTypePropertiesUsePeerVerification"] = None,
        encrypted_credential: Optional["ZohoLinkedServiceTypePropertiesEncryptedCredential"] = None,
        **kwargs
    ):
        super(ZohoLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.endpoint = endpoint
        self.access_token = access_token
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class ZohoLinkedServiceTypePropertiesEncryptedCredential(msrest.serialization.Model):
    """The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ZohoLinkedServiceTypePropertiesEncryptedCredential, self).__init__(**kwargs)


class ZohoLinkedServiceTypePropertiesEndpoint(msrest.serialization.Model):
    """The endpoint of the Zoho server. (i.e. crm.zoho.com/crm/private).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ZohoLinkedServiceTypePropertiesEndpoint, self).__init__(**kwargs)


class ZohoLinkedServiceTypePropertiesUseEncryptedEndpoints(msrest.serialization.Model):
    """Specifies whether the data source endpoints are encrypted using HTTPS. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ZohoLinkedServiceTypePropertiesUseEncryptedEndpoints, self).__init__(**kwargs)


class ZohoLinkedServiceTypePropertiesUseHostVerification(msrest.serialization.Model):
    """Specifies whether to require the host name in the server's certificate to match the host name of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ZohoLinkedServiceTypePropertiesUseHostVerification, self).__init__(**kwargs)


class ZohoLinkedServiceTypePropertiesUsePeerVerification(msrest.serialization.Model):
    """Specifies whether to verify the identity of the server when connecting over SSL. The default value is true.

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ZohoLinkedServiceTypePropertiesUsePeerVerification, self).__init__(**kwargs)


class ZohoObjectDataset(Dataset):
    """Zoho server dataset.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Type of dataset.Constant filled by server.
    :type type: str
    :param description: Dataset description.
    :type description: str
    :param structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :type structure: ~data_factory_management_client.models.DatasetStructure
    :param schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :type schema: ~data_factory_management_client.models.DatasetSchema
    :param linked_service_name: Required. Linked service reference type.
    :type linked_service_name: ~data_factory_management_client.models.LinkedServiceReference
    :param parameters: Definition of all parameters for an entity.
    :type parameters: dict[str, ~data_factory_management_client.models.ParameterSpecification]
    :param annotations: List of tags that can be used for describing the Dataset.
    :type annotations: list[~data_factory_management_client.models.DatasetAnnotationsItem]
    :param folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :type folder: ~data_factory_management_client.models.DatasetFolder
    :param table_name: The table name. Type: string (or Expression with resultType string).
    :type table_name: ~data_factory_management_client.models.GenericDatasetTypePropertiesTableName
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'DatasetStructure'},
        'schema': {'key': 'schema', 'type': 'DatasetSchema'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[DatasetAnnotationsItem]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'GenericDatasetTypePropertiesTableName'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, object]] = None,
        description: Optional[str] = None,
        structure: Optional["DatasetStructure"] = None,
        schema: Optional["DatasetSchema"] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List["DatasetAnnotationsItem"]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional["GenericDatasetTypePropertiesTableName"] = None,
        **kwargs
    ):
        super(ZohoObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'ZohoObject'
        self.table_name = table_name


class ZohoSource(TabularSource):
    """A copy activity Zoho server source.

    All required parameters must be populated in order to send to Azure.

    :param additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :type additional_properties: dict[str, object]
    :param type: Required. Copy source type.Constant filled by server.
    :type type: str
    :param source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :type source_retry_count: ~data_factory_management_client.models.CopySourceSourceRetryCount
    :param source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type source_retry_wait: ~data_factory_management_client.models.CopySourceSourceRetryWait
    :param max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :type max_concurrent_connections:
     ~data_factory_management_client.models.CopySourceMaxConcurrentConnections
    :param query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :type query_timeout: ~data_factory_management_client.models.TabularSourceQueryTimeout
    :param additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects (or Expression with resultType array of objects).
    :type additional_columns: list[~data_factory_management_client.models.AdditionalColumns]
    :param query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :type query: ~data_factory_management_client.models.ZohoSourceQuery
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'CopySourceSourceRetryCount'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'CopySourceSourceRetryWait'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'CopySourceMaxConcurrentConnections'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'TabularSourceQueryTimeout'},
        'additional_columns': {'key': 'additionalColumns', 'type': '[AdditionalColumns]'},
        'query': {'key': 'query', 'type': 'ZohoSourceQuery'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, object]] = None,
        source_retry_count: Optional["CopySourceSourceRetryCount"] = None,
        source_retry_wait: Optional["CopySourceSourceRetryWait"] = None,
        max_concurrent_connections: Optional["CopySourceMaxConcurrentConnections"] = None,
        query_timeout: Optional["TabularSourceQueryTimeout"] = None,
        additional_columns: Optional[List["AdditionalColumns"]] = None,
        query: Optional["ZohoSourceQuery"] = None,
        **kwargs
    ):
        super(ZohoSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'ZohoSource'
        self.query = query


class ZohoSourceQuery(msrest.serialization.Model):
    """A query to retrieve data from source. Type: string (or Expression with resultType string).

    """

    _attribute_map = {
    }

    def __init__(
        self,
        **kwargs
    ):
        super(ZohoSourceQuery, self).__init__(**kwargs)
